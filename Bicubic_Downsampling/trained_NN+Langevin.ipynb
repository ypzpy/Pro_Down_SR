{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS']='2'\n",
    "os.environ['LD_LIBRARY_PATH']=''\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pz281@ad.eng.cam.ac.uk/mnt/PhD/Pro_Down_SR\n"
     ]
    }
   ],
   "source": [
    "%cd /home/pz281@ad.eng.cam.ac.uk/mnt/PhD/Pro_Down_SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pz281@ad.eng.cam.ac.uk/anaconda3/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data_generation import *\n",
    "from scipy.linalg import sqrtm\n",
    "from downscaling import *\n",
    "from utils import *\n",
    "import random\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pz281@ad.eng.cam.ac.uk/mnt/PhD/Pro_Down_SR/Bicubic_Downsampling\n"
     ]
    }
   ],
   "source": [
    "%cd Bicubic_Downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Downscaling Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Training $u_l=G(u_h)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code downscaling matrix\n",
    "N_low = 30\n",
    "N_high = 120\n",
    "scale = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory already exists\n",
      "2024-06-05 10:09:40,279 : Training for 1000 epoches and learning rate is 0.01\n",
      "Epoch: 1 Loss: tensor(55.8895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(348.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(10.9832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(29.1769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(59.0342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(26.6897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(11.9775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(356.6868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(6.6373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(101.4400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(14.5000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(10.3257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(14.2910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(6.8778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(5.6684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(5.0443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(4.2773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(5.8763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(52.7974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(4.6379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(5.2279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(24.6964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(2.1913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(265.4648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(7.9456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(11.5841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(17.8677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(6.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(10.3942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(2.6478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(4.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(2.7519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(4.5700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(2.8551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(2.7742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(1.9940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(2.8618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(33.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(9.5889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(96.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(9.2905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(4.4749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(3.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(11.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(3.2110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(9.4711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(4.6880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(39.0589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(82.7603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(13.2929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(69.3928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(3.7644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(3.5398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(5.3932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(1.8261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(2.0323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(1.6000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(1.6542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(7.0167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(1.8963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(1.5245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(9.1974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(1.9672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(1.0706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(1.3009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(1.1392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(1.8658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.9853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(1.9713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(4.5900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(1.5548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(1.7775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(4.7379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(6.2361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(3.5905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(1.3654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(1.6678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(1.6225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(3.6309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.8665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.7787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(1.3636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(1.5983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(1.6070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(1.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(2.8397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(1.0305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.8717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.9974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(2.3261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(2.4393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(1.7002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(1.0485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.7456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.9572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(1.7317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(1.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.7203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(5.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(7.4939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(1.2945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.8052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.8707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(1.3229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(1.5817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.8837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(1.8906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.5616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.6062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.8810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.9197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.9949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.6067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(2.2830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(1.9419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(2.0055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.7188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(1.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.7691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.5358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.9018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.7179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.8375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.9168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.6634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(1.0305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.8873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.5130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.6210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.6826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.9127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.9791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.5604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.6438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(2.0103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(1.5876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(1.4204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.5328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.6616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.5619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.6346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(1.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.9853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(1.0553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.8179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.7226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.6944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.5256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.6555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.6447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.5783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(1.7211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.9853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(2.2326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.8431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.7167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(2.7232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.5548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.8532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.7879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.7229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.6957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.4883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.3970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.7550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(1.3774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(1.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.5937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.6928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.6199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.8904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.3482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.6794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.6804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(1.6785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(1.0942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(4.5207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(1.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(14.3541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(18.9973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.3796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(2.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(4.9465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(2.8567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.6774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(1.2761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.8581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.8088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(1.2579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.6095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.6856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.6099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.2539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(1.4084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.7877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(1.0592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.8655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(2.6051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.4337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(2.6603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.6973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(1.4994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.4157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(1.8076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.7207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.8156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.6064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(1.6019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(1.1987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.5684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.6235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.5701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.4157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.7474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.6196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.8072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(1.4064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.6830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(1.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.5608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.4959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.3880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(1.1858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(1.0519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(1.0340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.3033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.4312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.4112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.4494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.7597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.4896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(1.3034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.4849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.3472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.9297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.6073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.6510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.7342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.5728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.5940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.3362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.5802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.5376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.5256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.6916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.2991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.5513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.8326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(1.3027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(1.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.4856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.4764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(1.3366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.4317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.4690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.3380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(2.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(1.2521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.9168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.7780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(1.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(1.9633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.8115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(22.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(5.7484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(11.4564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(4.6494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(30.6832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(4.4916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.8021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(1.3211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(1.3597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(1.6913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(1.5935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.9885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.6572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.3650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(11.7625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(1.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(8.6154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(4.4292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(2.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(1.8067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(3.2714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(4.1846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(2.8058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(19.7168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(11.4555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(92.8792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(101.5995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(42.9841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(17.5055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(24.6863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(19.8574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(3.5569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(11.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(2.1663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(5.4214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(3.4224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(3.3565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(11.4361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(6.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(9.9617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(3.6193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.9970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.4968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.3545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.9510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.6697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.5654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(28.6225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(3.0307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(65.0430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(18.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(68.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(40.4947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(19.6221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(5.7457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(17.9166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(76.7233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(18.4186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(61.2543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(1.3734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(12.6941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(2.0548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(1.6620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(2.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(2.5666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(102.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(53.2600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(23.3779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(3.6535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.6764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(16.3555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(14.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(103.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(8.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(5.5057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(7.5610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(31.3901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(21.9164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(84.8373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(407.3349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(10.5769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(6.5528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(3.2997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(2.5094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(53.7804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(10.0519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(11.5136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(3.3933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(6.4408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(40.8506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(5.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(13.4596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(15.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(11.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(4.9462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(5.8416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(2.7026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(2.9077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(18.9348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(950.1788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(19.4016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(2.6130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(36.7991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(7.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(4.0348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(35.7383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(17.7021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(20.1697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(10.5916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(61.4323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(9.7101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(53.5327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(17.8778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(7.5487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(68.2211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(42.5304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(176.8365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(204.3445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(13.5038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(23.4939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(28.4607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(16.1427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(18.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(6.9330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(84.3988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(11.5017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(8.4417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(5.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(7.9721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(2.3384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(173.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(10.8805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(15.4039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(38.4487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(10.2579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(17.5946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(13.9678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(2.8864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(105.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(7.8590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(37.7873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(9.4750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(48.9310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(455.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(14.7799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(10.6097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(18.3622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(13.7653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(22.4583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(13.5723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(22.8703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(4.0881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(20.8679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(75.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(6.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(8.6106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(25.4495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(130.4964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(8.9562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(43.9499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(2.7552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(422.5264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(22.0615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(12.2925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(9.3297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(8.4268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(5.3734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(4.0567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(44.4915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(15.3311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(12.2485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(7.8619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(9.9631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(19.7946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(17.5705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(7.8459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(13.3666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(11.2530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(4.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(35.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(407.8098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(96.6815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(2.2846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(14.7262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(2.5012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(3.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(10.2959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(2.3298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(9.8807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(7.2425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(31.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(3.1181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(2.2143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(386.7556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(89.8339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(5.3108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(2.7217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(2.5940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(7.8585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(37.7068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(2.9927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(9.5010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(4.3546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(9.3810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(34.2691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(33.6807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(13.5239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(370.8532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(4.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(4.0381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(78.7214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(9.7930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(2.7953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(2.6880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(2.8622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(2.5533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(25.5985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(7.0373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(4.4038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(11.9843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(5.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(26.4900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(6.9907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(11.6435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(7.8597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(2.2653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(4.7695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(355.1072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(1.8251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(3.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(73.6874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(2.7290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(3.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(2.8378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(77.7863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(24.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(13.8659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(348.8955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(14.2878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(6.5942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(2.7122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(2.3463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(21.5695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(4.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(5.4235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(8.8014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(4.6839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(8.4655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(3.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(4.9523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(2.6023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(23.7795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(11.9589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(25.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(9.7348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(2.9492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(2.4191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(2.0495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(5.7359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(68.3944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(7.6417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(2.6707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(3.5842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(336.9016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(5.9794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(6.0771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(7.4738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(10.5265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(32.3683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(13.9286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(22.1711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(20.7645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(68.7191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(9.1659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(3.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(332.3969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(3.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(2.8151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(2.6480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(3.2807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(2.6967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(6.7124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(2.5317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(5.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(2.6457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(19.7581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(6.3296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(325.4476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(19.6291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(3.3383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(3.0319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(4.4533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(3.5060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(5.0272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(60.5079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(2.8765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(3.9357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(2.6509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(4.7781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(5.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(2.4994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(2.6025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(2.3523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(18.8018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(77.3388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(8.0632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(17.4208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(6.7063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(315.2504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(2.2511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(2.7195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(9.0484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(2.9201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(3.5696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(2.9115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(2.9233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(24.5845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(44.0260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(328.7108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(31.5411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(3.1830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(27.7401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(101.6852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(35.3506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(17.6213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(5.8836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(5.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(5.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(3.9572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(4.5355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(2.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(2.0364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(5.6782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(2.3789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(2.1833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(314.8345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(17.8374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(4.2156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(19.1441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(6.8747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(2.7063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(2.6677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(2.6124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(56.6071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(3.7313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(2.7268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(2.4498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(4.7196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(2.2599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(3.8609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(2.0747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(4.9290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(55.1254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(1.9012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(304.6753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(16.6796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(4.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(3.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(15.7423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(2.0879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(2.5257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(3.8764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.9831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(51.7799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(15.4730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(297.0080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(2.8102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.9219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(3.2543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(2.7391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(14.9994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(4.4479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(3.2542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(2.0180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.9967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(2.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(1.9869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(2.2804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(2.3409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(4.8342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(14.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(4.6647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(4.1607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(3.7469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(15.4204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(51.4426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(3.1898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(289.2309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(2.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(1.7357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(2.7898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(2.3520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(2.2673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(2.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(284.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(14.6765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(7.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(10.5320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(22.2645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(51.0080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(5.4540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(3.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(13.3775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(2.9436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(5.3525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(3.8526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(5.8207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(6.2458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(49.8170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(3.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(2.7495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(2.2873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(13.5292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(277.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(3.6797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(1.4289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(1.3632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(1.4212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(1.5530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(1.3241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(2.0989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(11.8632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(2.3419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(4.4866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(277.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(4.4788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(6.4373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(8.4054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(20.3499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(14.5016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(27.0217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(48.4256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(14.7392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(14.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(9.6187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(13.4378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(23.7216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(6.2044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(2.6152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(1.0612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.4044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.4755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.3785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.4588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(2.3674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(2.6967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.7250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(11.6411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.0780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(2.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(10.9616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(41.0527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.9535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(266.7770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(1.0312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(2.0588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(1.4804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(1.1478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(1.5305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(50.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(5.5347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(266.8883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(12.5306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(9.6394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(18.4053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(11.3107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(17.9626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(6.9904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(14.6341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(5.8066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(7.4175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(3.7053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(2.5409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(2.1888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(38.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(11.4232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(12.0415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(6.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(10.5743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(5.3233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(4.4657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(2.3102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(259.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(2.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(2.2369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(2.5538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(3.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(3.8813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(4.3884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(4.7957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(7.1848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(4.6571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(5.2796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(13.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(8.6275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(5.7965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(4.9142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(2.3177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(37.4380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(262.3134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(1.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(1.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.9875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(1.4748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(9.6642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(2.1580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(3.9756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(35.9025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(2.9456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(3.4388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(4.9989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(5.2281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(15.5967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(255.8018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(15.1794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(8.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(10.4195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(6.4044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(7.7003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(4.2195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(3.9751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(12.4433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(252.7798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(35.5991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(2.7262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(1.8294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(1.8552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(1.9384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(2.5338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(3.4910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(5.0844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(7.2108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(23.6223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(34.7058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(105.8514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(250.2398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(2.7246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(6.4491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(33.8500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.0388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.7914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.3649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.4321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.7266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(8.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.0095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.9703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.7875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.9672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.8613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.5574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.7725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(269.0430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.8688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.7358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.0655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.9592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.3161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.4446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(15.7609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(13.9207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(13.5202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(23.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(25.3665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(60.6420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(18.6609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(244.0540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(1.8482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(2.3966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(3.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(1.3050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(28.9115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.8059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.6753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.7653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.8726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.5212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(1.0224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.4569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.5935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.7494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.7943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.8382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.8155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.7963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.4810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.0387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.9757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.5788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.4898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.5643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(35.1847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(229.5818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(7.4724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(1.8877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(1.8584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(2.4313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(3.3848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(30.7557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(213.9761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(3.3083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(4.5714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(7.9800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(11.3914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(33.9964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(70.9539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(207.4474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(73.8114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(105.6804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(121.0429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(49.6269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(51.3268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(15.7112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(5.8495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(4.5687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.9872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(1.7230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.7395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(1.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(9.8073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(1.2457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(271.6318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.4955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(1.3114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.8337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.8825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.8708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(188.6263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.4996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(11.1915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(4.3169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.8011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.0336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.2306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(2.8794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(2.2087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(2.8095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.8701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.2046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(2.8274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(2.3708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.0223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.3565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(1.0427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.9551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(1.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(62.6865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(5.6724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(14.1111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(17.5388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(27.3241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(10.0669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(13.3366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(228.9530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(400.8651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(390.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(328.4698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(295.6488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(160.4683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(415.9254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(39.1942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(1.8575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(7.5655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(73.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(14.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(20.6311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(13.9608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(6.9896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(58.5684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(5.2865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(6.3376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(1.7388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(4.3397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(2.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.0687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.7632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(54.4381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.2523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.7771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(2.6453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.0213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.2402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.5782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(13.9117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(4.5360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(2.0139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(12.7249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(238.4720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.8387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(10.3919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(19.2070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(2.7473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(2.6177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(1.0430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.5557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.8783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.7517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(7.2413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.7284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.7264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(1.4376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.7316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.4528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(111.9957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(10.7953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(8.6626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(45.0669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(6.4609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(2.7756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.8565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(1.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.5195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(2.1906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(1.0189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.8343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(3.3084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(1.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.9753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(1.6875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.4219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(3.8007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.7603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.8229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.8949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.9699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(1.0090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(34.6079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(6.5207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(1.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.8709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(4.8440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(2.4374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(6.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(88.8734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(47.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(1.5008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(3.9881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(5.6251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.8340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(8.4622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(72.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(5.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(22.2211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(315.8823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(2.0484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(1.8267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(1.7761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.3826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.4110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.4668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(13.4413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.9634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.8976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(41.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.8635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.5027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.4408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.8622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(1.4529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.5501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(193.4912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(3.4702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(9.3348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(17.3521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(16.5419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(3.8150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(1.2628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(1.3775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.8142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(1.0195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.4651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.9035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(3.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.5978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(2.6897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.8197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.9357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.5684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.7348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.6439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(32.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(10.4384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(222.4207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(49.6220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(68.8100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(25.5290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(3.1879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(6.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(8.7249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(1.6890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(7.4970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(3.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(5.3422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(23.5445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.6624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.7259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(323.9440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(6.8544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(1.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(61.0242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(17.7503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.3610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(3.0956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.8283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(4.3543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.7867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.8824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.4883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(5.3632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.6785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.6218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.6102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(71.7955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(307.8110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(4.9367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.6127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(18.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(14.8650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(1.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(4.7704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(2.8478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(51.7020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.5362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(14.2742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.7032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(3.5031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.7800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(292.3318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(1.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.6673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.5444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(1.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(1.4903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(2.2420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.9972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(13.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.4721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.0401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(12.8979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.5405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.4488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.4297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.1940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.6509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(3.0452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.4536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.4950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(278.0431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(44.0570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(1.6022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(41.6895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(1.3656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.3668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(245.7638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(2.3735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.5607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(2.2896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(1.2562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.6230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(8.3825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.8743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.4920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(1.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.7884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(7.1927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(7.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.4506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.5867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.7611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.4106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(155.1949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(7.9123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(1.2086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(6.6794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(4.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(2.2291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(2.2308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(1.8286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(1.0351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.8001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.4551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.8340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.8382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.7841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.4106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.6055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.4922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.5044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.4621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.5241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.1787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(19.7363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(11.0951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(28.1846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(12.2932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(19.0612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(26.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(17.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(16.0422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(9.9543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(2.4623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(2.7168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.2036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(3.2659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.7818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.4259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.9703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.0368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.8021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(11.1651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(6.0514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(2.5350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(1.5805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(21.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(2.1634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(1.6328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(2.7126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(1.1837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.7670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.6197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.5290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.5579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.5601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(1.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.3905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.9969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.8346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(4.5469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(16.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(26.8762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(22.7381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(11.5872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(4.6778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(4.1753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(13.4882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(1.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(1.0087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.6814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.4442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(1.7334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.8585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.3818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(3.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(8.7338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(5.9725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(1.1770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(2.2508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(1.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(1.2540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(1.4575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(1.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(12.3502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.8275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.5168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(2.3408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.3765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.8160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.6876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.5780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.6435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.6075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.3492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(1.7348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.8238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(26.8765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(20.4096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(7.4649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(15.0628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.4475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(2.0110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(1.8570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.9186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.6402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(13.3935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(4.2302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.5122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(1.3783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.5278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.6820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.5489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(1.1922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.6296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.5484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.9517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.3734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.2647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.9777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.8307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.4323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.5986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.5627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.3857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.6618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.3724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.3793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.5112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.4198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(3.5128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(1.3292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(1.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.8872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(5.6150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(1.2796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.7848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(1.2001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(1.2653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.6665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.5724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.5734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(1.3963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.3110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.5328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.4546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.5642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(1.7854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(1.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.5390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(1.4027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.5763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.4358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.8286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(1.3734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.5681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.5789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.5743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.7120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.9208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.6063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.6690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.4268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(1.1965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.5187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.4249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(1.2545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.6437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.5635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.5126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(2.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(1.3761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.8187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(1.0730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.3751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.4083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(1.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.6956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.6644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.5725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.4477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.7206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.4760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.3877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.6770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.3991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.4881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.3685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.5199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.3745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.4331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.8946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(1.9207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(2.0253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.8222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.8603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(2.0303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(1.3349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.6796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.8926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.2679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(1.5409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.5402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.6104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.3735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(1.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.6665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.6131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.7341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.3675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.6051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.6326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.8184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.5119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.6687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.5710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.4226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.4552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.4642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.4362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.9961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.7447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.3191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.9056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(1.3957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.4814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(1.2471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.9768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.3653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.4555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.4342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.4728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.5594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.6241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.6383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(1.4360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.3461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.5151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.7108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.3278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(1.0806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.8588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.7749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.7224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.5763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.6170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.6420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.8173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.4229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.8688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.5635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.5010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.6203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.8868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.4837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.4905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(1.0218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.5760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.6689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.7443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.3441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.3034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.3726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.4802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.4267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.7725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.5372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.4354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.8013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(1.6779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.5425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.4963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.6623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.6477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.7424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.3332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.4071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.5070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.0741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.4478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.2654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.5601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.5564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.4452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.6783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.5262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.4707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.6065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.5150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.6568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.3822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.5615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.6497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.5845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.4478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(1.1996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.5585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.7485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.4632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.6704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.8663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.4601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.3225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(1.0094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.7050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.4808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.6694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.3691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.5982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.3496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.9055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.9187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.7818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.5444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.8340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.4781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.8482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.3871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.4267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.6692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.6773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.3471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(1.1978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.5849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.8342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.6698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.5581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.5804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.6187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.3379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.3692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.3516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(1.2533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.6825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.3942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.5574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.2414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.4299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.4765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.4393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(1.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.9277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.7643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.5862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(1.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.6075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.5054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.6255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.4511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.3064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.5628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.5821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.8398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.5971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.6110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.9320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.8859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.5862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.3153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.6514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(1.0120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.3781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.5231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.4604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.3228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.4259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(1.6331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.6826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.3225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.5460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.4332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(1.2380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(1.2060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.6213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.5272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.3703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.3444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.7469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.5114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.5071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.4388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.3887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.6637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(1.8815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(1.5618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.4296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(1.9215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.9910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.4573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.5010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.4539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.3194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.2659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.3638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.7167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(1.4395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.4311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(1.0532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.8792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.5099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.4095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.5377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.5280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.3392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.3376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.6761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(2.4894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(1.9945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(3.2463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(2.2313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.6466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.5451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.6297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.5610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.3548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.4098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(1.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.4147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.4698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.8519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.8935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.6727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.2881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.7624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.4636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.5036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.6092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.6665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.2726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.5510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.3872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(1.1459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.2693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.4087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(1.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.9315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.4484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.2893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.5994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.4230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.5134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.7483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.4183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.5290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.5220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.3207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.3301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.5774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.5029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.3671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.4292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.5805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(1.3936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.4956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.4661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.2384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.9488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.3805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.3547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.2717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.3477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(1.4732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.5404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.5187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.5065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.8770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.7341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.3086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.5109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.8288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.4577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.3512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.9114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.5193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.7528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.3992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.6286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.4484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.6074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(1.0822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.9053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.4012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.8110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.3098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.3285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.2654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.2736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.5317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.5171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.4338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.6276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.3185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.3289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.3956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.4467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(1.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.5325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.6559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.6865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.3863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.7742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.4300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.4815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.7807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.3139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.2667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.8381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.4837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.3382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.9756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.3315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.6323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.6799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.4440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.4267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.4218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.8583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.5505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.4859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.3018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.7238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.3754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.3481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.2980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(1.4652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.5420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.3026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.7631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.2877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.4858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.2786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.6913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.8755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.5973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.5495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.7078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.3185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.7741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.3129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.7195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.4347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.5242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.2169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.9093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.5353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.3302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.4535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.4926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.3726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(1.0077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.4814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.3800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.4976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.3928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.7058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.5744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.6065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.7507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.4959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.9447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.3285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.3383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.4016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.4353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.7059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.6842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.4260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.4400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.9274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(1.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.3833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.4231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.4876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.3655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(1.3390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.5363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.2923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.4321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.3690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.5234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.3742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.4829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.4297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.9058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.4444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.7430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.3159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(1.0798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.4300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.3307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.7351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.5811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.7086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.3073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.4551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.2450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.3344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.4115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.5159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.4266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.8277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.5232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.5271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.4590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.3586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.5209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.4456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.2659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(1.4803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.6978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.4446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.4748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.5520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(1.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.2946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.4580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.2059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.4144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.6817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.7208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.4130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.4824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.6697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.2875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.5732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.4706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.5337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.5158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(1.0370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.3182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.4088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.4211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.8160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.4949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.7497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(1.1995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.4109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.3377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.2761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.5001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.4742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.3641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(1.4780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.7214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.3640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.2976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.2371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.3024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.6128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.5408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.5541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(1.0192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.3548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.3711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.4761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.3207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.6276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.5044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.6360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.2737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.2705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.9684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.5531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.7300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.7029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.3464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.6885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.4756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.8213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.2933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.2807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.5776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.3597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.4121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.9184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.2749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.4295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.4015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.7597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.5240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.5336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.8081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.3384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.5845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.8557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.4237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.2391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.3880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.5889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.3573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.9725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.5670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.4124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.3909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.8574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.3647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.3335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.9080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.6996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.3414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.2675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.8576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.3038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.5024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.4838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.4033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.4771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.3227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.4687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.4482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(1.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.3921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.4563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.3208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.5169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.5235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.8250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.4931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.2780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.2289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.7547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.5586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.7974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.4513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.6353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.2399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.3762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.5103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.5373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.3876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.4358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.4772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(1.0203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.8594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.4388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.3463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(1.1617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.3062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.6092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.3847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.8024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.3373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.3118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.3901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.4119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.4025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.9837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.8405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.6556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.7192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.4759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.5173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.3912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(1.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.2881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.5408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.2632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.4402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.3961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.3289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.4847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.6949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(1.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.7110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.4750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.3889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.5212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.3229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.2845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.4546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.7162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.6444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.3614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.3892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.6800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.7339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.4547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.9528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.2838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.6119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.4346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.7771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.3219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.3096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.5342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.5207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.3612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.6081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.9906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.3962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.9568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.4315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.5317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.3685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.3330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.4949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.6758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.4387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.3697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.4437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.2174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.3768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(1.0233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.4873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.3770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.1996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.2811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.9831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.4876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.5637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(1.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.3446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(1.0047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(1.5487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.3622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(1.0171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.4422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.4484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.3965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.7019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.2906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.2761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.3351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.4286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.3434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.3509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.4790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.3404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.5773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.2490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.4217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.3672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.3622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(1.7752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.9101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(1.2991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.7253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.5973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.7139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.4312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.4847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(1.3888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.6939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.4278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.3292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.6287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.6113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.3469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.5427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.4679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.3417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.4271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.3043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.3730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.3972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.5782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.7780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(1.4529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.7033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.4041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.4090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(2.5992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(1.9903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.9703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.6232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(1.0577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.2686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(1.5138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.5634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.5864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.3186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.3657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.2976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.2670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.6100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.3822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(1.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.3828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.3573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.3877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.2720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.3994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.4268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(6.9607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(3.2701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(4.8142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(2.2340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(1.5958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.3756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.7178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(1.0041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.4398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(1.2339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.3594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.4164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.4879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.5754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.3429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.3296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(1.2090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.4952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.5212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.3910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.4043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.3068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.3062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.3236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.2893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.3585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.5748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.3352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.8201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.3069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.6901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.3467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.4673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(1.1587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.4674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.3783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.5506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.5950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.6472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.6722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.3625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.6252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.2896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.2318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.3640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.4361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.4562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(1.2175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.7124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.5849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.3219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.4816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.2227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.5195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.2978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.6806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.4218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.3493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.6161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.9007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.4843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.5226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.6206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.8079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.3439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.2231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.6509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.2778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(1.2280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.5287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.6518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.3352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.2658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.3480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.5279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.4445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.9548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.3186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.7314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.7596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.4567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.3418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.4354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.6615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(1.0989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.7143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.2945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.2936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.5654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.5655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.6228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.3985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.2093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.3292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.2928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.5811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.4212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.7408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.2960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.6430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.3672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.4659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.5492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.2242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.7701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.4263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.9914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.3405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.3660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.3966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.3378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.6648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.3686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.7709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.2402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.5144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(1.0428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.6805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.4983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.6797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.2957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.5810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.2455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.2692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.7539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.3491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.3756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.3207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.3834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.5705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.3057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.2684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.6388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.2826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.5586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.5967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.7531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.3682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.5264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.2104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.7118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.3581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.3782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.9557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.2642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.3109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.4663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.7502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.4755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.3539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.1888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.4231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.8691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.3749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.5887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.4124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(1.5453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.5219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.4427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.8943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.3459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.3199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.3260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.8181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.6150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.9581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.3447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.2720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.4629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.2122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.9813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.3570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.4295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.3279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.3904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.2781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.4379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.5999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.3956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.6055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.4314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.2780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.7619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.5149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.6420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.7207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.8160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.1976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.5007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.5125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.7536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.4137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.8401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.2947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.4031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.8413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.8715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.5657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.3002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.3169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.4023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.3166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.3253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.2966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.3226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.5132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.9403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.5266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.3746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.3843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.5072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.2156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.3432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.9213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.8423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.8764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.4735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.9052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.4451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.4188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.3537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.5168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.4288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.3569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.9466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.7114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.4000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.7267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.4450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.3779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.5418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.4539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.4314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.3566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.2530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.2703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.3710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.2235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.7508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.4104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.6293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.8448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.6272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.9355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.4674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.3141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.6351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.2211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.9374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.3953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.8001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.3808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.4686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.2858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.3790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.9765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.3376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.3809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.4160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.3596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.3596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.7081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(1.5342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.5794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.3021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.6168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.4715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.2201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.4133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.4025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.3237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.2997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(1.5753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.5081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.6704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.3181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.6283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.5433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.7888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.3984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.6809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.3116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.4439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.3052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.5024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.8121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.5216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.3135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.3665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.3826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.4723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(1.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(1.0234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.3252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.7865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.3978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.4132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.4121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.3403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.5141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.3417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.3097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.2205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.3069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.4129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.5754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.2654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.2395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.4259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.4188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.3490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.5945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.3430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.4723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.4837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.4434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.2375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.8473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.5328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.8038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.6183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.5943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(1.4185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.4049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.4386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.6611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.2697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.3193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.3427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.5001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.6692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.3576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.4099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.4968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.2467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.2892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.2202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.4962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(1.5188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.7347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.8221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.2467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.3447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.3721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.2515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.9625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.3711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.3654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.7035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.3830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.4653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.4474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.6744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.6297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.5097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.3270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.6697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.3009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.3751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.6704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(1.0033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.7783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.3545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.7167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.4754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.4701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.3710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.8088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.5980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.5986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.3399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.4550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.5337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.2972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.3201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.6364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.2181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.7579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.3230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.2736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.3380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.9411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.4662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(1.2822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.2089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.7230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.6796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.3137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.3206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.4205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.5642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.3899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.3882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.3364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.2447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.7057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.5816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(1.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.6064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.3655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.1813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.4911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.4794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.3792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.3409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.3129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.5089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.3439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.4702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.7719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.4912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.3822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.4671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.4500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.5596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.3694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.2480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.6285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.4069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.3413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.7106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.5877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.2977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.3891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.3208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(1.5063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(1.5730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.8424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.7274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.2904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.5525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.4831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.3320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(1.2331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.5404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.2383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.4257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.5317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.5424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.4494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.7179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.1911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.5550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.3902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.3378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.5288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.2285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.2408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.4109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(1.4014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.8218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.8846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(1.0112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.3919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.4378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.2883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.5206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.4302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(1.0393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.6427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.3453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.6944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.2878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.5458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.4951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.4301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.7721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.4104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.6405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.3420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.8242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.3486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.3072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.6042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.5225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.4660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.3444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.5602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.3808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.3360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.7400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.4058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.3357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.2080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.3772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.3750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.8070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.3097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.4077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.8708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.8459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.3506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.5807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.3956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.4346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.2680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.3501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.4520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.3343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.4703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.2873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.3284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.3149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(1.7075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(1.3010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.4820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.7434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.4373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(1.1392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.2339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.3273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.6076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.5115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.2689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.6575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.2747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.3292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.8278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.5288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.3211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.4462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.2910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.7104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.3081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.8921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.3797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.5128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.2819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.3406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.2729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.3519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.2109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.4082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(1.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.6478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.4349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.4290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.4833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.2857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.6134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.4143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.6470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.2979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.7621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(1.1788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.3653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.3514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.4827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.2914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.4017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.4910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.3553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.7699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.7358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.5711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.3548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.5792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.3436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(1.0306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.6104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.6140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.3271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.4316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.5946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.2372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.9821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.3103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.4390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.5313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.8364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.5714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.7919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(1.0279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.2192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.3272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.5618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.3979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.3751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.6491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.6733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.3162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.3116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.6411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.3174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.3663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.5835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.2160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.8196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.6433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.3705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.5430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.4036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.7002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.6741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.3326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.4303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.8023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.5007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.2223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.3868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.4356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.9678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.5250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.2768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(1.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(1.2911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.3189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.8465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.4621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.4007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.7189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.2064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.2816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.2236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.2198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.3536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.2659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.3230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.7495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.3611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.4234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.2726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.4743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.4552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.3785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(1.0218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.4607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.7741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.5267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.2329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.4227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.2677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.5779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.3148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.5785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.2366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.2275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.8973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.2430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.6595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.5809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.5130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.5516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.4216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.3878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.3445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.6471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.3126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.9270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.3090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.4588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.5886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.3747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.3041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.1643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.2716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.3459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.7451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.4128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.3627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.2795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(1.2320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.4424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.6157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.5140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.2942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(1.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.9863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.5156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(1.3844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.4545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.4313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.4562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.3894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.5320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.3864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.8785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.5753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.1912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.2975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.3535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.2249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(1.2498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.9103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.6804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(1.4262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.4895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.3656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.3670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.4504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.2937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.4502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.2697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.3004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.2063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.3938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.9526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.4684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.5056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.4918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.2177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.3294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.5046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.3999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.8592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.6236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.8864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.2697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.1707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.3065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.2772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.4727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.3095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.2716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.6848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.2394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.8092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.6094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.3981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.2789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.6760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.7695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.1774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.5399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.4794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.6056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.3046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.3882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.3272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.5555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.3480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.6606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.6520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.7850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.5387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.3318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.3355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.3820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.4155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.3212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.7409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.3130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.2913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.7407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.3236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.9286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.4089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.4172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.2913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.7464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.5462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.5253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.5364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.3447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.2362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.3239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.4153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.3931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.4201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.3914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.8169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.3863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.3731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.3495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.2716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.2927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.1793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.6331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.7756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.3199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.6239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.3804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.4792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.4067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.3007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.5797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.2539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.3212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.4705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.2060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.2861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.7951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.9772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.6697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.2275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.5375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.3339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.5878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.4220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.8602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.3932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.5989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.4116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.1927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.2666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.4228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.3961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.4845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.3170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(1.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.6218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.3099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.3990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(1.9189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.4315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.4855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.5119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.2192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.3916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.4286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.2135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.3230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.4535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.6908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.2823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.3381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.8494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.5700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.5371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.4692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.8639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.3081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.4326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.2231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(1.0349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.8403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.2193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.3181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.2638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.3640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.4845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.3541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.4786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.7021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.3329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.6110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.3163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.6750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.3527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.5434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.6986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.4792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(1.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.3457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.2506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.2186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.3692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.2813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.5367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.5049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.3314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.2197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.2312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.6879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.8023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.3941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.6869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.2193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.3610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.3850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.2280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.3890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.3502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.3818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(1.7588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(2.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.5491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.8400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.8247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.3962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.2198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.3498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.4043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(2.9578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(1.8623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.5536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(1.1691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.6714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.4574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.4528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.5827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.3790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.3389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.2938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.2618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.4771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.6359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.3095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.4073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.2705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.9426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.7018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.9045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.4221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.3680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(1.4107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.3558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.3117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.3921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.6723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.8145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.3727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.4498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.4196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.3087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(1.2809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(1.2460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.2773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.7566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.3432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.3526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.3777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(14.0047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(27.5805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(18.2539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(27.4348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(5.7018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.8721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(2.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(1.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(1.7021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.5356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(1.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(1.3811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(6.8876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(4.2729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(1.7936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.6598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.5574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.3992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.2913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.4532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.3426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.5313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.7592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.8771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.6083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.5133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(1.4036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(1.4738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(1.0794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.6512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.4385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.3676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(1.3193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.4027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.2826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.3808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.3004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.4064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.4568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(1.0788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.2113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.4252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.4642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.5573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.3731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(2.5768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(8.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(5.3304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(1.7072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.9315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.8451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.4594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(1.2355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.1705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.4528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(2.0260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(1.5382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.8090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.7764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.3185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.5325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.5507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.3401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.3799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.4343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.3815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.2407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.7364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.3430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.3714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.3814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.3009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.5872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.3241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.6562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.5007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.3268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.3573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.8568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.6628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.4645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.4808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.2462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.6010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.2454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.4021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.3836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.4311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.6048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.3519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.4081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.2679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.5345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.3682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.4267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.3170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.6511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.2421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.3774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.1754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.2890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.3944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.9311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.5799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.7964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.8114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.3582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.3905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.3414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.3237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.3770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.5635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.8055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.9618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.3558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.2869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.7315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.2512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.3425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.3462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.2854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.4564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.6693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.2637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.2836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.5565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.3380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.3822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.5510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.6117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.2760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.2933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.5796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.7876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.5869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.1819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.5068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.3716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.3517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.4022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.5278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.7726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.9457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.7227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.4641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.3345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.2570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.4560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.3003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.4030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.1840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.2111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.4194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.3234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.3117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.6588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.6582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.4112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.6152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.6602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.2710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.2771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.3758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.3497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.2820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.2698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.2305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.3815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.3720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.5842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.3332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.2007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.3676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.2095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.3275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.7488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.4722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.2065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.4498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.6224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.4739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.6769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.2242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.2552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.2282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.2904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.2236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.8193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.3691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.3550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.5290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.3816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.6482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.3464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.7445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.5874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.6244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.3616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.9447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.5201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.3323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.3242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.3028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.5532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.3743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.3324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.4928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.4309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.2506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.4315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.1904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.3465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.7798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.4308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.3134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.3402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.2746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.5903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.2856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.5089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.8805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.3374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.2143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.8136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.5515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.3729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.2045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.7109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.2865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.1859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.2312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.4155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.3940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.6392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.3694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.5959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.2409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.2540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.3406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.2989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.3692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.6630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.3875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.5574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.7231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.2565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.2048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.1912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.2133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.7834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.2295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.3689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.5664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.6109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.7202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.5979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.4818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.7561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.3916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.3134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.4443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.2785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.3027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.5644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.2651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.5285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.8741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.4463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.3152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.2860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.7777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.3345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.5027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.3323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.3830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(1.0246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(1.1890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.2403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.2836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.2820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.3588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.6711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.4511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.6097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.3128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.4126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.1863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.3209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.6664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.2990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.4138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.3304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.3396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.1871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.2216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(1.2425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.8576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.6378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.6521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.5130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.2416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.6460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.2932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.4846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.3006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.3356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.2431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.8859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.4077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.3043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.3645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.7459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.3061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.6366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.6367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.4812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.3653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.4879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.2740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.3399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.5604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.2386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.3671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.6698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.3911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.1815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.3349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.3242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.6152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.4785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.3342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.3410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.7266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.3176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.3447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.7220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.4263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.4844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.2658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.2782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.3117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.4137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.9817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.4622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.2072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.2772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.2320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.5238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.2313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.3948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.3773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.2921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.4355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.4062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.3431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.4271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.5321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.5287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.3527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.4680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.4288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.6062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.2133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.2213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(1.1864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.3131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.4249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.5540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.3410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.7866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.5137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.7322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.6701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.4642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.3374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.4916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.2038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.2530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.3380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.2374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.3674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.2976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.4286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.1921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.4943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.3787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.3849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.4115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.4910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.3038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.4320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.4007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.9639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.3837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.4863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.3209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.1822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.2892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(1.0678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.3242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.6353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.2111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.3156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.3072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.2515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.4433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.6893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.3757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.4037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.2098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(1.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.4538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.3424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.3421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.4089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.4326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.2738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.2393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.5583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.2249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.3302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.4229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.2708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.1937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.3406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(1.2696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.8085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.4747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.6976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.3525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.2279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.6584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.2190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.5746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.5299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.2955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.5124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.2323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.4766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.4860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.5636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.3468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.5235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.1977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.2024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.6927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.7037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.3454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.2786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.2831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.3626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.2935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.5024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.4375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.2660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.6500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.6331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.5676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.3166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.6993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.2851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.8618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.4320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.3649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.6710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.3993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.6279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.2326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.2235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.4771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.3108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.5781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.9106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.4019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.2295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.3427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.2991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.4203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.3899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.3499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.4433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.4630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.2410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.2835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.2026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.3639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.5625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.3752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.2404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.4653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.9233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.4347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.2872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.3386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.3847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.5490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.3690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.5433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.3821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.6720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.3409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.3584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.3671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.4173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.7316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.3717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.6046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.3478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.5444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.3927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.2819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.2172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.8182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.7184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.2762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.2713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.3070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.3822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.6789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.3985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.2944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.3506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.6262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.5288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.4624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.4606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.3474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.3345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.2019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.3413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.3974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.4650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.5775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.3054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.3463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.7967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.3725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.6260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.2855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.1726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.4408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.2960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.2735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.3503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(1.0570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.6356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.9738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.3227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.2836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.1906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.5048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.2971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.3564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.4030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.4909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.3359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.6709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(1.5283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(1.4631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.3369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.4769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.7433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.5193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.2298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.2815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.4231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.4561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(1.6214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.8370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(1.4147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(1.3261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.8460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.3779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.4427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.2144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.5500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.3057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.3165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.2310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.3309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.3238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.5793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.4120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.3279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.6298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.2304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.4246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.3107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.3641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.2289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.3259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.7813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.4224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.3552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.2855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.2987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.6987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.2273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.1650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.8779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.2455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.6661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(1.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.4498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.7653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.5676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.3688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.2695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.4471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.5324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.4437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.2777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.2420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.3773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.7445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.3047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.4155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.3728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.5995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.6376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.3702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.6967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.9870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.5336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.5424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.6232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.4545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.2760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.2145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.5786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.2832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.3275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.3297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(1.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.7233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.4810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.2332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.5631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.9241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.3673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.1562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(1.0074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.2684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.3802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.3006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.5340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.2567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.5677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.3232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.2404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.4498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.7229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.2506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.4225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.4438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.3566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.2462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.1997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.4905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.3230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.3572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.5057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.3272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.6490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.3056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.5586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.3521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.5622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.6761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.3516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.2952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.4338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.3630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.2615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.3881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.4544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.5194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.3369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.6317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.3459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.5128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.1956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.5109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.4550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.3065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.3342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.1764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.2001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.2359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.2407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.1769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.2269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.6185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.4527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.5984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.8627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.4778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.3222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.4096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.2907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.6319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.4025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.3590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.2244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.4553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.4003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.4162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.4053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.3019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.4744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.4512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.5633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.2168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.9422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.4156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.3202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.4553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.7421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.3912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.4555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.3797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.4494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.3353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.3589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.2150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.1754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.7184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.3321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.4975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.7893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.3805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.2286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.2990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.4728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.2697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(1.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.2164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.6874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.4415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.3583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.1697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.2841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.5338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.3712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.7797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.2995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.5511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.2961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.4886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.2350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.3429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.3731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.4051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.3610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.4496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.3549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.5175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.1792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.3983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.2640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.2539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.1589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.3669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.3607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.3272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.5117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.6362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.1930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.3745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.6434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.3340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.7059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.3673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.2300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.8697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.2352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.5720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.6737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.4513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.4103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.6148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.9638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.1677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.2080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.3422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.4848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.2337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.2955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.5152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.2825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.1833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.1906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.3017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.2282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.3399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.3094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.2101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.6696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.3940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.2920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.2296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.2484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.6973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.3404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.3966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.4914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.4266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.3108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.6411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.3386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.3273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.5358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.3925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.2283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.2589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.1893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.2820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.5785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.1632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.3754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.5991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.3026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.4502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.3645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.3971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.5266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.4547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.1392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.2169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.3186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.2821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.3064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.4672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.8702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.8577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.2811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.3001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.3211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.2201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.3017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.2172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.5196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.3667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.3000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.5750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.7495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.2950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.3575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.2629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.3356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.3306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.2818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.5275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.5212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.3524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.3340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.1874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.2002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.2674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.2942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.1905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.3487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.6946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.2793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.5741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.5183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.4669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.3433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.7154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.4202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.2796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.7429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.3271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.6333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.5367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.3533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.2839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.3242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.5294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.2802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.2670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.4137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.1956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.5578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.3196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.3730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.2483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.5690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.8187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.5487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.3142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.2139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.3037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.3147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.5168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.4203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.3040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.5096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.4702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.6115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.3428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.3497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.2748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.3269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.6236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.4556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.2151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.4786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.4861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.2871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.5352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.2088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.2732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.3835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.2348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.6811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.4301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.5833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.2154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.3681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.5198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.2356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.3878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.4830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.3037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.4328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.5912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.2933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.2058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.5216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.3278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.2279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.4844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.2808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.3608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.6035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.4243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.4060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.3713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.3428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.2434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.9659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.4051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.5894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.2285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.2361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.2321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.3068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(1.3318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(1.8410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.8727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.8341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.3095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.5899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.3937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(1.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.5732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.3206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.3132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.7686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.3329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.3609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.8926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.4001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.1739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.3711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.2729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(1.6206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(1.6952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.2218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.4388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.4254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(1.3337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(1.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(1.4778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.2753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.6670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.4443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.5054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.3547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.4280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.2750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.2202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.5540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.4286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.5005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.2023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.6566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.2773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.2551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.6284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.5480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.3467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.2159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.7658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.4391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.2758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.7281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.8263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.5264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.2792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.3467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.4586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.2410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.3193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.6496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.7644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.2189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.2072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.3754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.4024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(1.2410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.9133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(2.5642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(4.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(1.0489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.3486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.5022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.2135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.2159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.3480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.4045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.2266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.2184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.2708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.2329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.5317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.4294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.2679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.4569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.4630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.3651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.3382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.3082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.4330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(1.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.5592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.2306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(1.3824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.8794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.2333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.2117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.6159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.3139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.5014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.3116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.2877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.8143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.8086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.2036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.4699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.2534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.2007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.6309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.3690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.4112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.3340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.2232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.6284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.4695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.5413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.1806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.2216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.4601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.4865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.3328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.3024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.2637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.5401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.5716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.2365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.2412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.5211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.2860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.3316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.3336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.2899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.6756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.7132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.5490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.2733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.6210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.4686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.3101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.3570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.2371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.5935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.5090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.6526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.2408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.2311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.2653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.3720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.2375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.7508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.2217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.4216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.2725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.3492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.5686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.3326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.5630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.3460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.3532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.4771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.3670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.3893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.3397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.3282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.5980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.2448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.3344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.6118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.3827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.4321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.2758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.2118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.4487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.3188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.1920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.1849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.4723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.5872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.3071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.3887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.2878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.4571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.2969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.5424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.1523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.2067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.4028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.4510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.2320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.2023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.4794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.3036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.3728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.4492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.3217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.3458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.5586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.2163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.4649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.6453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.2395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.2017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.2083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.2118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.3299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.5249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.1786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.2416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.3128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.3446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.4253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.6174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.3704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.2708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.1975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.2465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.9046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.8089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.2283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.3082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.2099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.2329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.5687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.2598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.3266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.7226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.3385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.2952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.4842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.7426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.8332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.3562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.1585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.2820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.3042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(2.7496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(2.6729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.6067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(1.3939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.7723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(7.3193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(2.4340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.6777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.9227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.9468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.6886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.3519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.3940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.2464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.6199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(1.2695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.2154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.2856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.2535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.3266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.3058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.2809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(2.7470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(2.9423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.4594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(1.3520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(5.6013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.8171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.9591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.8534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.2215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.3223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.2410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.2647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.4561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.2938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.2678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.2414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.4612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.2682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.2139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.4027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.5805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.1925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.6176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.2329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.2297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.3052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.5744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.2942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.2729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.4324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.2126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.5908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.2332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.3500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.5669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.9464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(1.4127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.2775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.6112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(1.3512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.2970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.2936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.3970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.4628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.3819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.3475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.2311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.2292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.3300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.6143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.3744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.3880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.3280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.9027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.4069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.2091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.5247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.2402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.4390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.2968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.2103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.6661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.5412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.3321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.3659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.5302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.0757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.3567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.7659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.4304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.3196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.2123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.3857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.2166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.3337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.2552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.5258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.2207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.2790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.3223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.4194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.2846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.2003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.7133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.8855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.5347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(1.0364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.5364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.4073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(3.6067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(5.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(1.1945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.1828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(2.7727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(2.3110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.9005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.5099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.2741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(1.6797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.9606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.2228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.8662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.4188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.3989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.5731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.1796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.3952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(1.2738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.6525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.2863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.4562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.3779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.2598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.2465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.4397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.3217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.8122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.3643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.3661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.3985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.2273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.2039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.5564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.6492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.4125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.5521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.3977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.4242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.6350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.2851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.3406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.2005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.2230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.5889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.7157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.2145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.2705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.2018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.2762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.4191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.5891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.3168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.3004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.6275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.2354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.3434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.5889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.2851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.4711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.3527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.2978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.3560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.2403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.2687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.2147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.2277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.4833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.1465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.3676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.1929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.2306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.3170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.3697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.2372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.3986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.2198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.1961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(1.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.3341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.5830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.9080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.2730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.2039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.3754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.5996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.5857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.2731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.8088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.4388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.2135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.5476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.2217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.4028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.2615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.4644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.5721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.1900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.2076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.2026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.3078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.2883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.2483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.2817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.5281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.3279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.3357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.4031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.3946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.4472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.2099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.4163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.6766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.2099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.2926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.3013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.4712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.4356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.2350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.2239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.4964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.3182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.4827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.2091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.3590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.7767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.2999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.4739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.3539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.3859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.2376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.3000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.5258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.3065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.6605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.3795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.3174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.3043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.3349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.2024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.2047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.5443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.2269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.3156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.1636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.4376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.4331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.5194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.2881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.2144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.4968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.4182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.3994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.2774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.3940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.2181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.2145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.4268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.3390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.2125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.2186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.2936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.2261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.3266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.2645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.5390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.3197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.5882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.3346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.2821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.2738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.2061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.3169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.2709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.7582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.2333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.6313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.3006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.2534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.3311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.2850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.2117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.3254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.3612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.2105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.4878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.4881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.2505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.3891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.2331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.2161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.3113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.3754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.2027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.7792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.2215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.2682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.3075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.6367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.4242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.3978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.1915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.6051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.4328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.1127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.4653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.3825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.2087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.3056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.4364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.2858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.5297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.3350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.5046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.2748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.4137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.2686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.3270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.3930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.2220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.3553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.6118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.4580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.2331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.4974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.2966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.2167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.4844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.2110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.2956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.2110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.5262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.5821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.4435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.3447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.2672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.3148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.2930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.3341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.2265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.2424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.2936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.3255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.3370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.4942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.1921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.4856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.3557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.1874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.2534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.1875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.4832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.2282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.3078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.4174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.2211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.2748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.3794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.2110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.6934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.2318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.3277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.2886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.2684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.2352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.5339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.1989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.3485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.5066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.3886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.1921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.3215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.4804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.4501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.2493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.4634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.2496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.4176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.7049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.2799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.3682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.2208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.3574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.3649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.2430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.5971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.2759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.2938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(1.1556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(1.2080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.3753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.3736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.5294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.3213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.2825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.2447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.2962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(2.7113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(2.6099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.2803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.2205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.2308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.2437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.8963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.2140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(1.3034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.2885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.1845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.3016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.3313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.2842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.2669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(1.0382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(1.1905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.3291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.3709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.6129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.2102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.4183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.3377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.6400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.6156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.4209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.4072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.3043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.2908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.2893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.4202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.3196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.5224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.7298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.2052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.2520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.3038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.2448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.2490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.5026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.2161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.6914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.2353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.4657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.2217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.5685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.2433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.3357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.3213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.1864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.2017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.1922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.1831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.4505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.4790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.3525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.5279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.2716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.4909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.4433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.2859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.2357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.3444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.3898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.3875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.2810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.2007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.4694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.6042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.2394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.2437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.4584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.3233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.7903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.2105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.2202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.4592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.6889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.2842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.2223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.2166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.3157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.3347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.3882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.4385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.3148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.2871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.2794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.2738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.2116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.2118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.6238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.2168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.2789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.2211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.2933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.4739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.2088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.6849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.2348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.2095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.2337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.2800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.5914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.2355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.4885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.2796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.4964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.2333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.5367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.5372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.3825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.3097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.5141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.2280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.3032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.2754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.3016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.5486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.2704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.2502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.4123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.3718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.2036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.7471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.4147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.2242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.5464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.3084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.2018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.3334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.4517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.2281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.3948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.4682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.2318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.2651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.2629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.2159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.3091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.2120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.4703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.3908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.5299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.2818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.5332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.1960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.3958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.2284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.5399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.9716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.5943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.2916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.2278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.3624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.3000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.4014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.2226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.2402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.4653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.2762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(1.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.5565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.3577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.8151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.3772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.4206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.4189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.2814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.2262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.1834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.3276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.1747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.2316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.4179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.4294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.3832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.3183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.4602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.2460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.2061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.2415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.3067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.3607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.4498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.2295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.5660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.5798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.3411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.3804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.5296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.3266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.3802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.2396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.4760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.3349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.2000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.2414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.5226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.2980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.2213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.7421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.3732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.2324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.4641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.2771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.3132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.3833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.6733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.3359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.2031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.3330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.2178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.2693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.7231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.4714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.2695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.2805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.3406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.2757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.4765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.2235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.4057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.2302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.3637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.4541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.3004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.2249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.3390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.3637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.4555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.2873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.4954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.4165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.2696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.3995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.3909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.2685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.5649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.4583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.4523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.4859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.2002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.4656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.2024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.3850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.2893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.4842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.2812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.2995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.2786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.6394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.2337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.3633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.6112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.4899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.5862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.2093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.4172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.2934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.5521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.2885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.4194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.3450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.3333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.3713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.3306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.2672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.4221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.2088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.2979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.3420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.3050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.6586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.3058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.2302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.4210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.2492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.7453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.4202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.2369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.5009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.2781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.1800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.5096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.3769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.2162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.3514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.4669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.4336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.4719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.2252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.3670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.5150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.2197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.5201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.2154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.2772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.5392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.9562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.3060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.2460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.2723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.3281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.3427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.2790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.2801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.7673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.2723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.3911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.3981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.4837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.3098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.4525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.1596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.3458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.3323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.4147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.3111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.4797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.5696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.6147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.2241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.2353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.3800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.3678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.4248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.2844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.5873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.3874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.2683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.2288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.4028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.4220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.3418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.2230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.2277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.5748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.6600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.3841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.4374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.2019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.3048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.2162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.3577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.3765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.6325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.2281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.3481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.3315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.2755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.2131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.2372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.5141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.2358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.4151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.3377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.3459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.3972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.5173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.4786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.3652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.5038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.3232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.3730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.2795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.3081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.2118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.5120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.3379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.4205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.2460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.4043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.3157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.3492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.3115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.2737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.2147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.4234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.5156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.2914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.4151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.2269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.4109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.4750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.5011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.2312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.5409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.4273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.3968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.2955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.7122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.4468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.3507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.4812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.2061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.2772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.2083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.3210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.2540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.4493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.3307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.2850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.2419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.3447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.5090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.2635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.4121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.3307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.4759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.2332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.2949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.2391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.4948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.3058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.5616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.3922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.8606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.7821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.5576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.7647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.2162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.2472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.2173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.5976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.4708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.5574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.3990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.3191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.2442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.2339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.2174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.4893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.3986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(1.2292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.4395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(1.0898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.3068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.2040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.3857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.4361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.5044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.4203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.2748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.2320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.4066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.4237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.2386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.2344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.3469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.3312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.3015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.1875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.4219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.3212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.3538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.4995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.4486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.3123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.6238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.5050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.2346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.4965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.3938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.4913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.4097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.2237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.2941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.3488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.2352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.4499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.5292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.5345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.2949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.6851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.4876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.2345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.8123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.6597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.2431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.4962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.3781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.3689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.1728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.2290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.2740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.1972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.3197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.1756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.3146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.1699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.5497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.4916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.3367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.2616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.2344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.5214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.4826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.3307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.2277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.7579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.3171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.4009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.3315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.2049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.3912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.3063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.3659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(1.0209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.7260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.3983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(1.5688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.4575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.5861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.2868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.2064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.3809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.3183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.2285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.3328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.8099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.3554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.3169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.2070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.2908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.2820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.5072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.2618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.4786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.8166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.6180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.2368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.6950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.2889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.2449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.3912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.2114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(1.5011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(1.3498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(1.1819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.6821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.3703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.5461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.3837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.2909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.3284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.4135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.3111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.2213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.6096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.3153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.3237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.2711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.3227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.2114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.6833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.3559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.2301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.2090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.2374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.2016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.5148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.2378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.4012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.2489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.2634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.3458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.2205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.5121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.5020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.3043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.2169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.2202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.5508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.5297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.5460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.3354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.3555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.2071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.3259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.3613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.2401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.2437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.3837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.5168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.5896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.2709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.2455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.3315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.2285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.6018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.4610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.3365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.3617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.5034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.5058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.6869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.1897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(1.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.6273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.2766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(1.3487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.6105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.3656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.3900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.2316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.2695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.4436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.1759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.3354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.4744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.2129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.5887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.3747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.2122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.5067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.2407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.5357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.4606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.2535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.2226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.5131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.3845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.6177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.4898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.6516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.2511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.2098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.3087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.3567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.2901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.2428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.4468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.2022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.3218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.2629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.2044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.3148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.3317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.2409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.5343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.6314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.3089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.2496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.2841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.2718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.3411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.5178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.3124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.1954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.2064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.1938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.4976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.3128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.4443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.3330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.2017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.2897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.2040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.4174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.1830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.6400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.3293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.1879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.3921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.2697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.1753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.1858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.3640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.4545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.5102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.2125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.2542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.1774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.2859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.1851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.3302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.1920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.3173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.4338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.3313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.2854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.4419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.4362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.1838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.2091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.1960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.6270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.2397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.1497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.2408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.5438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.2123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.4673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.2540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.3868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.2141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.2710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.3532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.5904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.3918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.4361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.2094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.1497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.2045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.3697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.3582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.1838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.3533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.2121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.4649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.5482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.4804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.3254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.1827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.2282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.4627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.6301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.3218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.2405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.2307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.3563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.2295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.3893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.6397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.3270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.3295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.3295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.3114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.3319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.2440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.4863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.3060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.2059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.1955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.4069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.3779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.1537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.1980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.2987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.4227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.3355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.1729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.3287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.3438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.3916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.1978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.5713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.1614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.4341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.1427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.1630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.3547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.4147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.2300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.2979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.3239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.2762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.5446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.4346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.3926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.2783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.2248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.1911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.6632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.2800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.1426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.3382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.1866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.4202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.2307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.3044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.1822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.4829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.4183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.1806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.2284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.1630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.5292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.3193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.4725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.1828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.1427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.2726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.3259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.3213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.4296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.5123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.1725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.2180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.1521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.2793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.3602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.2019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.2714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.2390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.4796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.4835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.3114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.3021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.3420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.2192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.2735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.1822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.2646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.4051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.1617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.3164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.2687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.3244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.4191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.1642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.1525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.3188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.2881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.2490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.2235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.7055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.3530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.3394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.1764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.1806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.3051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.1702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.3502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.1882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.4291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.2306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.2456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.2283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.1533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.3459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.1758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.4692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.2701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.2802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.3994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.4564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.3191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.3091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.2114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.1330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.1943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.6222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.3015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.3985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.2691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.3676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.3466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.2371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.3526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.2239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.3424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.2662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.3024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.4123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.1634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.1509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.3786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.2666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.3520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.1501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.3879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.3689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.1891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.2437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.4197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.2004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.2048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.5498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.2505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.4401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.1848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.1757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.2331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.2919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.3064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.2808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.2076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.2850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.3900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.1786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.1604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.4536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.2667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.2952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.4911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.2935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.4810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.1665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.2099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.2372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.2741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.2312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.2881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.3270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.1960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.3396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.2408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.2812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.1770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.1544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.4560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.5589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.1900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.3231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.1683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.4147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.3722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.2752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.1939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.3030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.2280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.2046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.2216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.3247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.1783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.4483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.3722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.2073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.4017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.2897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.2421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.5180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.3235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.4040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.5056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.2312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.2454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.2675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.5027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.2999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.1918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.1947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.3180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.3682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.2653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.2109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.4254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.2868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.1405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.1901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.2774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.2077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.3363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.1318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.1683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.2133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.3069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.2286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.4434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.1842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.4525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.2079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.4186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.3888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.4305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.2170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.3341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.2458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.2211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.2704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.2172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.3641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.1908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.2285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.2189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.3350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.1995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.1622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.1849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.5300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.3407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.3306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.4257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.2113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.1740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.4297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.4130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.2378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.2199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.4663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.1979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.3153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.2254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.2757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.4138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.2284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.1072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.4586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.2136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.3498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.1813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.4703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.3532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.4115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.1848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.1624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.1938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.5574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.2750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.1623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.3034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.4086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.3157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.2204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.2016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.4215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.4229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.3556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.2340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.2101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.1786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.1972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.2678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.3326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.1827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.1781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.5160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.2034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.4935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.2876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.3714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.1840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.2395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.2160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.5307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.3317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.2001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.1512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.3560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.3330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.3851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.4521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.4246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.3392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.3162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.3203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.2641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.4109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.4030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.2707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.2295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.5688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.3721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.2334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.2830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.3568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.4840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.2220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.1747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.5881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.5227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.1805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.1512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.1643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.1696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.1847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.3665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.4503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.2034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.2326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.1716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.3077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.2406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.4649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.2078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.2714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(1.0374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.4785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.4573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.9204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.3665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.2304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.1892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.2315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.2660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.2567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.1979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.5768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.4091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.2873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.3005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.5771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.5290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.3426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.2892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.5182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.4097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.3045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.3143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.2346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.5258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.2736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.1783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.4741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.3042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.3722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.2741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.3435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.1659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.2004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.5370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.2073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.5440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.1588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.3447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.3201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.3465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.4748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.1966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.3852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.1437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.2935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.1696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.3867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.5539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.2457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.2665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.3992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.1954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.4270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.3248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.1804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.3608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.2114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.1651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.2875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.1640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.3572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.6304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.3758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.4215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.1689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.1725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.4251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.3307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.2276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.2345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.2685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.5609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.2275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.2199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.1863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.5827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.3038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.1545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.1889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.4999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.3145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.2829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.2365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.3307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.2970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.2008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.2076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.2030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.5323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.2431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.2023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.2244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.2670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.2049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.2736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.3259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.3443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.1749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.3911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.3117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.2731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.3628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.2755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.2657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.1665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.2304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.3618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.2747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.2298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.1969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.2389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.2323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.4254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.2823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.4090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.2121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.2001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.3338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.2161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.2008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.3220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.3599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.2829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.3478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.3136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.2281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.2204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.1931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.3667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.1916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.1871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.2035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.1991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.4213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.4170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.1594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.3079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.2376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.2340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.3920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.2950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.1956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.4168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.2384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.2457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.3854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.4577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.2874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.1523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.2328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.1848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.2407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.2076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.3824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.2810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.2394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.2634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.2994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.3967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.2631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.2885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.1651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.3084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.3437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.3723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.2689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.2437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.4325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.3066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.2680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.1622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.1976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.2170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.1801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.1645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.1955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.3704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.3557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.2906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.2253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.3415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.2824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.2866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.1739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.3762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.2178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.3557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.2962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.2723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.2165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.4477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.1847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.4015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.2640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.2154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.5377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.2170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.1860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.3001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.2783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.3453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.2293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.1866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.5893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.2281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.2020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.1570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.1814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.3277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.3027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.2233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.3217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.4962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.2481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.4741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.2888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.2274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.4292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.2323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.1613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.1716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.2019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.2133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.2277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.1784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.4823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.3364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.3163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.1822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.2093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.3201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.1804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.4327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.1611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.1736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.3153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.1742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.1908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.2207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.3491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.2339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.2322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.4734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.1678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.2192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.1851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.6994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.1637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.4190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.2197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.2984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.1525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.5251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.2505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.4899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.2442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.3317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.2089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.1490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.4016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.4414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.1697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.1932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.1127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.2086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.1940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.1813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.2389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.2289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.2299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.5723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.4410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.2762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.3622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.2401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.4230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.2430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.1887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.2104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.3459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.1596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.4375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.2794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.2505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.2208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.2466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.1716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.2060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.6297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.3920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.5850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.2709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.1764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.4089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.3938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.2093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.3745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.2755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.4787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.1580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.3940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.1637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.2235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.3688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.4227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.2133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.3755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.4079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.2632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.3363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.1916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.2228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.3952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.2095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.3828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.2215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.3724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.2828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.3552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.1611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.1843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.2254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.2438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.6843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.7767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.1767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.7302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.3080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.2305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.2449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.5993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.2988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.3628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.5383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.3888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.2737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.3176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.1739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.3610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.1837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.3909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.3502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.2160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.2773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.1560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.3174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.2135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.3667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.2395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.3007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.2217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.2308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.4667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.2636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.2778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.2236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.2186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.2132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.2723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.5365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.3161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.1650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.5584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.1573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.1596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.4113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.1797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.3470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.2073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.4625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.1560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.3756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.3085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.3453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.2358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.2816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.1977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.2432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.2024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.2961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.2988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.2118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.4078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.3861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.1608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.3040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.2403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.3833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.3060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.4841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.2008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.3587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.1850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.2095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.8306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.5028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.3107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.3549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.2735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.2457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.1954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.3570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.2651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.2737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.3614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.2866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.3062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.3920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.1962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.1893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.4696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.3737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.2132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.3956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.1595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.2111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.2149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.1643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.5083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.2241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.2189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.3420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.3296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.3394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.1530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.1726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.3284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.2841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.1480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.1767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.3047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.3336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.2022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.1794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.2304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.3352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.1862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.5292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.1488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.3516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.0735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.1605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.1781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.1643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.2954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.1760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.3362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.2127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.2152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.3566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.1765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.1405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.3224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.2419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.2092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.3414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.2266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.3064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.1922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.2533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.2378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.2306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.1979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.2063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.1889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.1823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.1994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.4722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.3026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.1661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.1965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.2713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.4118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.1735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.3075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.1041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.3487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.4431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.2201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.4145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.1688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.2275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.2785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.2198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.2747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.3077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.2823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.1893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.1666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.4058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.3024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.1897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.5465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.1550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.2349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.4872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.2103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.4090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.2123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.1814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.4029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.0931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.2813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.2762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.2081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.1804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.2319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.2199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.3107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.3518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.4203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.1676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.2667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.2537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.2405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.1181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.1521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.4550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.3424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.2141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.3957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.2095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.2701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.2402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.3179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.3884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.3567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.2306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.3351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.1740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.3294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.1938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.2964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.1958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.2335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.2237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.2962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.1041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.1822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.4488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.1512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.3260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.3702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.2739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.2200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.3373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.2434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.1784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.5810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.2420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.2659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.2362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.1635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.3075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.2237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.2278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.2072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.2975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.2030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.3017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.1800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.1909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.3430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.1632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.0765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.1680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.1758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.2190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.3255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.3078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.2059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.3897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.2994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.2916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.2005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.0828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.2792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.2639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.2286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.2899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.2231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.1082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.2671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.3676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.2254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.1747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.1512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.3338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.3425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.2095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.3276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.1598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.1484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.3578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.2431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.2352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.2976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.1890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.3206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.2089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.1699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.3046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.2582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.3155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.2671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.2840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.4051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.1774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.2899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.2822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.1704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.3745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.1661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.1545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.2701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.2917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.1573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.2258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.1794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.4084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.2734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.3920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.2448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.1759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.2346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.3480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.3641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.2144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.2437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.3299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.1564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.2156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.2017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.2019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.3136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.3915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.2409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.4847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.1643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.2990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.2324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.1878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.1793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.2654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.1388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.2275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.5506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.1696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.3844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.1739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.2432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.3652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.2162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.2315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.2326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.3332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.1976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.1613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.1710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.3129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.2378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.4890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.2326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.4315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.4209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.2353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.2297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.2917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.3828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.2757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.1965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.4073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.2752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.2745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.1728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.1837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.3026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.2506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.1680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.4697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.2908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.1680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.2356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.2371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.1437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.2256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.4067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.2904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.1768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.1485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.1729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.3457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.1481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.1516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.2773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.1480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.3178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.1717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.0576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.2402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.2208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.2932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.1866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.2659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.1705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.1767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.1699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.2343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.3891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.2026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.4078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.1980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.2386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.1353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.4602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.2419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.2790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.2112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.2241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.1623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.2447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.1828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.1709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.3186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.3765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.2987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.3780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.2207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.1330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.2859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.2520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.1901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.2072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.3062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.1932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.1899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.2322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.4080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.3832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.2386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.2277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.2722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.2947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.2898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.2126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.1512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.1589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.3396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.2997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.4395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.1637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.2022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.0927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.4350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.3828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.1851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.2178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.2907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.2990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.2383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.1684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.1824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.3106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.3202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.2635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.2218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.4354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.2542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.2083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.1611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.2262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.1539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.1951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.1711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.3426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.3495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.2515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.2813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.1113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.2030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.1915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.2625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.2702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.2328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.5730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.3594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.2698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.0962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.1798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.4662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.2485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.1550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.1909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.2348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.1789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.2154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.1878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.1681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.2648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.1814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.2119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.3156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.3627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.3987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.2036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.2518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.4056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.3712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.2752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.2020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.1975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.2789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.1441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.2372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.2118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.1522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.2651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.1856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.3636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.3627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.3491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.2827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.2119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.1728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.1754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.2373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.1459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.2691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.1682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.2490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.3472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.3874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.1713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.2251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.3232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.2293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.2729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.4130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.1625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.2317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.1840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.1891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.2211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.3281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.4569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.3430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.2832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.2394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.2881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.2866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.1585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.3562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.3107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.1608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.2343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.2832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.2029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.2351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.1887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.0724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.3006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.1680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.1540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.3459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.2159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.2394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.2351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.2031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.1586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.2180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.1634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.1926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.1929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.2838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.2410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.2332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.1844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.5167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.1993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.2980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.1481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.1844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.1500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.2795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.2091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.2207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.2329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.1254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.1953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.1818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.1868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.5643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.2156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.3037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.1609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.3638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.6671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.3619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.3014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.3726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.2354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.3855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.3197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.3399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.2153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.1739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.1676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.1918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.1693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.4353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.2766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.1530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.2653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.2334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.1589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.1971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.2269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.4057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.1480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.2466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.3032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.0992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.3167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.2298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.2097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.1509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.2461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.2101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.1681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.3076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.3513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.2845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.2378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.3511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.3384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.2368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.3086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.3014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.2749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.3047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.1953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.1827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.3628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.2653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.1983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.1763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.1760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.1917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.3793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.2228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.1626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.2845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.2125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.2321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.2460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.1980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.3076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.1958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.2836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.2190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.3810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.1926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.2921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.2462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.3335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.1769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.1705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.3244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.2213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.2111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.2173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.3912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.3061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.2164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.2245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.1954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.3245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.1585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.3231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.2143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.1887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.3109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.2103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.4405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.1845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.2937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.3126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.2042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.2735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.1951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.2877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.2220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.2915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.1867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.2233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.2844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.1613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.4583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.3113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.3842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.4431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.3394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.4169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.2215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.3299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.4308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.1842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.3037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.2136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.2081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.2676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.2324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.2080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.0656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.2251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.3352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.2052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.2232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.4321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.3345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.3320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.1585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.2438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.1860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.3118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.2780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.1797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.3045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.3707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.1759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.1904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.2488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.2137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.1988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.3486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.2087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.3691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.2861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.3055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.1920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.2263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.3078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.1997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.2617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.3848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.1979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.2352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.3092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.1875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.1659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.3239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.2618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.1776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.2685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.1871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.4902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.2235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.2335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.2313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.3065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.1488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.2881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.4430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.2698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.2758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.1357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.2873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.3242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.1520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.1948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.3214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.2878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.3173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.3795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.3137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.2424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.1882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.3731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.1954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.2115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.2007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.4514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.1917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.2072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.2048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.2859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.2245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.1895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.2421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.2537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.2822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.1966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.1291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.3309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.1357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.2507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.3712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.0744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.1405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.3321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.2038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.1906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.2059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.3123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.2356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.2976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.2284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.2675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.1920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.2302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.1570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.3906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.2685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.1707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.2452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.2104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.0848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.1907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.2374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.2087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.2826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.0888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.1645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.1688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.1502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.2352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.1901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.2008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.1577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.3812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.1589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.1787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.4189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.2080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.2135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.1858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.2018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.2205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.2717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.1490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.2136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.3290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.2432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.3603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.2855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.2008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.3017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.2802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.1946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.1696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.1982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.3354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.3034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.2343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.1644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.2187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.2822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.3772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.2300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.2048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.1943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.2782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.3097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.1894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.0791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.2518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.1813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.2973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.1651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.4026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.2608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.2710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.3866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.3115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.2406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.2206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.3272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.2362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.2535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.0746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.1742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.2734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.1636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.2200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.2980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.2262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.3338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.2263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.2972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.2261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.2233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.4401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.4261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.2366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.1792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.1512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.2996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.2046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.2757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.1850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.1888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.1742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.2091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.2379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.1623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.3020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.3500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.2990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.2707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.2450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.2683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.1774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.2642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.2070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.1634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.3367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.1990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.2349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.0879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.3386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.2520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.2275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.1604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.2417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.1621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.3078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.2076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.2075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.3757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.1863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.1537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.2845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.3013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.2515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.2252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.3670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.2079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.2877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.3678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.1622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.2520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.1955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.2754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.2007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.2434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.1948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.2988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.1480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.2167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.2998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.2965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.0845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.4154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.1765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.3295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.2280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.1710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.3109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.2355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.1712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.2700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.1823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.1735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.3718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.2112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.2022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.1897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.1966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.2646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.1907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.2035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.2301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.2227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.2515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.2311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.2966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.1915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.4224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.3624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.4558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.4025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.2039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.1828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.1967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.1925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.2415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.2040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.1717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.3678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.2535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.2317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.1595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.1850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.3384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.2048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.1595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.1776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.3261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.2013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.2323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.4766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.1827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.3447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.2804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.2729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.2961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.1745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.1972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.3126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.1776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.1767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.2283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.1580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.2943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.2811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.3546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.1683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.3585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.2186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.3623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.2181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.2350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.1874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.3656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.1847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.1598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.1760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.1713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.2013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.4060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.2490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.2487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.2462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.4080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.4174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.2758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.1666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.1823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.2184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.2218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.3757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.5074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.2262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.1392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.2771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.2300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.2790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.2976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.3979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.2323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.2857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.3723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.1865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.1909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.2728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.1848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.3058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.2857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.3092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.2313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.1932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.1776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.2024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.3408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.0658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.1845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.2809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.3188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.1613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.2090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.2390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.1521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.3373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.2084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.1943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.1595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.3946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.1907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.2137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.1800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.1544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.3134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.2447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.2083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.2249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.2044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.3382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.1770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.1893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.3121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.1931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.1633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.2072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.1672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.2337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.1956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.2953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.0658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.2230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.1625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.5030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.0870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.2217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.2120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.3357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.3179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.2101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.2863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.3148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.2040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.3026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.1783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.2269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.2551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.1783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.1932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.3239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.3724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.2405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.0818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.2784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.1872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.2785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.0765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.2120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.3484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.1927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.2033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.2058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.2072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.2819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.2875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.2020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.0624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.2485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.2404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.4279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.3885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.1560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.2850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.3490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.1962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.2181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.3092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.3888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.1617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.3107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.2327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.2222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.1984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.0746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.3445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.3037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.2151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.1976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.1596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.1545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.2786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.0669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.1716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.2113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.2036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.3123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.2217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.1838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.1909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.1678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.2174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.2752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.3835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.3607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.2151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.4021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.1560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.2723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.3670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.2308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.2036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.1793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.2368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.2511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.1912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.3279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.4045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.2220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.4158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.2205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.2026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.2120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.2439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.2003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.2768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.1857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.1645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.3332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.2878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.2419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.1700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.2990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.2092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.0816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.2817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.3664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.1662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.2064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.2070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.1697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.2070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.0927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.1705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.3494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.2635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.2645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.1889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.2083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.0848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.1709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.2228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.2222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.3071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.2732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.1533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.1082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.1609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.2784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.2754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.3089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.3102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.2120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.3655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.1516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.2746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.2791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.1540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.2725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.2282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.2201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.2181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.1854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.2192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.4670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.3426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.2289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.2292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.2647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.2299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.0927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.3051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.2102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.2169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.0955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.3979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.2201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.3496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.2506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.2447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.1988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.3367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.1573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.2029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.2705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.3183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.3174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.2924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.3591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.1849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.2164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.1947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.2131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.0676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.3199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.3340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.2027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.2337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.2297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.2067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.2813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.2059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.4501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.2438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.1747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.2538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.2113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.1594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.2256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.3384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.1888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.0795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.2281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.2936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.1707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.2939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.1866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.1634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.2154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.2365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.2987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.1637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.2679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.3643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.2889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.1644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.4045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.2503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.1948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.2023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.2244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.2353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.3251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.3392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.2269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.1995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.2539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.2487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.3013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.2407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.1521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.2302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.2830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.2116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.2777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.2110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.3523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.3040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.2754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.2036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.4451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.2374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.1490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.1111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.3002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.2254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.3289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.3226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.1984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.1569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.2749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.2002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.2047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.3804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.0848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.2645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.2035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.3143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.3074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.2067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.2176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.2813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.3144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.3057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.2167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.3327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.2350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.2880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.2871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.3092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.2155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.1897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.3632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.2081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.3028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.2483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.2433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.1866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.1622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.2300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.2135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.1859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.1481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.3204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.2533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.1497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.2039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.3148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.1693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.3087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.3805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.2084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.3228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.0888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.2101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.3659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.1749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.2286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.1643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.2164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.2098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.3539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.2692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.0776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.3349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.1707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.2127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.2839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.1757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.2428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.2067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.2905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.2941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.3006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.2359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.2423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.1569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.1961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.2896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.3646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.2155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.0852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.2952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.2298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.2867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.3059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.1501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.1844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.3086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.2640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.2461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.2001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.1683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.2384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.2461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.1789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.2218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.2010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.2484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.3367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.2326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.2942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.0702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.3612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.3008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.2256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.3234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.3688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.2442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.2015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.1598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.3130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.2404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.1539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.2278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.2083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.1832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.2173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.1995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.2530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.1630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.1466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.2724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.2512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.1537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.1683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.2998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.2815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.2358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.2766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.2268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.2344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.2076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.1072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.2092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.2641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.2871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.3059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.2286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.2390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.2022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.1573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.1569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.1862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.3530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.2056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.1995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.2325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.1405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.2147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.4156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.2642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.1580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.2403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.2094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.2304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.2295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.1694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.1865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.3650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.2567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.2565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.2189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.1801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.3093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.3282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.2061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.3017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.2396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.1709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.4726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.2222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.1898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.1922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.4035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.2071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.1650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.2052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.1570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.2222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.1544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.2013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.2447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.1944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.2413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.2211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.3885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.1594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.2087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.2823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.2455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.2651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.0735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.1111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.2659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.2064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.2485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.2488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.2799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.2758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.2958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.1867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.1551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.2794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.2052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.1584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.1328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.2862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.1929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.2912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.1705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.2520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.1833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.2078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.2112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.1926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.3110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.2299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.3242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.3044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.2047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.2195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.1924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.1046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.1980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.1797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.1917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.2391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.2730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.2909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.3188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.2456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.2673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.2127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.2104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.1993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.2230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.1893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.4002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.1459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.1388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.1900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.2505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.1925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.2204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.2340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.2637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.0870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.2837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.3290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.2034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.0791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.2440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.1659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.3583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.2176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.1490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.1682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.2056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.0751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.1640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.2173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.2902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.2980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.1799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.2357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.3957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.2721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.1760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.2877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.3759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.1827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.2119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.3138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.3118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.1948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.2287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.2187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.0805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.2310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.1662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.2328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.1782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.2567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.2720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.2632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.2078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.1966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.2095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.1576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.4115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.1997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.2876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.1705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.2097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.0839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.2304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.2359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.1608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.2988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.1551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.2625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.1977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.2795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.1939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.2233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.1497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.2162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.2467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.1792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.2350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.2966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.1677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.2537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.2293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.3423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.2085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.3152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.1678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.3014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.1735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.2202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.4467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.2057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.2288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.2226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.2125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.2206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.0568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.2242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.4034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.2126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.3506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.2058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.3482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.3142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.0841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.2986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.0584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.1984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.0870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.2397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.2132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.2256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.2806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.2034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.1587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.2340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.2101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.4058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.1911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.2780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.1788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.1862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.2406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.3726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.1749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.2057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.2325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.1758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.2375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.1537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.1800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.1604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.2088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.3514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.2725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.1987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.2393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.2335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.2255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.2373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.2137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.1891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.2863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.2172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.2218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.0767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.2000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.1712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.1800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.2193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.1577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.2832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.2065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.1913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.1693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.2272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.2064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.1837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.1787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.2363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.0625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.2193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.3371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.2149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.4469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.1636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.1291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.1988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.3679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.1832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.2231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.1676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.2131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.3228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.2844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.2154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.2721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.3543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.2661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.2311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.1569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.2042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.1900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.2409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.3281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.3014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.1754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.1856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.3515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.1863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.1961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.2292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.3563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.2368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.2155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.1520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.2273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.1917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.3173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.1865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.2290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.2017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.2170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.2125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.0689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.1980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.3398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.2935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.1806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.1520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.2837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.1357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.3460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.2007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.0781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.2287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.2048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.3152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.2240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.3402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.2115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.1943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.3024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.2092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.1502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.1845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.3643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.1955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.2753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.1632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.2199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.2647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.1889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.1757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.2674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.0850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.2368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.0828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.1800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.2390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.2027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.2434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.3721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.1979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.2021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.2102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.3886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.0734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.2043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.1572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.2262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.2221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.2174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.2064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.1742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.3403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.2241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.2423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.2860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.2828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.2153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.1072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.2141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.2033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.2354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.2043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.2199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.1522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.1712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.3143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.2412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.2152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.1889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.2273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.1584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.1597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.1907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.3130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.1745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.2122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.1848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.1763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.3007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.2181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.3199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.2256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.2278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.1635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.1665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.0992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.2144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.4303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.2286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.3083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.2978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.3534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.2206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.2944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.2765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.2163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.2766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.3369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.2079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.2099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.2090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.1648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.1801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.1659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.1975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.3561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.2362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.1846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.2050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.0480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.2483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.2410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.2184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.1833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.2886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.1533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.3240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.0513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.3089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.3950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.2349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.1486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.3220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.3593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.1681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.1484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.1662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.2077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.2346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.3235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.1882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.2136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.1957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.2104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.2174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.3566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.1173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.2356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.2701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.2487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.2636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.1598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.1766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.1818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.2166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.1758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.3407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.2466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.1768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.2414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.1921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.2292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.2724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.2067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.2424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.1838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.2336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.1865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.1890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.2230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.1833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.2989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.2149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.2536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.1776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.2442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.2078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.2150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.2416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.2091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.0781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.2067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.1689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.2611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.2407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.0840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.2472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.2139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.2833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.1788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.2101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.2244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.4260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.3164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.2245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.3606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.1937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.2038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.0656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.2956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.2206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.2217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.3094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.2320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.1643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.2921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.0748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.1912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.1956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.2391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.1353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.2112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.2048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.2679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.2502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.2241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.1630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.2518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.1640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.3706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.1937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.1974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.1540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.2389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.1597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.1847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.2384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.2147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.3461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.3158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.0744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.3047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.2307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.1865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.2136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.2260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.1520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.2450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.2030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.2359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.1857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.0666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.1872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.2252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.2971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.2379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.2793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.1642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.2237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.0771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.2045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.1725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.2391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.2835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.1441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.2320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.1618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.2081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.2084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.2709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.3384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.2361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.2101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.2863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.1774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.2800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.2804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.1716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.2098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.2689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.2070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.2253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.2353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.2382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.3403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.2034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.3251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.2010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.1957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.2348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.2087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.1740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.2221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.3173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.2626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.1911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.2394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.0746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.2273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.0778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.0778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.2319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.2518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.2384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.2150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.2716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.1662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.3167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.2153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.2961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.2168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.2055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.3033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.2863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.2931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.0828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.2635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.1764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.2417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.1680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.2105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.2286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.1127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.2326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.2163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.1946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.2029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.1764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.1843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.1872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.3058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.0879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.1850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.2112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.2249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.3192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.2631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.1614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.1127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.2227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.2428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.2734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.1898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.1694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.4398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.2232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.2046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.3072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.2418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.2140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.3074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.2998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.0994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.2337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.2279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.2222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.2401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.2691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.3124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.2216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.1486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.3034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.2002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.2202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.3050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.2121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.1683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.2117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.2972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.2027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.3263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.2060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.0962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.2703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.2086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.2415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.2198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.2393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.3229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.2393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.2565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.3142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.1859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.1726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.2047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.1994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.2004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.2140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.1979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.2685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.1918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.2152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.1812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.3661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.1608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.1711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.1459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.2113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.2721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.1611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.1834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.2153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.2410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.2200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.1586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.2611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.2060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.1874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.0522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.1868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.3182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.1589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.1604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.2950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.3365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.2906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.1726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.1872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.1710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.1747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.2956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.1707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.2365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.2075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.1570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.2820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.1596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.2207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.2892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.3236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.2642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.0994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.2310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.2640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.2166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.1796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.2467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.0840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.2836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.1551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.3367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.2403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.1856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.2215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.2002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.1892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.3300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.2166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.1930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.1840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.0693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.2213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.2050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.2675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.2211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.2102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.2265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.3745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.2168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.2027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.1576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.1765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.2174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.2061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.1850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.1745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.1900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.1913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.2120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.3397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.2160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.3476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.2393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.2044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.2265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.2991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.2254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.0656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.2179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.2063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.1659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.2237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.2043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.3221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.2348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.2173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.1924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.3361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.1357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.2127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.2329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.2700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.1987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.2397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.2099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.1500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.1585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.1971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.2113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.3230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.2399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.2357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.1976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.1967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.2793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.2035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.3070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.1353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.3187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.2335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.1753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.2898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.2031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.2216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.2222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.1486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.3386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.1392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.3100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.2001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.2220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.1584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.2169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.2017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.2058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.3202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.2302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.1939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.3003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.0783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.2040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.2038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.1595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.2864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.1521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.1633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.2840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.2693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.2155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.2089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.2639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.3225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.2080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.2369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.0841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.1972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.4112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.2424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.1830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.2325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.0579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.1931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.1989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.2492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.2260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.1726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.2104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.2404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.2986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.2325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.0630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.2827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.2405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.2539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.1711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.2121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.2618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.2538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.1710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.1525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.1618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.2875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.1879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.1516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.2669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.2841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.1162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.2129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.3045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.3662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.2059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.2075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.3031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.1815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.2017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.1835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.3363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.1562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.2287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.2246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.1318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.1995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.4282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.2110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.2178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.2778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.2718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.2137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.2431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.1694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.1645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.2492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.2228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.1709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.2215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.1696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.2785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.2017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.3234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.2664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.2133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.0629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.2378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.1875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.3083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.2819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.2339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.1621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.3791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.0879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.2172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.2721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.2665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.2109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.2693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.1976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.2915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.1588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.2433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.2050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.1928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.1729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.1676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.2997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.2354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.2117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.2018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.2022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.2882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.1699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.2965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.3390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.2167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.2409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.2293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.2118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.2969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.2223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.2172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.2540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.2004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.3403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.3956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.2299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.2805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.2899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.3752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.1994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.1838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.2325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.2276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.2408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.0622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.3242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.1906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.1705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.1509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.2869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.3223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.2081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.2418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.1573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.2127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.3053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.2354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.2826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.2354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.2184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.1783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.1798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.1484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.3179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.1862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.1605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.3207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.2632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.2145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.1113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.2180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.1676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.2723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.1864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.1908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.2389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.2688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.3534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.2269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.2343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.2345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.2759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.1756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.1969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.0931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.2721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.1862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.1618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.2824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.1485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.1794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.2430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.2254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.3079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.2033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.2537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.2252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.1868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.2420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.2090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.1427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.2589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.2055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.1882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.2235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.2231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.2047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.0955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.3222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.2503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.1867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.1530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.1986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.2077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.2983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.2551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.1984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.2111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.2419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.2340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.3337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.1854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.0732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.3228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.2730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.2289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.1975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.1678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.2172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.2119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.3356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.2691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.2418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.2538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.1906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.2552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.2359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.2708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.2057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.2706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.3490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.2121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.2537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.2608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.0744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.2357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.1813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.2310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.1330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.2396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.2215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.2023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.0773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.2025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.3205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.2301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.1509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.2125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.1840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.3483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.1588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.2467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.2482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.0640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.2512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.3981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.0821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.3033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.1904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.2169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.2679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.2046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.2759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.1984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.2008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.2873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.2390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.1580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.1667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.3794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.0776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.1834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.1921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.1556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.2418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.2067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.1915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.1969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.2866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.1949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.2932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.2867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.2018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.2867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.3191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.0535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.2179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.2169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.0852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.2003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.2285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.2906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.1426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.2355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.2147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.1490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.2626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.2746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.2440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.2836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.3213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.2317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.1901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.2616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.2354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.1793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.2854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.2990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.2334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.1041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.1648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.2640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.2664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.1441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.1804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.2239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.1635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.2793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.3279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.2634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.2277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.0700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.2029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.4107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.2328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.1630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.3368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.1569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "epoch_num = 1000\n",
    "batch_size = 8\n",
    "lr = 0.01\n",
    "gamma = 0.5\n",
    "\n",
    "minimum_loss = float('inf')\n",
    "loss_track = []\n",
    "\n",
    "# Load training data\n",
    "trainset = DataFromH5File5(\"/home/pz281@ad.eng.cam.ac.uk/mnt/PhD/Pro_Down_SR/data/DownBy4_30_120.h5\",N_low,N_high,scale)\n",
    "train_loader = data.DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialise training model\n",
    "G = DownScale()\n",
    "G.apply(weights_init_xavier).to(device)\n",
    "mse = nn.MSELoss(reduction='sum')\n",
    "optG = torch.optim.Adam(G.parameters(), lr = lr, weight_decay=0, betas=(0.5, 0.999))\n",
    "r_scheduleG = torch.optim.lr_scheduler.StepLR(optG, step_size=100, gamma=gamma)\n",
    "\n",
    "# Logger info\n",
    "dir_name = f'models/train_NN/model1/30_120/lr{lr}_gamma{gamma}'\n",
    "makedir(dir_name)\n",
    "logger = setup_logging('job0', dir_name, console=True)\n",
    "logger.info(f'Training for {epoch_num} epoches and learning rate is {lr}')\n",
    "\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    \n",
    "    for i, d in enumerate(train_loader, 0):\n",
    "        \n",
    "        residual, high_res, low_res = d\n",
    "        size = residual.shape[0]\n",
    "        low_res = low_res.to(device).reshape(size,1,N_low,N_low)\n",
    "        high_res = high_res.to(device).reshape(size,1,N_high,N_high)\n",
    "        \n",
    "        optG.zero_grad()\n",
    "        out = G(high_res)\n",
    "        loss = mse(low_res,out)/batch_size\n",
    "        loss.backward()\n",
    "        optG.step()\n",
    "        \n",
    "        if loss < minimum_loss:\n",
    "            save_model(dir_name, epoch, 'best_model', r_scheduleG, G, optG)\n",
    "            minimum_loss = loss\n",
    "            \n",
    "        if epoch%100 == 0:\n",
    "            save_model(dir_name, epoch, 'model_epoch_{}'.format(epoch), r_scheduleG, G, optG)\n",
    "            \n",
    "        loss_track.append(loss.cpu().data.numpy())\n",
    "        np.save(f'{dir_name}/chains/loss_curve.npy', np.array(loss_track))\n",
    "        \n",
    "        print(\"Epoch:\", epoch, \"Loss:\", loss)\n",
    "\n",
    "    r_scheduleG.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_low = 30\n",
    "N_high = 120\n",
    "scale = 4\n",
    "a, b, c = 8,3,5\n",
    "\n",
    "h_low = 1/(N_low-1)\n",
    "x_low = np.arange(0,1.0001,h_low)\n",
    "y_low = np.arange(0,1.0001,h_low)\n",
    "\n",
    "h_high = 1/(N_high-1)\n",
    "x_high = np.arange(0,1.0001,h_high)\n",
    "y_high = np.arange(0,1.0001,h_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_low, r_low, A_low, x_low, y_low = generate_data(N_low,a,b,c)\n",
    "w_high, r_high, A_high, x_high, y_high = generate_data(N_high,a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = DownScale().to(device)\n",
    "G.load_state_dict(torch.load('models/train_NN/model1/30_120/lr0.01_gamma0.5/ckpt/best_model.pth')['netG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_high_tensor = torch.tensor(w_high).to(torch.float32).to(device)\n",
    "w_low_tensor = torch.tensor(w_low).to(torch.float32).to(device)\n",
    "out = G(w_high_tensor.reshape(1,N_high,N_high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxsAAAGJCAYAAADi7y6oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABlJ0lEQVR4nO3deXgUVbo/8G9XJ92dkJ3sISHsm0CUSCZqRMc4Qdy4M464sowD42jmqpmfI7gQlFFwY1AHzVUvOipcGR11uMKgGMyoQxQloogsIluAJCSEkJCQdNJdvz+46TGSnFMh1VW9fD/P088DdapOnequeiunlvNaVFVVQUREREREpDPF7AYQEREREVFgYmeDiIiIiIi8gp0NIiIiIiLyCnY2iIiIiIjIK9jZICIiIiIir2Bng4iIiIiIvIKdDSIiIiIi8gp2NoiIiIiIyCvY2SAiIiIiIq9gZ4OIiIjIyzIzMzFz5kzd6tu3bx8sFgtefvll3eok8gZ2NihgvPzyy7BYLPjiiy+6Le8MzJ0fRVEQFxeHyy67DOXl5Qa3lojIHJ2xsvPjcDiQmpqKgoICPP3002hqajK7iT3at28fZs2ahSFDhsDhcCA5ORkXXnghiouLzW4aEfUgxOwGEBnt+uuvx5QpU+ByubBr1y48++yzuPjii/H5559j7NixZjePiMgQDz30EAYNGoT29nZUV1ejrKwMd955J5YsWYLVq1dj3LhxZjexi927d+Pcc89FWFgYfvWrXyEzMxNVVVWoqKjAo48+igcffNDsJhJRN9jZoKBzzjnn4KabbvL8Py8vD5dddhmee+45PPvssya2jIjIOJdddhmys7M9/583bx42bNiAK664AldddRW2b9+OsLAwE1vY1Z/+9CecOHECW7ZswcCBA7uUHTlyxKRWEZEMH6OioJeXlwcA+P77701uCRGRuX7605/igQcewP79+/Haa695pm/YsAF5eXno168fYmJicPXVV2P79u2e8q+//hoWiwWrV6/2TNu8eTMsFgvOOeecLuu47LLLkJOT4/l/ZmYmrrjiCnzyySeYOHEiHA4HBg8ejFdeeaXLct9//z0GDBhwWkcDABITE7v8/+9//zsuv/xypKamwm63Y8iQIVi4cCFcLleX+S666CKcddZZ+PrrrzFp0iSEh4dj6NChePPNNwEA//znP5GTk4OwsDCMGDECH3zwQZflFyxYAIvFgh07duDaa69FVFQU+vfvjzvuuAOtra3C7xoAGhoacOeddyI9PR12ux1Dhw7Fo48+Crfbfdp8M2fORHR0NGJiYjBjxgw0NDRI6yfyBexsUNDbt28fACA2NtbchhAR+YCbb74ZAPD+++8DAD744AMUFBTgyJEjWLBgAYqKirBx40acf/75nvh51llnISYmBh999JGnno8//hiKouCrr75CY2MjAMDtdmPjxo248MILu6xz9+7duOaaa3DppZfiySefRGxsLGbOnIlt27Z55hk4cCAqKyuxYcMG6Ta8/PLLiIiIQFFREZ566ilMmDAB8+fPx9y5c0+b99ixY7jiiiuQk5ODxx57DHa7Hddddx1WrVqF6667DlOmTMHixYvR3NyMa665ptt3Wq699lq0trZi0aJFmDJlCp5++mnMmTNH2MaWlhZMmjQJr732GqZPn46nn34a559/PubNm4eioiLPfKqq4uqrr8arr76Km266CX/84x9x8OBBzJgxQ/o9EPkElShAvPTSSyoA9fPPP++2fO/evSoA9cEHH1Rra2vV6upq9eOPP1bPPfdcFYD6xhtvGNxiIiLjyWKlqqpqdHS0evbZZ6uqqqpZWVlqYmKievToUU/5V199pSqKok6fPt0z7fLLL1cnTpzo+f/Pf/5z9ec//7lqtVrVf/zjH6qqqmpFRYUKQP373//umW/gwIEqAPWjjz7yTDty5Ihqt9vV3//+955p33zzjRoWFqYCULOystQ77rhDfeedd9Tm5ubT2t/S0nLatN/85jdqeHi42tra6pk2adIkFYC6cuVKz7QdO3aoAFRFUdRPP/3UM/29995TAagvvfSSZ1pxcbEKQL3qqqu6rOu2225TAahfffVVl+2cMWOG5/8LFy5U+/Xrp+7atavLsnPnzlWtVqt64MABVVVV9Z133lEBqI899phnno6ODjUvL++09hD5It7ZoKBTXFyMhIQEJCcnIy8vD9u3b8eTTz6Ja665xuymERH5hIiICDQ1NaGqqgpbtmzBzJkzERcX5ykfN24cLr30Uqxdu9YzLS8vDxUVFWhubgYAfPLJJ5gyZQqysrLw8ccfAzh1t8NiseCCCy7osr7Ro0d7HmkFgISEBIwYMQJ79uzxTBszZgy2bNmCm266Cfv27cNTTz2FqVOnIikpCS+88EKX+n74rklTUxPq6uqQl5eHlpYW7Nix47Rtve666zz/HzFiBGJiYjBq1Kguj3t1/vuHbep0++23d/n/7373OwDo8v382BtvvIG8vDzExsairq7O88nPz4fL5fLcJVq7di1CQkLw29/+1rOs1Wr1rIPI1/EFcQo6c+bMwS9/+Uu0trZiw4YNePrpp097jpeIKJidOHECiYmJ2L9/P4BTf4D/2KhRo/Dee++hubkZ/fr1Q15eHjo6OlBeXo709HQcOXIEeXl52LZtW5fOxujRo7t0XAAgIyPjtPpjY2Nx7NixLtOGDx+OV199FS6XC99++y3effddPPbYY5gzZw4GDRqE/Px8AMC2bdtw//33Y8OGDZ5HuDodP368y/8HDBgAi8XSZVp0dDTS09NPmwbgtDYBwLBhw7r8f8iQIVAUxfOYWXe+++47fP3110hISOi2vPOl9/379yMlJQURERFdyrv7TYh8ETsbFHSGDRvmOSFdccUVsFqtmDt3Li6++OIuI7MQEQWjgwcP4vjx4xg6dGivlsvOzobD4cBHH32EjIwMJCYmYvjw4cjLy8Ozzz6LtrY2fPzxx/iP//iP05a1Wq3d1qmqarfTrVYrxo4di7FjxyI3NxcXX3wxVqxYgfz8fDQ0NGDSpEmIiorCQw895MnJUVFRgXvuuee0l697Wndv2/RDP+68dMftduPSSy/FH/7wh27Lhw8fLq2DyB+ws0FB77777sMLL7yA+++/H+vWrTO7OUREpnr11VcBAAUFBZ6Rn3bu3HnafDt27EB8fDz69esHALDZbJg4cSI+/vhjZGRkeB6LysvLQ1tbG1asWIGamprTXg7vq86LRFVVVQCAsrIyHD16FG+99VaXde3du1fX9f7Qd999h0GDBnn+v3v3brjdbmRmZva4zJAhQ3DixAnPxa+eDBw4EKWlpThx4kSXuxvd/SZEvojvbFDQi4mJwW9+8xu899572LJli9nNISIyzYYNG7Bw4UIMGjQIN954I1JSUpCVlYW//OUvXYZa/eabb/D+++9jypQpXZbPy8vDZ599hg8//NDT2YiPj8eoUaPw6KOPeuY5Ex9//DHa29tPm975XkTnY0WddyR+eAfC6XR6NY/SsmXLuvz/mWeeAXBqmN+eXHvttSgvL8d77713WllDQwM6OjoAAFOmTEFHRweee+45T7nL5fKsg8jX8c4GBZzly5d3e4fi6quv7nGZO+64A0uXLsXixYvx+uuve7N5REQ+4R//+Ad27NiBjo4O1NTUYMOGDVi/fj0GDhyI1atXw+FwAAAef/xxXHbZZcjNzcUtt9yCkydP4plnnkF0dDQWLFjQpc68vDw8/PDDqKys7NKpuPDCC/Ff//VfyMzMxIABA86ovY8++ig2b96Mn//8557s5hUVFXjllVcQFxeHO++8EwBw3nnnITY2FjNmzMB//ud/wmKx4NVXX9X0+NOZ2rt3L6666ipMnjwZ5eXleO2113DDDTdg/PjxPS5z9913Y/Xq1bjiiiswc+ZMTJgwAc3Nzdi6dSvefPNN7Nu3D/Hx8bjyyitx/vnnY+7cudi3bx9Gjx6Nt95667R3T4h8FTsbFHB+ePXnhy666KIel0lNTcUNN9yAV199Fd9//z2GDBnipdYREfmG+fPnAzj1+FNcXBzGjh2LpUuXYtasWYiMjPTMl5+fj3Xr1qG4uBjz589HaGgoJk2ahEcffbTLo0PAqT/0rVYrwsPDu/yhnZeXh//6r/8647saAHDvvfdi5cqV+Oc//4kVK1agpaUFKSkpuO666/DAAw942tK/f3+8++67+P3vf4/7778fsbGxuOmmm3DJJZegoKDgjNcvsmrVKk8ej5CQEBQWFuLxxx8XLhMeHo5//vOfeOSRR/DGG2/glVdeQVRUFIYPH44HH3zQ80K6oihYvXo17rzzTrz22muwWCy46qqr8OSTT+Lss8/2yvYQ6cmierOrT0RERBSgFixYgAcffBC1tbWIj483uzlEPonvbBARERERkVews0FERERERF7BzgYREREREXkF39kgIiIiIiKv4J0NIiIiIiLyCnY2iIiIiIjIK4Iuz4bb7cbhw4cRGRkJi8VidnOIyACqqqKpqQmpqalQlDO7xtLa2gqn06lzy7Sx2WyeBGvUO4z5RMGF8d73BF1n4/Dhw0hPTze7GURkgsrKyjPKXtza2opBYWGo9kKbtEhOTsbevXsD7gRkBMZ8ouDEeO87TO1sfPTRR3j88cexefNmVFVV4e2338bUqVOFy5SVlaGoqAjbtm1Deno67r//fsycOVPzOjuzot5V+RfYo8L70Hoi8hdtjS34U/qMLlmRe8PpdKIaQKViQZS+TZNqBJBeXQ2n0+n3Jx8zY37BzjUIjezX7TxpYSek9YQp4qucCuRjrVg0zBMorDrUIftOtXyfLsnT4h0Q3+1qV+VXxmXrcOvwxLoVLuk8oRa3sNxf9tETbnmcS1B6PmbbGlvwePqvGO99iKmdjebmZowfPx6/+tWv8POf/1w6/969e3H55Zfj1ltvxYoVK1BaWopf//rXSElJQUFBgaZ1dt5Gt0eFs7NBFGT6+hhNlNWCKKMfxVFVwG3+HwB6MDPmh0b2Q2hURLfz2MLk369dCRWW+8sfckax6rCtsu9Uy3feIflD3yopV9jZMJxTQ2fDoYi3FWC89yWmdjYuu+wyXHbZZZrnLykpwaBBg/Dkk08CAEaNGoVPPvkEf/rTnzSfeIiIzphVAcw4+bTLT6z+gDGfiPwG471u/Go0qvLycuTn53eZVlBQgPLy8h6XaWtrQ2NjY5cPERH5PsZ8IiL/51edjerqaiQlJXWZlpSUhMbGRpw8ebLbZRYtWoTo6GjPhy8KEtEZC7GY8wlSjPlEZBrGe934VWfjTMybNw/Hjx/3fCorK81uEhH5K6tizoc0Y8wnIl0w3uvGr4a+TU5ORk1NTZdpNTU1iIqKQlhYWLfL2O122O12I5pHRIFOsZz6GCnwHt/VjDGfiEzDeK8bv+ps5ObmYu3atV2mrV+/Hrm5uSa1iIiCilUx/uRjCbyRSbRizCci0zDe68bUzsaJEyewe/duz//37t2LLVu2IC4uDhkZGZg3bx4OHTqEV155BQBw66234s9//jP+8Ic/4Fe/+hU2bNiAv/71r1izZo1Zm0BEwYQnnz5hzCciv8F4rxtTOxtffPEFLr74Ys//i4qKAAAzZszAyy+/jKqqKhw4cMBTPmjQIKxZswZ33XUXnnrqKQwYMAAvvviiV4ZAHNVaJSwfcUSeWzKjqlZYHne0Sd6QdvHY2h1hNmF5dXKsdBX7UhKF5TtiU6R1fGtNEpcfT5DW8V1VtLD8cHX3j038kLuh77u0EtMhLE9N7v7F1E7DUo5L1zE6WrxvjHbVCMsBYOQx8T6aWXVEWkdy9TFhechJcSIzAECoOH1XfX95YqUDKeL9Y2disrB8u0O+j5L5zIz5GeHHYQ/v/tiefPxb6fIjDx4S139AfEwDAKolsUE2vn7/7vOE/FBNerywfGdmmrSOiv4DheWbnPKX7isOiI/pXTvl6dIGfifOtxBTK08d6JY8Al+fLI73dWNapOsYP1IcR8cmyPeN8cphYfm4+oPSOoYcFJ8T0vZr2EdrJX+XaPnjO1Ec8w9miP/m+HTYMOkqdoaJ/+Yg32JqZ+Oiiy6CqvYcXF9++eVul/nyyy+92Coioh5YTXiGN4AGJ2HMJyK/wXivG796Z4OIyFS8rU5EFBwY73XDzgYRkVa80kVEFBwY73XDzgYRkVZWi/HjoLsCdCxEIiJfxnivG3Y2iIi0slpOfQwVoJe6iIh8GeO9bgIzVSEREREREZmOdzaIiLSyKsbfViciIuMx3uuGnQ0iIq148iEiCg6M97phZ4OISCs+w0tEFBwY73XDzkYPMhqOCsuzPt0ur+TDXeLyLeJsnwCAE+IMziHJ4oyyA3IypKuIvXSUsLwuW561tskuXs+OgzHSOizr+wvL8z8SZ5MFgOTdfb8KUT1UPBrENxe2Cst3XCoPFukRjcLy+DZ5dvmzv/1eWN5vvYZ99LMD4vLqE/I6IsRZ7OOy5Nm94y4eLiw/eWGosHx7skEZxHmly29FWNpht3QfTzNr5ZmVM8okWcbf1XC8fV0jLpf9YTNGnHkZAJKmjBSWd4TI99/dMeLszC3t8j8d9u0Xnzdy3hdnmQaAkf8SH/eJe/r+h1ndQHFegy8LxG0AgJ0Ol7B8cJwkczyACLVNWC7LDg4Aaf/4WjzDmh3SOrBDcixE2OV1ZKcKiwdMFu+jaYnivwUAoMbe8/5z0i3P+q4J471u+C0SEWmlWP59tcuozxmM875s2TJkZmbC4XAgJycHmzZt6nHeF154AXl5eYiNjUVsbCzy8/OF8xMRBQU/iff+gJ0NIqIAsmrVKhQVFaG4uBgVFRUYP348CgoKcOTIkW7nLysrw/XXX48PP/wQ5eXlSE9Px89+9jMcOnTI4JYTEVEgYmeDiEirztvqRn96YcmSJZg9ezZmzZqF0aNHo6SkBOHh4Vi+fHm3869YsQK33XYbsrKyMHLkSLz44otwu90oLS3V4xsjIvJPfhDv/QXf2SAi0sqMFwbVU+trbOz6no/dbofd3vX5aafTic2bN2PevHmeaYqiID8/H+Xl5ZpW19LSgvb2dsTFxfWx4UREfszEeB9oArMLRUTkDSZe6UpPT0d0dLTns2jRotOaV1dXB5fLhaSkri/4JiUlobq6WtMm3nPPPUhNTUV+fn7fvy8iIn/FOxu64Z0NIiKtTLzSVVlZiaioKM/kH9/V0MPixYvx+uuvo6ysDA6HfPQ3IqKAxTsbugnMLhQRkTeYeKUrKiqqy6e7zkZ8fDysVitqaroOsVpTU4Pk5GThpj3xxBNYvHgx3n//fYwbN06/74yIyB/50Z0NXx+BkJ0NIqIAYbPZMGHChC4vd3e+7J2bm9vjco899hgWLlyIdevWITs724imEhGRDvxhBEI+RkVEpJViMf6ZWrc46diPFRUVYcaMGcjOzsbEiROxdOlSNDc3Y9asWQCA6dOnIy0tzfPOx6OPPor58+dj5cqVyMzM9LzbERERgYgIeUJPIqKAZGK81zIgSKcfjkAIACUlJVizZg2WL1+OuXPnnjb/ihUruvz/xRdfxN/+9jeUlpZi+vTpemzFadjZICLSyoxneN29W9+0adNQW1uL+fPno7q6GllZWVi3bp3npfEDBw5AUf59An3uuefgdDpxzTXXdKmnuLgYCxYs6HPziYj8konxPj09vcvknuKxv4xAyM5GD/q1tYlnONIoLgeA3UfF5du6v8XVRZNTXH70pLg8OVK6in4NLcLyULdLWocb4gOyqTlUWsfgQ+LdMXWn/ApD6va+BwbFJV5P9RBxO/do2FbZ96XlO5f9bth/TFoHttWKy6ua5HVE2sTlEZJyABgjPp6kx6NRzBgtpJd3NgCgsLAQhYWF3ZaVlZV1+f++ffvOoFH+xwo3QuDutiykQ368SX8HLfuFs0Nc7ur9b91bqiJvZ4gq/j6sSvff4w9ZrOJtcUvKAcAmOb3ZJCEQAEIkp9DwaHEsdjTLzyknm8XnhHa3hu/cIv5OQzrk37mUlj+cnZJj4YQOsViSJdtt8ZGXpE2M91oHBBGNQLhjxw5NqzRiBEJ2NoiItPKDOxtERKQDE+N950Ag3mbUCITsbBARaeUndzaIiKiP/CDe6zEC4QcffOD1EQg5GhURERERkZ/xlxEIeWeDiEgrPkZFRBQc/CTe+8MIhOxsEBFppZhwW92Al4aJiOhH/CTe+8MIhOxsEBFpZcaVLqPXR0REfhXvfX0EQnY2iIi0MuOFQQ1DhBIRkc4Y73XDzgYRkVZ+dKWLiIj6gPFeNxyNioiIiIiIvIJ3NnrQGB4unmFwgryScweIy8PkmaZxsl1cntBPXJ6VKl1FfXKMsLzNKm9nqCT7aVyMPOvogZHiVK8Rx+R944Zkq3QemSODxBlUZe3Usq2y70vLdy773eI0/PZwSbLS1jbL65Dtx2clicsB6fEkPR6NwtvqfkuFBW50f9XwcHycdPn4CZnC8qh4DaO45A+VzyOSJE/yVT9EfLwdSpBva6siPqajQyVpuQEMHCCOHTvOtUnrcIaJ9/34SvmfMLIM4g1J4hi4Z5w8nqemilOdh1klmeMBtFjF38eh5P7SOqJ+MljcjtRoaR2oOyEuD9Vwjk0Wr6dqqDj/Q22EfD8/oXSfURsAWhVJFnStGO91w84GEZFWVosJJx9Jh5CIiPTHeK8bdjaIiLRSLKc+Rq+TiIiMxXivG3Y2iIi0MmPcdYWv1hERGY7xXjfsbBARacXRSYiIggPjvW4CswtFRERERESm450NIiKtTBmdhNeEiIgMx3ivG3Y2iIi04m11IqLgwHivG3Y2iIi0UhTjX+AL0BcGiYh8GuO9btjZICLSile6iIiCA+O9btjZ6MGeGHFGY/fEMdI6koelCcsjm1qkdYS6xJkwW+3irKP10fKstodiY4XlVQ55Ns9+FnGW1bEDjkrr2D9ZnC197096zhja6etmDVnZJSL7idsxQJIhfGBso3Qd/RRxHVq+889GibMRp2nIOBt3qThbrKNNnim43SrOKNsUKc/+XR0bIyzfFx0vrcMQHArRb7kFGcS/6j9AuvyhCTHC8rDx4rgBAFa1bwm7XBb5vtAcKj4nnLTK42iLIq4j0SrJMg3gJ5nVwvIjSfI4WX+xQ1he65Rns253ib8ze4j4HDsiTP67JkWIz+XxoeJs6gBQaxGfq7ckD5TWsad/orDcdq48k3lf91EAaFfEv0tziHgfPGiPka6jET3vG23QKYM4471uAnOriIiIiIjIdLyzQUSkFW+rExEFB8Z73bCzQUSkFV8YJCIKDoz3umFng4hIK17pIiIKDoz3umFng4hIK6vFhCRPgXnyISLyaYz3umFng4hIK8Vy6mP0OomIyFiM97oJzIfDiIiIiIjIdLyzQUSkldWEcdeNXh8RETHe64idDSIirSwm3Fa3BOZtdSIin8Z4rxvTOxvLli3D448/jurqaowfPx7PPPMMJk6c2OP8S5cuxXPPPYcDBw4gPj4e11xzDRYtWgSHQ5xptLe2hqQIy7+Iy5DW4YwVZ9FsV/veg1WgCstDLfJsoA5FnCHVYZFnHY2GOCP2eeEHpHVcFC7O+hmaIm9HqB7ZTyVZetsV8WHjhDyrbYtFnKH3kCVGWsf3keKs2q395NnU29PE29pTxuXe0LIP2izi395uEe+j/SDP8qsLXunqM7Ni/knVCrfa/bG7oXWIfPkO8fHU4tRwvLn6djzZQ+THUpgqPhb621uldaSGiLN7R+OktI506zFheYxdXkekIm6rlmzXsqzrJ0PEv1tziHw/a7CGCctPWORZ2/d1xArLt7SL/yYBgKY28XmlpV3+J5/L3feYL9tPo+zivxesLvnvmuzoOSu70933vwNONYTxXi+mdjZWrVqFoqIilJSUICcnB0uXLkVBQQF27tyJxMTE0+ZfuXIl5s6di+XLl+O8887Drl27MHPmTFgsFixZssSELSCioMIXBvuEMZ+I/AbjvW5M7WwsWbIEs2fPxqxZswAAJSUlWLNmDZYvX465c+eeNv/GjRtx/vnn44YbbgAAZGZm4vrrr8dnn33W4zra2trQ1vbvXnRjo/iKDRFRj3ilq08Y84nIbzDe68a0rXI6ndi8eTPy8/P/3RhFQX5+PsrLy7td5rzzzsPmzZuxadMmAMCePXuwdu1aTJkypcf1LFq0CNHR0Z5Penq6vhtCRERSjPlERMHJtDsbdXV1cLlcSEpK6jI9KSkJO3bs6HaZG264AXV1dbjgggugqio6Ojpw66234t577+1xPfPmzUNRUZHn/42NjTz5ENGZ4W31M8aYT0R+hfFeN351v6asrAyPPPIInn32WVRUVOCtt97CmjVrsHDhwh6XsdvtiIqK6vIhIjojnbfVjf4EKcZ8IjIN471uTLuzER8fD6vVipqami7Ta2pqkJyc3O0yDzzwAG6++Wb8+te/BgCMHTsWzc3NmDNnDu677z4oSmD+SETkI3il64wx5hORX2G8141pkdpms2HChAkoLS31THO73SgtLUVubm63y7S0tJx2crFaTw0zqqriIWCJiPpMMeEqV4D8Qc2YT0R+hfFeN6aORlVUVIQZM2YgOzsbEydOxNKlS9Hc3OwZqWT69OlIS0vDokWLAABXXnkllixZgrPPPhs5OTnYvXs3HnjgAVx55ZWeExAREfkmxnwiouBjamdj2rRpqK2txfz581FdXY2srCysW7fO8wLhgQMHulzVuv/++2GxWHD//ffj0KFDSEhIwJVXXomHH37YrE0gomDC2+p9wphPRH6D8V43pmcQLywsRGFhYbdlZWVlXf4fEhKC4uJiFBcXG9AyIqIfUUy4zR1gt9UZ84nILzDe68b0zoav2tkcLyz/el9/aR2Hvo8QlicctknrCG0Xl7dEuIXlTRltwnIAGD6kUVielVYrreOc0EPi8qP7pXWM2CeuI2lPjbAcAHD0hHwemf7i361mcJKwfGdmmnQVFf0HCst3t8vr2HIoQVi+63v5KDyRB+zC8vAT8sDXHiour011SutIGyL+3cZlHhWWnxNRJV2HLqwArAZfeeLTQrpwQYGrh9cUv9x3evbyH6vaHiksz9zhkNYRU9O3H7MqySWdZ+f4FmH5qNHHpXUo6eL3YVJDxOcMABh/9KCwfPSeSmkdcbskx/WRJmkdUinRwuL6IeJ4DwDfDMkQlpfHD5bWUdsaLiz/fLd8Hz3xrfjclbFTvo9GHBPHfLdV/q5U1YAOYXnlWPE+Omyw/DwePbDn84rTJTkpacV4rxt2NoiItOKVLiKi4MB4rxt2NoiItOIzvEREwYHxXjeB2YUiIiIiIiLT8c4GEZFWVosJz/AG5pUuIiKfxnivG3Y2iIi04jO8RETBgfFeN+xsEBFp5LZY4Db4mVq3JTCvdBER+TLGe/2ws0FEpJFbUeA2+MqT0esjIiLGez2xs0FEpJFbMeFKV4COTkJE5MsY7/UTmF0oIiIiIiIyHe9s9OBgvTgTZ/OmGGkdP1srzgia+aU8VaTjhLiX25Aizua5/QJ5xtDPrhCvIz1enqU13CrOEj34sDz7d9KGbeIZ1n8nrQPf1cvnkRkWJyxOunSYsLx9svyw2hGbIiw/2ib/3bbtFGe+zXlXnkF81CfiTKsxVfKrLK0R4n1w39nybdk0RfydHYxqE5afIz5cdeOyKnBZjb1GY/T6ApVLtaJD7T7mVtXI99FRm8TxfPwHNmkdiXvEx5MiSRBeP0CevVmWpfzrSHF2ZwAYmSyOCw6lXVpHRk2tsDzuk13SOrD6W3H51/LzCmyS82x2mrA47rIR0lVk9hPvP9tiU6V1ON3idh4+LN9HL/hYvI+OlMR7AIg72Ld9FACqh4mPhYrLxNu62+6WruPs9J7raJd8l1ox3uuHnQ0iIo14W52IKDgw3uuHnQ0iIo1URYFq8At8Rq+PiIgY7/XEzgYRkUa80kVEFBwY7/UTmF0oIiIv6Dz5GP3prWXLliEzMxMOhwM5OTnYtGlTj/Nu27YNv/jFL5CZmQmLxYKlS5f24RsiIgoM/hLv/QE7G0REAWTVqlUoKipCcXExKioqMH78eBQUFODIkSPdzt/S0oLBgwdj8eLFSE5ONri1REQU6PgYFRGRRqeuPBmd5Kl3V7qWLFmC2bNnY9asWQCAkpISrFmzBsuXL8fcuXNPm//cc8/FueeeCwDdlhMRBSN/iPf+gp0NIiKNVIvxt7lVy6n1NTY2dplut9tht9u7THM6ndi8eTPmzZvnmaYoCvLz81FeXu79xhIRBQgz432gYWeDiEgjl0WBy2LwuOv/t7709PQu04uLi7FgwYIu0+rq6uByuZCUlNRlelJSEnbs2OHVdhIRBRIz432gCcytIiLyAjNfGKysrMTx48c9nx/evSAiIn350wvivj4oCO9s9KDDJe6HOVrk/bSIevE8UbXyncohSd7ttorr6Hdc3s6Qk+J5XJLvAgAUVZzZNtQpz1qLRnGWaNSflNdxpFk+j0z/MHG5pJ1atlX2fWn5zmW/m5bfPuqIeP+J6v6d4i5sJ8V1yI4DQH48yY5Ho5gxWkjn+qKiohAVJc4KHx8fD6vVipqarpmVa2pq+PK3gKLIM3NL69CQWTlEEuJskhDnaJLveyGS5N4tzfLsyi63+HgLUeUZnhW35DvVchyFSTJeS85/msgyjIfKv68Oq3ieUA3fV4ginkfLqwMuSVNDnPI6bC19r8NxQrKOVvHv1npSwz6q9vyFuFR9YrSZ8b43OgcFKSkpQU5ODpYuXYqCggLs3LkTiYmJp83fOSjIL3/5S9x11116NFvKN87gRETUZzabDRMmTEBpaalnmtvtRmlpKXJzc01sGRERecMPBwUZPXo0SkpKEB4ejuXLl3c7/7nnnovHH38c11133Wnv/XkL72wQEWnkDxlli4qKMGPGDGRnZ2PixIlYunQpmpubPaNTTZ8+HWlpaVi0aBGAUy+Vf/vtt55/Hzp0CFu2bEFERASGDh2q78YQEfkJM+O9lgFBAP8ZFISdDSIijfzhtvq0adNQW1uL+fPno7q6GllZWVi3bp3npfEDBw5A+cEJ9PDhwzj77LM9/3/iiSfwxBNPYNKkSSgrK9NlG4iI/I2Z8V7LgCCA/wwKws4GEZFGbkUxYdz13q+vsLAQhYWF3Zb9uAORmZkJVfIOERFRsDEz3ldWVnZ5R8+ox528hZ0NIiKN3BYL3AaPg270+oiIyNx4r2VAEMB/BgXhC+JERBr501CIRER05vwh3vvLoCC8s0FERERE5If8YVAQdjaIiDRSTXiG1+jRUIiIyH/ivT8MCsLOBhGRRi5Y4DL4GV4X+BgVEZHR/Cne+/qgIOxs9CAuUpzqdddIeTbrLZeKe6hHBkmyowJwnBDveMcTxFlH946VpKwFEDdQvC2RdnnK0FZFvCvVJMRI60iakCGdR2psknwemQEx4nJJO7Vsq+z70vKdy363by6Q71/N0eIRLqJr5VdZWiPEQevwUElKYwC1kuNpiOR4NMqpZ2qNHp2EnQ09WCwqFEv3++rANEnaZADbfiI+nlr7ybNEJxwUH/e2k+LfujFenqZ83xhx7EgfID93OULE62lR5LGlMrG/sDxq4mBpHVFJkhdkrxglrQNWyfGaGCksrhokP6ccjo8Tlrcp8ozYMTZxjBs8SJKWG8C288T7V3OMQ1pHXJW4rYp8F8SxJPGx8P148T6YlirfR3s6lmVlvcF4rx92NoiINFItFqgGX+kyen1ERMR4ryd2NoiINPKHpH5ERNR3jPf64ZuHRERERETkFbyzQUSkkduiwG0x+Bleg9dHRESM93piZ4OISCPeViciCg6M9/phZ4OISCO3xQK3wS/wGb0+IiJivNcTOxtERBq5FQUuw4dCDMzb6kREvozxXj/sbBARacQrXUREwYHxXj+B2YUiIiIiIiLT8c4GEZFGvNJFRBQcGO/1w85GD4bF1AvLo37SJq3j6FiHsPxYa6i0DrdbvOOFWN3C8hHh7dJ19A9vEZan2E9I62hS7MLyLakDpXUcio0VlsfkjpHWEeaUb6/MSZv4d2kIDxeW14ZFSdch+760fOfnjawSlh/NOC6to/Ey8baecMlvfiqKKiyPd8h/kxH9WoXlSY5maR1GUBUFqsHP1Bq9vkBlhQtWuLoty808LF1+ePIxYXlDnjjeA0Bzm/iU2+QSx3urVXysAcAYyfGW2E8c7wEg1d4oLG+wiGMgAGxNSBeW74lNlNZhP6dDWB7i7v737I0OxSosbwmxSetoVcRxtM0iP9en2sTfed5g8bkeAOrSJPvopeLzDgA0tonbqsqbAVuoeKZsu3gf7WeTnzOiQnr+G8wZ4pQurwXjvX7Y2SAi0ohXuoiIggPjvX7Y2SAi0ognHyKi4MB4rx92NoiINHLDhJMPAvPkQ0Tkyxjv9ROYD4cREREREZHpeGeDiEgjt0WB22JwkieD10dERIz3emJng4hII7fF+GdqJQPSERGRFzDe68f0LtSyZcuQmZkJh8OBnJwcbNq0STh/Q0MDbr/9dqSkpMBut2P48OFYu3atQa0lomDmVixwGfxxK4F19mHMJyJ/wHivH1PvbKxatQpFRUUoKSlBTk4Oli5dioKCAuzcuROJiaePwe10OnHppZciMTERb775JtLS0rB//37ExMQY33giCjq8rd43jPlE5C8Y7/VjamdjyZIlmD17NmbNmgUAKCkpwZo1a7B8+XLMnTv3tPmXL1+O+vp6bNy4EaGhpxLPZGZmGtlkIgpiqsUC1eDb6kavz5sY84nIXzDe68e0zobT6cTmzZsxb948zzRFUZCfn4/y8vJul1m9ejVyc3Nx++234+9//zsSEhJwww034J577oHV2n0W0La2NrS1/TvTZGOjOEtnp7HWamF5nl2ehTVCEWcZt/UTZ0cFAIsqzhgr2zGbNWQ/bQoJE5Y3WMTlAFAPcUbZjUqctI5Guzi76QlJllYAcHaIs8FqYQsRZ6WNCBVnN42S/O4AEAfx/pNhEWeCBYBxNnHW40jlpLSOfg5xplXZ/gfI90GnIg8zJ0LFv32DVbx/yfY/Mp/ZMV+BCgXd78/nKAel7Y8POSEsj7DLj/swRXy8tYWIj5V2DcdSo00cr+tD+8nrsIizoe/viJHW8aUzWVje0Kol47o45rt0eMBdFu+jw+TZqOMd4libapX/3RErOScMVo5K64izNgvL+9lbpXXYreK/S2T7KAC0WcW/m2wf3RMaL11Hq+DP1zar/NxHxjLtfk1dXR1cLheSkpK6TE9KSkJ1dfd/6O/ZswdvvvkmXC4X1q5diwceeABPPvkk/vjHP/a4nkWLFiE6OtrzSU9P13U7iCh4uGEx5RMIGPOJyJ8w3uvHrx4Oc7vdSExMxPPPP48JEyZg2rRpuO+++1BSUtLjMvPmzcPx48c9n8rKSgNbTESBpDOjrNGfYMWYT0RmYbzXj2mPUcXHx8NqtaKmpqbL9JqaGiQnd3/7NSUlBaGhoV1un48aNQrV1dVwOp2w2U5/ZMhut8MueTyHiEgLvjB45hjzicifMN7rx7StstlsmDBhAkpLSz3T3G43SktLkZub2+0y559/Pnbv3g232+2ZtmvXLqSkpHR70iEi0hOvdJ05xnwi8ieM9/oxtQtVVFSEF154AX/5y1+wfft2/Pa3v0Vzc7NnpJLp06d3eZnwt7/9Lerr63HHHXdg165dWLNmDR555BHcfvvtZm0CEQURl8ViyidQMOYTkb9gvNePqUPfTps2DbW1tZg/fz6qq6uRlZWFdevWeV4gPHDgABTl3/2h9PR0vPfee7jrrrswbtw4pKWl4Y477sA999xj1iYQEZFGjPlERMHH1M4GABQWFqKwsLDbsrKystOm5ebm4tNPP/Vyq4iITmfGbe5Au63OmE9E/oDxXj+mdzaIiPyFGwrcBj99avT6iIiI8V5P7GwQEWllMT6jLAL0ShcRkU9jvNcNOxs9GNYkziB+zq690jqStknGd99fL29IqzhbNWIk2b2HJYnLAeweLU569VnmUGkde0PFGcI/rxJnkwWAr7+NEZYP2CbPEh1b3fdd+liyOIPqwTHiTK/jRjdI1/GTVHH27zHtVdI6cvbtFpYP/VZDfoHvasTlDRoysTokmd0HyrPH14wR74MVwwcJyz+LGixdhx54W91/2Swu2CzdZ4seUy8+HgFg3O79wvK4HfI6cPi4uPwHo251KylKuooTI1KE5VuHZUjrKE8Sx/x6pzz79+e7xeeepq/k25KxUzyEcdTRvl8FPpoiziC+abw8Bo4ad0xYHpouXgcADLSI/x4Yf+SAtI4xu8UxP2Kn/LyCGkm2c0XDdz4gRlhcP1y8j24Yd5Z0Fd+FJfRY1gp5pnQtGO/1w84GEZFGZmR4DdSMskREvozxXj+B+XAYERERERGZjnc2iIg0OnVb3eiMsoF5pYuIyJcx3uuHnQ0iIo14W52IKDgw3uuHnQ0iIo34wiARUXBgvNcPOxtERBq5YIHL4CtPRq+PiIgY7/XEzgYRkUa80kVEFBwY7/XD0aiIiIiIiMgreGeDiEgjFRaoBt/mNnp9RETEeK8ndjZ6kNQozqKZtGWfvJLV28TlX2jIOHuiTVw+QJKF9YKB0lUMtYt3gx1padI6Wq3iOg5U9ZPWMfqjSGF51vvibLIAkLqj7wfq4ZE2YfmWn1mF5QdiJVnfAWQli7+v6HZ51tqh30uywf5Dsv8BwCfirMg4KMkmCwARkt8lO1VaRVK7OMNuUnJ/cQXyZMS6UC2K4UMhqgavL1CFQkUous/QPaDuqHT5uI3fiWd4R8Px9qXkmLVKfutx4qzcABBx1WhheWY/efbvnf3FGZ5dbvk+eeSIeD1nfx4mrWP0R6HC8vj98nivSJJ31w1UheX9GuXb+l28U1h+Vqp4OwCgnyKuI6OqVlpHxIc7xDP8/VtpHdheJy4P1/BnY066sDjuKvG2pmeI9z8AqLVF9Fh20iU/f2rBeK8fdjaIiDTiUIhERMGB8V4/7GwQEWnEkw8RUXBgvNdPYN6vISIiIiIi0/HOBhGRRrzSRUQUHBjv9cPOBhGRRi6LBS6Dx0E3en1ERMR4ryd2NoiINOKVLiKi4MB4rx92NoiINHJDgdvgV92MXh8RETHe66nXWzVjxgx89NFH3mgLEZFP60zyZPSnt5YtW4bMzEw4HA7k5ORg06ZNwvnfeOMNjBw5Eg6HA2PHjsXatWs9ZYz5RBSM/CXe+4NedzaOHz+O/Px8DBs2DI888ggOHTrkjXYREdEZWLVqFYqKilBcXIyKigqMHz8eBQUFOHLkSLfzb9y4Eddffz1uueUWfPnll5g6dSqmTp2Kb775BgBjPhER9U2vOxvvvPMODh06hN/+9rdYtWoVMjMzcdlll+HNN99Ee7s8czIRkb/qfIbX6E9vLFmyBLNnz8asWbMwevRolJSUIDw8HMuXL+92/qeeegqTJ0/G3XffjVGjRmHhwoU455xz8Oc//xkAYz4RBSd/iPf+4oze2UhISEBRURGKiopQUVGBl156CTfffDMiIiJw00034bbbbsOwYcP0bisRkalUE04GnbfVGxsbu0y32+2w2+1dpjmdTmzevBnz5s3zTFMUBfn5+SgvL++2/vLychQVFXWZVlBQgHfeecfz/0CI+RaoUKCeeQWOUHF5XLi8jmiHuNwlaZ9seQAItwmL223y077se7Iqbmkd1lDxPG6r/LdQXOLykDZpFQhxisttLbLl5cd7m1N83bbdreG6rh6P6vcT//aIC5PXESmpw2aV1xFtF5dLjqX2EPk+6rL0/IWJynrDzHgfaPr0i1RVVWH9+vVYv349rFYrpkyZgq1bt2L06NH405/+pFcbiYh8gplXutLT0xEdHe35LFq06LT21dXVweVyISkpqcv0pKQkVFdXd7tN1dXVmudnzCeiYME7G/rpdWejvb0df/vb33DFFVdg4MCBeOONN3DnnXfi8OHD+Mtf/oIPPvgAf/3rX/HQQw95o71ERKZxAXDBYvDnlMrKShw/ftzz+eHdC29izCeiYGRmvO8tPQcF8YZeP0aVkpICt9uN66+/Hps2bUJWVtZp81x88cWIiYnRoXlERL7DjNFCOtcXFRWFqKgo4bzx8fGwWq2oqanpMr2mpgbJycndLpOcnCycnzGfiIKRmfG+NzoHBSkpKUFOTg6WLl2KgoIC7Ny5E4mJiafN3zkoyKJFi3DFFVdg5cqVmDp1KioqKnDWWWfpsRmn6fWdjT/96U84fPgwli1b1u1JBwBiYmKwd+/evraNiIh6wWazYcKECSgtLfVMc7vdKC0tRW5ubrfL5ObmdpkfANavX++ZnzGfiMh36T0oiDf0+s7GzTff7I12EBH5PH/IKFtUVIQZM2YgOzsbEydOxNKlS9Hc3IxZs2YBAKZPn460tDTPOx933HEHJk2ahCeffBKXX345Xn/9dXzxxRd4/vnnATDmE1FwMjPeaxkQBPDeoCB6YwZxIiKNXKoFLtXYk09v1zdt2jTU1tZi/vz5qK6uRlZWFtatW+d5CfzAgQNQlH/f1D7vvPOwcuVK3H///bj33nsxbNgwvPPOO167nU5E5A/MjPfp6eldphcXF2PBggWnzS8aFGTHjh3drqM3g4LohZ0NIiKN/OHOBgAUFhaisLCw27KysrLTpv3yl7/EL3/5y16vh4goUJkZ7ysrK7u8o9fdXQ1/ws4GEZFG/vLCIBER9Y2vDwgCeGdQEG/QJ/MJEVEQcEMx5UNERMbyh3jvjUFBvIF3NnpQI+lR1mRlSutICpVk2sweIG9Ia7u4PEaSEXRYkrgcwO4hKcLy46HyrKMOpUNYnpHSLK3j6wvFWUUb+8tHoI6t7vsufSxZvC0Hx4hTzo7TsK2y70vLdy773YZeJl7HqZnixeUNJ+V1yDIrD4yTVlEzJl1cruEKD5GIKBvwwfj+0uVjsgcJy+MTI+WNmDxCPo9Iovw4qBqYICyvTJBva6siPqZjbPLU3Znp4ji4RRLvAaAxXpyFPLZKns06VJIBvDFefF7Zc1ardB0DUsXnhDCrPBY3K+LM3QdSxL8rAPT7yRBheVRajLQOHJfEfKuGP4aTxfvpgUzx3yVH+sn38yal58eKWmWp5wOM3oOCeAM7G0REGqmqBW6DXxhUDV4fERH5T7z3h0FB2NkgItKoM8ur0eskIiJj+VO89/VBQdjZICLSSFUtht9p4J0NIiLjMd7rh50NIiKN/GXoWyIi6hvGe/2ws0FEpJE/JPUjIqK+Y7zXD8dUJCIiIiIir+CdDSIijXhbnYgoODDe64edDSIijfjCIBFRcGC81w87G0REGvFKFxFRcGC81w87Gz34LjJZWF47Xp7hMmL0SGG5zS3PKmpRVWG5ahHvmM0h4qykANAUIs5W3WCVZ7OOtoizrJ6bUi2tY0TCMWH5ifPkGWedHfKMsjIDQsTZR3NDxVndo0Lk2XWjFfH3VWWLltZRNmS0sHzzQHHGYwDod6lTWC7b/wD5PuhU5GHmRGjP2WABoCEkXFqHEdwmJHkyen2BSvSHw5a4DOny+6LiheWh4+RZi0PUvmU2dkuONQBok2T/PikpPzWP+LyRbGmS1pE3UJz9e2RyvbSOhkkOYXlruzzet7nFr6ZGSuO9/DzdP0ycdTspVP591Vv6CcsrEgdK69gZnyIsD82Wb4uiIebLdFjEv0ubVbwPHg6Rn/9a0HMdbdAngzjjvX7Y2SAi0shtwugkgXryISLyZYz3+uFoVERERERE5BW8s0FEpJEKQDX4mdq+P9RARES9xXivH3Y2iIg04jO8RETBgfFeP+xsEBFp5FItUJhRlogo4DHe68cn3tlYtmwZMjMz4XA4kJOTg02bNmla7vXXX4fFYsHUqVO920AiIgBu1ZxPIGG8JyJ/wHivH9M7G6tWrUJRURGKi4tRUVGB8ePHo6CgAEeOHBEut2/fPvy///f/kJeXZ1BLiSjYdSZ5MvoTKBjvichfMN7rx/TOxpIlSzB79mzMmjULo0ePRklJCcLDw7F8+fIel3G5XLjxxhvx4IMPYvDgwcL629ra0NjY2OVDRETG83a8BxjziYh8jamdDafTic2bNyM/P98zTVEU5Ofno7y8vMflHnroISQmJuKWW26RrmPRokWIjo72fNLT03VpOxEFn84XBo3+BAIj4j3AmE9E+mC814+pnY26ujq4XC4kJSV1mZ6UlITq6u4zTn/yySf47//+b7zwwgua1jFv3jwcP37c86msrOxzu4koOHVmoTb6EwiMiPcAYz4R6YPxXj9+NRpVU1MTbr75ZrzwwguIj4/XtIzdbofdbu/1ura6koXlNW39pHUcbXYIy5tbQ6V1uN3iHS/E6haWR4W3S9fRP7xFWJ7mOCGtI8VyXFg+0l0jrSOhTfy4Q0yLuJ0AEOaUb6/MSZv4d2kIDxeW1ypR0nUcskYLyw+osdI6yp3iK7ZHW8TtBIDGFvG2drjk1yMURfxGWz+Hhn2wX6uwPMnSLCxPCzHmURmOTmKcM4n3QM8x/6RqhVvt/pS3oVn+eFZjq/g80qQhnrtcffstQ0PE8R4AosKcwvKkfvI4mmITH0/xEB+PADBIrReWx2moI0Yyj01xSetwhlqF5SdDbcLyRpv4PA4AR0MjhOX1FvnfC3s64oTln7emSeuoPylu64mTGv7mkMQbxSJ/g9kWKt5PY8LahOWOkA7pOtLCm3osc7rl+4UWjPf6MbWzER8fD6vVipqarn+I1tTUIDn59D/2v//+e+zbtw9XXnmlZ5rbfWqnDgkJwc6dOzFkyBDvNpqIgpYZL/AFyguDjPdE5E8Y7/VjamfDZrNhwoQJKC0t9Qxn6Ha7UVpaisLCwtPmHzlyJLZu3dpl2v3334+mpiY89dRTfDaXiLxKdVukdxu9sc5AwHhPRP6E8V4/pj9GVVRUhBkzZiA7OxsTJ07E0qVL0dzcjFmzZgEApk+fjrS0NCxatAgOhwNnnXVWl+VjYmIA4LTpRETkWxjviYiCj+mdjWnTpqG2thbz589HdXU1srKysG7dOs9LhAcOHICimD5CLxERXKoFFj7De8YY74nIXzDe68f0zgYAFBYWdnsbHQDKysqEy7788sv6N4iIqBtmDE0YaEMhMt4TkT9gvNePT3Q2iIj8gQoTXhgM0KEQiYh8GeO9ftjZICLSiFe6iIiCA+O9ftjZICLSyK2e+hi9TiIiMhbjvX74Jh4REREREXkF72z04LsGcTbPT7ckSOsY+Lk4a2jqbnk2T8cJ8S214wniTJ07x4ozdQIAzhVni71gVJW0iuH2I8LyrMP7pXWMq9gtnmHzAWkdONggn0dmQIy4fEKGsPjrc4ZKV9GYPkJYXtEmzkgLABt3pIhn+FyeyXzQVnFW5Oha+fWI1gjxpZjDQ+UZxDefK84U/JOsWmF5WrxBGcTdFlgMHgfdFaDjrhutHSFQejjlbdkjz1De9JX4eMrcLj6WAKD/YXE2a5ljSfIM4uUTxBnCM85ukNYxcaB4PYNCxNnBAWDU0UPC8vG75OeEiG/FdaCm5yzSmqVGC4tPjJDEWQBfDR8oLP8kaZi0jtrWcGH5ph2J0jrULeJ9NGOHOFs6AMTWiWO+W8MuXDdAnMF7kyTeDxkm/13jBrf2WOZ0yf+20oLxXj/sbBARacSMskREwYHxXj/sbBARacQXBomIggPjvX7Y2SAi0sjtthh+m9sdoLfViYh8GeO9ftjZICLSyG1CRtlAvdJFROTLGO/1w9GoiIiIiIjIK3hng4hII9V96mP0OomIyFiM9/phZ4OISCO3ChNuqxu6OiIiAuO9ntjZICLSyG3CuOuB+sIgEZEvY7zXDzsbREQauVQLYPCVLleAvjBIROTLGO/1w85GD+qbxNlgE3aESevIWu8Qlg/+Qv5+vkOSSLNBkty033H5Oj5KFGd4bhoszzrqCO0QlifVNkjrkGYI/8dOeR3b6+TzyIySZxMWSUqXL+9IE39fTW3y77x+v3gfvPAT+T56Vqk4BMTIk8ejNVJcvidbnnK2JVL8oGr9EEl25r79ZJqpbgtUg688Gb2+QKUKxsyvPSrP/j3qG3E8H/+B/JhN3CP+LUPaxMvXZcqfsXA0i9fxZYI43gPAmDRxXHAo4vgFAANrxLE44pPvpHXgza3i8m+OyOuwS+JPdpqwOGKqU7qKgdH9hOXb4gdI6+hwi8/VtXXyffS8zeJ5Rv9Tnlk77mDf4031MPH+EyLZBXdFyvevtsyef9d2LWnONWC81w9HoyIiIiIiIq/gnQ0iIo3cACwGv8AXoIOTEBH5NMZ7/bCzQUSkkdttAfjCIBFRwGO81w87G0REGvHkQ0QUHBjv9cPOBhGRRqpqgWrwaCFGr4+IiBjv9cTOBhGRRm43DH+o1h2oD/ESEfkwxnv9cDQqIiIiIiLyCt7ZICLSiM/wEhEFB8Z7/bCzQUSkkcuEJE+BevIhIvJljPf6YWejByFW8YNzreHyB+tOxInnaUyQ71TOMPE8jYniQaCbo+Xt7AgTz2OVfBcA4LaI29lu07CrRUkypMbJM2IjUZzJVRPZeiTt1LKtsu9Ly3cu+920/Pay/UdxyffR1ghxHbLjAJAfT7Lj0SiBdqWrvr4ev/vd7/C///u/UBQFv/jFL/DUU08hIiKix2Wef/55rFy5EhUVFWhqasKxY8cQExPjtTYaITREPpi+ahXPoyVpseISl4dIklXLMowDgFWyDmeb/OlplySbtRZuRbLfRsozYiMjRlx+9KTm9vQoQXLOiJC3s9UuzsytqPL9K0QRxzhFkdfRIUkQrmkflSTvlu3DgHw/tkjOK5r2UbXneVw6vWQdaPHeTHxng4hII9VtzsdbbrzxRmzbtg3r16/Hu+++i48++ghz5swRLtPS0oLJkyfj3nvv9V7DiIhMFmjx3ky8s0FEpJHLhKEQ3V5a3/bt27Fu3Tp8/vnnyM7OBgA888wzmDJlCp544gmkpqZ2u9ydd94JACgrK/NKu4iIfEEgxXuz8c4GEZEfaGxs7PJpa9PwTI1AeXk5YmJiPB0NAMjPz4eiKPjss8/62lwiIiIAvLNBRKSZqloMf6a288paenp6l+nFxcVYsGDBGddbXV2NxMTELtNCQkIQFxeH6urqM66XiCgQmBnvAw07G0REGrndgMXgZ2o7n+GtrKxEVFSUZ7rd3v2Lq3PnzsWjjz4qrHP79u26tY+IKBCZGe8DDTsbREQaqSaMTtI59GJUVFSXzkZPfv/732PmzJnCeQYPHozk5GQcOXKky/SOjg7U19cjOTn5jNtLRBQIzIz33mDm6IPsbBARaeR2W2Dx8ZNPQkICEhISpPPl5uaioaEBmzdvxoQJEwAAGzZsgNvtRk5Ozhm1lYgoUPhDvO+NG2+8EVVVVVi/fj3a29sxa9YszJkzBytXruxxmc7RBydPnox58+ad8brZ2SAiCkKjRo3C5MmTMXv2bJSUlKC9vR2FhYW47rrrPCNRHTp0CJdccgleeeUVTJw4EcCpdz2qq6uxe/duAMDWrVsRGRmJjIwMxMXFmbY9RETUPbNHH+RoVEREGrnc5ny8ZcWKFRg5ciQuueQSTJkyBRdccAGef/55T3l7ezt27tyJlpYWz7SSkhKcffbZmD17NgDgwgsvxNlnn43Vq1d7r6FERAYzM94H2uiDvLNBRKRRoN1Wj4uLE95Cz8zMhPqj7McLFizo0yhYRET+wMx4H2ijD7Kz0YMBcSeE5fUTux8J5ofe798hLE+4xCatI7RdXN4SIb7s2ZQh7w2PGdIoLO9vb5XW0aKIt2VPapK0jtCfjhGWJ2XGS+vAUfHvpkn/nl+WAoCaweJt0bKtsu9Ly3c+ZsRxYXlFiCosB4DvzhHvx+En5Dc/20PF5bWpTmkdaUPEv5vseDSK6rIALoNPPgavL1BZLCoUS/fHxOCMJunyX19oFZYf7++S1tG/SnzKDW0V/9bNMfLbXPtGi2NH5sBmaR3hoeJzV4tVfu46kCR+byg8Z4i0jvi0WPEMV8q3BVZJDEuIFBYfyJC//3S4v/jxwTZFvO8AQJwk5g8bLI+BFReL11Of4pDWEXNEXIeiIR4djxcfC3vHiLc1fcBJ6TqsgmGi3D0c571lZrwPtNEH2dkgItLIxaEQiYiCgpnxPtBGH2Rng4hIo0B7jIqIiLrnD/HeX0Yf5AviREREREQB6oejD27atAn/+te/uh19cOTIkdi0aZNnuerqamzZsqXL6INbtmxBfX19r9bPOxtERBqpqgmPNenz+DEREfVCoMX7FStWoLCwEJdccoknqd/TTz/tKe9p9MEHH3zQ8/8LL7wQAPDSSy9JH9/6IXY2iIi08oPb6kREpIMAi/dmjj7IzgYRkUZWF2AxfHQSQD7OERER6YnxXj/sbBARaaSYNDpJIJ58iIh8GeO9ftjZICLSSAmw2+pERNQ9xnv9cDQqIiIiIiLyCt7Z6MGIfnXC8szR4uzNAOAcJc7E2a72va+nSIYuCNVwD9ChiNOUOyzibLIA0AhxZtJN/QdJ69jSP0NYHnq2vB2hOgwd0W4R/y7tiviwcUKeLbbFIs7AO8Am37/iM8XZcy/IkKT2hnwfdKPvV1m07IM2i/jGsd0i3keNYnGd+hgqEO+pm8AKF6w9fJnnDTgsXX50sniox+Pny7Nqn3SKj8kOyVXN/op8qJoBNvGx0l+SqRoAEkLF2aobLGHSOrb0TxeW74hNkdZhyxLHfEXt+9A9bov4O29V5HHUaRHH/FaLvI60UHHMv2iQPAaOGyD+u6XxEvk+2touPr/J9lEASLGKY/5QyT4aouGcER3S1mOZU1DWG4z3+mFng4hIIytvqxMRBQXGe/2ws0FEpJFZLwwSEZGxGO/14xPvbCxbtgyZmZlwOBzIycnpkr3wx1544QXk5eUhNjYWsbGxyM/PF85PRKQXxW2B4jL4E2BXuhjvicgfMN7rx/TOxqpVq1BUVITi4mJUVFRg/PjxKCgowJEjR7qdv6ysDNdffz0+/PBDlJeXIz09HT/72c9w6NAhg1tORMHG8n+31Y3+BArGeyLyF4z3+jG9s7FkyRLMnj0bs2bNwujRo1FSUoLw8HAsX7682/lXrFiB2267DVlZWRg5ciRefPFFuN1ulJaWGtxyIiLqDcZ7IqLgY+o7G06nE5s3b8a8efM80xRFQX5+PsrLyzXV0dLSgvb2dsTFxXVb3tbWhra2f49M0NjY2LdGE1HQUlynPkZyB8joJEbEe4Axn4j0wXivH1PvbNTV1cHlciEpKanL9KSkJFRXV2uq45577kFqairy8/O7LV+0aBGio6M9n/R08XB8REQ9UdwWUz6BwIh4DzDmE5E+GO/1Y/pjVH2xePFivP7663j77bfhcHSf52HevHk4fvy451NZWWlwK4koUHRe6TL6Q9riPcCYT0T6YLzXj6mPUcXHx8NqtaKmpqbL9JqaGiQnJwuXfeKJJ7B48WJ88MEHGDduXI/z2e122O12XdpLRMHNjBf4AuWFQSPiPcCYT0T6YLzXj6mdDZvNhgkTJqC0tBRTp04FAM/Lf4WFhT0u99hjj+Hhhx/Ge++9h+zsbK+0bWxHlbA887g4UycAJB9rEJZHNrVI6wh1ibu5rXZxRtD66AjpOg7FxgrL90QkSOvYY+kvLN/SIv5jAgD2H4sSlh9tkP8B0dQsz9QqE9lPkoE3RpyddGCs/BnxQeHHhOWD1aPSOgafqBWWpx0TrwMA4o6LMwU72pzSOtqt4uy5TZHh0jqqY2OE5fui44Xle0LF5XqxmnDlyfAMtl5idrwPtbh7zGY/AvLRrRI7xMd1XFuztA57uzi2tIeIT8laslk3hIiPt1qr/Jxw1CKeZ2+H+JwBAF+0pgrL607Is5CfOCneXmeH/OEMRfK3m8MmzlIe008eA5MjxL99mk2cHRwA4iGuY5hbHO8BIL5DHM9j2jT8zdEh/j5k+ygAtCjiv0uOSfbR7xxJwnIAaEHP+0ab9aR0eS0Y7/VjelK/oqIizJgxA9nZ2Zg4cSKWLl2K5uZmzJo1CwAwffp0pKWlYdGiRQCARx99FPPnz8fKlSuRmZnpedY3IiICERHyIEpEROZgvCciCj6mdzamTZuG2tpazJ8/H9XV1cjKysK6des8LxEeOHAAivLvqxfPPfccnE4nrrnmmi71FBcXY8GCBUY2nYiCjKKeyiprKNXg9XkR4z0R+QvGe/2Y3tkAgMLCwh5vo5eVlXX5/759+7zfICKibnRmeTWU0evzMsZ7IvIHjPf68YnOBhGRP7C4T32MXicRERmL8V4/7GwQEWlkNeFKlyVAr3QREfkyxnv9sLNBRKSRxYTRSdQAHZ2EiMiXMd7rx6+T+hERERERke/inQ0iIo0UtwWKwUmX1ABN8kRE5MsY7/XDzgYRkUYWl/FJlwI1yRMRkS9jvNcPOxs9GNwgztZ5weffyiv5ZLe4/JsaeR0nxRlnkdBPWDxgwgDpKgZcMFzchLHyzN1b7eJssVsPijOMA0Djx+J5Rpc7pHUk7hVns9biyCDx0f5tbquwvDFPnuU3cag4k2tKmzwLec528f4V98kuaR3YfFBcXivPioww8famnCXPBjv8gqHCcuXc0cLyPQkGZRB3W2A1+gW+AL3SZTQr3LCi+6FeRh6rki5/zvY9wvKIbyTHEgAckmSSdkuGokmNlq7COTJFWP71qExpHRtThwnLj7XJY/HnuxKF5e6KKGkdmdvEmahTavoe7+tTxfH+04nyrNuZ5zQIyx0DxVm5AWCwclRYPq6mUlrHWTv2C8tt3x6W1oFqyblH0fD0fXqMsPjE6DRh+QfnjJWuYme/ns8rrRCfo7VivNcPOxtERBopfGGQiCgoMN7rh50NIiKNFLfxGWXVAB13nYjIlzHe64ejURERERERkVfwzgYRkUYWl8XwpEuBmuSJiMiXMd7rh50NIiKNrK5TH0MF6DO8RES+jPFeP+xsEBFpxBcGiYiCA+O9ftjZICLSyOK2QDH4Nrc7QIdCJCLyZYz3+mFng4hII4v71MfodRIRkbEY7/XD0aiIiIiIiMgreGeDiEgjM14YDNRneImIfBnjvX7Y2ehBVEuLeIY9tfJKPj8oLv9MUg4ATU5xeUqkuNwqv3kVNzRRWG4f3S6to10Vr6e+wS6tY/AOm7B8eLl8d03d3vfnHWOqxXWciBW3c89Y+bbKvi+7S/6dx1U3iGfYclhaB8r2icurmuR1RIq/D5yUbwtSo4XFUWMkx6NBFJfxz/Aavb5AFQoVoej+GYUBtUely0ds2iOeYeUWeSO+qpHPI3JuqnQW23+IzxlpcZJzBoCoxAGam9SThuOhwvJx2yRxA8BZH4rnSdwjPzaUDnH5kSFW8fIa/vjbmdYmLG9Nl5+7+kHyu1XL91Fb2S7xDG9sldaBXZL1hIl/VwDA+enC4oifq8LylKHi5QGgytHzOSPU1SpdXgvGe/2ws0FEpJEZo5MYvT4iImK81xM7G0REGvHkQ0QUHBjv9cPOBhGRRrytTkQUHBjv9cPRqIiIiIiIyCt4Z4OISCPFbcJt9QAdd52IyJcx3uuHnQ0iIo0UF6AYfD84UJ/hJSLyZYz3+mFng4hII4sJJx9LgJ58iIh8GeO9ftjZICLSSHFZoCh8YZCIKNAx3uuHnQ0iIo14W52IKDgw3uuHnY0eNNslWaATo+SVDO0vLj8hyQ6uZZ7kCHH5wFjpKppjwoXl7Yo4wyoAKBBnBI3sJ88iXZcmTvV6eIR8d3VryJguUz1U/IaWrJ1atlX2fWn5zmW/Wz8Nvz3GJIjL+4fJ64iQZAKWHQeA9HiSHo9EEhaoPR53HSHy4w3RkmNhRLy8Dlk875C8HZqm4bwT109Y3OaQZ+6WxSerIi4HgNAQSYyTNwNuDT+LjOyPNz3+uGtzis87brXvV6s7QjSc2xIlfw9o2Udl+6CWdsj2U8mx1BYqz1LusvTcDlEZmYOdDSIijXili4goODDe64edDSIijTgUIhFRcGC81w/vNRERadSZUdboj7fU19fjxhtvRFRUFGJiYnDLLbfgxIkTwvl/97vfYcSIEQgLC0NGRgb+8z//E8ePH/daG4mIzBBo8d5MvLNBRKSR4gIMHpzEq1fWbrzxRlRVVWH9+vVob2/HrFmzMGfOHKxcubLb+Q8fPozDhw/jiSeewOjRo7F//37ceuutOHz4MN58803vNZSIyGCBFu/NxM4GEZFGgXTy2b59O9atW4fPP/8c2dnZAIBnnnkGU6ZMwRNPPIHU1NTTljnrrLPwt7/9zfP/IUOG4OGHH8ZNN92Ejo4OhITwlEJEgSGQ4r3Z+BgVEZEfaGxs7PJpa2vrU33l5eWIiYnxdDQAID8/H4qi4LPPPtNcz/HjxxEVFcWOBhERdYtnByIijcy80pWent5lenFxMRYsWHDG9VZXVyMxMbHLtJCQEMTFxaG6ulpTHXV1dVi4cCHmzJlzxu0gIvJFvLOhH3Y2iIg0sphw8rH838mnsrISUVH/Hr/e3kPukblz5+LRRx8V1rl9+/Y+t6uxsRGXX345Ro8e3adODxGRLzIz3gcadjaIiDRS3MaPFqK4T60vKiqqS2ejJ7///e8xc+ZM4TyDBw9GcnIyjhw50mV6R0cH6uvrkZycLFy+qakJkydPRmRkJN5++22EakjCRUTkT8yM997QOZrg//7v/0JRFPziF7/AU089hYiI7pNB1tfXo7i4GO+//z4OHDiAhIQETJ06FQsXLkR0dHSv1s3ORg8OxIizHof9ZJS0joyB4mydcUeb5A1pF3dzO8LEaVirk+VZpPelJArL6+yR0joireLnx0cOaJDW8d1kccbZD7Lk2azdDX3fpZUYcYbw1OSTwvJhKfJhQGXfl5bv/MvRQ4TlmbHyOpIvHCYsDzmpIct9qDjNb31/eTsOpIgzmcuOR6MoLuNfdOvtbfWEhAQkJEgywwPIzc1FQ0MDNm/ejAkTJgAANmzYALfbjZycnB6Xa2xsREFBAex2O1avXg2Hw9G7BpqkDVb0dMrblZIiXb79p+L9PGVsurAcACKaxLFD5kSkPAYeTowTl8fKzwlN1u7vmnWKssjfFxqcIT6/fXWxPD340TTxvhVXLY/3Fskfi80x4gPswHAN2zqw5+GiAcCm4SCuDxFnft+WmSGt42SY+HeLP3eQtI6IplZhuVvDpf5jMeJM5lWSfbQyUlwOAE5Lz799u6CsN/wh3veGmaMPsrNBRKRRIJ18Ro0ahcmTJ2P27NkoKSlBe3s7CgsLcd1113lGojp06BAuueQSvPLKK5g4cSIaGxvxs5/9DC0tLXjttdc8L6sDpzo5Vqv8D0giIn8QSPHe7NEH2dkgIgpSK1asQGFhIS655BLPbfWnn37aU97e3o6dO3eipaUFAFBRUeEZqWro0KFd6tq7dy8yMzMNazsRUaDqvIjTyW639/ienhay0Qf/4z/+Q1M9Zzr6IDsbREQaBdKVLgCIi4vr8RY6AGRmZkJV//1440UXXdTl/0REgcrMeB9oow+ys0FEpFGgdTaIiKh7Zsb7QBt9kJ0NIiKN2NkgIgoOZsb7QBt9kJ0NIiKNFBegGPwUkeI2dn1EROQf8d5fRh9kZ4OISCPFZYGiBs6460RE1L1Aivdmjz7IzgYRERERUQAzc/RBdjaIiDSymHBb3cLHqIiIDBdo8d7M0QfZ2ejBdoc4o+z2DHnGWcgTfgaMKIizrP4k5qC0Duk88qTtAeNgSIx8ngTJPAkavrBxmppD/8cfnuGl7rWrChS1+9c9v4oYIF1+X7g4i314Rru0DkXt24/ZYZE/ttBitQnLT2rIrtwM8Xj+0RZxlmkA+MmAKmH5OalHhOUA0HqxuK3tbvnru64+PpYyTsMBH2btEJZHWJ3SOg5B/DJwW4z8t/8uKlFYHuYWtxPo+z4KAE5F/Lu1KOJ99IRFnk/i4pqeR1hqlmRB14rxXj/sbBARacSTDxFRcGC814/Ro3p1a9myZcjMzITD4UBOTg42bdoknP+NN97AyJEj4XA4MHbsWKxdu9aglhJRMFNc5nwCCeM9EfkDxnv9mN7ZWLVqFYqKilBcXIyKigqMHz8eBQUFp40H3Gnjxo24/vrrccstt+DLL7/E1KlTMXXqVHzzzTcGt5yIiHqD8Z6IKPiY3tlYsmQJZs+ejVmzZmH06NEoKSlBeHg4li9f3u38Tz31FCZPnoy7774bo0aNwsKFC3HOOefgz3/+s8EtJ6Jgo7hNuNIVQLfVGe+JyF8w3uvH1M6G0+nE5s2bkZ+f75mmKAry8/NRXl7e7TLl5eVd5geAgoKCHudva2vzjA38wzGCiYh6i7fVz5wR8R5gzCcifTDe68fUzkZdXR1cLheSkpK6TE9KSkJ1dXW3y1RXV/dq/kWLFiE6OtrzSU9P16fxRBR0lA5zPoHAiHgPMOYTkT4Y7/Vj+mNU3jZv3jwcP37c86msrDS7SUTkp3ily/cx5hORHhjv9WPq0Lfx8fGwWq2oqanpMr2mpgbJycndLpOcnNyr+e12O+x2+ZjNREQyigtQ+jZsf+/XafDQi95iRLwHGPOJSB+M9/ox9c6GzWbDhAkTUFpa6pnmdrtRWlqK3NzcbpfJzc3tMj8ArF+/vsf5iYjIfIz3RETByfSkfkVFRZgxYways7MxceJELF26FM3NzZg1axYAYPr06UhLS8OiRYsAAHfccQcmTZqEJ598Epdffjlef/11fPHFF3j++ec1ra8z9XpbY4t3NoiIfE7n8d55/J8pp7sRBl/oghOB84Kz0fEe+Pdv7hTE/FZLm7Qem/uksNzi1pJBvG/7X4dFfn2wVZLNulVDBvE2iJ/laFPl2+qUfB9OtzwjdrtkHiMyiLs1XGq2WsXfl1NDBvEQRbwPtlrkf7NY3ZL9WFMG8b5fWncq4t+tVfJiQqtF/iyRKEt4ZxnjvQ9RfcAzzzyjZmRkqDabTZ04caL66aefesomTZqkzpgxo8v8f/3rX9Xhw4erNptNHTNmjLpmzRrN66qsrFQB8MMPP0H4qaysPKMYdfLkSTU5Odm0dicnJ6snT548o7b7GiPjvaoy5vPDT7B+GO99h0VVdejG+hG3243Dhw8jMjISFsupPmtjYyPS09NRWVmJqKgok1t4ZrgNvoHb4Bt+vA2qqqKpqQmpqalQlDN7erS1tRVOp/wKpTfYbDY4HA5T1u3vfhzzA3H/9kfcBt8QiNvAeO97TH+MymiKomDAgAHdlkVFRfntwdaJ2+AbuA2+4YfbEB0d3ae6HA5HwJ0AgkFPMT/Q9m9/xW3wDYG2DYz3viXgh74lIiIiIiJzsLNBRERERERewc4GTo3LXlxc7Ndjs3MbfAO3wTcEwjaQdwTCvsFt8A3cBt8QCNsQ6ILuBXEiIiIiIjIG72wQEREREZFXsLNBRERERERewc4GERERERF5BTsbRERERETkFUHR2Vi2bBkyMzPhcDiQk5ODTZs2Ced/4403MHLkSDgcDowdOxZr1641qKU96802vPDCC8jLy0NsbCxiY2ORn58v3Waj9Pa36PT666/DYrFg6tSp3m2gRG/b39DQgNtvvx0pKSmw2+0YPny43+1PALB06VKMGDECYWFhSE9Px1133YXW1laDWtvVRx99hCuvvBKpqamwWCx45513pMuUlZXhnHPOgd1ux9ChQ/Hyyy97vZ1kHsZ834j5/h7vgcCI+f4c7wHG/ICgBrjXX39dtdls6vLly9Vt27aps2fPVmNiYtSamppu5//Xv/6lWq1W9bHHHlO//fZb9f7771dDQ0PVrVu3Gtzyf+vtNtxwww3qsmXL1C+//FLdvn27OnPmTDU6Olo9ePCgwS3vqrfb0Wnv3r1qWlqampeXp1599dXGNLYbvW1/W1ubmp2drU6ZMkX95JNP1L1796plZWXqli1bDG55V73djhUrVqh2u11dsWKFunfvXvW9995TU1JS1Lvuusvglp+ydu1a9b777lPfeustFYD69ttvC+ffs2ePGh4erhYVFanffvut+swzz6hWq1Vdt26dMQ0mQzHm+0bM9/d4r6qBEfP9Pd6rKmN+IAj4zsbEiRPV22+/3fN/l8ulpqamqosWLep2/muvvVa9/PLLu0zLyclRf/Ob33i1nSK93YYf6+joUCMjI9W//OUv3mqiJmeyHR0dHep5552nvvjii+qMGTNMPfn0tv3PPfecOnjwYNXpdBrVRE16ux233367+tOf/rTLtKKiIvX888/3aju10HLi+cMf/qCOGTOmy7Rp06apBQUFXmwZmYUx3zdivr/He1UNjJgfSPFeVRnz/VVAP0bldDqxefNm5Ofne6YpioL8/HyUl5d3u0x5eXmX+QGgoKCgx/m97Uy24cdaWlrQ3t6OuLg4bzVT6ky346GHHkJiYiJuueUWI5rZozNp/+rVq5Gbm4vbb78dSUlJOOuss/DII4/A5XIZ1ezTnMl2nHfeedi8ebPn1vuePXuwdu1aTJkyxZA295WvHdPkPYz5p5gd8/093gOBEfODMd4DvndMExBidgO8qa6uDi6XC0lJSV2mJyUlYceOHd0uU11d3e381dXVXmunyJlsw4/dc889SE1NPe3gM9KZbMcnn3yC//7v/8aWLVsMaKHYmbR/z5492LBhA2688UasXbsWu3fvxm233Yb29nYUFxcb0ezTnMl23HDDDairq8MFF1wAVVXR0dGBW2+9Fffee68RTe6zno7pxsZGnDx5EmFhYSa1jPTGmH+K2THf3+M9EBgxPxjjPcCY74sC+s4GAYsXL8brr7+Ot99+Gw6Hw+zmaNbU1ISbb74ZL7zwAuLj481uzhlxu91ITEzE888/jwkTJmDatGm47777UFJSYnbTeqWsrAyPPPIInn32WVRUVOCtt97CmjVrsHDhQrObRkQ/4o8xPxDiPRAYMZ/xnrwhoO9sxMfHw2q1oqampsv0mpoaJCcnd7tMcnJyr+b3tjPZhk5PPPEEFi9ejA8++ADjxo3zZjOlersd33//Pfbt24crr7zSM83tdgMAQkJCsHPnTgwZMsS7jf6BM/kdUlJSEBoaCqvV6pk2atQoVFdXw+l0wmazebXN3TmT7XjggQdw880349e//jUAYOzYsWhubsacOXNw3333QVF8+5pFT8d0VFQUr3AFGMZ834j5/h7vgcCI+cEY7wHGfF/k+3tNH9hsNkyYMAGlpaWeaW63G6WlpcjNze12mdzc3C7zA8D69et7nN/bzmQbAOCxxx7DwoULsW7dOmRnZxvRVKHebsfIkSOxdetWbNmyxfO56qqrcPHFF2PLli1IT083svln9Ducf/752L17t+ekCQC7du1CSkqKKR0N4My2o6Wl5bQTTOfJVFVV7zVWJ752TJP3MOb7Rsz393gPBEbMD8Z4D/jeMU0IjqFv7Xa7+vLLL6vffvutOmfOHDUmJkatrq5WVVVVb775ZnXu3Lme+f/1r3+pISEh6hNPPKFu375dLS4u9olhEHuzDYsXL1ZtNpv65ptvqlVVVZ5PU1OTWZugqmrvt+PHzB6dpLftP3DggBoZGakWFhaqO3fuVN999101MTFR/eMf/2jWJqiq2vvtKC4uViMjI9X/+Z//Uffs2aO+//776pAhQ9Rrr73WlPY3NTWpX375pfrll1+qANQlS5aoX375pbp//35VVVV17ty56s033+yZv3MYxLvvvlvdvn27umzZMg6DGMAY830j5vt7vFfVwIj5/h7vVZUxPxAEfGdDVVX1mWeeUTMyMlSbzaZOnDhR/fTTTz1lkyZNUmfMmNFl/r/+9a/q8OHDVZvNpo4ZM0Zds2aNwS0+XW+2YeDAgSqA0z7FxcXGN/xHevtb/JAvnHx62/6NGzeqOTk5qt1uVwcPHqw+/PDDakdHh8GtPl1vtqO9vV1dsGCBOmTIENXhcKjp6enqbbfdph47dsz4hquq+uGHH3a7f3e2ecaMGeqkSZNOWyYrK0u12Wzq4MGD1ZdeesnwdpNxGPN9I+b7e7xX1cCI+f4c71WVMT8QWFTVT+6LERERERGRXwnodzaIiIiIiMg87GwQEREREZFXsLNBRERERERewc4GERERERF5BTsbRERERETkFexsEBERERGRV7CzQUREREREXsHOBhEREREReQU7G0RERERE5BXsbBARERERkVews0FERERERF7BzgYFtNraWiQnJ+ORRx7xTNu4cSNsNhtKS0tNbBkREemNMZ/I91hUVVXNbgSRN61duxZTp07Fxo0bMWLECGRlZeHqq6/GkiVLzG4aERHpjDGfyLews0FB4fbbb8cHH3yA7OxsbN26FZ9//jnsdrvZzSIiIi9gzCfyHexsUFA4efIkzjrrLFRWVmLz5s0YO3as2U0iIiIvYcwn8h18Z4OCwvfff4/Dhw/D7XZj3759ZjeHiIi8iDGfyHfwzgYFPKfTiYkTJyIrKwsjRozA0qVLsXXrViQmJprdNCIi0hljPpFvYWeDAt7dd9+NN998E1999RUiIiIwadIkREdH49133zW7aUREpDPGfCLfwseoKKCVlZVh6dKlePXVVxEVFQVFUfDqq6/i448/xnPPPWd284iISEeM+US+h3c2iIiIiIjIK3hng4iIiIiIvIKdDSIiIiIi8gp2NoiIiIiIyCvY2SAiIiIiIq9gZ4OIiIiIiLyCnQ0iIiIiIvIKdjaIiIiIiMgr2NkgIiIiIiKvYGeDiIiIiIi8gp0NIiIiIiLyCnY2iIiIiIjIK/4/05MUnxZKz7cAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 900x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(9,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.pcolormesh(x_low, y_low, w_low_tensor.cpu().data.numpy(), cmap='rainbow')\n",
    "cbar = plt.colorbar(pad=0.05, aspect=10)\n",
    "#cbar.mappable.set_clim(-0.03, 0.03)\n",
    "plt.title('LR')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(1,2,2)\n",
    "plt.pcolormesh(x_low, y_low, out.cpu().data.numpy()[0], cmap='rainbow')\n",
    "cbar = plt.colorbar(pad=0.05, aspect=10)\n",
    "#cbar.mappable.set_clim(-0.03, 0.03)\n",
    "plt.title('DownSampled')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upscale by 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_low = 30\n",
    "N_high = 120\n",
    "scale = 4\n",
    "a,b,c = 8,5,5\n",
    "\n",
    "h_low = 1/(N_low-1)\n",
    "x_low = np.arange(0,1.0001,h_low)\n",
    "y_low = np.arange(0,1.0001,h_low)\n",
    "\n",
    "h_high = 1/(N_high-1)\n",
    "x_high = np.arange(0,1.0001,h_high)\n",
    "y_high = np.arange(0,1.0001,h_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_low, r_low, A_low, x_low, y_low = generate_data(N_low,a,b,c)\n",
    "w_high, r_high, A_high, x_high, y_high = generate_data(N_high,a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Parameters for prior variance\n",
    "prior_sigma = 0.002\n",
    "ll_sigma = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.eye(N_high**2) * prior_sigma**2\n",
    "G_inverse = np.eye(N_high**2) * (1/prior_sigma**2)\n",
    "\n",
    "# Turn matrices to tensors\n",
    "G = torch.tensor(G).to(torch.float32).to(device)\n",
    "G_inverse = torch.tensor(G_inverse).to(torch.float32).to(device)\n",
    "A_high = torch.tensor(create_A(N_high)).to(torch.float32).to(device)\n",
    "b_high = torch.tensor(create_forcing_term(N_high,a,b,c)).to(torch.float32).to(device)\n",
    "\n",
    "# Store sparse matrices as sparse tensor\n",
    "A_high = A_high.to_sparse()\n",
    "G = G.to_sparse()\n",
    "G_inverse = G_inverse.to_sparse()\n",
    "operator = torch.spmm(A_high.T,G_inverse).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(w_low).to(torch.float32).to(device)\n",
    "posterior_initial = torch.randn(*[N_high,N_high]).to(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = DownScale().to(device)\n",
    "# G.load_state_dict(torch.load('models/train_NN/model3/31_121/lr0.01_gamma0.1/ckpt/best_model.pth')['netG'])\n",
    "G.load_state_dict(torch.load('models/train_NN/model1/30_120/lr0.01_gamma0.5/ckpt/best_model.pth')['netG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Langevin dynamics\n",
    "K = 1000\n",
    "s = 0.0004\n",
    "\n",
    "z = posterior_initial\n",
    "chains_evolution = []\n",
    "z = z.clone().detach().requires_grad_(True)\n",
    "for i in range(K):\n",
    "    # Grad log-likelihood\n",
    "    x_hat = G(z.reshape(1,N_high,N_high)).reshape(N_low,N_low)\n",
    "    log_likelihood = (-1/(2*math.pow(ll_sigma, 2)) * torch.matmul((x-x_hat).reshape(1,N_low**2),(x-x_hat).reshape(N_low**2,1)))\n",
    "    grad_ll = torch.autograd.grad(log_likelihood, z)[0]\n",
    "    # grad_log_likelihood = torch.matmul(G,grad_ll.reshape(N_high**2,1)).reshape(N_high,N_high)\n",
    "    \n",
    "    # Grad prior\n",
    "    difference = torch.spmm(A_high,z.reshape(N_high*N_high,1)) - b_high.reshape(N_high**2,1)\n",
    "    # log_prior = - 0.5 * difference.T @ G_inverse @ difference\n",
    "    # grad_log_prior = torch.autograd.grad(log_prior, z)[0]\n",
    "    grad_log_prior = (- torch.spmm(operator,difference)).reshape(N_high,N_high)\n",
    "    \n",
    "    # Random noise term\n",
    "    W = torch.randn(*[N_high,N_high]).to(device)\n",
    "    # random = torch.matmul(G_sqrt,W.reshape(N_high**2,1)).reshape(N_high,N_high)\n",
    "    \n",
    "    z = z + 0.5 * s ** 2 * grad_log_prior + 0.5 * s ** 2 * grad_ll + s * W\n",
    "    # chains_evolution.append(z.cpu().data.numpy())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "X, Y = np.meshgrid(x_high, y_high)\n",
    "ax1.plot_wireframe(X, Y, z.cpu().data.numpy(),color='r')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_zlabel('w')\n",
    "ax1.set_title('SR')\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "X, Y = np.meshgrid(x_high,y_high)\n",
    "ax2.plot_wireframe(X, Y, w_high,color='r')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_zlabel('w')\n",
    "ax2.set_title('high-res')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR L2 Error: 0.00023719500703068996\n"
     ]
    }
   ],
   "source": [
    "error1 = abs(w_high - z.cpu().data.numpy())\n",
    "print('SR L2 Error:', (error1**2).sum()/error1.shape[0]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Training $u_l=Hu_h+G(u_h)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Training $u_l = Hu_h + G(Hu_h)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code downscaling matrix\n",
    "N_low = 31\n",
    "N_high = 121\n",
    "scale = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory already exists\n",
      "2024-06-03 12:55:31,777 : Training for 500 epoches and learning rate is 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: tensor(16.6291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(3.3938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(4.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(1.5530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(1.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(1.4716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(1.7028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.6647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.6079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.3417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.3480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(2.7933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(4.4649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(1.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(1.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(1.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.7128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.8857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.4200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(1.2252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(1.0471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(4.2475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(1.0501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(1.4212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.5995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.4970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.6263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.3803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.1945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.3838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.3140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.8878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.4088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.8567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.2812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.7421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.2731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.4558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(1.4367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.3640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.2057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.2828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.4757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.4398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(1.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.2797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.4890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.2119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.4218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.2785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.3084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.2145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.1700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.2327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.2489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.3184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.7281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.2934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.2897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.3197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.2727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.2008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.5193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.2223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.7100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.4516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(1.6445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.9573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(1.3630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.5041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.4311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.3798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.4297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.2824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.9410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.3067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.3101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.3722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.3170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.5265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.4245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.2159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.4259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.0955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.6405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.5817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.3518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.3167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.7488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.3063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.3078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.5690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.4108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.3758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.2781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(9.4686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.8414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(1.9267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(1.3277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(1.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.8520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.5377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.6624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.6352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.5951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.4175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(1.6669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.6450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(3.1162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.4600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(2.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(4.3376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.5917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.5713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.8030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.4778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.7871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.4106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.9722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.7669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.6125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.4177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(3.8303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.5831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(1.2742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(1.4750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.8960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.8170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(1.3868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.8521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.4209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(1.2035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.6520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.5342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.1958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.5157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.3237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(3.7080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.6002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.4825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(1.6770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.5110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.4311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.3819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.6352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.6558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(1.7748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(1.5886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.6935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.8245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.5390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.2707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.6503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(1.4909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.6022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.4397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.4558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.9023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.5133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.3309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(1.0553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(1.4082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.8115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.4118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.6544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(5.2155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.5236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.4557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(1.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(20.4826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(7.8824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.8379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(88.2187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.6614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(2.7444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(4.4507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(7.6771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(2.7922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.7228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(12.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(13.6326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.9327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(4.1985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(1.8862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(5.3933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(7.8318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(3.4337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(2.6800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(1.5626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(1.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.8948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.9596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.5510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.5183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(1.2867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.6210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(2.0246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(3.7825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.5701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(1.5120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(1.9837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.9175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.7247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.7338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.5767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.6921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.5608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.0314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.3948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.5374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(4.4062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.5366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.5590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.8992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(1.7297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.6997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.9842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.6911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(2.3922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.7115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.9417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(1.0606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(1.5106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.2747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.6865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.5941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.5252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(1.8743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(4.3203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.4761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(1.4825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.6921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(1.5791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(1.1757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.5008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.8339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.9253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.7255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(1.7639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(1.0072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(5.2987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(1.9516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.4557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.5137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.4862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.6187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.9175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.4323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.6669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.6206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.6108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.9681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(1.4849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.9318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(5.9755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.7287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(1.6217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(1.6603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.9850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.9380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.6966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.5421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(5.0703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.9393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(1.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.5739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.8577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.8531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(2.2213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.9521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.8832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.6090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.9491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(1.5661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(1.2893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.5888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.8855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(1.0728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(1.6068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.5783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(2.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.9346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(1.3471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(3.7392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.6331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.6026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.9904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.6328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(1.4932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.4081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(2.2949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.6964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.6097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(1.2458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.8232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(1.0529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.6424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.9958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(1.8999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(5.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(1.5146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.5763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(1.1856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(1.0962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.9308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.4622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.8783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.4601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.9811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(1.3842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.5313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(1.8055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.5132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.9875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.3202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.9517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(1.4525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(1.8313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(1.8182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.7229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(3.9757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(1.6625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.7377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.7408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.4077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(1.1617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(1.2601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.5727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.8700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.9769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.7943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.7073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.9356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(3.7730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.9703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.4500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.7436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(1.4943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.7893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(2.4308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(1.9121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(2.4698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(1.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(4.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.4562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.4628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(1.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.6873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.9516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(1.0202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.4276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(1.3941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.9002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(1.6053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(1.4497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(1.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.5455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.9790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.6662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(2.7389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.7231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.6724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.7579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.6160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(1.0488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.9821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(1.8124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(4.2253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.5695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.8655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(1.0142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(1.3338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.8365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(1.2506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.4707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(1.2095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.7767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(1.3147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(1.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.7203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(2.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(2.2200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.5112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.8795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.7568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(1.5692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(3.7352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.3154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.8766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.4398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.7275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(1.6722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(2.4443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(1.8364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.7829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(1.0192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.6051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.7398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(1.5756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(3.7755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.5960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.8651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.9258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.8269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.8233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(1.0280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(4.3599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(1.4838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.7634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(1.0964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(1.1986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(4.2061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(4.0421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(2.9983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(5.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(4.0388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(1.3971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.8064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.7496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.5291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(2.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.9330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(2.4073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(1.0359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(1.1974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(1.3903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.5405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.9330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.7469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.5154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(1.3754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(1.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.6455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(1.5528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(1.4505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(4.4365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.8547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(1.0448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.7976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(4.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.9542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.5960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.5717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(1.5752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(1.3137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(1.4914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(1.6453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(1.6392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(1.1689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.9050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(1.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.8218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.5039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.7647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.5118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(4.3443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.3958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(1.1882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(1.0676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.8229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.4922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.8932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(1.4646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(1.0065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(2.9661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(2.0673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.8090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.6552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.5751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(1.5488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.9638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(1.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(1.5614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(1.4729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(1.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(1.8597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.7570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.3282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.5140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(1.0798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.5743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.8398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(4.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.5740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(1.6019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(1.0561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.3495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(1.5922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(1.1576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.8685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(1.2896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.4040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.5463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.8920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(1.9624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.8610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(1.1725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(1.0632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(1.0039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(4.2833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(1.4126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.9602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.9765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(2.2325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.7390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.8528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.5866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.9876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(4.7794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.7763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(1.7862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(1.0461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(1.0628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.4967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.4005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.8411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(1.3670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.6152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.5722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.8050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.7102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.5992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.5084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.3902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.0555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(3.6485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.1678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.8315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.8575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.4541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.2611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.6394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.7613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(3.6056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(1.7032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(1.0327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.8128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.5874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.5054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.9568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.6689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.9882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(1.0489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(1.8576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(1.4582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.4400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(1.9049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.8869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(1.4093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.5484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(1.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(1.0416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.4560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.6199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(1.0411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(1.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(2.0496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(2.5886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.6572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(4.0585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(1.6264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.3738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.9365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.6728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.7855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.4590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(1.1709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.9620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.7764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(1.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(2.0415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(1.9003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.6956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(1.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.8121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(4.6259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.4176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.7058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.5972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(1.4855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.9256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.7283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(1.2845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.8339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(1.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.4508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.9699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.6616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.6318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.9269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(1.2666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(2.4646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(3.6655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(1.2488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(2.0889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(1.0108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.5020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(3.2086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.5581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.0755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.8650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(4.0489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.6462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.3421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.9451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.4598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.4974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.2113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.6597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.2946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.7441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.5395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(1.6815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.2993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(1.6722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(1.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.4739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(2.0358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.5326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(1.5859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.6362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(1.3122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.6618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(1.5936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.8629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.4444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(4.2555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.7398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.3780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.2607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.5730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.6103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.4819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.5965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.7988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.6332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.2954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.9064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.6115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.1994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(3.9788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.6002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.5303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.4026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(1.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(2.8288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(1.0558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.7814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.5240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(5.0427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.5160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.4966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(1.2018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(1.0504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.7397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(1.2216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.7637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.8570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(1.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.5514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(1.8470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(1.6671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.5497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.5923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.6685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.9601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.9094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(1.0714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.2864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(1.0570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(1.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(4.0209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.9265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(1.9736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(1.2467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.9558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.6562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.6567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.4825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(1.6705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.7218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(1.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.8001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.8449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(4.0728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(1.6881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.5931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(1.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.9283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(2.4697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(1.2545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.6876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(2.2215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.5961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.6262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.3593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.8156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.3666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.2035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.7118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.0540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.0027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.5800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(2.2088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.8992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(4.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.9599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.8094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.8927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(2.1697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.0707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.9782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.7892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.3641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(4.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.5484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.5438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.9595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.6463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.4836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.9055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.9848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.5957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.8617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.7571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(2.5843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(1.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(2.2785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(1.3096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.8314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.6565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(1.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(3.9491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.9411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.7274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.9195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.4770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.4917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.7588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.8167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.4300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.9639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.5457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.4122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.3008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.0677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.6828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.7184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.9887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.5145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.8942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(3.9597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.4786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.5836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(1.2817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(4.2101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.7678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.7768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(1.7635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.6886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.6790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(1.0302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(1.3480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(1.8595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.5966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(1.0214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(1.6761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(1.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(1.7836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(3.6072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(1.4882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.5212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.8232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.7980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.4539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.9341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(1.6372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(2.1444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(1.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.6381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(1.2597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(1.3043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.3966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.8416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.6154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.2834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.7868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(5.2039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.9120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.7673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.6535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.5934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.4751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.4440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.7553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.8785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.6373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.6746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.9343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.8696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(1.4493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.4720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(2.4971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.7847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.5806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.8888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(2.0105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(1.5866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.8136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(1.1766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.5951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(3.4780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(1.2552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.7261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.6568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.5187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.4010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(1.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.6363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.9022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.4736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.7927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(1.0887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(1.6365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.9050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(4.6822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(1.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.7211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(1.0352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(1.4021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(2.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(2.3090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.5539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.6294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.5687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.7316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.5602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.9223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.2048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.7535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.8753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.9067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.3949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(3.9902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.0511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.4503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.9382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(1.6982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.9798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.8696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.7055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(1.5206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.8645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(4.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.9710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(1.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.9554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.6383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(1.4540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.7429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(1.1441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(1.7432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.3508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.5418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.4778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.9558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(1.3773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.5439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(3.8606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(2.2948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.6011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.8239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.5061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.8615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(2.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(1.1931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(1.1757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.8002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(1.7282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.7634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(1.6633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.8548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(1.6622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.7045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.8581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(1.2016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(1.7701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.5824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(2.4528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.4841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(3.9988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.6202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.5653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.7518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.9189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(2.2548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(1.3461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(1.0293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.4736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(1.9153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.9950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.3257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.7596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(1.3266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.5170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.5575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.8284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(2.3991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.4841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(4.0298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.6064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(1.8350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.5565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(3.7733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.6471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.6728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(1.4981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.6380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(1.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.6803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(1.0425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.7437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(1.4133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(1.7276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(2.1961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.6511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.7665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.8375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(1.6593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.8568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(1.0263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(1.1944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(1.4128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(3.6077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.6042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.4066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(2.8837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.8251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(1.5476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.6477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(1.4957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.3844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.4541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(1.7487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.5929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.7436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(1.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.5888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(1.2537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.5050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.6734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(1.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(4.2681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.6298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.9829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.6297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(1.1958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.7369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(3.0505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.9013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.9591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.8284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.0839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.3990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.4860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.6343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.6084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(5.1622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.3061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.7297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.6297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.6744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(1.6138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.5457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.9799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.6641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.8938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(3.7718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(2.5660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(1.2501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(1.0522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.4224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(1.1254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.6432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.5937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.8842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(1.3165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(1.5185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.9878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.9272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.1758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.3263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.3103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.8077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.7337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.7005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(3.6445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.7811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.6453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.0457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.5533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.3866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.7298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.6610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.6328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.3544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(1.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.4068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.4979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(2.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.5022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(2.3093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.9317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.9290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.7937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(1.9659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(1.8673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.8041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(3.7041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(1.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.2613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(3.6168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(1.3219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.8527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(1.4479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(1.6830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.4940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(1.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.9944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(1.6699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(2.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(1.1041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.6479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.8919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.4411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.2272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.2399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.5784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.8146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.5584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.9639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.6121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.8281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.7602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.8550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.8909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.0397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(3.7261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.4905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.6072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.5240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.8452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.6137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.3973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.5845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.2604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.4579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(3.7976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.8040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.9836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.5240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.7563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.7174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.2216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.7456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(3.5358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.7914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(1.4418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(1.0391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(1.3700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.9572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(1.3289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.6072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.4332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(1.0845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.6596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(2.4513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.4978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.9756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.5918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(2.0755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.5953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.5937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.5038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.5361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(1.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(1.0617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(1.2549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.8538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(2.0388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.6620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(2.1406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.8223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(4.4635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(1.1626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.6844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(1.3303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.7991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(1.7703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.6723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(1.3142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(1.2761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.7951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.9270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.5395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.8982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.6231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(4.7296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.7318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(1.9416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.6266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(1.7023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.4936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.7064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(1.3677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(1.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(1.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.7839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.7414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.3833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(4.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(1.8682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(1.7196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.9784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(1.0438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.8512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.5645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(1.8282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.5619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(1.9954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(1.5104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.7074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.7643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.4263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(1.4096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.5282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(4.3449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(1.6593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(1.2536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.7773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.5237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(1.4421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.6876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(1.0244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.7875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.7966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.9174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(1.9891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(1.5415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(1.9247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.5064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.5729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.8325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(1.0499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.8342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.8513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.6121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(4.6839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(1.3494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.7639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.6155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.8261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(1.9273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(1.5240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.8887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.5557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.6097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.6661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.6775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.8226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.9370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(3.8203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(1.6219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.7274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(1.6301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.8135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(1.7927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.6565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(1.5380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.8803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.5779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(1.5015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.5888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.9695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.7060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.6645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(3.8726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.8565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(1.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.7133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(2.2020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(1.9678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(1.0453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(2.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.6444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(1.4655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.9473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(1.7681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.9535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.4896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.5980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(1.6366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.5695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.6774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.7722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(1.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(1.0256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.5546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(4.4846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.6522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.8632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.4071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.6451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(1.9354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.5875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(1.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(1.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(1.4029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(1.1501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(1.3357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(4.9839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(1.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.8695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.7145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(1.0689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(1.6129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.7076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(1.3701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(1.3897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(3.6666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(1.3919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(1.8753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(1.2974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(1.5237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.9246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.5560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.6091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.7044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.6497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.7604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.8144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(1.0209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.5412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.8994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(1.0362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.5353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.5031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(1.6082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(2.7324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.8441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(1.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(1.4172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.8505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(4.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.6210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.9078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(1.0548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(1.8070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.9498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.4500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.8875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(1.7581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(1.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(3.7719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.5964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(2.1956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(1.9833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.7922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.6437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.9136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.4780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(1.0519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.4604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.6294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(3.6482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.9655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(1.7892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.7116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(1.3664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.4917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(1.8917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.6043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(1.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.7185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(1.8387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.6725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(1.2356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.8846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(1.4073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(4.9869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(1.2896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(1.0478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.3113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(1.0243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.4891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.7625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.4684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.6600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(2.2399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(1.8600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.6170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.8273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.9115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(1.3093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(1.0456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.6517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(4.8184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.6474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.1633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.0190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.3719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.3549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.4694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.6075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(2.5438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.6239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.8425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.4071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(1.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.6874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(1.8522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.9163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.7609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.8196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.5728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(1.9659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(2.4926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.4458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.8124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.5083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.7492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(3.9745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(1.1716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.9821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(2.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(1.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(1.7508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(1.0253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.7430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.8981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.4107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(1.0807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(1.6173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.5353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.4745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.4483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(1.8897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.6864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(3.8304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(1.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.6977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(1.2293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(1.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(1.6425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.8566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.4141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.8531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.9536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.9848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(1.6296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(1.2084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(1.9159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.6097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(4.0101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.7036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(2.0238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.7481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.7105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(1.5529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(3.6606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.8471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.6785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(2.0349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.9255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.2854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(1.5454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.9300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.5472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.5914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(1.5685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(1.1918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.6255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(1.0230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.8132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(1.3519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.8141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.8128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.6846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(1.7807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(4.3845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.5019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.8183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.3774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.6699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.5846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(2.6790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(1.9194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.4772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.9205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.8839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.8295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(1.6186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.8039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(4.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.9155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.4915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(1.4754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.9765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.9129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.7700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(1.0056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(2.2261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(1.3551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.6451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.9847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(1.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.7481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(1.2662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(1.6730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.5621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(1.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.7009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(1.9357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.4378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(4.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.5168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(3.0137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.5288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.4176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.8698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(1.5248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(1.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(1.5681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.7342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.8855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.5876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.6066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(4.5334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(1.6168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(1.3058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.8597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(1.6778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.4625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.7442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.7395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.8247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(1.4384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.9269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(1.7587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.4733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(3.9909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.3813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.9102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(1.6216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.3324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.7018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(1.9784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.6611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(1.3914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.7856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(1.6737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.8047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.7617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(1.3233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.7394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(1.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.7313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(4.0671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(1.6196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.8253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(1.0208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.4391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(1.8445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.8073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(1.3732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(1.6870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.6556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.7617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.6514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.6255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.5807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.7758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(2.1807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.3254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(1.8139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(1.3605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.6157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.7399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.8052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(1.0110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(4.5372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(2.3610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.6977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.5335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.6422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(1.6669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.5479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(1.6886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.6566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(1.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.6753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.4366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.7700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(1.0806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(2.6528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.7977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(1.4260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(1.4455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(3.6859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.8532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(1.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(1.2187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(1.3138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.5791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(1.7448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(1.5841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.5537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(3.4193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(3.6379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.7063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.7173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.2997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(2.2469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.4211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(1.0099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.7709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(1.0813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.5751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(2.4881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.5342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(1.4186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(1.8884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.7981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.8565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.7792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(1.3796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.9589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(1.8306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.4117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.4956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(4.0421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.7250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(2.2319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.8549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.7346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.4847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(1.6988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.4085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(5.4541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.9648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.3326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.7488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.5600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(1.5025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.7942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(1.3942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(1.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.7521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.6276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(1.0399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(1.4745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.5857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(1.0706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(1.5263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(2.6861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.6709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.6783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(4.7421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.9479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.8779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.6749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.4457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(1.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(1.2620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.8354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(3.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(1.0164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.4739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(2.0228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.9531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.7194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.3243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.9026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(1.1525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(1.3489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.4685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.4543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.7540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(4.0037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.8958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(3.8168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.4836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.8926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(1.6149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.6290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.8310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(2.0726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(1.5002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.6636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.7343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(1.6004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(1.7423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(1.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.7052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.5774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.5814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.9771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(1.2179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.7693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.9477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(2.7788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.8465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.5854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(1.0088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(1.9102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.7932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(4.3730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.5061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.7872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(1.5167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.3906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.9802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(1.8490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(1.2018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.8911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(1.9662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.8132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(1.8635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.7253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.4210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(1.1633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(1.4167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.6746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.7214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(3.9166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.8476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.8893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.7095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.8958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(1.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.7284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.3992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(1.4599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(3.6818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(1.8933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.3620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(2.5736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.8631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(1.0677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.6469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.6948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(1.8241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(1.6429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.8250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.9603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.7496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(1.4358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.9364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(1.0352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.4544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(1.9769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(1.6332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(1.0606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(3.9438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(1.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.6533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.6920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.7321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(1.4352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(3.8309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(1.8094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.3578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.5759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.9758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.6502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(1.4543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.6888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.5889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.7425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(1.3736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(1.7893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.8633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(1.5528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(1.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.6909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(2.3941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.5514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.8824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(3.6107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(1.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.6882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.6796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.6843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.9011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.6520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(1.4932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(2.1697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.7858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.7444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(1.7473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(1.6641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.5814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(1.0976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(1.7314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.5315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.6434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(1.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.9699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.8101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(3.7270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(2.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.5904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.5400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(2.0913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.6971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.8764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.5151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.7852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(1.0705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(1.3774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(1.5249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.4250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(1.0663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.5603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(1.2882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(1.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(1.3582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.4200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.4157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(2.0116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(5.1588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.7200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(1.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.6800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(1.3401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.6687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.6071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.5930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.9641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(2.5206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(1.1101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.9567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.7921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(1.8280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.3230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(1.6747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(3.9423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.7519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(1.3790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(1.5518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.7259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(1.2335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.4907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.5916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.7475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(1.1910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(4.0083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.8551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.8298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(1.1712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(1.5643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(1.1781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(1.4733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.7481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.8346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.3309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.4973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(1.5447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.7480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.4582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.7191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(1.6892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(3.9975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(1.2792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(1.2569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.6368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(1.8679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.7466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(1.6654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(1.4272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.8523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.9258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.3739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.5263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(1.1440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.7853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(1.5592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.8168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(2.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(1.8698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(1.3732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(4.0233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.6120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.4516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(1.2232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(1.0296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(1.4701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(1.7914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(1.0249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.5306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.7906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(1.0487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.8463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.6054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(3.7543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(1.2216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.6295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.8457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(1.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(1.3152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(2.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.4967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(2.5514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.5981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.9590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.8049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.7719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.4240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.6357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(1.0229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.8308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(1.5526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.4875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(2.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.5517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(1.6728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(4.0057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.5490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.6851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(2.0582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.6711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(1.5993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.9877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(1.6669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.6350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.5503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.9351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.8109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.7899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.5174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.7036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.6436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(5.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.9673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.8880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.7093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(1.2155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.8003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(1.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(1.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.6292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(1.6090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.8890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(1.6881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.7155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.8796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(1.5890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.8239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.3102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(4.2213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.7586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(1.8673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(1.7218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.6928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.4599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.8381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.6004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(1.6874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.4645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(1.2453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.8104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.9000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.9172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(1.5188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.7684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(3.8361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.6590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.8529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(1.3270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(2.7797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.5817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.3737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.5319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(1.1985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(1.3614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.5443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.6920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(1.9421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.5157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(1.2016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(3.9922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.3290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(2.2101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.6082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.5723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(4.0497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(1.3940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.5273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.5948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.8318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(1.0435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.5814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.5629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.4889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(1.3793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.8566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(2.3966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.5470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.6140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(2.5075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.6690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.7580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.7389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.9624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(1.7876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.5705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(4.0326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(1.5605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.6197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.8926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.5755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(1.3946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.4563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.9198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.6681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(4.1917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.4128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(1.2243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.5740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.8026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(2.0063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(1.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.5017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(2.4502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.5045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.8093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.4040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.4898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(1.0530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.6362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.8564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(1.8509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.8497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.9530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(1.2206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(1.2761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.4248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.3673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(3.8337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(1.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.6450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(1.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(1.3575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.6288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.7066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.7601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(1.4141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.6223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(1.3671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(1.3450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(4.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.8308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.7343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.7863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.8128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.7529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(1.1726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.6199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.5433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.9852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.7396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.3695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(3.7634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.4344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.4907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.4275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(1.1357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.8093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.8141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(1.3817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(1.2845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(1.1696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(2.0504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(1.2361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.7115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.5798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.6828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.4007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.8322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(1.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.3812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(1.0611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(1.2129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.8012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.5580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.7296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(1.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.7826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.8477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(4.5472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.7149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(1.3624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.5383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.7208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.7285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(1.6015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.6673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.6269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(4.3757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.3395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.8094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(1.0496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.5978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.8659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.7226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.2117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.9013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(1.6529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.9756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.4623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.6436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.5655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.4548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(1.0109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(1.0140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(1.3905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(1.0568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(1.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(4.3820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.5933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.8770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.5576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.9353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.6600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.7389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.5299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(1.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.5290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(1.3428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(1.4978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(3.5536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.6879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.9237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.6779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.3804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.7594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.6306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.8308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.9073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(1.3559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.6292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(1.4485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.7161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.8818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.9515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.8125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.5918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.5016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.5661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(4.0494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(1.7170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.7321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.4237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.8936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.3037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(1.0141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.5861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.5982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(1.3735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.8372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.3228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.4144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(1.5859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(1.8757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.6865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.4961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.6701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.4765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.7352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.3982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(4.4161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.7325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.3923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(1.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.4519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(1.2274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.5134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.3888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(4.0467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.9532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.5193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.6380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(1.8651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.6722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.5234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.2868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.5378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.3897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(1.7024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.5613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.6368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.5297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.9927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(1.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.4717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.9968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.4807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.3035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(1.0538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(3.7077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(1.0591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(1.1637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.4725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.6800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(1.4186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.2896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(1.5203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.3237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.8537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(3.7331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.4750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.7748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.5454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.9524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(1.6412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.4218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.3435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(1.5596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.6089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.3693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(1.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(1.4613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.4491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.5564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(1.0473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(1.1756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.3375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.8183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.4492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(4.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(1.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.6979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.3942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.6549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.5737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(1.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.2771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(1.7470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.6435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.6255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.6119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.4071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.3915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(1.8747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.9277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.3209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.5919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.4718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.4716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(4.9573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.7458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.4074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(1.6482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.4610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.6546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(1.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.7634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(1.2919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(3.9036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.5537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.7514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.9675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.7107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.4192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.4881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.3427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(1.2979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.3550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.7435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.3312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.9064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(1.4108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.5671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(1.0463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.9855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(1.3335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.3646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.5843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(1.0539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(3.7413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.6396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.3191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(1.0374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.7170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.5943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.3560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.7710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(1.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.2826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.6086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.7594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.3464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(1.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(3.8300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.6625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.3987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(1.5485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(1.1933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.9603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.8870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.9594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.5418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.5639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(1.2981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.4603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.6354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(4.4143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.8771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.8594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.4098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.7673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.9928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.8350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.4269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.2260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.4466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(1.0627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(3.5221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.5865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.9243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.4841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.5604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(1.4958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.7387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.5192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.3082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(1.5860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.8184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(1.4111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.3890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.1971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.4195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.3208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.6169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.6062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.2036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(1.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.9112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(1.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(1.3690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.8123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.8118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.9011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.7484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(3.8285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.5347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.6656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(1.2340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.6018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.4191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.4077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(4.1478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.8495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.8193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(1.6540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.5710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.6445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.5170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.3339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.3221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.4132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.6573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(1.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.8605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(1.2202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.8693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.6224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.8165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.3409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(1.3716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.5964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.3976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.8664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(3.6535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.4200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.9843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.5658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(1.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.2110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(1.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.9527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.3977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.3900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.9578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.5877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.5552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.4152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(1.0592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(3.6248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(1.1500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.7690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.6200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(1.2473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.5454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.3879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.5958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(3.6343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.8125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.4111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.8408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.6346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.5412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.3696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(1.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.4030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.6131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(1.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(1.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(1.2723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.4100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.9215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.5107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.5689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.7127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(4.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.3390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.6370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.7175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.6043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.9300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.9748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.7589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(1.0130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(1.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.4986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.8081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.4092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.3861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.8962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.8557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.3787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.9849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.3280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.5136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.8904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(1.5058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.9041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.3700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.9698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(3.9329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.6094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.6385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(1.0268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.7453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.7293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.5729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.3866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.3950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(1.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.5360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.6038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.4379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(1.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(4.2760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.5190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.9495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.5790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.4896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(1.0045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.6769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(1.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(1.1838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.8009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.3286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(1.0951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.3492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(4.8420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.3943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.3966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.5474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.5140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.5233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.4303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.4737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(1.4799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(4.0214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.6327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.4776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.2945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.5387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.9695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.7547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.5463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.4987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.6961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(1.7054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.3432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.8002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.4783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.2958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.4834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.4897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(1.1882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.4103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.6789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(1.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.7046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(1.5943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.6172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.4561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.3208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(4.0750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(1.0577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.3541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.4590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.3928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(1.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.3249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.6654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.5500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.6483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.6387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.4265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(4.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(1.6114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.5821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.2333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.5480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(1.7619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.7446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.3327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.8293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(2.0136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.5636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.9486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.3347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.3001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.5995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.5758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.7849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(4.5578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.5611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.4720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.3606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.9048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.6554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.3153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.4725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.3467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.7771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(1.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(3.5972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.6308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.5495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(1.0183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(1.3201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.3666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.8024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(1.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(1.0934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.6969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.3977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.4187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.2221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.4064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.4616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.6628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.4024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.9146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(3.6456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.4640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.9519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(1.9810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.9126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.6303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.4547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.9514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.5619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.5369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.4132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.3448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.4394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.3469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(1.3356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.6927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.4137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.9764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(5.0476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.8709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.4970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(3.6657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.8669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.8976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.5000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.3642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(1.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.5147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(1.7689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.6295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.4140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.4556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.5576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.3962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.8838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.4424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.6917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.3929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.6234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(1.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.4618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.4511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(1.8196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.9890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.3034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.8815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(3.5592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.2507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.5269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.8983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.6423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.4566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.8163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(1.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.5963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.6626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.4954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(1.0089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(1.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.3959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.3253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.3707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.8021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(4.3242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.2886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.2291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.4932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.4687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(1.4416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(1.0278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.5735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.5574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.9518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.3185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.3195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.3640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.4335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.6803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(3.5133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.2803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.7354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.4056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(1.6738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(1.0061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(1.2626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.3535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.4309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.7827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(3.7139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(1.0389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(1.8838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.5525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.4723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(1.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.4702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.5279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.5731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(1.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.3914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.4133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(1.0043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.6794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.3429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(3.5754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.7359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.3462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(1.2087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.9179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.9171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.5458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.2331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.8175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.7072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(1.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.4544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.3898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.4159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.9387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.9214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.4880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.5928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(1.5081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(4.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.8753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.6019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.4050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.5827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.5379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.3265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.6582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.7953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.5425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(1.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.5351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.6995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.4033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.3719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(1.0495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(1.3856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.7033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.5171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.4479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.5164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(3.9016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.7155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.7831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.3784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.5885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.6974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.4567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.4337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(1.1842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.5238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.4150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.5716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.4850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(4.0281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(1.0989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.8497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.7561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.5870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.7540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(1.2312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.3314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.7232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.4247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(1.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.7290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(1.6678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.7498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.9818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.4499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.4418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(4.2237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.4409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.3351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.4840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.8228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.4170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.6351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(3.8131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.4990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(1.5275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.3989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(1.2604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.3356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.9544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.6600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.7686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.3518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.7298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.8971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.3402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.4241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.3777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.3362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(1.3646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.7071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.3845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(3.6253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.3940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.6487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.4520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.9476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.5612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.4161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(1.6220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.8843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.7478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.4058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.9403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.3863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.4738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.3446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.5597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.9709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.6961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(1.7859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.4850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.4300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.9045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(3.4728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.3690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(1.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.3742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.4655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.5982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(4.9033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.1858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(1.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(1.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.5774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.1956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.4527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.3987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.6864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.4454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.6312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.5357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.9795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.5256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.4118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.5002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.4248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.8939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.7917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.3057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.5611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(1.0180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.3404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.4454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.8720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.8137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.7396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.8851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(4.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.4647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.5589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(1.0477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.9053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.5470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(1.9187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.5986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.8893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.7194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.4809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.2645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.5093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.6228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(3.4140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.1974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.3690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.7978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.4037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.8091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.4761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.5200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.3268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(1.5717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.5472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.6806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.3814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(1.0107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.9924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.2493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.3327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(4.2102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.7575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.5760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(1.0927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.5523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.5388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(1.0135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.4187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.3092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.4329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.3524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(1.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.9604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(4.2533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.5250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(1.2743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.4979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.7563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.4222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.3918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.8751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.6341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(1.0461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.5819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.4592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(1.2515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(4.3536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.1537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.8163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(1.2554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.5487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.7677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.4638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.9005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.3645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.7885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.5007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(1.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(1.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(1.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.2684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.3368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(3.9931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.4221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.8726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.3404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.5765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.7084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.9573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.7570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.5442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.4404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(1.1106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.3177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.6291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.7198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.3942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.3131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.5720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(1.2275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.4493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.7557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(4.3975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.8469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(1.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.8475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(1.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.4027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.5851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.6110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.3612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.2883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(3.5555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.5651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.4728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.7196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(1.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.2959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.8433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(1.6678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.5352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.6659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.3111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.6550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.6067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.8981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.2718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.9709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.4902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.5726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(3.7087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.5946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(1.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(1.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.3617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.3873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(1.2617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.3912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.5175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.3424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.8963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(1.0242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.9264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(3.7682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.3732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.7824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.4357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.9304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.8762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.4062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(1.4239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.5833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.2704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.2336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.3492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.4487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.2615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(1.3217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(1.2937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.7794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.6680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(1.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.5516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.4468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.3386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.6128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.8883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.9443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(3.5630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.6245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(3.5623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.7770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.4112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.5006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.8247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(1.9747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.3456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.4335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.4944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(1.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.8214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.4300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.9248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.4505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.5044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.3594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.4724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.5614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(1.0436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.4651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.4735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.5971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(1.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.6535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.9192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(3.5808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.6909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.9011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.6543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.7641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.4804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.7341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.2374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.4210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.6684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.4942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.9944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.6516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.6684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.4421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(3.8825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.7699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.5099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(1.7715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.8641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.8967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(4.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.5958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(1.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.8660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.5433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.5687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.3976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.4064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.5241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.7335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.3363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.9140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.9238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.5568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.2369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(1.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(1.2118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(1.2653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.3827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.3344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.7990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.4233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.7238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.5069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.3570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(3.7356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(1.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.7277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.3193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.5171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.5837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.3275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.6830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(1.4468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.9193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(4.2913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.6859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.3495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.3642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.9655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.4526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.3275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.8043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.6355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.8137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.6027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(1.0215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(3.9108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.3244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(1.2599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.4539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.9674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.4008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.6114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.5393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.5494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(1.0296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.4423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(1.3620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.9040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(3.6588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.5753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.9093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.2545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.6815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.3573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.7388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.8998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.3373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.8691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.7045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.6256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.3402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.6222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.4033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(1.3004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.6206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.3476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.4211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.3518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(4.4889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.5629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.4033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(1.3331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.6405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.5499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.3334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.5572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.2934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(1.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.7655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.5417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(3.5037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.4203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.7488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.7633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(1.5307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.9107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.2258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(1.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.3414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.4542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.4527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.8385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.4370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.6519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.3150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.7843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.3938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.9801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.6712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.6732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(4.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.7874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.3652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.4821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(1.8023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.2991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.4415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.7710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.4478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.3347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.4463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.4165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(1.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(1.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.3196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(1.2170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.3858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.4355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(1.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.7543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.5381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(3.7963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.9757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.4576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.3753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(1.5542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.5677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.5073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.5331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.4126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.6348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.7835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(4.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.6831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.8541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.4847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.7931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.4161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.3441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.5919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.3019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.9648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.6356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.6140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.3055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.7503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.6624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(3.6642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(1.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.3357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.9351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.8114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.3098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(1.0115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.4669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.6830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.8348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.9686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.5447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.3882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.3771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.6265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.6586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.3318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.4682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(1.0767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(1.3492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.3992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.5724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(3.9088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.3808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(1.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.6925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(1.4556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(1.0291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.2255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.5027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(3.4671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.5157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.4843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.6207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.4108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.4665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.5046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(1.0676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.4003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.5915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.3970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(1.0312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.7504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.8822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(1.0083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(1.1556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.5629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(3.5876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.4397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.5470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.5768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.6615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.6902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(1.0792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.7843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(4.4188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.8576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.4238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.6531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.4661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.4317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.2242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.8337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.7147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.3324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.4709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.6364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(1.1971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.4550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.9259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.3480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.2454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.2858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(1.2678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.4808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.3281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(1.1806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(3.6480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.5201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(1.6320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.3330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.6549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.8847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.5287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.4958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.4562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(1.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.3035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.5848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.5752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(3.8942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.9507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.5587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(1.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(1.4540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.2321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.5923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.3214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.8113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(1.2880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.4440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.6235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.3160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(1.4787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.5101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.4685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.7935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.7065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.4673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.8723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(3.5596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.2800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.3742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.3494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.3062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.8532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.3780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.4001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(1.0282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.3010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.6194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(3.5441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.9285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.3270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(1.4948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.4341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.5715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.9651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.8336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.3583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.4443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.5808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.6488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(4.0231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.2040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.2671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.4988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.6034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.4720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(1.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.6578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(1.0680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.7465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.5347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.4797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.9688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.2378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.8375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(3.8062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(1.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.7079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.3428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.8175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.4547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(1.0714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(1.3193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.3867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.3802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.5035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.2825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.4794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.4081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.6237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(1.0254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.7182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.5789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(3.5605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.4370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.3272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(2.2059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(1.4633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.3494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.2493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.4892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.6184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.5348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(1.3419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.4789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.6794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.3356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.6719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.7187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.4620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(1.4111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.6676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.4844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(1.5271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.3222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(4.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.4817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.2698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.6435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.4231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(1.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(3.6395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(1.0497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(1.3089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.5711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.5462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(1.1915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.3186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.3047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.6600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.3926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.6963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.4600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.5495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.3684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.3970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.4810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(1.2340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.5671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(1.1540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(3.7826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.4147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.5724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.7128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.2838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.3131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.4396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.9247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(1.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.5711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.4127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.5577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.6182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.4565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.3897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(3.4934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.9300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.4670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(1.4008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.9095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(1.3686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.8353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.4559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.4172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.3867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.4850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.7380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(4.4576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(1.3745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.2924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.3036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.5431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.5445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.9010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.3020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.4543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.3967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.5763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(1.2449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.6507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.3437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.7905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.5719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.6811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.3498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(1.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.8411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.6683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.3846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.6846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.8858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(3.6146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.4263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.5149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(1.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.8584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(1.2994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.5237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.4522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(4.0246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(1.0186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.4356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.6839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.5778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.3564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.3674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.4388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.4769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.8477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.4867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.4234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.3572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.8851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.5956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(1.0432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.5000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.6502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.8113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.8413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.3957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.6532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.2800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.9148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(3.7195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(1.1672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(1.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.6511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.4970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(1.0099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.4790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(1.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.2002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.2781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.4870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(1.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.5086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.6853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.8459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.5166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(3.4636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.8031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.4327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.4261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.5469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(1.2011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.3728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.7344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.2280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(1.2515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.5293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.6175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(3.8284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.3713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.7592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.7753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.3798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.7499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.4042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.9943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.4265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(1.0088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.5921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(3.4538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.9516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.5474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.2889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.5080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.6624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(1.0443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.8842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.4948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.8894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.6557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(1.4424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.4020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.4595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.8884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.6868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.4152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.8494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.5143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.2914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(3.4766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.4452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.5059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.7252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.5155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.2816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.4473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(1.3508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(3.7018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.5941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.9459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(1.0593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.5084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.3880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.3745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.4504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.2174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.9477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.5448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.9754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.3676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(1.5145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.2848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(3.5087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.3661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(1.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.6128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.5499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.3578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.6592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.5390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.4229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.7289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.5092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.9944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.6965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.3961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.5023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.5477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.3576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(3.4997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.9421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.6342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.5122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.2826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.4845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.6194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(1.6008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.3696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.6066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(1.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.8653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.2637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.6534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.6301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(1.2490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.4077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.5611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.8641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.4488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.4232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.4458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.5195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.6173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.2914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(4.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(1.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.5309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.6718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.7142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(1.0661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(1.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(3.5429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.3878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.4452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.6134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.7068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.6478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.5085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.7141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.4089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.3463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.7982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.3556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.4294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(1.1622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.5973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(3.3816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.3575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.2173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.2968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.3510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.8929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.6398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.4521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(1.1938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(1.5725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.2222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.6992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.5888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.6160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.3821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(1.5171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.6009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.5470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.8832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(3.8066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.3674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(1.2576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.4266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.4772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.4446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.6381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.7001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.6151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(3.3934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(1.2938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.3967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.7331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.9581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.2848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.8809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.5027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.6841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.7671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.4657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.5191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.5666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.3893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.5820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.8568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.8242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.2946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(3.3223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.7868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.8417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.7178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(1.2639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.4003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.6674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.2886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.6567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.4467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.5832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.8897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.7846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(1.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.4931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.6311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.7624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.5079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.7020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(3.9781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.4486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.7471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(1.0623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(3.4634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.7967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.2996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.3040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.8750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.5657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.4310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(1.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.6902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.4833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.6631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.3094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.5556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.6139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.7362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(1.0395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.7618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(1.0675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.3906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.4173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(1.2640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.4981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.2304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.5459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.6564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.3329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.9134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(3.3367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.5370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(1.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.6328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.6349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.4158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.8685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.5536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.9888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.4426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(1.0527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.2750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.3922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.3382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.3659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.8416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.7693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(3.9311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.6804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.3734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.4858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.3639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.3486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.9611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.3403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.7844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.9438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.3788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.9134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.5842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.9479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.3489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.9862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.5629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.5335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(3.4544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.4622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.3577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.2003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.8272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.5768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.5823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(3.5810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(1.1364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.8247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.5144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.8559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.7276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.5617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.3838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.7587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.5608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(3.5273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.7450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(1.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.3715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.4118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.9190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.4397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.4872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.6971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.9351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.4937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.5733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.8949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.3867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.4609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.3886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(1.0602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.7583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.6782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.4392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.7458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.6576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.3769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.8051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.5640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.4074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.8360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.3315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.8844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(3.5448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.4462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.3774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.5424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.1938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.6279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.2837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(1.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(1.3189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.6351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.4930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.7968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.3813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.6803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.4280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.4774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(4.2169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.5729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.5270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.3064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.4110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.6297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(1.3675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.3637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(1.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.8722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.5878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.4287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.3780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.8793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(3.7907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.4541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.5185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(1.3847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.5041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.5905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(4.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.1928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.4581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.7371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.4026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.8918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.7728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.2373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.9438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.3997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.4171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.5579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.2936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.4670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.4460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.5839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.5830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(1.4966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.3761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(3.2867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.4126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(1.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.4174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.3346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(1.2986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.4812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.3184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.9591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(1.0183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(1.0468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.4677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.6869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.5292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.4575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.7345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(1.3090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.5622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.5894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(3.4409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.2974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.3431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(1.6432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.5363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.4830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.9354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.9437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(3.9011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(1.0736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.4410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.5234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.4438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.2846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.4136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.4793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.4305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(1.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.3557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(1.0117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.4115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.5256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.3643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.4718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(1.1643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.8732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.5044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.2768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(3.4581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.6214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.9679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.3375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.6115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.6068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(1.2660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.5453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.3821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.7824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.3254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(4.4548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.4245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.3718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.7405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.5039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.2653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.5794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.5627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.4329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.4946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.4137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.8413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.7499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(1.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(1.3876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.5189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(3.6096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.5623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.3213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.8132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.3380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.3910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.2796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.4326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.4658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.4236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.7622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.5429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.8073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.3518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.8223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(1.3556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.5503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(3.3141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.4537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.7133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.3243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.3511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(1.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.5009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.4875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.4210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.3042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.2661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(1.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.3318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.3591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(1.1749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(3.7616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.4839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.4881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.7284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.4629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(1.3072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.5070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.6543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.5814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.7747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.5792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.2889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.2754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.7503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.5958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.9187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.6436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(1.0729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(1.0219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.3760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.5052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.8222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.3073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(3.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(3.7847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.3844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.5744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.5731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.5490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.6728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(1.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.5606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.4940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.2724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(1.1753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.4753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(1.2458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.3269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.3945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.4207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.5488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(3.4951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.4188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.6098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.4893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.6349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.6619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(1.4580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.3568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.7730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(1.0177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.5923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.8586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(3.6793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.4365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.8405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.7866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.6064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.6847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.4506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.3041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.4633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.9006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.3280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.2399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.5830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.4856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.7821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(1.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(1.0202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.2722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(3.7797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.4931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.7417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.8606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.6801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.5912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.7257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.5686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.8124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.4374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(1.2095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.4407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.6127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.4547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.8085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(3.4146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.4622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.6280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.8292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(1.0176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.4915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.3603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.2946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.7833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.8414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(1.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.3049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.3496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(3.3096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.3934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.9375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.2725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(1.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.3917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(1.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(1.0942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.5235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.3666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.6253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.6271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.7050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.7838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.3468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.7842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(1.0578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.2872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.4687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.7700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.5185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.4835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(1.0227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.4663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(3.3014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.4410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.3950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.9865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.3399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(1.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.3182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.4384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.4969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.6922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(1.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.3887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(3.7956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.5310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.4763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.5732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.6633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.5137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.6812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.5949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.2971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(1.2948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.4614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.6324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.3292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.5596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.4021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.3855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.8194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.5896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.8935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.3844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(1.3237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.4150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.4733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(3.5850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.5998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.6768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.3943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.5618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.8103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.6110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(3.7338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.5845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.5574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.8636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.9335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.9630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.7692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.3908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.6291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.5197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.8621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.3854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.6399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.5438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(1.0210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(3.6901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.6839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.5648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.4339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.4874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(1.0522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.7235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.3504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.6055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.5729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.4185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(1.1815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.3397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(1.3001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.4944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(3.2832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.5480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.4078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.5608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(1.3710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.4021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.4340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.2709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.5755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.7026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(1.3991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.3589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.6465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.3856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.5990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(3.2584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.3231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(1.0231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.2340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.2987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.4834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.8765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.2804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(1.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.8069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(1.3139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.6704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.4139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.4035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.5794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.3186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.8885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.3533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.7001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.2728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(1.2123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.7050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(3.4976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.4543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.7276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.5082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.3590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(1.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.9608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.7050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.8004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(1.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.4852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.6184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.2404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.4409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(3.4242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.4014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.6438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.4363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.4514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.3586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.4389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.5632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(1.0646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.6225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.4216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.3655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(3.4936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.6280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.3913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.5758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.9807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.9333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.5761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.4060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.9360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(3.3003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.4872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.5245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.3211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.3411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.4258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.3032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.7642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(1.0667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.3114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.4914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.8432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(1.4215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(1.2045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.4128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.5564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.5678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(1.4651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.8833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.3399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.6999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.2673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(3.7895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.5633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.5226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.3982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.3742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.3523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(1.0398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.8162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.3704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.3067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.4286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.4451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.8865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.3519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(3.3536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.3571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.8738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.6489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.5339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.3853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(1.2044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.9179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.5209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.7126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.8333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.3107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.5733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.7162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.8285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.8804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(3.5195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(1.5306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.1986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.2972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.3554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.5163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.4730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.3394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(1.1651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.4770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.5648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.5012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(1.0679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(3.4625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.3529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(1.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.2853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.8717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.7720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.5826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.7318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.7005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.3924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.4838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.6303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.4765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.3417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(3.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.6293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(1.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(1.0794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.7393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.6151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.4490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.5127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(1.0843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.3846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.7305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.6069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.2761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.3583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.5220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(1.1728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.3783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.2731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(3.6839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.4842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.3460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.6554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.4989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.5138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.4033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.3111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.6625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.6637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.9280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.4605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(1.3000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(1.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.2932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.2714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(1.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.4010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.9337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.4751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.7038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.8821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.3877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.3934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(3.5931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.4739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.6141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.9248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.3688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.4824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.4574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.4581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.3401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.8849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.4704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.7820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(3.3613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.7686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.8845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.3174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(1.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.5654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.6892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.7926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(3.5393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.4329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.8885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.4960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(1.0700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(1.5630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.4746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.6821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.3608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.5256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.4128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.4359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.2296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.4274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.9592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.4424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.6381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.6897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(3.5532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.3170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.7908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.4957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.5609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.6145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.9921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.6611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(1.0240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.3410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.6186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.7300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.5331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(1.2018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.4761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.6556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.7083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.2353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.7274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.8154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.5495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(3.3444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(1.0209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.6916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.8710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.3241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.2413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.4494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.3206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(3.4219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.5980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.4452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.8340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(1.4915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.3586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.4324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.4052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.6058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.4951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(1.1830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.7322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.6920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.5674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.2773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.6928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(1.0129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.5248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.7741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(1.2132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(3.4142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.6948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.9977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.7409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.3753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.4179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.5586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.8100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.2814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.4477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.6984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.7483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(3.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.4652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.6434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(1.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(1.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.5156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(1.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.4744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(1.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.2860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(1.5639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.2277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.2916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.4715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.6454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.6434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(1.0711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.3099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.4920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.8019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(3.5250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.4673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(1.0042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(1.0606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.3416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.7977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.5564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.5765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.2943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.6550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.6383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.3052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(1.2122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.4139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.6045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(3.4192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.3728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.4485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.6496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.3087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(1.4162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.8281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.8164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(3.3370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.7237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.3077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.2960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.3248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.3496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.5083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.4517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(1.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.8265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.4583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.6422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.4066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.4145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.7884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.3392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.6201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.5760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.4528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.5319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.6176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.5569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(1.0263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(3.5682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.3104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(1.3801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.4053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.5222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(3.1819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.7295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.4334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.2362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.6047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.9715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.5427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.6613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.3280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.6222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(1.4358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(1.3681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.3497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.4855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(1.3378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.4249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.5028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.4369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.3460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.2777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.5467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.9130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.8573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.3708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(3.3749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.9154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.7446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.8932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.4210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.4576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.3783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.4452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.5339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.6651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(3.6858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.4053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.6093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(1.0516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.9092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(1.0191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.4935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.4340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.5741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.5799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.4063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.5733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.2824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.2945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(3.3957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.5322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.7445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(1.2204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.5118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.4978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.8169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.8323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.9530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.4518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.8157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.3991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.3578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.5978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.4487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.3474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.4024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.4314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.5814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.7314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.4182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.5617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(4.0572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.5800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.4262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(2.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.4151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.9518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.9271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.5235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.3156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(1.3762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.5379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.6424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.3971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.6793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(3.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.3505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.3549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.5502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(1.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.4707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(3.3226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.3730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.4636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.5710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.4962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.4224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(1.0272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.4416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.2376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.9363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(1.2665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.4108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.5771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.6290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.8417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.6117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.3313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.5571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.7490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.3864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.9251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.9219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.3647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(3.9167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.7837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.3408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.2923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.4314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.6221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.9741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.8135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.3646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.3862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.5732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.5301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.5564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.4414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(1.0070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.4805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.6273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.3132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.7687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.4216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(1.2477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.3617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.6117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(3.9467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.2116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.6776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.2912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(1.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.7212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.4564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.3951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.4515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(1.0080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.6238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.4384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.2758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.6645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(1.3537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.7089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(3.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.6248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.4232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(2.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.3525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(1.0111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.5328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.4476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.2786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.5533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.7505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.3120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.3207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.8306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.6067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(3.2222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.2983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(3.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.3187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.6273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.8201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.4213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.4633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(1.2445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.3879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.5608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.7466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(1.2335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.6420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(1.1806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.2218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.3531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.3696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.8026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(1.1967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.4406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(1.1735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(3.8471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.5901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.4898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.3969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.4573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.4520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.4861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.2742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.4524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.8311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.3998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.3375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(1.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.9561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.5287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.5486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.3636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.7522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.5875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(1.0462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(3.3979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.7126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.5615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.3212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.6837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.2872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(1.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.4592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.5941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.3894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(1.2613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.5029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.5896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.7213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.5561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.4177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.6339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.2132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(4.0795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.5085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.3424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(1.3487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.4233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.2734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.8250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.8237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.6634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.2727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.4160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.4877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.6590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.5652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.5153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.5823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.5212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(3.9674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.2697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.7002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(1.7539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.3883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.8841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.9255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.4942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.3531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.3730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.2816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.3741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.3158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(3.3353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(1.1842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.5089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.4917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.4910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.6802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.6912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.4111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.8890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.8755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.4359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.4256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.3243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(1.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.4437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(3.2980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.5312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(1.0505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.5736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.3410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(1.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.3364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.2757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.5029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(1.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.4182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.2958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(1.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.4356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.6639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.4583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.9562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.7296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.6147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(3.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.8597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.3086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.5337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(1.0047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.3619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.7487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.5887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.5661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.3474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.3138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(1.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(1.0375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.7701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.5782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(3.2368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.3048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(1.2941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(3.6066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(1.5570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.3099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.4846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.4734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.4505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.6866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.8470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.8159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.4794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.3483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.3176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.4255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.9033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(1.4063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(3.8136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.3084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.4510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.4035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.6655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.4717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.3345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.4301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.3060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.4496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(1.4060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.2402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.3774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.6326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.3514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(1.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.3612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(1.0128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.4327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.3452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.7838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.3291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.4090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.6653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.3601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.8511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.9366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(3.6135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.4147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.5815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.8732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.7880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.5040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.3473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(1.0316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(3.4383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.2129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.3913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.4788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(1.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.9944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.5951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.3261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.4384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.6447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.4575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.6553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.4272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.4175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.5021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.3531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.3827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.5551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.7423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.9176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.5508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.8394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.5123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.3405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(3.3203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(1.7982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.2684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(1.1726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.3827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.5783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.5740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(1.3010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.3936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.5218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.6662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.8587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(3.4862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.3275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.6176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.7245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.3983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.3203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.5366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(1.0032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.3556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(1.4620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.7468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.8588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.6146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.3461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.3194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.7044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.6888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.7624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(3.3379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.3807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.3252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(3.1521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.9422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.3307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.4390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(1.0284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.4387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.7710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.7715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(1.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.4638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.4990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.6793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(1.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.9312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.3505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.4646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(1.0409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.3592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.9774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.9270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(3.2343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.3599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.6179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.3300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.5761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(1.0618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.5839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.5182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.4839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.2853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.5656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.8386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(1.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.5265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(1.2092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.5590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(1.0406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.3904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.3093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(3.7278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.4786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.2958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.3082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.4812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.3781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(1.5748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.2935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.8498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.5613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(3.5362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.8164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.4385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.6454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.8852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.6632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.4835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.5355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.3732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.8140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.2866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.4573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.8107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(3.3774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.9746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.6063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.6204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.4795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.4984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.7029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.4915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(1.0195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.4363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.7467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.6638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.5366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.3086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.2316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.6188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(1.0081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.4282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.7853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.3715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.4091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(1.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.6016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.3006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(3.9369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.4069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.7862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.5207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.7325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(1.0722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.9250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.2465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.3614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.5545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.4921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(1.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.7822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(3.5922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.5317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.4869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.7550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.7643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.9207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.4477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.4722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.8339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.2982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.3603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(1.7700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.3294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(3.4735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.4854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.4169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.5291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.6186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.4694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.4214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.3328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.3318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(1.3041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.7357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(3.3933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.2284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.8566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.6138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.9835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.6596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.7568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.6054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.3223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.6219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.3945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.4488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.5288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.6333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(3.4912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.2681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.4627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(1.2329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.3538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.6014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.8340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.5278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(1.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.5980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.4365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.7166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.2958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.4280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(1.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.2840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.4716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(3.2740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(1.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.8284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.7166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.6774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.5299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.7240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.5076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.5676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.4784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.3950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.6190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.6429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(1.2269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.6273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.5481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.5631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.5736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.2170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.4484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(1.5362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.7265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(3.3395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.1945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.8512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.5416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.3529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.5306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.3141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.5638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.4576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(1.0530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(3.2487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.6776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.7407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.8490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.6911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.6081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(1.0642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.5519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.3108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.6270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.7457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.4986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.4353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.7371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(1.1760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.5614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.3070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(3.2511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.5134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.7219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(1.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.6643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.9550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.2845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.7515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.2842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(1.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.6746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(1.1702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.4614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.5844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.3600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(1.2343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.5414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.2401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(3.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.4415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.7987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.4711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.3330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.6501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.6860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.5181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(1.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.9130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.5865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(3.2984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.3838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.3438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.3677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.9540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.4579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(1.0578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.5932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(3.2512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(1.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(1.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.4272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.8550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.3810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.6247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.5685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.4449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.4530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(1.0405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.3227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.7558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.4244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.5796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.7130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.4142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.9962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(3.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.7858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.4466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.9271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.5690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.7268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.3658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.2637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.5980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.5846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.9923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.5689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.3963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.8485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.7033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.7575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(3.9402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.6454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.7810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.2777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.5162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.4177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(1.0081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.7935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.4622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.6116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.2737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.7932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(1.0297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.4855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.3639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.2688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.8804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.3282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.3536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.8579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.7565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.9616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(3.3756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.9958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.2260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.6495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.9809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.4504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.7092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.2970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.3764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.4615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.5685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.8228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.2811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.7516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.4947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.4112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.7343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(1.0812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.9244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(3.2137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.7321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(3.3171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.8737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.3326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.5696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.4984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.4722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.9098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.3864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.5226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.8819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.5743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.9259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.6312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.8189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.2868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.4766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(1.0566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.4153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.4190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.3553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(3.1770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.4206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.4054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(1.6195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(1.2318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.3643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.6481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.5801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.5754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.5439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.8565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.5531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.3582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(1.1713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.9519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(1.0474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(3.4073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(1.1767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.4799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.4217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.3036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.4801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.2766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.5457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.5421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.3390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.4284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(1.2915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.7789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.9315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.3026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.8265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(3.1598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.4521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.4024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.3906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.7210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.6084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.3706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(1.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.3805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(3.3654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.3493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.6574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.4857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.3859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(1.3403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(1.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.6366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.6936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.2919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.5288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(1.4122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.2717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.3346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.3838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.7917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.4158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.4389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(3.4955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.7004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.3302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.6179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.6197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.6792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(1.1155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.4616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(1.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.8210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.6235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.8167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.6544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.3124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.9720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(1.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.6835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(3.7420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.4387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.2851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.4828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.3704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.4681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.7341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.4936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.3271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.2687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.5265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.4459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.4095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.7032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(1.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.2452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(1.2554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.3870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(3.2440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.8939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.9924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.4007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.5641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.8117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.7849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.7160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.9506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.6204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.3940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.9312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.9669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(1.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.3540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.2968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.3950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.5870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(3.4012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.5261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.3130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.2440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(1.3112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(3.3018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(1.0394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.3942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.7880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.4102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.4635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.3425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.8865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.5131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(1.4288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.3164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.4738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.3951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.7095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.9277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.6100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.3517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(3.6583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.7207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.5379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.7767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.3925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.3659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.8949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.4938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(1.1733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.5600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(3.3570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.8338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.4332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.6293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.2841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.8883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.4404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.8603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.4419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.4503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.7192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.2374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(1.0931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.9070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.7340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.3480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.5597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.4252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.5007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.9734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(1.0246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.6750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.3967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(3.3069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.9573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.4847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.4471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.8099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.4302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.2888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.9175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.2738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.8878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.3516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.9271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.5160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.4551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(3.3540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.4615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.4953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.5142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.4209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.3660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.8898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.6947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.6989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(1.2376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.4224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.8127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.4425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.5112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.2752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(1.5371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.3601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(1.1072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.7570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.4117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.5706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.2880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.3758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.3906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(3.9750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.3642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.5260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.4397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.5049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.8524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(1.0654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(3.9887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.3032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.6066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.4041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.3811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.5262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.6517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.6869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.4659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.7753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.4016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.4502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.8601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.3303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.4332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.4461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(3.5220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.4675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.9029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(1.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.3261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.3194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(1.1570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(1.2162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(3.4975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.3812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.3552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.9444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(1.2720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.6439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.2994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.7398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.4623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.3636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.3392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.7181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.5424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.6978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(1.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.7210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.9582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.8242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.7723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.3580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.9587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(3.4409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.3524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(1.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.5591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.6739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.7800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.7928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.5686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.7057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.6133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.2845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.4962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(1.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.3281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.6379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(1.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.3547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(1.0107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(3.1623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.4823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.6379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.3139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.7032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.4291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.7288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(1.4909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.4518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.7665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.4312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.4327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.9625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.4956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.4093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(3.1353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.9598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.6132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.2159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.2466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.9575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(1.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.5873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(1.2289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.6925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.2004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.5440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(3.4889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.3958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.9659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.2669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.7028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.4604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.4087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(1.0680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(1.0854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.3577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.8003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.4703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.5507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(3.6176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.9748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.5216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.3388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(1.3256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.3369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.4951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.7100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.5492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(1.5046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(3.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.8502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.4538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.2282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.3340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.7460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.6201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.6274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.5242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.6278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.6790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.6282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.4392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.7633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(1.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.3124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.8330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.3514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.6350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.4246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.6704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(3.7419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.4008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.4847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.5705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.7131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.4407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.3309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.9111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.5274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.9085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.4602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(1.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(3.4010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.8252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.3422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.2677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.5620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.9475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.7596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.5649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.2167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(1.3036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(3.4878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.4818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.3806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.5389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.6300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.2640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(1.1728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.7819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.9437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.4282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.3952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.4964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.7399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.2742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(1.1577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.6251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.9248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(1.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.5696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.5560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.2634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(3.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.9611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.4200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.6277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.7866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.4161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.7884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.7596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.3947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.9286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.5185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.8891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.9649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.5237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(3.1648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.4611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.3785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.4620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.8217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.4044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.7657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.3251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.3698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.4174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.3756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.7621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.6015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.3276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(1.2776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.9075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.6303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.5125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.2626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.8887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.2928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.7940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(3.8201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.6240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.5414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.6224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.4941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.4298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.5014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(1.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.3554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.6750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.4640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(1.2876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(3.1770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.8427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.9618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(1.0287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.6053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.4536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.3800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.7819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.5799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.7892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.2320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(4.1835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.8069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.5164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.4411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.3124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.4748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.7612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.4679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.7809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(3.3780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.7679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.4855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.9441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.3918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.5872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.9389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.5092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.9435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(1.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.3132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.3614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.5796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(1.0647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.4218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.3174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.5924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.4953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(3.3537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.3423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(1.3259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.5146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.4714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.4186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.3449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.5365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.6261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(1.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.7148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.8703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.2716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.3797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.3380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.2304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(3.4081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.7034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.5364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(1.3028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.6496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.5399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.8053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.3848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.8761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.6209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.4413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.5732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.3608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.2778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.6508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.7116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.3514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.7610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.7414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(1.0648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.3943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.3162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(4.3118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.6209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.4971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.7486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.9347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.4916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.2977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.3421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.6318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(3.6179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.7451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.2626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.8222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.3375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.8863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(1.0685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.2462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.5948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.4951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.3869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.5710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(1.0169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.8889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.3682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(3.2762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.5442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.3785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.5463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.3211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.7899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.2402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.6327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(1.6097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.4432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.3094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.3674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.2189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.3990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.6322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(3.6255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.4476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(1.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.5734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.9065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.6032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.8894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.3191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.4240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.8149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.8176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.5968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.5297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(3.2861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.8193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.7180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.3423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.3177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(1.5522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.5710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.3406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.5652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.4321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.7651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.5135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.8778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.3157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.3507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.4278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.9907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.6273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.3782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.5103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(3.3998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.6183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.3983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.4511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.8093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.6012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.9087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.2698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.7045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(1.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.4692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.6318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(4.0188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.4469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.7525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.9810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(1.3394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.4377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.3211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.5142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.3672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.7506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.5688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.3751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.5592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.7405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(1.0313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.2945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.7004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(1.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.3084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(3.3788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(1.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.1796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.3877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.5259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.9779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.5077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.4258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.3622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.3883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.3753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.7911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.4321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.8779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.9817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(1.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.2747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.3234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(4.0118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.4322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.3318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.6736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.4632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.6445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.6097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.6004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.5973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.2821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(3.2283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.3819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.6890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.5735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.4652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.6303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.9196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.3455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.6314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(1.4009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.9077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.8635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(3.4288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.4713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(1.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.2797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.2831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.5862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.2966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.6640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.3734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(1.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.8397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(1.2243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.2811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.2172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.4526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.5240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.8267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.4316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(1.1871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.5777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.4157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.5035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(1.4024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(1.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.3594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(3.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.3569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.3563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.6279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.5274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.3032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(3.6040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.5127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.6658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.6625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.9609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.3700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(1.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.3853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.5359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.8856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.8882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.4420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.3053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.7075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.5258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(1.5170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.2598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.9603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.2013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.5842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.4303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(3.3276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.5888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.3956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.7997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.5810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.7950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.2672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.9587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(3.7360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.6840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.6184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.3320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.5138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.7232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.8367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.4171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.6243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.2951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.3001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.9025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.5364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.7854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.6665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.5254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.4532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.4702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.5953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.6539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.9081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(1.0128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(3.4062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.4427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.7395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.6123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.7013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.7018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.7579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.3013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.5610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(1.6956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.2751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.6053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.4399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.6304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.3883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(3.3460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.2855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(1.2260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.5853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.9518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.3521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.2730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.4845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.4463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.5296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.3012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.5672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.3832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.3163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.6213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(1.3409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.2083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.5259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.5897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.6503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(3.7026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(1.0572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.4334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.9538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.6104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.2977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.3629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.5926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.5031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.5278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.5714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.5768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.8421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(3.2359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.3922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.6047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(1.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.5364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(1.0235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.9018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.3685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.3414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.7778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.4116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.3724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.3328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.3598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(1.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.4090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.7290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.3989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.3661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.5827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.7989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.5316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(3.8667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(1.0616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.3219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.5133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.5820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.4497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.7139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.3481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.9768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(1.4457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.3725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.8359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(3.1492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.5877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.2657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(1.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.4787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.3051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.4099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.4976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.4420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.2778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.6829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.4214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.3189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.5575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.7738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.4704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.6024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.9845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(1.6931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(3.8176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.2348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(1.2841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.4368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.3563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(1.2355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(3.3724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.3039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.4346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.6939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.6349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.3814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.9783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.4692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.3568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.4767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.2938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.7729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.4374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(1.6201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.4848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.8229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.5757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(3.4170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.8317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.6663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(1.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.6646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.6822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.4791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.2742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.6332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(1.0058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.3885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.4197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.3976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(1.1544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.4419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.4405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.4507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.6037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(1.4488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.5063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.2657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(3.5811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(1.5386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.6694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.4152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.4093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(1.2775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(3.2616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.5540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.6610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.7091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.2914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.3560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.8746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.4130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.7493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.2906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.6257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.8633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(1.6327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(3.3187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.6950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.3491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.4624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.7423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.3467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.6391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.3032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.5990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.6595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.8922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.9090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.2467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.3636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.5987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.4454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.7462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(3.3897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.7559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.3851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.4013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.4358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.7390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.3964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(1.4049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.7669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.5997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.8693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.7819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.6607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.2984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.4794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.2957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.8323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.5012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(1.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.4198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.6995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.7712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(3.5955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.4362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.4953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.7819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.4545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.6187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.7434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.4571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.2662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.4654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.8035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.5847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(1.8214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.4022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(3.2810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(1.0594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(1.0326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.9978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.5944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.3045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.4919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(1.2560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.7503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.3978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.4622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(3.6770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.6739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.4405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.4792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.2163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.4563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.7399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.5584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.6864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.7161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(3.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.9130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.5027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.3378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.3588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.7442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.3713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.4335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(1.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(1.3095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.5276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.7762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.6316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.9810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.3546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.3251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(1.4768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.3397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.2886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.3288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(3.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.3880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.9230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.6245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.7899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.5329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.6448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.2752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.9935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.5316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(3.3658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(1.2245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.5923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.4739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.4434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.8666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.6282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.8135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.3277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.6308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.3414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.3384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.3400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.8650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.2637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.2910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(1.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.8958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.4653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.3098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(3.2869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(1.0225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.7224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.4822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.5321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.5184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(1.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.5429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.5542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.5408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.5382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.7655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(1.3154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.5957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.8167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.3835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.4029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.4268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.4219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(1.0026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(3.0944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.3805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.7058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.4743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.3667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.8915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.1980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.3722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.5897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.5247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.5485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(1.6652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.5406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.7150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.5584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.4512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.3685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.2530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(3.9654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.2166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(1.1749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.5155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.5441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.7640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.5575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.5676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.4520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(3.4717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.3955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.4187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.4092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.3285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.5406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(1.0592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(1.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.5334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.5860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.6241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.5370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(1.2327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.5745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.3384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.9478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.5132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.2665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.3595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(3.8056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.4475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(1.2231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.5616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.9000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.6143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.8999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.3539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.4809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.3730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(1.0684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.6978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.6309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.4841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(3.4798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.3830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(1.0665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.3591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.3738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(1.0329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.5504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.3214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.9362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.8134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.8114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(3.6443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.7213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.3461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.3065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.5507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.3719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.5925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.7451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(1.2318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.7980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.3184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.4528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.3957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(1.3528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(3.2997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.6194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.3181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.4793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.5826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.4119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(1.0271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.3631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.3057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.8153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.4254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(1.2011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(1.0928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.5016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.2825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.5482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.4386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.6614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.9429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.5164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.4418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(3.3173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.6633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.3132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(1.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.6071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.3634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(3.3543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.9414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.7483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.8394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.4199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.3771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.3734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.6492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.9991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.5083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.5227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.4170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.3599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.2949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(1.2093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.4774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.4951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.4154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.7177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.2109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.3452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.7048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.4719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.3977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(1.4295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.6162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.3804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(3.9485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.3953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.3149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.7395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(3.4762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.8303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.3889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.5978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.5387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.7869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.5073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.3917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.6567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(1.0377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.8224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.5251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.4614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.6477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.6762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(1.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(1.0536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.5173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.7177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.4411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.5509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.8730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.5951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.5687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(3.4699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.5086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.2984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(1.5202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.7427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.3304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(3.4553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.4220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.6498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(1.0204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.3698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.4062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.4638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.7531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.4517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.4583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.4632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.6821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.2789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.4352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.3430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.8207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.5574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.3215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(1.3196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.7477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.3597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.8476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.5546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.3738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.8236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(3.5250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.7208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.4353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(1.0327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.9121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.4657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(1.0346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.4355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.8868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.4308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.5145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.3996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.4236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.5975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.6888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.6852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.3930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.4359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(3.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.9425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(1.2714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.7699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.5076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.5464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.1813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.3644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(3.1925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.5774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.4235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.4823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.5258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.6595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.4016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.4216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(1.1980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.5266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.5300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.3622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.5115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(1.4319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.4167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.2675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.3731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(1.0239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.3864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.6780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.4213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(1.2824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(3.1596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.4558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.6308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.4030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.4967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.5402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(3.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.4697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(1.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.5463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.3073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.1851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(1.3251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.4031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.8760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.5633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.7188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.2732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(1.0588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.3886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.9732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.4846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.7422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.4768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.4593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(3.3548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.4312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.6281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.6111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.5091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.2439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(1.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.9181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.4309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.6858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.4457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.9240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.3709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.3275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.6054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.2856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(3.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.5778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(1.4235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.5301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.7446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(1.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.4624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.7454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.4549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.8159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.3847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.9431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.4380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.5159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.6132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.8551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.3338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.9972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.9612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.4119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.4228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.3013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.9898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(3.3299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(3.7369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.8607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.5565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.5385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.5185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.3893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.8946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.3863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.3086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.7727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.8318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.9552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.2669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.4461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.7776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.2189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.3998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.3739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.6594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.7198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.9629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(1.2882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(3.3676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.2688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.3631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.2485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.7243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.6506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.5334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(1.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.3801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.4483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.7900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(1.0311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.5447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(4.1173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.5712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.3413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.5982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.8911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.5289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(1.0631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.5229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.2667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.2450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.3736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.5080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.4222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.6479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.8721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(1.0461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.5982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.8230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.9262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.3868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.4944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.7498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.2976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.3506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(3.6094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.3445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.3029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.7203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.2979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.3817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.5165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.4684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.2789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(1.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.4431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.7927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(1.0654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(1.2534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.5709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(3.0904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.4627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.5909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.7760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.6147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.3759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.4688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.3083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.7198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.5781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.4879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(3.8058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.9886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.8220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.7196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.5145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.4877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.5356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.4269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.8376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.7119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.3957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.5386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(3.3023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.5078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.5064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.9524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.5303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.6317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.6802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.4868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.5973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.4155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.9206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.5784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.3732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.4540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.6175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.4066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.4752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.3551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.8568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.6412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(1.4122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.4737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(1.3328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(3.3057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.4208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.2778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.3708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(1.4573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.2994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(1.2221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.4313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.8461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.2971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.4417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.3912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.4671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.4960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(3.8640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.9715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.4913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.3416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.3839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.3743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.3261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.7391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.9212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.3901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(1.2476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.7937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(3.4399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.6419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(1.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.5170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.4772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.5954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.9003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(1.6164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.2778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.3270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.6562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.3150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(4.0422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.9129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.4384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.5181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.3301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.6178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.5733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(1.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.7407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.7004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.5145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.3746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.6772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.6407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.3520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.3840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(1.0172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(3.4076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.4576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.7674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.6622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.7046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(3.3944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.4800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.7161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.8733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.5968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.5518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.6405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.6615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(1.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.3765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.4073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.8209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.3111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(1.2057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(1.4047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.7112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.2327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.4372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(3.4815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.5621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.3239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.4650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.5502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.9196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.5587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.2287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.6187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.4362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.9363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.7822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.7432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.4929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.5322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(3.3625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.8055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.3814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.2851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.4135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.5876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.3533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.3593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.8809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(1.0504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.4873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(3.3888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.3778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.4364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.3281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(1.0792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.4474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.2648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(1.2474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.3777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.6585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.2678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.5545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.7262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.4676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(1.5557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.6765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(1.0564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.6368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.7044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.6630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.3292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(3.5618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.9465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.9071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.6223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.2222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.5764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.5701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.4259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.4422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(3.5267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.3598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.5781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.3969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.6062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.5665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.3902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.5916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(1.7461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.3288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.6524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.8340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.5636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.5960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.6878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.4835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(1.1978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.6405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.9436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.3580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.5501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.9059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.4962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.5841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.4383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.4180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.3520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(3.2694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.3503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.7687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(1.0569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.5634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.9174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.2353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(4.2325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.3804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.3111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.8953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.3537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.4886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(1.0271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.4547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.6629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.4488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.5283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.4687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.3345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.4483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(3.5373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(1.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.5475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.5727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.8655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(1.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.6262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.3252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.1804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.5594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.8305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.9386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(1.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.3712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.4074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.3903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.4290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(3.8389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.3260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.3686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.2939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.5141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(1.2416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.2809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.4141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(1.2334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.4531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.9097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(1.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.2289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.3810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(3.2785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.9795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.6006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(1.4571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.6435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.5836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.3306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.5317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.5417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.2693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.2818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.4029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.6592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.4110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.3143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.8417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.7630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(1.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(3.8341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.8381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.5471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.8078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.7365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.3424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.5602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.6423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(1.3953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(1.1573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.4437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.3241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.3244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(4.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.4869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.4105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.3523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.4872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.8074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.3716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.4019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.3159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.7277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(3.5971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.4959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.8491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.5930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(1.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.8909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.4515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.8767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.3519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.7127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.5236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.3751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.3090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.5127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(3.9349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.3812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.5383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.6956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.7899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.6265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.4228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.3044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.6953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.5215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.4104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.4571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(1.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.7009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.5279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.4334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.5727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.4354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(3.4435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.5010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.6482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.3943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.4813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(1.1822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.2996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(1.8880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.5419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.5022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.2890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.9217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.1905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(1.0399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.4897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.7945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.9866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.2808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.5706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.5711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.8977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.8311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.3514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(3.3999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.5095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.2806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.6977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.1993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(3.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.9818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.3607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(1.2587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(1.3858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.3138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.3976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.9783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.5705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.3448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.3197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.4963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.6154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(1.0728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.4647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.3534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.3793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.5786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.3714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(1.5711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.4845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(3.2985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.9546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.7678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.7802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.4159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.4536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.6479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.8337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.4304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(1.2530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(3.4450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.9158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.2831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.3521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.3765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.3331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(1.0048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.8580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.5629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.3814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.5371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(1.1747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.4503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(1.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.4354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.6426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.4913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.3991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.6291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.5020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(1.0898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.7923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(3.4772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.4556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.3079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.3818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.9851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.3856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.4850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.4587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.7241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(3.1794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.5032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(1.2293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(1.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.4946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.4499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.5060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.9590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.3349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.4260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.3176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(3.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.7911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.4332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(1.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.4689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.8660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.5276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.3832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.7988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.3128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.9523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.5777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.7980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.4075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.8078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.7198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.9802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.7083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.2248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.3180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(1.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.3491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.3746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(3.3332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.3888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.5011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.4815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(1.4304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.2705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.9035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.5565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.6533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.6664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.4528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(3.2266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.9039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(1.0521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.4655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.5031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.6010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.4691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.5663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.2884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.8473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.8998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.5114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(1.2040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.3610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(3.9740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.4075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.8276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.6864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.2340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.4362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.6184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.8349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.3205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.4533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.4068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.3438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.5834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(3.4298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.3541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.3825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(1.1713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.7928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.6379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.3180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.4864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.6753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.9988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(1.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.4024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.4510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.2872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.4233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(1.0578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.2720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.4195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(1.2641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(3.2231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.5390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.2805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.6626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.4272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.6849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.4453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.4872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(1.2525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.4384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.5422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.9852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.2149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.9820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.4479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.5704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(3.3472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.3709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.3527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.3860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.5006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.7931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(1.2462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.6811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.6829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.5561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.3042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.2855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.4904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.4195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.6180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.2746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(1.0276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.3104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.5745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.5628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.7238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.4278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.7472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(1.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.4128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.7840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(3.4937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(1.1716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.4676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(3.2485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.8996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.5483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.4881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.6304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.8570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.7602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.4104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(1.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.5776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.3964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.3044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.2703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.4526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.3225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.5087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.8538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.2720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(1.0403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.2256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.5231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(1.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.5710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.7954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.4139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(1.3323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.1768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(3.5093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.3662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.3625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.8607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.6739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.4515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.4038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(1.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(3.2561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.6226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.4481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.4788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.5625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(1.3061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.8025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.4888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.5854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(3.7646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(1.1728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.3616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(1.2882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.8430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.4552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.3709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.3783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.6174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.4504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.4605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.8962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.4210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.5670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.4123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.5213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.5199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(1.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(3.8357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.5231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.8540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.4502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.7405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.4631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.3313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.4389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(1.0085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.4326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.2706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.5776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.4809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.6599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.5948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.3687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.5896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.8000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.7938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.3568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(1.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(3.7208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.4835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.5759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.5725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.4080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.4149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.8329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(1.2285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.3920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.1648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.5870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.7833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.5831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.2353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.4647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.5460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(3.3444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(1.4966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.6411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.2915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.5116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.4723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.3944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.4355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(1.2091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.2640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(3.3576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(1.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.9672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.9046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.2762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.6722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(1.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.3315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.3191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.5847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.9174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.8447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.2396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.4482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(1.0644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.3155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.4886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(1.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.5691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(3.3290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.8206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.4887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.2961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.6036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.3314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.6777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.5507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.9838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.3041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(3.4947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.3402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(1.2246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.8909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.8612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.4067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(1.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.4408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.8054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.3253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.2771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.4010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.3848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(1.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.6529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(1.2642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.7164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.4342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.7685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.5644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(3.3693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.6332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(1.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.4480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.2029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.4408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.7764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.4805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.6538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.3079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(1.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(3.5318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(1.1318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.4893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.4801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.3592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.5532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.3536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.6973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.4281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.4001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.4731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.7989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.3214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(3.2990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(1.2036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.4778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(1.2683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(1.4810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.7859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(3.4354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.3763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.3582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.4595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.4756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.4069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.5855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.3610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.8779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.3718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(1.8046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(1.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.6981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(3.5032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.3362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(1.0635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(1.0614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.5187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.3798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.4436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.2751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.5329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.7171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(1.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.4048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.2237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.9713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.3001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.5196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.9831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.4393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.4795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.2200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.5253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.3155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.4274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.6069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(1.0979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.7098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.4322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.6340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(3.4244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.5213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(1.2790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.3101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.7302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.4240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.2094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.5713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.9488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.6130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.8304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.9104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.6267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.4551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.4018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.5815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.9127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(3.1895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.7487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.8938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.3205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.9771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(3.4070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.3308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.5982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.6433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.7695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.3095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.2887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.2986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.5614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.4386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.6459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.6176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(1.3114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.2693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.3929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.5860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(1.2608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(1.0491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.5705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.5786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.2300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.4706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(3.4083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.7117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.3906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.3054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.7792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.8952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.5092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.3976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.2898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(3.3407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.9101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.6876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.3379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.5268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(1.0950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.3516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.4177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.6013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(1.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.7737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.7230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.4465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.5239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(3.2123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.3995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(1.2266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.3339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.7433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.3854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.5638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.3225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.7820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.2685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.8638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.9003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.6871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.9360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.4415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.3505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.9709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(1.1625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.4975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.4599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.7042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(1.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.6073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.3275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.5843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.3321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.4157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.3367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.4830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.8091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.4005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(3.2311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.2774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(4.1509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(1.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.7150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.4047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.5328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.4369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.5663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.3989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.3092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.5278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.7121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.4105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.4425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.9006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.9784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.6645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.4974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.3665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.6094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.2937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.3045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.4008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.4380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.5339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(1.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.6283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.9779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.8075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(3.5178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.5621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.5132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(3.6461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.9717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.8515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.3447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.1648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(1.0054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.4374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.4251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.5405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.4217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.9308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.8922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.3390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.3510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(1.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.4844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.7524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.3582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.7156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.3812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(3.3202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.4727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.7277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.5269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.7469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.5525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.2698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.3789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(1.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.9784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.2625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.3927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.6161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.4827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.4496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.6668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(1.0288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.6664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(3.4079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.5074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(1.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.2251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(1.1704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.6111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.4550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.6147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.4095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.7585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.5618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(3.1111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.6538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.4156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.7656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(1.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.5433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.7987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.4080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.7415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.4237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.7904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.5093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.5120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.5770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.9098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.3215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(3.3583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.7558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.3401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.3107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.7220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(1.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.5779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(1.1693, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "epoch_num = 500\n",
    "batch_size = 8\n",
    "lr = 0.01\n",
    "gamma = 0.5\n",
    "\n",
    "minimum_loss = float('inf')\n",
    "loss_track = []\n",
    "\n",
    "# Load training data\n",
    "trainset = DataFromH5File5(\"/home/pz281@ad.eng.cam.ac.uk/mnt/PhD/Pro_Down_SR/data/DownBy4_31_121.h5\",N_low,N_high,scale)\n",
    "train_loader = data.DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialise training model\n",
    "G = ResidualLearning()\n",
    "G.apply(weights_init_xavier).to(device)\n",
    "mse = nn.MSELoss(reduction='sum')\n",
    "optG = torch.optim.Adam(G.parameters(), lr = lr, weight_decay=0, betas=(0.5, 0.999))\n",
    "r_scheduleG = torch.optim.lr_scheduler.StepLR(optG, step_size=100, gamma=gamma)\n",
    "\n",
    "# Logger info\n",
    "dir_name = f'models/train_NN/31_121/lr{lr}_gamma{gamma}'\n",
    "makedir(dir_name)\n",
    "logger = setup_logging('job0', dir_name, console=True)\n",
    "logger.info(f'Training for {epoch_num} epoches and learning rate is {lr}')\n",
    "\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    \n",
    "    for i, d in enumerate(train_loader, 0):\n",
    "        \n",
    "        residual, high_res, low_res = d\n",
    "        size = residual.shape[0]\n",
    "        low_res = low_res.to(device).reshape(size,1,N_low,N_low)\n",
    "        high_res = high_res.to(device).reshape(size,1,N_high,N_high)\n",
    "        \n",
    "        downscaled = F.interpolate(high_res.reshape(size,1,N_high,N_high),(N_low,N_low))\n",
    "        \n",
    "        optG.zero_grad()\n",
    "        out = downscaled + G(downscaled)\n",
    "        loss = mse(low_res,out)/batch_size\n",
    "        loss.backward()\n",
    "        optG.step()\n",
    "        \n",
    "        if loss < minimum_loss:\n",
    "            save_model(dir_name, epoch, 'best_model', r_scheduleG, G, optG)\n",
    "            minimum_loss = loss\n",
    "            \n",
    "        if epoch%100 == 0:\n",
    "            save_model(dir_name, epoch, 'model_epoch_{}'.format(epoch), r_scheduleG, G, optG)\n",
    "            \n",
    "        loss_track.append(loss.cpu().data.numpy())\n",
    "        np.save(f'{dir_name}/chains/loss_curve.npy', np.array(loss_track))\n",
    "        \n",
    "        print(\"Epoch:\", epoch, \"Loss:\", loss)\n",
    "\n",
    "    r_scheduleG.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_low = 31\n",
    "N_high = 121\n",
    "scale = 4\n",
    "a, b, c = 8,3,5\n",
    "\n",
    "h_low = 1/(N_low-1)\n",
    "x_low = np.arange(0,1.0001,h_low)\n",
    "y_low = np.arange(0,1.0001,h_low)\n",
    "\n",
    "h_high = 1/(N_high-1)\n",
    "x_high = np.arange(0,1.0001,h_high)\n",
    "y_high = np.arange(0,1.0001,h_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_low, r_low, A_low, x_low, y_low = generate_data(N_low,a,b,c)\n",
    "w_high, r_high, A_high, x_high, y_high = generate_data(N_high,a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = ResidualLearning().to(device)\n",
    "G.load_state_dict(torch.load('models/train_NN/31_121/lr0.01_gamma0.5/ckpt/best_model.pth')['netG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_high_tensor = torch.tensor(w_high).to(torch.float32).to(device)\n",
    "w_low_tensor = torch.tensor(w_low).to(torch.float32).to(device)\n",
    "downscaled = F.interpolate(w_high_tensor.reshape(1,1,N_high,N_high),(N_low,N_low)).reshape(N_low,N_low)\n",
    "out = G(downscaled.reshape(1,N_low,N_low))\n",
    "residual = w_low_tensor-downscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(9,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.pcolormesh(x_low, y_low, residual.cpu().data.numpy(), cmap='rainbow')\n",
    "cbar = plt.colorbar(pad=0.05, aspect=10)\n",
    "#cbar.mappable.set_clim(-0.03, 0.03)\n",
    "plt.title('LR')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(1,2,2)\n",
    "plt.pcolormesh(x_low, y_low, out.cpu().data.numpy()[0], cmap='rainbow')\n",
    "cbar = plt.colorbar(pad=0.05, aspect=10)\n",
    "#cbar.mappable.set_clim(-0.03, 0.03)\n",
    "plt.title('LR')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upscale by 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_low = 31\n",
    "N_high = 121\n",
    "scale = 4\n",
    "a,b,c = 8,5,5\n",
    "\n",
    "h_low = 1/(N_low-1)\n",
    "x_low = np.arange(0,1.0001,h_low)\n",
    "y_low = np.arange(0,1.0001,h_low)\n",
    "\n",
    "h_high = 1/(N_high-1)\n",
    "x_high = np.arange(0,1.0001,h_high)\n",
    "y_high = np.arange(0,1.0001,h_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_low, r_low, A_low, x_low, y_low = generate_data(N_low,a,b,c)\n",
    "w_high, r_high, A_high, x_high, y_high = generate_data(N_high,a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Parameters for prior variance\n",
    "prior_sigma = 0.002\n",
    "ll_sigma = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.eye(N_high**2) * prior_sigma**2\n",
    "G_inverse = np.eye(N_high**2) * (1/prior_sigma**2)\n",
    "\n",
    "# Turn matrices to tensors\n",
    "G = torch.tensor(G).to(torch.float32).to(device)\n",
    "G_inverse = torch.tensor(G_inverse).to(torch.float32).to(device)\n",
    "A_high = torch.tensor(create_A(N_high)).to(torch.float32).to(device)\n",
    "b_high = torch.tensor(create_forcing_term(N_high,a,b,c)).to(torch.float32).to(device)\n",
    "\n",
    "# Store sparse matrices as sparse tensor\n",
    "A_high = A_high.to_sparse()\n",
    "G = G.to_sparse()\n",
    "G_inverse = G_inverse.to_sparse()\n",
    "operator = torch.spmm(A_high.T,G_inverse).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(w_low).to(torch.float32).to(device)\n",
    "posterior_initial = torch.randn(*[N_high,N_high]).to(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G = ResidualLearning().to(device)\n",
    "# G.load_state_dict(torch.load('models/train_NN/model3/31_121/lr0.01_gamma0.1/ckpt/best_model.pth')['netG'])\n",
    "G.load_state_dict(torch.load('models/train_NN/model3/31_121/lr0.01_gamma0.1/ckpt/best_model.pth')['netG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Langevin dynamics\n",
    "K = 1000\n",
    "s = 0.0004\n",
    "\n",
    "z = posterior_initial\n",
    "chains_evolution = []\n",
    "z = z.clone().detach().requires_grad_(True)\n",
    "for i in range(K):\n",
    "    # Grad log-likelihood\n",
    "    downscaled = F.interpolate(z.reshape(1,1,N_high,N_high),(N_low,N_low)).reshape(N_low,N_low)\n",
    "    x_hat = downscaled + G(x.reshape(1,N_low,N_low)).reshape(N_low,N_low)\n",
    "    log_likelihood = (-1/(2*math.pow(ll_sigma, 2)) * torch.matmul((x-x_hat).reshape(1,N_low**2),(x-x_hat).reshape(N_low**2,1)))\n",
    "    grad_ll = torch.autograd.grad(log_likelihood, z)[0]\n",
    "    # grad_log_likelihood = torch.matmul(G,grad_ll.reshape(N_high**2,1)).reshape(N_high,N_high)\n",
    "    \n",
    "    # Grad prior\n",
    "    difference = torch.spmm(A_high,z.reshape(N_high*N_high,1)) - b_high.reshape(N_high**2,1)\n",
    "    # log_prior = - 0.5 * difference.T @ G_inverse @ difference\n",
    "    # grad_log_prior = torch.autograd.grad(log_prior, z)[0]\n",
    "    grad_log_prior = (- torch.spmm(operator,difference)).reshape(N_high,N_high)\n",
    "    \n",
    "    # Random noise term\n",
    "    W = torch.randn(*[N_high,N_high]).to(device)\n",
    "    # random = torch.matmul(G_sqrt,W.reshape(N_high**2,1)).reshape(N_high,N_high)\n",
    "    \n",
    "    z = z + 0.5 * s ** 2 * grad_log_prior + 0.5 * s ** 2 * grad_ll + s * W\n",
    "    # chains_evolution.append(z.cpu().data.numpy())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "X, Y = np.meshgrid(x_high, y_high)\n",
    "ax1.plot_wireframe(X, Y, z.cpu().data.numpy(),color='r')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_zlabel('w')\n",
    "ax1.set_title('SR')\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "X, Y = np.meshgrid(x_high,y_high)\n",
    "ax2.plot_wireframe(X, Y, w_high,color='r')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_zlabel('w')\n",
    "ax2.set_title('high-res')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR L2 Error: 0.00027698612237858676\n"
     ]
    }
   ],
   "source": [
    "error1 = abs(w_high - z.cpu().data.numpy())\n",
    "print('SR L2 Error:', (error1**2).sum()/error1.shape[0]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Training $u_l = Hu_h + G(u_l)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code downscaling matrix\n",
    "N_low = 31\n",
    "N_high = 121\n",
    "scale = 4\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory already exists\n",
      "2024-06-04 16:10:08,075 : Training for 400 epoches and learning rate is 0.01\n",
      "Epoch: 1 Loss: tensor(53.6763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(4.2408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(1.5791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(105.5328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(4.3576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(6.4123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(7.0294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(2.3801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(2.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(1.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.9896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(2.0046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.5024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.8590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.8154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.5209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.6293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.7786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.8663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(1.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.8801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.6494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.5338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.3467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(1.1640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.3564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.4613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(3.6720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.8403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(1.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(2.2160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(1.5952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.6397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.7731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.4244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(1.4969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.4304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.4794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.4156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(1.1851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(1.2434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.6394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(3.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.4462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.9690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.4051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.3782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(3.9020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.6433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.4374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.4104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(4.9488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.3941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.4618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.4133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.6050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.2168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.7638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.6424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.2923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.3351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(2.6258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.3671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.3342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.5875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.3492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.6465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.2046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.2039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.4617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.3760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.2022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.8741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(2.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.2327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.2199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.3080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.2321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.2936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.5859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.2023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.3981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.4670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(1.7011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.4764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.3340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(1.4856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.3453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.4625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.3959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(1.2317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.3014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.4118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.4874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(1.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.2290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.2123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.2274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.3082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.2853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.2155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.3211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.2075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(1.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.4229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.4098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.7253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.2363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.6116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.2440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.2044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.2104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.9244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.5161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.2160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.2794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.2277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.2011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.2363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.2727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(1.0105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(2.2766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.1992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(1.0093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.6927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.3438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.2052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.3132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.1951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.2044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(1.4767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.4600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.5895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.7094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.2677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.2984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.1927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.3002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.2256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.1911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.3093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.1677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.1672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(1.0468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.2160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.3333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.3403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.2119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.4143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.7685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.2608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.1759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.7949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.1843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.2570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.2218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.2013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.2749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.2781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.7463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.4285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.2086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.1576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.1405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.2332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.3142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.1996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.4191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.1745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.7099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.2412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.3144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.1111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.2038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.1972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.2811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.9408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.2999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.4743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.3041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.2677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.1651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.7586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.2391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.3969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.1551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.1597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.1823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.2676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.2098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.6204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.1974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.2114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.4562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.3184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.3868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.1782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.1516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.0702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.0646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.5806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.5151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.4442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.6088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.4023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.2887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.2487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.2176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.1522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.4949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.1906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.2702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.1659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.1623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.4801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.3734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.1440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.2282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.0663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.0841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.0544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.1127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.4084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.6465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.2254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.4642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.3509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.2232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.3130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.4111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.3736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.1848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.1586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.2383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.0754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.0741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.4228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.4677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.5455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.2974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.4330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.4443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.1589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.1992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.5755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.1882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.1930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.1661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.0785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.2153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.0771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.1875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.3380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.2793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.1962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.2862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.1490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.4615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.2838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.3676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.4171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.3119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.1900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.4168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.2642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.1621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.0511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.3838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.2648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.1966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.4704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.6914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.4593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.2245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.1781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.0664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.0676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.1509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.5025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.4446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.8271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.7631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.1990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.4085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.2189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.8660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.2741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.0818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.5082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.2853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.2952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.3545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.1520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.3083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.3457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.1938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.3480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.7596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.3111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.3270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.2027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.4083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.1485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.4722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.0581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.1540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.0439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.1938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.2923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.5183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.2408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.4433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.2169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.1900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.0552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.0879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.1564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.2206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.3935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.0842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.2986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.1856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.0955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.0816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.2447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.3874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.3422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.2721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.7636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.2661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.2302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.2091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.1735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.4336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.2235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.1891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.2093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(3.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(1.9942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.7908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(1.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.4523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.7648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.7901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(3.9856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(1.2927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.3521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.8584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.9702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.6641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.5757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.3875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.5181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.2195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.2363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(1.3603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.2833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.3143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.4694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.2872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.1745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.2350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.3313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.1918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.1635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.6690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(1.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(1.6538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.3573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.5580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.6376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.5643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.5065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.2056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.2174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.3506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.2002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.2978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.9454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.8003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.2371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.3630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.1940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.1767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.2005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.1560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.1113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.6096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.2042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.2761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.4460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.2099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.1757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.3173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.0601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.3564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.4675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.2739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.0842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.0842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.5824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.4313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.3596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.1624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.1849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.3894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.1812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.1978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.0992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.4961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.4153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.2503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.7905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.4736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.1965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.3409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.4288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.2156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.4550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.1848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(1.0250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.5888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.5064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.1819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.1864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.1710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.5721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.2034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.1540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.2254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.4321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.2193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.2154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.0576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.4956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.1957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.1766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.0491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.0503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.0505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.4041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.5966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.4044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.1865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.0622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.3037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.4680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.1819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.6746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.1634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.6209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.1904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.2376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.0746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.2129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.0722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.1759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.3990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.1588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.2000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.0439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.2842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.2746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.1533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.0773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.3548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.2022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.2109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.1388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.1523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.0693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.1544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.3345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.2908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.4933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.3189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.2484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.2539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.4523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.4180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.3026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.3663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.5037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.3729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.3141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(2.1862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.7544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.4299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.2393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.6196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.4239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.1830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.6466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.4546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.4615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.3412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.1824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.3775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.2708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.0562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(1.0288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.7013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.5659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.3204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.2022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.7018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.3911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.4331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.1540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.9861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.6104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.2804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.1788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.0599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.2403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.2034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.0732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.6278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.4543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.4415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.2447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.4922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.1623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.3012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.2904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.4731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.2292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.0664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.2283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.0605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.8212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.5248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.1928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.3657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.1342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.0839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.7675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.4603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.6052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.6121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.4524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.3382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.2535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.1586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.6186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.2035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.0773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.0841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.3618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.2262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.3253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.2503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.1328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.1318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.0424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.4618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.5248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.7882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(1.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.5192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.4959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.2733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.0992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.1662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.2989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.4036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.6367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.4214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.3820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.2437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.0482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.1793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.8582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.5738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.8028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.4215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.6444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.2755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.3039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.1879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.1924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.3185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.2415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(1.6717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.7880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.3139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.4345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.3686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.9976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.1991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.8039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(2.9586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.3349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.5488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.4511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.2888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.2724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.3915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.2453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.2827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.7853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.1608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.2414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.3678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.5715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.7881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.4858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.2254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.2094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.1982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.1521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.5097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.2826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.1988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.2537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.1860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.2368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.1533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.2248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.1860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.4472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.6143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.6051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.3712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.2021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.1682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.1678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.2123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.3852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.5609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.3715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.7150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.3946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.2702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.3897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.1637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.1141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.1742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.0994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.9566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.7730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.2853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.1758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.3443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.3159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.1988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.6208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.1850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.2485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.0692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.0639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.0442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.5361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.7612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.6513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.9155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.5408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.2258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.1677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.4393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.1651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.1754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.6371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.1594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.2040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.1858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.0677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.4592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.3631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.4609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.1807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.5612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.0466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.0829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.2416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.4424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.6174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.3997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.1958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.3161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.2567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.1974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.5284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.2982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.2087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.3505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.2150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.3140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.2242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.1929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.0698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.1749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.2137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.1665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.3164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.3200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.2242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.3089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.3291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.1901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.1539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.0598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.1776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.0694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.0518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.1181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.2808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.1640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.0850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.0748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.0495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.0852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.1711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.2351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.1824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.0840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.2036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.0524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.2773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.1736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.0850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.0625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.0597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.1986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.0734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.0456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.0749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.3027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.0603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.1437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.2775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.2324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.0482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.0559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.1497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.0619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.0693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.1046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.0486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.0677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.1831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.0841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.0733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.1437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.0666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.1101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.2373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.2159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.0642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.0554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.1595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.1589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.1846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.1173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.2088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.0754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.2127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.0623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.2305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.0655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.0664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.0555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.0581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.2007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.0606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.0773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.2405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.0679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.0508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.1521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.1805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.0655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.2079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.0545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.1806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.0434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.2031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.0554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.0748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.1713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.0547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.1835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.1572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.2289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.0735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.0578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.0530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.0406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.0717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.0511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.1895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.0603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.0870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.1893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.2248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.0549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.1879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.1580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.0743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.0482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.2680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.1525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.0412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.0781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.0527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.0521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.0598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.0496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.2682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.0693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.0503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.2048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.1046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.0477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.0664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.2260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.1832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.0597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.0560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.2246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.0785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.1682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.0931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.0595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.0504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.1728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.0879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.1440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.1988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.1640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.0633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.0669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.0533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.0424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.1353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.0559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.0705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.1993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.0661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.1500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.2433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.1967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.0563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.0785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.1846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.0735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.1502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.0663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.1490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.1162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.0638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.0783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.0420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.0829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.1894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.0368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.0778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.0694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.0702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.1859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.1604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.2023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.0640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.0625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.1525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.0510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.0754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.2343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.0614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.0585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.0511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.2244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.0549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.1173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.0870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.2442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.2231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.0693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.0621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.1843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.0484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.2384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.1850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.0621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.0795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.2310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.0581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.1667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.0501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.0543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.0697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.0307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.0927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.0343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.0379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.0492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.0463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.1868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.1932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.1486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.1781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.0658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.1645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.0751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.3564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.1046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.2178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.0449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.2184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.0480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.1800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.1824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.0442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.0663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.2178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.1957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.1725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.0828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.0557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.0705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.0646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.0573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.0845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.1427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.0576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.0483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.0498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.0576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.0536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.0663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.1318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.0741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.0525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.1976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.0431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.0795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.0778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.0548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.1466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.1500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.0584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.1551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.0465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.0540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.0571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.1127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.2019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.0523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.1254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.0757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.2980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.0836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.0785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.0544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.0848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.0615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.1622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.2241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.0616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.0749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.0489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.2086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.0767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.1849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.0816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.1781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.1930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.1777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.1388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.0533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.0470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.0716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.0642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.0692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.0309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.1082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.0589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.1484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.1891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.0541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.0564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.0741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.0507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.1587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.0636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.0495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.0623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.0802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.2354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.1041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.0484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.1812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.1041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.0666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.2227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.0676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.1642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.0697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.0525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.0508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.0776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.1760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.0689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.0530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.0749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.1082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.1594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.0522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.1800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.1837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.0773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.2031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.0840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.0616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.1916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.0511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.0717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.0840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.0585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.0620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.0754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.2269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.0639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.0527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.1756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.0628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.0616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.0656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.0501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.1509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.0472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.0252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.1588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.0785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.1291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.0842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.0829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.2173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.0717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.0409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.0613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.1955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.1705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.0570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.0516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.1440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.0783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.0556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.1788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.2206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.0622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.0614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.0538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.0692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.1794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.1813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.0498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.0845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.0597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.0551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.0422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.1962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.0994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.1847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.0666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.0458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.0593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.1633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.0931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.0724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.0852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.0614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.0783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.0746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.0767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.0621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.0325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.0638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.0620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.1759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.1765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.0491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.0448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.1787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.0640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.0654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.0457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.0503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.0533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.0553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.1977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.0664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.0436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.1824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.0624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.2105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.0449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.0692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.0457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.1632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.0531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.0702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.0755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.0515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.0628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.0400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.0717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.0679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.0481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.0476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.0805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.0392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.1832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.0625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.1598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.0625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.0563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.0716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.0870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.0712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.2001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.0836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.0746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.0598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.2193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.1141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.0679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.0426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.0556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.2145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.0805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.0472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.0437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.1681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.0512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.1796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.0700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.0568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.0599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.0453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.0845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.0848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.0564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.0541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.1763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.1613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.0620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.0612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.0512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.0698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.0446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.1564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.0465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.0535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.0615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.1465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.0469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.1768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.0399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.1500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.0551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.0597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.0744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.0693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.1768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.0694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.0712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.0423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.0743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.0621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.1759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.0418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.0927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.1589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.0492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.0992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.0594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.0771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.0741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.0698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.0402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.0493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.1520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.2217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.0802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.0407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.2289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.0666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.0629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.0524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.0633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.0461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.1540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.0606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.0712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.0547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.2308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.0679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.0594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.0537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.0410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.0816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.0689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.2164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.1967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.1683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.0510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.1101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.1661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.2049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.0570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.0757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.0534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.0517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.0568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.0642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.0724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.0828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.0848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.0927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.0454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.0795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.0664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.0485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.0555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.0470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.0385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.0840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.0724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.0613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.0654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.1661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.0543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.0622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.0697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.0434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.1632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.1753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.0619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.0512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.1632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.0639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.0484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.0616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.2081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.0628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.0630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.0836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.0593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.1878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.2217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.0461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.0658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.0776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.0511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.0640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.0441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.0755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.0654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.0299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.2178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.1792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.0619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.0425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.0585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.0538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.2033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.1770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.1500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.0462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.0773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.0640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.0783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.0513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.0724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.0565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.0733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.1516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.0566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.0755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.1342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.0664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.0547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.0614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.0620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.0473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.1623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.1680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.0795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.2016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.0722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.0595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.0470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.0623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.0543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.0658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.0559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.0605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.0821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.0545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.0593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.0633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.0828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.1725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.0579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.0593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.0482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.0527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.0852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.0717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.0579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.0841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.0475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.0805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.2320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.0755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.0556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.2184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.0553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.0748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.2112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.0439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.0532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.0702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.0566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.0319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.0477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.0638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.0572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.0444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.0629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.0743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.0564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.0622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.0646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.0547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.0597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.0485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.0628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.2099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.0778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.0746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.0563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.0514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.0636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.0384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.0476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.1899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.0566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.0507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.0666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.0581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.0741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.0545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.0616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.0486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.0754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.0511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.2104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.0724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.2027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.0504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.2466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.0495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.1625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.0549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.0560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.0712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.0840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.0342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.0568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.0836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.0624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.0677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.0505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.0783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.0783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.0805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.2286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.0677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.0521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.0613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.0515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.0735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.0454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.0555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.0836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.0409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.0625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.0414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.0549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.0414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.0731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.0451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.0536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.0748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.0621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.0605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.0829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.0773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.0576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.0549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.0530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.1590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.1509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.0527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.0534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.0458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.2035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.0545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.0446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.0655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.0722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.0836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.0527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.0516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.0605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.0566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.0466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.0962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.0540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.0778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.2276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.0528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.0603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.0510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.0398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.0447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.0836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.0623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.0537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.0482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.0633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.0785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.0598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.1967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.0449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.0841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.0397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.0694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.2178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.0638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.0528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.0613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.0287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.0785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.0776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.0829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.0585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.0582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.0501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.0522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.0612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.0732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.0697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.0550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.0421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.0749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.0517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.0538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.0521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.0556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.0848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.0852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.0437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.0888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.0705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.0962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.0485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.0582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.0677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.0546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.0555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.0544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.0584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.0481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.1101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.1954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.1776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.0440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.0702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.0570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.0845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.0716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.0545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.2769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.0458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.0744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.0636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.0550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.0578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.0624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.0630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.0566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.0558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.0393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.0735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.0783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.0550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.0539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.0314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.0802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.0621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.0754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.0514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.2292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.0589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.0612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.0563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.0661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.0310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.0454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.0505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.0594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.0547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.1889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.1993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.0850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.0575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.0744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.1589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.0554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.1922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.0531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.0717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.0816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.0693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.0994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.0606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.0698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 400\n",
    "batch_size = 8\n",
    "lr = 0.01\n",
    "gamma = 0.1\n",
    "\n",
    "minimum_loss = float('inf')\n",
    "loss_track = []\n",
    "\n",
    "# Load training data\n",
    "trainset = DataFromH5File5(\"/home/pz281@ad.eng.cam.ac.uk/mnt/PhD/Pro_Down_SR/data/DownBy4_31_121.h5\",N_low,N_high,scale)\n",
    "train_loader = data.DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialise training model\n",
    "G = ResidualLearning()\n",
    "G.apply(weights_init_xavier).to(device)\n",
    "mse = nn.MSELoss(reduction='sum')\n",
    "optG = torch.optim.Adam(G.parameters(), lr = lr, weight_decay=0, betas=(0.5, 0.999))\n",
    "r_scheduleG = torch.optim.lr_scheduler.StepLR(optG, step_size=100, gamma=gamma)\n",
    "\n",
    "# Logger info\n",
    "dir_name = f'models/train_NN/model4/31_121/lr{lr}_gamma{gamma}'\n",
    "makedir(dir_name)\n",
    "logger = setup_logging('job0', dir_name, console=True)\n",
    "logger.info(f'Training for {epoch_num} epoches and learning rate is {lr}')\n",
    "\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    \n",
    "    for i, d in enumerate(train_loader, 0):\n",
    "        \n",
    "        residual, high_res, low_res = d\n",
    "        \n",
    "        size = residual.shape[0]\n",
    "        residual = residual.to(device).reshape(size,1,N_low,N_low)\n",
    "        high_res = high_res.to(device).reshape(size,1,N_high,N_high)\n",
    "        low_res = low_res.to(device).reshape(size,1,N_low,N_low)\n",
    "        \n",
    "        downscaled = F.interpolate(high_res.reshape(size,1,N_high,N_high),(N_low,N_low))\n",
    "        \n",
    "        optG.zero_grad()\n",
    "        out = G(low_res) + downscaled\n",
    "        \n",
    "        loss = mse(out,low_res)/batch_size\n",
    "        loss.backward()\n",
    "        optG.step()\n",
    "        \n",
    "        if loss < minimum_loss:\n",
    "            save_model(dir_name, epoch, 'best_model', r_scheduleG, G, optG)\n",
    "            minimum_loss = loss\n",
    "            \n",
    "        if epoch%100 == 0:\n",
    "            save_model(dir_name, epoch, 'model_epoch_{}'.format(epoch), r_scheduleG, G, optG)\n",
    "            \n",
    "        save_model(dir_name, epoch, 'current_epoch', r_scheduleG, G, optG)\n",
    "            \n",
    "        loss_track.append(loss.cpu().data.numpy())\n",
    "        np.save(f'{dir_name}/chains/loss_curve.npy', np.array(loss_track))\n",
    "        \n",
    "        print(\"Epoch:\", epoch, \"Loss:\", loss)\n",
    "\n",
    "    r_scheduleG.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_low = 31\n",
    "N_high = 121\n",
    "scale = 4\n",
    "a, b, c = 8,3,5\n",
    "\n",
    "h_low = 1/(N_low-1)\n",
    "x_low = np.arange(0,1.0001,h_low)\n",
    "y_low = np.arange(0,1.0001,h_low)\n",
    "\n",
    "h_high = 1/(N_high-1)\n",
    "x_high = np.arange(0,1.0001,h_high)\n",
    "y_high = np.arange(0,1.0001,h_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_low, r_low, A_low, x_low, y_low = generate_data(N_low,a,b,c)\n",
    "w_high, r_high, A_high, x_high, y_high = generate_data(N_high,a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = ResidualLearning().to(device)\n",
    "G.load_state_dict(torch.load('models/train_NN/model4/31_121/lr0.01_gamma0.1/ckpt/best_model.pth')['netG'])\n",
    "# G.load_state_dict(torch.load('models/model4/21_121/lr0.01_gamma0.1/ckpt/current_epoch.pth')['netG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_high_tensor = torch.tensor(w_high).to(torch.float32).to(device)\n",
    "w_low_tensor = torch.tensor(w_low).to(torch.float32).to(device)\n",
    "downscaled = F.interpolate(w_high_tensor.reshape(1,1,N_high,N_high),(N_low,N_low)).reshape(N_low,N_low)\n",
    "out = G(w_low_tensor.reshape(1,N_low,N_low))\n",
    "residual = w_low_tensor-downscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(9,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.pcolormesh(x_low, y_low, residual.cpu().data.numpy(), cmap='rainbow')\n",
    "cbar = plt.colorbar(pad=0.05, aspect=10)\n",
    "#cbar.mappable.set_clim(-0.03, 0.03)\n",
    "plt.title('LR')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(1,2,2)\n",
    "plt.pcolormesh(x_low, y_low, out.cpu().data.numpy()[0], cmap='rainbow')\n",
    "cbar = plt.colorbar(pad=0.05, aspect=10)\n",
    "#cbar.mappable.set_clim(-0.03, 0.03)\n",
    "plt.title('LR')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upscale by 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_low = 31\n",
    "N_high = 121\n",
    "scale = 4\n",
    "a,b,c = 8,5,5\n",
    "\n",
    "h_low = 1/(N_low-1)\n",
    "x_low = np.arange(0,1.0001,h_low)\n",
    "y_low = np.arange(0,1.0001,h_low)\n",
    "\n",
    "h_high = 1/(N_high-1)\n",
    "x_high = np.arange(0,1.0001,h_high)\n",
    "y_high = np.arange(0,1.0001,h_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_low, r_low, A_low, x_low, y_low = generate_data(N_low,a,b,c)\n",
    "w_high, r_high, A_high, x_high, y_high = generate_data(N_high,a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Parameters for prior variance\n",
    "prior_sigma = 0.002\n",
    "ll_sigma = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.eye(N_high**2) * prior_sigma**2\n",
    "G_inverse = np.eye(N_high**2) * (1/prior_sigma**2)\n",
    "\n",
    "# Turn matrices to tensors\n",
    "G = torch.tensor(G).to(torch.float32).to(device)\n",
    "G_inverse = torch.tensor(G_inverse).to(torch.float32).to(device)\n",
    "A_high = torch.tensor(create_A(N_high)).to(torch.float32).to(device)\n",
    "b_high = torch.tensor(create_forcing_term(N_high,a,b,c)).to(torch.float32).to(device)\n",
    "\n",
    "# Store sparse matrices as sparse tensor\n",
    "A_high = A_high.to_sparse()\n",
    "G = G.to_sparse()\n",
    "G_inverse = G_inverse.to_sparse()\n",
    "operator = torch.spmm(A_high.T,G_inverse).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(w_low).to(torch.float32).to(device)\n",
    "posterior_initial = torch.randn(*[N_high,N_high]).to(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = ResidualLearning().to(device)\n",
    "# G.load_state_dict(torch.load('models/train_NN/model3/31_121/lr0.01_gamma0.1/ckpt/best_model.pth')['netG'])\n",
    "G.load_state_dict(torch.load('models/train_NN/model4/31_121/lr0.01_gamma0.1/ckpt/best_model.pth')['netG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Langevin dynamics\n",
    "K = 1000\n",
    "s = 0.0004\n",
    "\n",
    "z = posterior_initial\n",
    "chains_evolution = []\n",
    "z = z.clone().detach().requires_grad_(True)\n",
    "for i in range(K):\n",
    "    # Grad log-likelihood\n",
    "    downscaled = F.interpolate(z.reshape(1,1,N_high,N_high),(N_low,N_low)).reshape(N_low,N_low)\n",
    "    x_hat = downscaled + G(downscaled.reshape(1,N_low,N_low)).reshape(N_low,N_low)\n",
    "    log_likelihood = (-1/(2*math.pow(ll_sigma, 2)) * torch.matmul((x-x_hat).reshape(1,N_low**2),(x-x_hat).reshape(N_low**2,1)))\n",
    "    grad_ll = torch.autograd.grad(log_likelihood, z)[0]\n",
    "    # grad_log_likelihood = torch.matmul(G,grad_ll.reshape(N_high**2,1)).reshape(N_high,N_high)\n",
    "    \n",
    "    # Grad prior\n",
    "    difference = torch.spmm(A_high,z.reshape(N_high*N_high,1)) - b_high.reshape(N_high**2,1)\n",
    "    # log_prior = - 0.5 * difference.T @ G_inverse @ difference\n",
    "    # grad_log_prior = torch.autograd.grad(log_prior, z)[0]\n",
    "    grad_log_prior = (- torch.spmm(operator,difference)).reshape(N_high,N_high)\n",
    "    \n",
    "    # Random noise term\n",
    "    W = torch.randn(*[N_high,N_high]).to(device)\n",
    "    # random = torch.matmul(G_sqrt,W.reshape(N_high**2,1)).reshape(N_high,N_high)\n",
    "    \n",
    "    z = z + 0.5 * s ** 2 * grad_log_prior + 0.5 * s ** 2 * grad_ll + s * W\n",
    "    # chains_evolution.append(z.cpu().data.numpy())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "X, Y = np.meshgrid(x_high, y_high)\n",
    "ax1.plot_wireframe(X, Y, z.cpu().data.numpy(),color='r')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_zlabel('w')\n",
    "ax1.set_title('SR')\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "X, Y = np.meshgrid(x_high,y_high)\n",
    "ax2.plot_wireframe(X, Y, w_high,color='r')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_zlabel('w')\n",
    "ax2.set_title('high-res')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR L2 Error: 0.00027698612237858676\n"
     ]
    }
   ],
   "source": [
    "error1 = abs(w_high - z.cpu().data.numpy())\n",
    "print('SR L2 Error:', (error1**2).sum()/error1.shape[0]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upscale by 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_low = 31\n",
    "N_high = 121\n",
    "scale = 4\n",
    "a,b,c = 8,5,5\n",
    "\n",
    "h_low = 1/(N_low-1)\n",
    "x_low = np.arange(0,1.0001,h_low)\n",
    "y_low = np.arange(0,1.0001,h_low)\n",
    "\n",
    "h_high = 1/(N_high-1)\n",
    "x_high = np.arange(0,1.0001,h_high)\n",
    "y_high = np.arange(0,1.0001,h_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_low, r_low, A_low, x_low, y_low = generate_data(N_low,a,b,c)\n",
    "w_high, r_high, A_high, x_high, y_high = generate_data(N_high,a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Parameters for prior variance\n",
    "prior_sigma = 0.002\n",
    "ll_sigma = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.eye(N_high**2) * prior_sigma**2\n",
    "G_inverse = np.eye(N_high**2) * (1/prior_sigma**2)\n",
    "\n",
    "# Turn matrices to tensors\n",
    "G = torch.tensor(G).to(torch.float32).to(device)\n",
    "G_inverse = torch.tensor(G_inverse).to(torch.float32).to(device)\n",
    "A_high = torch.tensor(create_A(N_high)).to(torch.float32).to(device)\n",
    "b_high = torch.tensor(create_forcing_term(N_high,a,b,c)).to(torch.float32).to(device)\n",
    "\n",
    "# Store sparse matrices as sparse tensor\n",
    "A_high = A_high.to_sparse()\n",
    "G = G.to_sparse()\n",
    "G_inverse = G_inverse.to_sparse()\n",
    "operator = torch.spmm(A_high.T,G_inverse).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(w_low).to(torch.float32).to(device)\n",
    "posterior_initial = torch.randn(*[N_high,N_high]).to(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G = ResidualLearning().to(device)\n",
    "G.load_state_dict(torch.load('models/train_NN/31_121/lr0.01_gamma0.5/ckpt/best_model.pth')['netG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Langevin dynamics\n",
    "K = 1000\n",
    "s = 0.0004\n",
    "\n",
    "z = posterior_initial\n",
    "chains_evolution = []\n",
    "z = z.clone().detach().requires_grad_(True)\n",
    "for i in range(K):\n",
    "    # Grad log-likelihood\n",
    "    downscaled = F.interpolate(z.reshape(1,1,N_high,N_high),(N_low,N_low)).reshape(N_low,N_low)\n",
    "    x_hat = downscaled + G(downscaled.reshape(1,N_low,N_low)).reshape(N_low,N_low)\n",
    "    log_likelihood = (-1/(2*math.pow(ll_sigma, 2)) * torch.matmul((x-x_hat).reshape(1,N_low**2),(x-x_hat).reshape(N_low**2,1)))\n",
    "    grad_ll = torch.autograd.grad(log_likelihood, z)[0]\n",
    "    # grad_log_likelihood = torch.matmul(G,grad_ll.reshape(N_high**2,1)).reshape(N_high,N_high)\n",
    "    \n",
    "    # Grad prior\n",
    "    difference = torch.spmm(A_high,z.reshape(N_high*N_high,1)) - b_high.reshape(N_high**2,1)\n",
    "    # log_prior = - 0.5 * difference.T @ G_inverse @ difference\n",
    "    # grad_log_prior = torch.autograd.grad(log_prior, z)[0]\n",
    "    grad_log_prior = (- torch.spmm(operator,difference)).reshape(N_high,N_high)\n",
    "    \n",
    "    # Random noise term\n",
    "    W = torch.randn(*[N_high,N_high]).to(device)\n",
    "    # random = torch.matmul(G_sqrt,W.reshape(N_high**2,1)).reshape(N_high,N_high)\n",
    "    \n",
    "    z = z + 0.5 * s ** 2 * grad_log_prior + 0.5 * s ** 2 * grad_ll + s * W\n",
    "    # chains_evolution.append(z.cpu().data.numpy())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "X, Y = np.meshgrid(x_high, y_high)\n",
    "ax1.plot_wireframe(X, Y, z.cpu().data.numpy(),color='r')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_zlabel('w')\n",
    "ax1.set_title('SR')\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "X, Y = np.meshgrid(x_high,y_high)\n",
    "ax2.plot_wireframe(X, Y, w_high,color='r')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_zlabel('w')\n",
    "ax2.set_title('high-res')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR L2 Error: 0.0001569370913305863\n"
     ]
    }
   ],
   "source": [
    "error1 = abs(w_high - z.cpu().data.numpy())\n",
    "print('SR L2 Error:', (error1**2).sum()/error1.shape[0]**2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
