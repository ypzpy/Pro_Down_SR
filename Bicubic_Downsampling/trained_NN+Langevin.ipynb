{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS']='2'\n",
    "os.environ['LD_LIBRARY_PATH']=''\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pz281@ad.eng.cam.ac.uk/mnt/PhD/Pro_Down_SR\n"
     ]
    }
   ],
   "source": [
    "%cd /home/pz281@ad.eng.cam.ac.uk/mnt/PhD/Pro_Down_SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pz281@ad.eng.cam.ac.uk/anaconda3/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data_generation import *\n",
    "from scipy.linalg import sqrtm\n",
    "from downscaling import *\n",
    "from utils import *\n",
    "import random\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pz281@ad.eng.cam.ac.uk/mnt/PhD/Pro_Down_SR/Bicubic_Downsampling\n"
     ]
    }
   ],
   "source": [
    "%cd Bicubic_Downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Downscaling Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Training $u_l=G(u_h)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code downscaling matrix\n",
    "N_low = 30\n",
    "N_high = 120\n",
    "scale = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory already exists\n",
      "2024-06-05 10:09:40,279 : Training for 1000 epoches and learning rate is 0.01\n",
      "Epoch: 1 Loss: tensor(55.8895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(348.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(10.9832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(29.1769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(59.0342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(26.6897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(11.9775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(356.6868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(6.6373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(101.4400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(14.5000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(10.3257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(14.2910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(6.8778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(5.6684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(5.0443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(4.2773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(5.8763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(52.7974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(4.6379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(5.2279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(24.6964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(2.1913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(265.4648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(7.9456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(11.5841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(17.8677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(6.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(10.3942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(2.6478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(4.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(2.7519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(4.5700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(2.8551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(2.7742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(1.9940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(2.8618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(33.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(9.5889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(96.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(9.2905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(4.4749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(3.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(11.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(3.2110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(9.4711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(4.6880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(39.0589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(82.7603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(13.2929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(69.3928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(3.7644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(3.5398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(5.3932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(1.8261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(2.0323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(1.6000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(1.6542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(7.0167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(1.8963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(1.5245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(9.1974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(1.9672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(1.0706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(1.3009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(1.1392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(1.8658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.9853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(1.9713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(4.5900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(1.5548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(1.7775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(4.7379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(6.2361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(3.5905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(1.3654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(1.6678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(1.6225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(3.6309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.8665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.7787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(1.3636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(1.5983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(1.6070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(1.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(2.8397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(1.0305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.8717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.9974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(2.3261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(2.4393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(1.7002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(1.0485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.7456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.9572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(1.7317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(1.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.7203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(5.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(7.4939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(1.2945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.8052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.8707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(1.3229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(1.5817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.8837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(1.8906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.5616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.6062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.8810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.9197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.9949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.6067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(2.2830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(1.9419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(2.0055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.7188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(1.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.7691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.5358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.9018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.7179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.8375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.9168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.6634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(1.0305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.8873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.5130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.6210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.6826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.9127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.9791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.5604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.6438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(2.0103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(1.5876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(1.4204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.5328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.6616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.5619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.6346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(1.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.9853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(1.0553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.8179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.7226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.6944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.5256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.6555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.6447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.5783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(1.7211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.9853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(2.2326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.8431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.7167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(2.7232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.5548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.8532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.7879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.7229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.6957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.4883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.3970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.7550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(1.3774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(1.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.5937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.6928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.6199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.8904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.3482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.6794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.6804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(1.6785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(1.0942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(4.5207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(1.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(14.3541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(18.9973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.3796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(2.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(4.9465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(2.8567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.6774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(1.2761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.8581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.8088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(1.2579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.6095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.6856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.6099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.2539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(1.4084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.7877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(1.0592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.8655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(2.6051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.4337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(2.6603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.6973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(1.4994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.4157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(1.8076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.7207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.8156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.6064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(1.6019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(1.1987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.5684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.6235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.5701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.4157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.7474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.6196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.8072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(1.4064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.6830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(1.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.5608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.4959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.3880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(1.1858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(1.0519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(1.0340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.3033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.4312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.4112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.4494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.7597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.4896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(1.3034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.4849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.3472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.9297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.6073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.6510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.7342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.5728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.5940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.3362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.5802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.5376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.5256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.6916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.2991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.5513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.8326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(1.3027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(1.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.4856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.4764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(1.3366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.4317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.4690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.3380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(2.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(1.2521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.9168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.7780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(1.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(1.9633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.8115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(22.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(5.7484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(11.4564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(4.6494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(30.6832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(4.4916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.8021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(1.3211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(1.3597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(1.6913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(1.5935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.9885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.6572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.3650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(11.7625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(1.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(8.6154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(4.4292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(2.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(1.8067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(3.2714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(4.1846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(2.8058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(19.7168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(11.4555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(92.8792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(101.5995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(42.9841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(17.5055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(24.6863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(19.8574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(3.5569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(11.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(2.1663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(5.4214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(3.4224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(3.3565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(11.4361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(6.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(9.9617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(3.6193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.9970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.4968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.3545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.9510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.6697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.5654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(28.6225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(3.0307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(65.0430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(18.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(68.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(40.4947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(19.6221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(5.7457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(17.9166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(76.7233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(18.4186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(61.2543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(1.3734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(12.6941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(2.0548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(1.6620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(2.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(2.5666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(102.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(53.2600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(23.3779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(3.6535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.6764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(16.3555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(14.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(103.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(8.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(5.5057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(7.5610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(31.3901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(21.9164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(84.8373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(407.3349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(10.5769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(6.5528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(3.2997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(2.5094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(53.7804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(10.0519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(11.5136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(3.3933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(6.4408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(40.8506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(5.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(13.4596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(15.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(11.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(4.9462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(5.8416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(2.7026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(2.9077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(18.9348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(950.1788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(19.4016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(2.6130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(36.7991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(7.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(4.0348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(35.7383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(17.7021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(20.1697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(10.5916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(61.4323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(9.7101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(53.5327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(17.8778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(7.5487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(68.2211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(42.5304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(176.8365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(204.3445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(13.5038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(23.4939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(28.4607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(16.1427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(18.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(6.9330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(84.3988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(11.5017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(8.4417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(5.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(7.9721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(2.3384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(173.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(10.8805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(15.4039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(38.4487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(10.2579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(17.5946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(13.9678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(2.8864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(105.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(7.8590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(37.7873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(9.4750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(48.9310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(455.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(14.7799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(10.6097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(18.3622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(13.7653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(22.4583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(13.5723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(22.8703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(4.0881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(20.8679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(75.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(6.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(8.6106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(25.4495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(130.4964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(8.9562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(43.9499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(2.7552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(422.5264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(22.0615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(12.2925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(9.3297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(8.4268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(5.3734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(4.0567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(44.4915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(15.3311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(12.2485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(7.8619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(9.9631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(19.7946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(17.5705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(7.8459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(13.3666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(11.2530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(4.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(35.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(407.8098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(96.6815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(2.2846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(14.7262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(2.5012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(3.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(10.2959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(2.3298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(9.8807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(7.2425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(31.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(3.1181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(2.2143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(386.7556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(89.8339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(5.3108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(2.7217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(2.5940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(7.8585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(37.7068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(2.9927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(9.5010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(4.3546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(9.3810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(34.2691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(33.6807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(13.5239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(370.8532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(4.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(4.0381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(78.7214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(9.7930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(2.7953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(2.6880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(2.8622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(2.5533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(25.5985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(7.0373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(4.4038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(11.9843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(5.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(26.4900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(6.9907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(11.6435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(7.8597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(2.2653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(4.7695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(355.1072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(1.8251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(3.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(73.6874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(2.7290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(3.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(2.8378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(77.7863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(24.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(13.8659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(348.8955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(14.2878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(6.5942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(2.7122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(2.3463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(21.5695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(4.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(5.4235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(8.8014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(4.6839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(8.4655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(3.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(4.9523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(2.6023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(23.7795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(11.9589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(25.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(9.7348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(2.9492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(2.4191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(2.0495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(5.7359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(68.3944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(7.6417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(2.6707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(3.5842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(336.9016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(5.9794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(6.0771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(7.4738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(10.5265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(32.3683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(13.9286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(22.1711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(20.7645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(68.7191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(9.1659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(3.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(332.3969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(3.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(2.8151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(2.6480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(3.2807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(2.6967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(6.7124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(2.5317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(5.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(2.6457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(19.7581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(6.3296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(325.4476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(19.6291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(3.3383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(3.0319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(4.4533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(3.5060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(5.0272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(60.5079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(2.8765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(3.9357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(2.6509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(4.7781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(5.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(2.4994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(2.6025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(2.3523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(18.8018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(77.3388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(8.0632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(17.4208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(6.7063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(315.2504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(2.2511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(2.7195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(9.0484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(2.9201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(3.5696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(2.9115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(2.9233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(24.5845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(44.0260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(328.7108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(31.5411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(3.1830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(27.7401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(101.6852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(35.3506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(17.6213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(5.8836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(5.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(5.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(3.9572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(4.5355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(2.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(2.0364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(5.6782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(2.3789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(2.1833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(314.8345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(17.8374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(4.2156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(19.1441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(6.8747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(2.7063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(2.6677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(2.6124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(56.6071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(3.7313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(2.7268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(2.4498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(4.7196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(2.2599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(3.8609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(2.0747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(4.9290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(55.1254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(1.9012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(304.6753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(16.6796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(4.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(3.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(15.7423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(2.0879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(2.5257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(3.8764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.9831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(51.7799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(15.4730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(297.0080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(2.8102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.9219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(3.2543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(2.7391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(14.9994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(4.4479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(3.2542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(2.0180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.9967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(2.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(1.9869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(2.2804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(2.3409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(4.8342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(14.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(4.6647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(4.1607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(3.7469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(15.4204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(51.4426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(3.1898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(289.2309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(2.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(1.7357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(2.7898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(2.3520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(2.2673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(2.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(284.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(14.6765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(7.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(10.5320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(22.2645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(51.0080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(5.4540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(3.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(13.3775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(2.9436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(5.3525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(3.8526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(5.8207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(6.2458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(49.8170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(3.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(2.7495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(2.2873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(13.5292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(277.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(3.6797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(1.4289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(1.3632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(1.4212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(1.5530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(1.3241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(2.0989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(11.8632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(2.3419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(4.4866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(277.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(4.4788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(6.4373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(8.4054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(20.3499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(14.5016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(27.0217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(48.4256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(14.7392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(14.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(9.6187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(13.4378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(23.7216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(6.2044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(2.6152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(1.0612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.4044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.4755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.3785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.4588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(2.3674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(2.6967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.7250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(11.6411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.0780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(2.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(10.9616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(41.0527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.9535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(266.7770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(1.0312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(2.0588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(1.4804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(1.1478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(1.5305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(50.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(5.5347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(266.8883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(12.5306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(9.6394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(18.4053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(11.3107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(17.9626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(6.9904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(14.6341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(5.8066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(7.4175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(3.7053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(2.5409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(2.1888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(38.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(11.4232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(12.0415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(6.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(10.5743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(5.3233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(4.4657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(2.3102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(259.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(2.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(2.2369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(2.5538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(3.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(3.8813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(4.3884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(4.7957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(7.1848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(4.6571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(5.2796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(13.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(8.6275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(5.7965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(4.9142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(2.3177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(37.4380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(262.3134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(1.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(1.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.9875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(1.4748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(9.6642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(2.1580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(3.9756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(35.9025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(2.9456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(3.4388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(4.9989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(5.2281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(15.5967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(255.8018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(15.1794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(8.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(10.4195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(6.4044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(7.7003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(4.2195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(3.9751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(12.4433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(252.7798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(35.5991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(2.7262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(1.8294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(1.8552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(1.9384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(2.5338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(3.4910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(5.0844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(7.2108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(23.6223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(34.7058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(105.8514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(250.2398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(2.7246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(6.4491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(33.8500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.0388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.7914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.3649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.4321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.7266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(8.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.0095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.9703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.7875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.9672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.8613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.5574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.7725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(269.0430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.8688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.7358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.0655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.9592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.3161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.4446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(15.7609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(13.9207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(13.5202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(23.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(25.3665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(60.6420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(18.6609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(244.0540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(1.8482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(2.3966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(3.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(1.3050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(28.9115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.8059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.6753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.7653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.8726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.5212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(1.0224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.4569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.5935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.7494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.7943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.8382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.8155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.7963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.4810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.0387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.9757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.5788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.4898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.5643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(35.1847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(229.5818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(7.4724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(1.8877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(1.8584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(2.4313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(3.3848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(30.7557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(213.9761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(3.3083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(4.5714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(7.9800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(11.3914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(33.9964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(70.9539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(207.4474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(73.8114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(105.6804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(121.0429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(49.6269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(51.3268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(15.7112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(5.8495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(4.5687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.9872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(1.7230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.7395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(1.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(9.8073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(1.2457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(271.6318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.4955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(1.3114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.8337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.8825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.8708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(188.6263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.4996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(11.1915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(4.3169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.8011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.0336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.2306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(2.8794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(2.2087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(2.8095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.8701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.2046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(2.8274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(2.3708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.0223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.3565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(1.0427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.9551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(1.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(62.6865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(5.6724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(14.1111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(17.5388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(27.3241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(10.0669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(13.3366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(228.9530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(400.8651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(390.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(328.4698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(295.6488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(160.4683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(415.9254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(39.1942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(1.8575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(7.5655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(73.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(14.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(20.6311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(13.9608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(6.9896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(58.5684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(5.2865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(6.3376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(1.7388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(4.3397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(2.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.0687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.7632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(54.4381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.2523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.7771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(2.6453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.0213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.2402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.5782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(13.9117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(4.5360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(2.0139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(12.7249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(238.4720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.8387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(10.3919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(19.2070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(2.7473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(2.6177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(1.0430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.5557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.8783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.7517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(7.2413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.7284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.7264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(1.4376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.7316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.4528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(111.9957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(10.7953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(8.6626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(45.0669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(6.4609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(2.7756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.8565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(1.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.5195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(2.1906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(1.0189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.8343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(3.3084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(1.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.9753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(1.6875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.4219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(3.8007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.7603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.8229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.8949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.9699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(1.0090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(34.6079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(6.5207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(1.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.8709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(4.8440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(2.4374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(6.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(88.8734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(47.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(1.5008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(3.9881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(5.6251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.8340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(8.4622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(72.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(5.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(22.2211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(315.8823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(2.0484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(1.8267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(1.7761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.3826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.4110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.4668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(13.4413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.9634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.8976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(41.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.8635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.5027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.4408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.8622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(1.4529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.5501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(193.4912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(3.4702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(9.3348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(17.3521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(16.5419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(3.8150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(1.2628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(1.3775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.8142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(1.0195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.4651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.9035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(3.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.5978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(2.6897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.8197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.9357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.5684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.7348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.6439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(32.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(10.4384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(222.4207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(49.6220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(68.8100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(25.5290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(3.1879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(6.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(8.7249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(1.6890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(7.4970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(3.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(5.3422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(23.5445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.6624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.7259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(323.9440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(6.8544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(1.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(61.0242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(17.7503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.3610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(3.0956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.8283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(4.3543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.7867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.8824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.4883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(5.3632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.6785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.6218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.6102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(71.7955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(307.8110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(4.9367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.6127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(18.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(14.8650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(1.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(4.7704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(2.8478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(51.7020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.5362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(14.2742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.7032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(3.5031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.7800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(292.3318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(1.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.6673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.5444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(1.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(1.4903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(2.2420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.9972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(13.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.4721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.0401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(12.8979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.5405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.4488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.4297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.1940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.6509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(3.0452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.4536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.4950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(278.0431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(44.0570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(1.6022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(41.6895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(1.3656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.3668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(245.7638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(2.3735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.5607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(2.2896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(1.2562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.6230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(8.3825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.8743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.4920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(1.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.7884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(7.1927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(7.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.4506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.5867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.7611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.4106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(155.1949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(7.9123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(1.2086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(6.6794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(4.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(2.2291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(2.2308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(1.8286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(1.0351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.8001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.4551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.8340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.8382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.7841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.4106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.6055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.4922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.5044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.4621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.5241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.1787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(19.7363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(11.0951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(28.1846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(12.2932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(19.0612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(26.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(17.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(16.0422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(9.9543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(2.4623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(2.7168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.2036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(3.2659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.7818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.4259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.9703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.0368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.8021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(11.1651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(6.0514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(2.5350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(1.5805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(21.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(2.1634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(1.6328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(2.7126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(1.1837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.7670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.6197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.5290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.5579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.5601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(1.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.3905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.9969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.8346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(4.5469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(16.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(26.8762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(22.7381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(11.5872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(4.6778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(4.1753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(13.4882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(1.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(1.0087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.6814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.4442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(1.7334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.8585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.3818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(3.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(8.7338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(5.9725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(1.1770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(2.2508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(1.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(1.2540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(1.4575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(1.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(12.3502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.8275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.5168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(2.3408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.3765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.8160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.6876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.5780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.6435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.6075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.3492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(1.7348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.8238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(26.8765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(20.4096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(7.4649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(15.0628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.4475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(2.0110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(1.8570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.9186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.6402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(13.3935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(4.2302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.5122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(1.3783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.5278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.6820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.5489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(1.1922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.6296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.5484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.9517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.3734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.2647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.9777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.8307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.4323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.5986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.5627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.3857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.6618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.3724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.3793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.5112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.4198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(3.5128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(1.3292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(1.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.8872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(5.6150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(1.2796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.7848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(1.2001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(1.2653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.6665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.5724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.5734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(1.3963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.3110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.5328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.4546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.5642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(1.7854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(1.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.5390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(1.4027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.5763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.4358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.8286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(1.3734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.5681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.5789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.5743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.7120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.9208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.6063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.6690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.4268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(1.1965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.5187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.4249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(1.2545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.6437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.5635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.5126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(2.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(1.3761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.8187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(1.0730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.3751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.4083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(1.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.6956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.6644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.5725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.4477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.7206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.4760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.3877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.6770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.3991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.4881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.3685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.5199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.3745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.4331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.8946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(1.9207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(2.0253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.8222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.8603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(2.0303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(1.3349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.6796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.8926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.2679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(1.5409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.5402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.6104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.3735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(1.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.6665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.6131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.7341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.3675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.6051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.6326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.8184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.5119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.6687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.5710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.4226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.4552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.4642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.4362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.9961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.7447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.3191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.9056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(1.3957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.4814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(1.2471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.9768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.3653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.4555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.4342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.4728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.5594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.6241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.6383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(1.4360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.3461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.5151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.7108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.3278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(1.0806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.8588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.7749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.7224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.5763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.6170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.6420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.8173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.4229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.8688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.5635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.5010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.6203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.8868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.4837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.4905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(1.0218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.5760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.6689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.7443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.3441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.3034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.3726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.4802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.4267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.7725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.5372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.4354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.8013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(1.6779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.5425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.4963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.6623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.6477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.7424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.3332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.4071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.5070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.0741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.4478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.2654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.5601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.5564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.4452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.6783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.5262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.4707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.6065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.5150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.6568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.3822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.5615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.6497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.5845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.4478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(1.1996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.5585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.7485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.4632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.6704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.8663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.4601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.3225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(1.0094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.7050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.4808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.6694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.3691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.5982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.3496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.9055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.9187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.7818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.5444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.8340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.4781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.8482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.3871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.4267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.6692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.6773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.3471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(1.1978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.5849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.8342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.6698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.5581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.5804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.6187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.3379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.3692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.3516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(1.2533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.6825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.3942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.5574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.2414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.4299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.4765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.4393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(1.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.9277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.7643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.5862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(1.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.6075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.5054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.6255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.4511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.3064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.5628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.5821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.8398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.5971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.6110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.9320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.8859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.5862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.3153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.6514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(1.0120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.3781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.5231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.4604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.3228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.4259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(1.6331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.6826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.3225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.5460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.4332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(1.2380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(1.2060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.6213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.5272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.3703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.3444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.7469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.5114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.5071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.4388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.3887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.6637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(1.8815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(1.5618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.4296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(1.9215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.9910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.4573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.5010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.4539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.3194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.2659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.3638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.7167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(1.4395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.4311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(1.0532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.8792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.5099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.4095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.5377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.5280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.3392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.3376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.6761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(2.4894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(1.9945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(3.2463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(2.2313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.6466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.5451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.6297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.5610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.3548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.4098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(1.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.4147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.4698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.8519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.8935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.6727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.2881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.7624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.4636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.5036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.6092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.6665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.2726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.5510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.3872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(1.1459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.2693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.4087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(1.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.9315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.4484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.2893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.5994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.4230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.5134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.7483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.4183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.5290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.5220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.3207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.3301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.5774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.5029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.3671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.4292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.5805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(1.3936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.4956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.4661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.2384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.9488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.3805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.3547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.2717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.3477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(1.4732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.5404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.5187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.5065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.8770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.7341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.3086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.5109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.8288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.4577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.3512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.9114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.5193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.7528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.3992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.6286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.4484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.6074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(1.0822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.9053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.4012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.8110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.3098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.3285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.2654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.2736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.5317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.5171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.4338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.6276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.3185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.3289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.3956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.4467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(1.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.5325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.6559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.6865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.3863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.7742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.4300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.4815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.7807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.3139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.2667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.8381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.4837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.3382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.9756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.3315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.6323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.6799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.4440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.4267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.4218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.8583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.5505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.4859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.3018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.7238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.3754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.3481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.2980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(1.4652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.5420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.3026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.7631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.2877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.4858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.2786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.6913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.8755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.5973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.5495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.7078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.3185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.7741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.3129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.7195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.4347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.5242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.2169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.9093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.5353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.3302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.4535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.4926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.3726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(1.0077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.4814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.3800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.4976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.3928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.7058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.5744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.6065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.7507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.4959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.9447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.3285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.3383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.4016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.4353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.7059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.6842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.4260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.4400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.9274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(1.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.3833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.4231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.4876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.3655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(1.3390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.5363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.2923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.4321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.3690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.5234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.3742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.4829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.4297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.9058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.4444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.7430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.3159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(1.0798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.4300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.3307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.7351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.5811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.7086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.3073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.4551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.2450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.3344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.4115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.5159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.4266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.8277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.5232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.5271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.4590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.3586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.5209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.4456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.2659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(1.4803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.6978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.4446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.4748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.5520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(1.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.2946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.4580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.2059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.4144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.6817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.7208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.4130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.4824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.6697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.2875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.5732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.4706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.5337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.5158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(1.0370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.3182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.4088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.4211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.8160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.4949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.7497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(1.1995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.4109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.3377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.2761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.5001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.4742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.3641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(1.4780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.7214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.3640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.2976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.2371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.3024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.6128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.5408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.5541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(1.0192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.3548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.3711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.4761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.3207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.6276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.5044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.6360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.2737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.2705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.9684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.5531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.7300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.7029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.3464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.6885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.4756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.8213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.2933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.2807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.5776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.3597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.4121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.9184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.2749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.4295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.4015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.7597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.5240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.5336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.8081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.3384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.5845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.8557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.4237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.2391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.3880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.5889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.3573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.9725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.5670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.4124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.3909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.8574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.3647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.3335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.9080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.6996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.3414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.2675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.8576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.3038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.5024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.4838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.4033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.4771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.3227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.4687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.4482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(1.0000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(1.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.3921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.4563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.3208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.5169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.5235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.8250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.4931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.2780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.2289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.7547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.5586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.7974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.4513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.6353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.2399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.3762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.5103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.5373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.3876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.4358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.4772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(1.0203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.8594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.4388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.3463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(1.1617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.3062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.6092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.3847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.8024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.3373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.3118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.3901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.4119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.4025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.9837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.8405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.6556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.7192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.4759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.5173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.3912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(1.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.2881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.5408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.2632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.4402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.3961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.3289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.4847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.6949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(1.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.7110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.4750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.3889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.5212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.3229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.2845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.4546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.7162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.6444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.3614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.3892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.6800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.7339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.4547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.9528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.2838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.6119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.4346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.7771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.3219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.3096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.5342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.5207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.3612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.6081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.9906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.3962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.9568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.4315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.5317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.3685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.3330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.4949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.6758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.4387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.3697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.4437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.2174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.3768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(1.0233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.4873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.3770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.1996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.2811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.9831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.4876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.5637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(1.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.3446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(1.0047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(1.5487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.3622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(1.0171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.4422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.4484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.3965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.7019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.2906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.2761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.3351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.4286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.3434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.3509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.4790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.3404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.5773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.2490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.4217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.3672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.3622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(1.7752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.9101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(1.2991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.7253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.5973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.7139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.4312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.4847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(1.3888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.6939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.4278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.3292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.6287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.6113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.3469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.5427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.4679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.3417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.4271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.3043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.3730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.3972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.5782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.7780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(1.4529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.7033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.4041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.4090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(2.5992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(1.9903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.9703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.6232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(1.0577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.2686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(1.5138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.5634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.5864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.3186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.3657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.2976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.2670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.6100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.3822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(1.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.3828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.3573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.3877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.2720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.3994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.4268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(6.9607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(3.2701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(4.8142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(2.2340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(1.5958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.3756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.7178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(1.0041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.4398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(1.2339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.3594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.4164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.4879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.5754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.3429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.3296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(1.2090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.4952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.5212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.3910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.4043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.3068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.3062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.3236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.2893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.3585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.5748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.3352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.8201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.3069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.6901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.3467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.4673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(1.1587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.4674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.3783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.5506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.5950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.6472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.6722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.3625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.6252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.2896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.2318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.3640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.4361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.4562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(1.2175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.7124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.5849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.3219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.4816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.2227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.5195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.2978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.6806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.4218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.3493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.6161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.9007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.4843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.5226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.6206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.8079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.3439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.2231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.6509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.2778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(1.2280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.5287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.6518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.3352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.2658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.3480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.5279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.4445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.9548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.3186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.7314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.7596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.4567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.3418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.4354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.6615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(1.0989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.7143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.2945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.2936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.5654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.5655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.6228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.3985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.2093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.3292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.2928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.5811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.4212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.7408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.2960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.6430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.3672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.4659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.5492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.2242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.7701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.4263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.9914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.3405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.3660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.3966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.3378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.6648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.3686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.7709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.2402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.5144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(1.0428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.6805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.4983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.6797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.2957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.5810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.2455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.2692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.7539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.3491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.3756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.3207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.3834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.5705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.3057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.2684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.6388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.2826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.5586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.5967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.7531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.3682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.5264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.2104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.7118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.3581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.3782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.9557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.2642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.3109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.4663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.7502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.4755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.3539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.1888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.4231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.8691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.3749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.5887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.4124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(1.5453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.5219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.4427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.8943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.3459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.3199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.3260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.8181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.6150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.9581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.3447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.2720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.4629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.2122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.9813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.3570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.4295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.3279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.3904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.2781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.4379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.5999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.3956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.6055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.4314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.2780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.7619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.5149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.6420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.7207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.8160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.1976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.5007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.5125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.7536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.4137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.8401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.2947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.4031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.8413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.8715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.5657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.3002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.3169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.4023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.3166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.3253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.2966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.3226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.5132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.9403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.5266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.3746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.3843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.5072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.2156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.3432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.9213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.8423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.8764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.4735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.9052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.4451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.4188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.3537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.5168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.4288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.3569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.9466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.7114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.4000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.7267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.4450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.3779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.5418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.4539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.4314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.3566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.2530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.2703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.3710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.2235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.7508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.4104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.6293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.8448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.6272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.9355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.4674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.3141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.6351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.2211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.9374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.3953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.8001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.3808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.4686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.2858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.3790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.9765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.3376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.3809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.4160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.3596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.3596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.7081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(1.5342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.5794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.3021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.6168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.4715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.2201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.4133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.4025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.3237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.2997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(1.5753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.5081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.6704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.3181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.6283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.5433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.7888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.3984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.6809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.3116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.4439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.3052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.5024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.8121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.5216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.3135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.3665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.3826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.4723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(1.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(1.0234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.3252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.7865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.3978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.4132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.4121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.3403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.5141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.3417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.3097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.2205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.3069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.4129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.5754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.2654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.2395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.4259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.4188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.3490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.5945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.3430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.4723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.4837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.4434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.2375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.8473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.5328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.8038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.6183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.5943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(1.4185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.4049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.4386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.6611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.2697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.3193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.3427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.5001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.6692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.3576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.4099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.4968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.2467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.2892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.2202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.4962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(1.5188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.7347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.8221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.2467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.3447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.3721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.2515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.9625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.3711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.3654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.7035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.3830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.4653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.4474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.6744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.6297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.5097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.3270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.6697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.3009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.3751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.6704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(1.0033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.7783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.3545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.7167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.4754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.4701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.3710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.8088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.5980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.5986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.3399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.4550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.5337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.2972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.3201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.6364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.2181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.7579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.3230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.2736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.3380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.9411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.4662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(1.2822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.2089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.7230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.6796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.3137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.3206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.4205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.5642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.3899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.3882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.3364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.2447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.7057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.5816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(1.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.6064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.3655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.1813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.4911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.4794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.3792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.3409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.3129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.5089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.3439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.4702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.7719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.4912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.3822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.4671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.4500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.5596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.3694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.2480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.6285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.4069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.3413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.7106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.5877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.2977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.3891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.3208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(1.5063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(1.5730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.8424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.7274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.2904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.5525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.4831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.3320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(1.2331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.5404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.2383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.4257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.5317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.5424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.4494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.7179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.1911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.5550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.3902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.3378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.5288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.2285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.2408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.4109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(1.4014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.8218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.8846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(1.0112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.3919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.4378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.2883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.5206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.4302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(1.0393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.6427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.3453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.6944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.2878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.5458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.4951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.4301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.7721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.4104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.6405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.3420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.8242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.3486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.3072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.6042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.5225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.4660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.3444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.5602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.3808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.3360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.7400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.4058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.3357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.2080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.3772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.3750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.8070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.3097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.4077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.8708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.8459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.3506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.5807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.3956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.4346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.2680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.3501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.4520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.3343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.4703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.2873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.3284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.3149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(1.7075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(1.3010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.4820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.7434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.4373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(1.1392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.2339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.3273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.6076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.5115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.2689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.6575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.2747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.3292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.8278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.5288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.3211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.4462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.2910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.7104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.3081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.8921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.3797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.5128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.2819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.3406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.2729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.3519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.2109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.4082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(1.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.6478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.4349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.4290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.4833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.2857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.6134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.4143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.6470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.2979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.7621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(1.1788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.3653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.3514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.4827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.2914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.4017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.4910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.3553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.7699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.7358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.5711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.3548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.5792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.3436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(1.0306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.6104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.6140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.3271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.4316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.5946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.2372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.9821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.3103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.4390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.5313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.8364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.5714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.7919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(1.0279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.2192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.3272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.5618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.3979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.3751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.6491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.6733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.3162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.3116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.6411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.3174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.3663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.5835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.2160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.8196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.6433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.3705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.5430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.4036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.7002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.6741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.3326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.4303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.8023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.5007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.2223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.3868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.4356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.9678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.5250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.2768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(1.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(1.2911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.3189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.8465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.4621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.4007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.7189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.2064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.2816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.2236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.2198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.3536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.2659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.3230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.7495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.3611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.4234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.2726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.4743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.4552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.3785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(1.0218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.4607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.7741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.5267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.2329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.4227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.2677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.5779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.3148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.5785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.2366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.2275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.8973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.2430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.6595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.5809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.5130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.5516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.4216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.3878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.3445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.6471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.3126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.9270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.3090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.4588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.5886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.3747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.3041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.1643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.2716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.3459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.7451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.4128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.3627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.2795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(1.2320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.4424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.6157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.5140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.2942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(1.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.9863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.5156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(1.3844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.4545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.4313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.4562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.3894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.5320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.3864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.8785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.5753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.1912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.2975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.3535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.2249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(1.2498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.9103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.6804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(1.4262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.4895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.3656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.3670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.4504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.2937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.4502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.2697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.3004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.2063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.3938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.9526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.4684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.5056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.4918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.2177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.3294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.5046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.3999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.8592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.6236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.8864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.2697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.1707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.3065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.2772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.4727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.3095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.2716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.6848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.2394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.8092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.6094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.3981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.2789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.6760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.7695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.1774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.5399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.4794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.6056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.3046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.3882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.3272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.5555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.3480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.6606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.6520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.7850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.5387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.3318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.3355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.3820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.4155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.3212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.7409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.3130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.2913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.7407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.3236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.9286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.4089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.4172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.2913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.7464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.5462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.5253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.5364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.3447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.2362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.3239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.4153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.3931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.4201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.3914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.8169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.3863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.3731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.3495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.2716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.2927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.1793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.6331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.7756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.3199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.6239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.3804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.4792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.4067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.3007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.5797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.2539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.3212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.4705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.2060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.2861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.7951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.9772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.6697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.2275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.5375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.3339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.5878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.4220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.8602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.3932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.5989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.4116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.1927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.2666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.4228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.3961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.4845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.3170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(1.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.6218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.3099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.3990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(1.9189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.4315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.4855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.5119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.2192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.3916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.4286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.2135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.3230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.4535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.6908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.2823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.3381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.8494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.5700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.5371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.4692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.8639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.3081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.4326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.2231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(1.0349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.8403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.2193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.3181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.2638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.3640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.4845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.3541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.4786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.7021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.3329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.6110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.3163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.6750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.3527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.5434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.6986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.4792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(1.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.3457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.2506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.2186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.3692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.2813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.5367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.5049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.3314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.2197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.2312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.6879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.8023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.3941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.6869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.2193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.3610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.3850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.2280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.3890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.3502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.3818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(1.7588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(2.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.5491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.8400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.8247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.3962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.2198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.3498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.4043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(2.9578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(1.8623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.5536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(1.1691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.6714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.4574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.4528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.5827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.3790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.3389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.2938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.2618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.4771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.6359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.3095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.4073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.2705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.9426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.7018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.9045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.4221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.3680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(1.4107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.3558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.3117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.3921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.6723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.8145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.3727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.4498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.4196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.3087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(1.2809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(1.2460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.2773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.7566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.3432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.3526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.3777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(14.0047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(27.5805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(18.2539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(27.4348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(5.7018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.8721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(2.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(1.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(1.7021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.5356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(1.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(1.3811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(6.8876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(4.2729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(1.7936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.6598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.5574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.3992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.2913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.4532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.3426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.5313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.7592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.8771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.6083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.5133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(1.4036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(1.4738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(1.0794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.6512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.4385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.3676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(1.3193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.4027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.2826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.3808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.3004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.4064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.4568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(1.0788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.2113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.4252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.4642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.5573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.3731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(2.5768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(8.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(5.3304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(1.7072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.9315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.8451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.4594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(1.2355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.1705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.4528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(2.0260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(1.5382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.8090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.7764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.3185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.5325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.5507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.3401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.3799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.4343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.3815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.2407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.7364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.3430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.3714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.3814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.3009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.5872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.3241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.6562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.5007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.3268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.3573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.8568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.6628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.4645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.4808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.2462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.6010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.2454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.4021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.3836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.4311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.6048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.3519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.4081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.2679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.5345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.3682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.4267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.3170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.6511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.2421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.3774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.1754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.2890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.3944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.9311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.5799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.7964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.8114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.3582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.3905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.3414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.3237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.3770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.5635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.8055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.9618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.3558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.2869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.7315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.2512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.3425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.3462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.2854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.4564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.6693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.2637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.2836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.5565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.3380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.3822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.5510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.6117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.2760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.2933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.5796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.7876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.5869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.1819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.5068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.3716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.3517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.4022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.5278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.7726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.9457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.7227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.4641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.3345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.2570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.4560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.3003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.4030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.1840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.2111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.4194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.3234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.3117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.6588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.6582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.4112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.6152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.6602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.2710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.2771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.3758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.3497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.2820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.2698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.2305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.3815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.3720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.5842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.3332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.2007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.3676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.2095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.3275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.7488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.4722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.2065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.4498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.6224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.4739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.6769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.2242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.2552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.2282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.2904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.2236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.8193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.3691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.3550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.5290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.3816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.6482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.3464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.7445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.5874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.6244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.3616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.9447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.5201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.3323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.3242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.3028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.5532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.3743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.3324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.4928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.4309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.2506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.4315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.1904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.3465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.7798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.4308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.3134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.3402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.2746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.5903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.2856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.5089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.8805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.3374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.2143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.8136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.5515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.3729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.2045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.7109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.2865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.1859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.2312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.4155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.3940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.6392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.3694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.5959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.2409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.2540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.3406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.2989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.3692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.6630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.3875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.5574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.7231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.2565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.2048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.1912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.2133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.7834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.2295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.3689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.5664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.6109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.7202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.5979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.4818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.7561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.3916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.3134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.4443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.2785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.3027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.5644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.2651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.5285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.8741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.4463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.3152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.2860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.7777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.3345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.5027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.3323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.3830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(1.0246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(1.1890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.2403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.2836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.2820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.3588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.6711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.4511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.6097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.3128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.4126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.1863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.3209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.6664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.2990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.4138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.3304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.3396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.1871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.2216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(1.2425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.8576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.6378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.6521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.5130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.2416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.6460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.2932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.4846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.3006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.3356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.2431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.8859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.4077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.3043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.3645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.7459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.3061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.6366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.6367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.4812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.3653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.4879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.2740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.3399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.5604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.2386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.3671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.6698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.3911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.1815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.3349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.3242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.6152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.4785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.3342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.3410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.7266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.3176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.3447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.7220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.4263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.4844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.2658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.2782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.3117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.4137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.9817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.4622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.2072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.2772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.2320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.5238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.2313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.3948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.3773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.2921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.4355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.4062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.3431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.4271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.5321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.5287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.3527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.4680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.4288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.6062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.2133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.2213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(1.1864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.3131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.4249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.5540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.3410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.7866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.5137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.7322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.6701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.4642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.3374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.4916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.2038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.2530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.3380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.2374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.3674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.2976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.4286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.1921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.4943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.3787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.3849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.4115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.4910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.3038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.4320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.4007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.9639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.3837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.4863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.3209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.1822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.2892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(1.0678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.3242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.6353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.2111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.3156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.3072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.2515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.4433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.6893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.3757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.4037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.2098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(1.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.4538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.3424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.3421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.4089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.4326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.2738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.2393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.5583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.2249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.3302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.4229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.2708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.1937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.3406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(1.2696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.8085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.4747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.6976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.3525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.2279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.6584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.2190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.5746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.5299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.2955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.5124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.2323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.4766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.4860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.5636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.3468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.5235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.1977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.2024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.6927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.7037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.3454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.2786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.2831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.3626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.2935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.5024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.4375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.2660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.6500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.6331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.5676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.3166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.6993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.2851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.8618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.4320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.3649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.6710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.3993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.6279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.2326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.2235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.4771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.3108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.5781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.9106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.4019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.2295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.3427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.2991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.4203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.3899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.3499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.4433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.4630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.2410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.2835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.2026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.3639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.5625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.3752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.2404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.4653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.9233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.4347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.2872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.3386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.3847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.5490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.3690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.5433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.3821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.6720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.3409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.3584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.3671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.4173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.7316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.3717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.6046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.3478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.5444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.3927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.2819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.2172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.8182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.7184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.2762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.2713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.3070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.3822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.6789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.3985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.2944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.3506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.6262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.5288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.4624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.4606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.3474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.3345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.2019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.3413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.3974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.4650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.5775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.3054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.3463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.7967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.3725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.6260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.2855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.1726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.4408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.2960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.2735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.3503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(1.0570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.6356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.9738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.3227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.2836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.1906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.5048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.2971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.3564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.4030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.4909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.3359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.6709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(1.5283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(1.4631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.3369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.4769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.7433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.5193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.2298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.2815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.4231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.4561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(1.6214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.8370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(1.4147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(1.3261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.8460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.3779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.4427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.2144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.5500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.3057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.3165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.2310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.3309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.3238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.5793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.4120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.3279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.6298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.2304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.4246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.3107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.3641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.2289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.3259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.7813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.4224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.3552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.2855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.2987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.6987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.2273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.1650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.8779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.2455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.6661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(1.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.4498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.7653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.5676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.3688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.2695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.4471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.5324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.4437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.2777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.2420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.3773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.7445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.3047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.4155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.3728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.5995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.6376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.3702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.6967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.9870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.5336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.5424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.6232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.4545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.2760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.2145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.5786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.2832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.3275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.3297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(1.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.7233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.4810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.2332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.5631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.9241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.3673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.1562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(1.0074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.2684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.3802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.3006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.5340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.2567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.5677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.3232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.2404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.4498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.7229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.2506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.4225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.4438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.3566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.2462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.1997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.4905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.3230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.3572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.5057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.3272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.6490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.3056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.5586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.3521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.5622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.6761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.3516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.2952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.4338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.3630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.2615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.3881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.4544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.5194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.3369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.6317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.3459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.5128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.1956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.5109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.4550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.3065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.3342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.1764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.2001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.2359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.2407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.1769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.2269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.6185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.4527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.5984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.8627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.4778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.3222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.4096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.2907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.6319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.4025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.3590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.2244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.4553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.4003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.4162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.4053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.3019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.4744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.4512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.5633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.2168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.9422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.4156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.3202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.4553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.7421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.3912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.4555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.3797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.4494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.3353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.3589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.2150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.1754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.7184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.3321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.4975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.7893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.3805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.2286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.2990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.4728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.2697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(1.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.2164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.6874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.4415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.3583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.1697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.2841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.5338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.3712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.7797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.2995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.5511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.2961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.4886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.2350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.3429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.3731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.4051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.3610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.4496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.3549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.5175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.1792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.3983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.2640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.2539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.1589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.3669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.3607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.3272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.5117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.6362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.1930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.3745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.6434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.3340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.7059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.3673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.2300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.8697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.2352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.5720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.6737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.4513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.4103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.6148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.9638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.1677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.2080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.3422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.4848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.2337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.2955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.5152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.2825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.1833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.1906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.3017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.2282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.3399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.3094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.2101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.6696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.3940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.2920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.2296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.2484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.6973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.3404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.3966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.4914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.4266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.3108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.6411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.3386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.3273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.5358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.3925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.2283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.2589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.1893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.2820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.5785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.1632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.3754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.5991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.3026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.4502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.3645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.3971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.5266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.4547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.1392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.2169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.3186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.2821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.3064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.4672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.8702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.8577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.2811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.3001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.3211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.2201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.3017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.2172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.5196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.3667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.3000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.5750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.7495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.2950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.3575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.2629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.3356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.3306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.2818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.5275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.5212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.3524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.3340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.1874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.2002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.2674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.2942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.1905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.3487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.6946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.2793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.5741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.5183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.4669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.3433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.7154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.4202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.2796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.7429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.3271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.6333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.5367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.3533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.2839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.3242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.5294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.2802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.2670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.4137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.1956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.5578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.3196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.3730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.2483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.5690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.8187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.5487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.3142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.2139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.3037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.3147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.5168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.4203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.3040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.5096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.4702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.6115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.3428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.3497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.2748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.3269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.6236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.4556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.2151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.4786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.4861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.2871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.5352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.2088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.2732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.3835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.2348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.6811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.4301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.5833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.2154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.3681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.5198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.2356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.3878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.4830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.3037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.4328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.5912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.2933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.2058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.5216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.3278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.2279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.4844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.2808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.3608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.6035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.4243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.4060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.3713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.3428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.2434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.9659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.4051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.5894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.2285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.2361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.2321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.3068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(1.3318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(1.8410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.8727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.8341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.3095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.5899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.3937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(1.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.5732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.3206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.3132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.7686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.3329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.3609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.8926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.4001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.1739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.3711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.2729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(1.6206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(1.6952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.2218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.4388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.4254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(1.3337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(1.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(1.4778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.2753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.6670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.4443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.5054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.3547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.4280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.2750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.2202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.5540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.4286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.5005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.2023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.6566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.2773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.2551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.6284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.5480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.3467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.2159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.7658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.4391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.2758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.7281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.8263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.5264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.2792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.3467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.4586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.2410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.3193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.6496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.7644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.2189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.2072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.3754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.4024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(1.2410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.9133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(2.5642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(4.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(1.0489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.3486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.5022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.2135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.2159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.3480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.4045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.2266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.2184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.2708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.2329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.5317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.4294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.2679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.4569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.4630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.3651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.3382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.3082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.4330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(1.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.5592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.2306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(1.3824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.8794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.2333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.2117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.6159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.3139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.5014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.3116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.2877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.8143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.8086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.2036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.4699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.2534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.2007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.6309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.3690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.4112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.3340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.2232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.6284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.4695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.5413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.1806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.2216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.4601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.4865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.3328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.3024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.2637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.5401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.5716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.2365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.2412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.5211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.2860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.3316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.3336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.2899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.6756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.7132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.5490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.2733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.6210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.4686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.3101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.3570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.2371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.5935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.5090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.6526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.2408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.2311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.2653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.3720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.2375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.7508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.2217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.4216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.2725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.3492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.5686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.3326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.5630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.3460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.3532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.4771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.3670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.3893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.3397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.3282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.5980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.2448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.3344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.6118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.3827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.4321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.2758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.2118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.4487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.3188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.1920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.1849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.4723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.5872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.3071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.3887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.2878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.4571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.2969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.5424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.1523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.2067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.4028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.4510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.2320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.2023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.4794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.3036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.3728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.4492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.3217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.3458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.5586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.2163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.4649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.6453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.2395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.2017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.2083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.2118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.3299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.5249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.1786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.2416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.3128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.3446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.4253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.6174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.3704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.2708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.1975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.2465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.9046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.8089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.2283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.3082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.2099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.2329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.5687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.2598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.3266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.7226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.3385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.2952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.4842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.7426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.8332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.3562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.1585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.2820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.3042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(2.7496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(2.6729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.6067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(1.3939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.7723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(7.3193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(2.4340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.6777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.9227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.9468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.6886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.3519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.3940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.2464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.6199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(1.2695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.2154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.2856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.2535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.3266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.3058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.2809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(2.7470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(2.9423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.4594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(1.3520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(5.6013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.8171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.9591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.8534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.2215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.3223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.2410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.2647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.4561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.2938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.2678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.2414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.4612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.2682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.2139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.4027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.5805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.1925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.6176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.2329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.2297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.3052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.5744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.2942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.2729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.4324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.2126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.5908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.2332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.3500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.5669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.9464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(1.4127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.2775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.6112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(1.3512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.2970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.2936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.3970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.4628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.3819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.3475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.2311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.2292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.3300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.6143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.3744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.3880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.3280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.9027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.4069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.2091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.5247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.2402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.4390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.2968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.2103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.6661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.5412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.3321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.3659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.5302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.0757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.3567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.7659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.4304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.3196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.2123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.3857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.2166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.3337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.2552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.5258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.2207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.2790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.3223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.4194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.2846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.2003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.7133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.8855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.5347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(1.0364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.5364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.4073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(3.6067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(5.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(1.1945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.1828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(2.7727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(2.3110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.9005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.5099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.2741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(1.6797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.9606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.2228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.8662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.4188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.3989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.5731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.1796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.3952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(1.2738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.6525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.2863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.4562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.3779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.2598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.2465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.4397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.3217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.8122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.3643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.3661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.3985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.2273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.2039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.5564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.6492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.4125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.5521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.3977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.4242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.6350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.2851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.3406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.2005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.2230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.5889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.7157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.2145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.2705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.2018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.2762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.4191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.5891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.3168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.3004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.6275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.2354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.3434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.5889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.2851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.4711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.3527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.2978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.3560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.2403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.2687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.2147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.2277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.4833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.1465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.3676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.1929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.2306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.3170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.3697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.2372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.3986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.2198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.1961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(1.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.3341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.5830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.9080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.2730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.2039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.3754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.5996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.5857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.2731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.8088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.4388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.2135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.5476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.2217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.4028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.2615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.4644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.5721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.1900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.2076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.2026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.3078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.2883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.2483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.2817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.5281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.3279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.3357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.4031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.3946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.4472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.2099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.4163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.6766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.2099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.2926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.3013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.4712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.4356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.2350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.2239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.4964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.3182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.4827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.2091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.3590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.7767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.2999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.4739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.3539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.3859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.2376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.3000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.5258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.3065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.6605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.3795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.3174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.3043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.3349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.2024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.2047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.5443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.2269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.3156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.1636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.4376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.4331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.5194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.2881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.2144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.4968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.4182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.3994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.2774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.3940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.2181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.2145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.4268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.3390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.2125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.2186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.2936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.2261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.3266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.2645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.5390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.3197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.5882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.3346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.2821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.2738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.2061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.3169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.2709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.7582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.2333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.6313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.3006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.2534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.3311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.2850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.2117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.3254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.3612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.2105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.4878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.4881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.2505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.3891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.2331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.2161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.3113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.3754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.2027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.7792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.2215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.2682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.3075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.6367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.4242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.3978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.1915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.6051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.4328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.1127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.4653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.3825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.2087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.3056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.4364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.2858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.5297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.3350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.5046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.2748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.4137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.2686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.3270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.3930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.2220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.3553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.6118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.4580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.2331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.4974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.2966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.2167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.4844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.2110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.2956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.2110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.5262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.5821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.4435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.3447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.2672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.3148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.2930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.3341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.2265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.2424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.2936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.3255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.3370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.4942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.1921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.4856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.3557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.1874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.2534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.1875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.4832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.2282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.3078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.4174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.2211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.2748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.3794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.2110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.6934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.2318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.3277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.2886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.2684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.2352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.5339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.1989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.3485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.5066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.3886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.1921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.3215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.4804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.4501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.2493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.4634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.2496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.4176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.7049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.2799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.3682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.2208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.3574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.3649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.2430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.5971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.2759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.2938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(1.1556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(1.2080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.3753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.3736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.5294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.3213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.2825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.2447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.2962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(2.7113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(2.6099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.2803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.2205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.2308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.2437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.8963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.2140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(1.3034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.2885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.1845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.3016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.3313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.2842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.2669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(1.0382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(1.1905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.3291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.3709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.6129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.2102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.4183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.3377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.6400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.6156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.4209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.4072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.3043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.2908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.2893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.4202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.3196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.5224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.7298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.2052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.2520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.3038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.2448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.2490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.5026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.2161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.6914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.2353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.4657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.2217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.5685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.2433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.3357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.3213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.1864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.2017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.1922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.1831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.4505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.4790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.3525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.5279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.2716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.4909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.4433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.2859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.2357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.3444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.3898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.3875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.2810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.2007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.4694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.6042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.2394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.2437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.4584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.3233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.7903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.2105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.2202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.4592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.6889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.2842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.2223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.2166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.3157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.3347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.3882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.4385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.3148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.2871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.2794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.2738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.2116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.2118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.6238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.2168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.2789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.2211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.2933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.4739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.2088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.6849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.2348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.2095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.2337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.2800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.5914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.2355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.4885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.2796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.4964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.2333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.5367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.5372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.3825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.3097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.5141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.2280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.3032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.2754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.3016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.5486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.2704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.2502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.4123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.3718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.2036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.7471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.4147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.2242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.5464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.3084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.2018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.3334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.4517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.2281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.3948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.4682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.2318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.2651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.2629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.2159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.3091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.2120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.4703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.3908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.5299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.2818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.5332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.1960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.3958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.2284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.5399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.9716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.5943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.2916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.2278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.3624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.3000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.4014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.2226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.2402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.4653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.2762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(1.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.5565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.3577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.8151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.3772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.4206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.4189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.2814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.2262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.1834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.3276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.1747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.2316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.4179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.4294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.3832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.3183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.4602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.2460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.2061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.2415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.3067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.3607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.4498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.2295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.5660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.5798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.3411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.3804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.5296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.3266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.3802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.2396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.4760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.3349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.2000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.2414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.5226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.2980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.2213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.7421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.3732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.2324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.4641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.2771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.3132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.3833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.6733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.3359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.2031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.3330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.2178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.2693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.7231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.4714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.2695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.2805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.3406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.2757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.4765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.2235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.4057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.2302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.3637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.4541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.3004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.2249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.3390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.3637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.4555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.2873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.4954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.4165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.2696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.3995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.3909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.2685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.5649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.4583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.4523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.4859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.2002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.4656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.2024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.3850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.2893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.4842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.2812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.2995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.2786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.6394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.2337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.3633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.6112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.4899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.5862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.2093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.4172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.2934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.5521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.2885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.4194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.3450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.3333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.3713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.3306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.2672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.4221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.2088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.2979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.3420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.3050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.6586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.3058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.2302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.4210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.2492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.7453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.4202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.2369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.5009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.2781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.1800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.5096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.3769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.2162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.3514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.4669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.4336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.4719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.2252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.3670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.5150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.2197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.5201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.2154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.2772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.5392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.9562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.3060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.2460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.2723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.3281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.3427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.2790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.2801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.7673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.2723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.3911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.3981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.4837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.3098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.4525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.1596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.3458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.3323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.4147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.3111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.4797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.5696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.6147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.2241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.2353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.3800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.3678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.4248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.2844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.5873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.3874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.2683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.2288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.4028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.4220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.3418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.2230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.2277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.5748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.6600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.3841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.4374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.2019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.3048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.2162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.3577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.3765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.6325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.2281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.3481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.3315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.2755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.2131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.2372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.5141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.2358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.4151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.3377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.3459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.3972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.5173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.4786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.3652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.5038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.3232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.3730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.2795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.3081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.2118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.5120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.3379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.4205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.2460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.4043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.3157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.3492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.3115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.2737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.2147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.4234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.5156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.2914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.4151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.2269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.4109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.4750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.5011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.2312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.5409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.4273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.3968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.2955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.7122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.4468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.3507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.4812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.2061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.2772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.2083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.3210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.2540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.4493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.3307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.2850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.2419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.3447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.5090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.2635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.4121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.3307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.4759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.2332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.2949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.2391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.4948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.3058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.5616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.3922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.8606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.7821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.5576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.7647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.2162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.2472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.2173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.5976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.4708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.5574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.3990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.3191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.2442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.2339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.2174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.4893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.3986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(1.2292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.4395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(1.0898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.3068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.2040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.3857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.4361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.5044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.4203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.2748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.2320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.4066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.4237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.2386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.2344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.3469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.3312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.3015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.1875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.4219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.3212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.3538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.4995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.4486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.3123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.6238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.5050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.2346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.4965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.3938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.4913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.4097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.2237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.2941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.3488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.2352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.4499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.5292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.5345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.2949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.6851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.4876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.2345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.8123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.6597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.2431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.4962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.3781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.3689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.1728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.2290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.2740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.1972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.3197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.1756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.3146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.1699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.5497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.4916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.3367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.2616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.2344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.5214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.4826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.3307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.2277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.7579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.3171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.4009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.3315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.2049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.3912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.3063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.3659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(1.0209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.7260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.3983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(1.5688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.4575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.5861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.2868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.2064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.3809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.3183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.2285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.3328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.8099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.3554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.3169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.2070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.2908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.2820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.5072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.2618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.4786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.8166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.6180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.2368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.6950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.2889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.2449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.3912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.2114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(1.5011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(1.3498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(1.1819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.6821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.3703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.5461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.3837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.2909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.3284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.4135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.3111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.2213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.6096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.3153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.3237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.2711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.3227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.2114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.6833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.3559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.2301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.2090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.2374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.2016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.5148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.2378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.4012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.2489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.2634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.3458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.2205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.5121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.5020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.3043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.2169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.2202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.5508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.5297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.5460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.3354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.3555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.2071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.3259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.3613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.2401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.2437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.3837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.5168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.5896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.2709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.2455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.3315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.2285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.6018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.4610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.3365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.3617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.5034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.5058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.6869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.1897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(1.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.6273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.2766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(1.3487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.6105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.3656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.3900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.2316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.2695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.4436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.1759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.3354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.4744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.2129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.5887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.3747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.2122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.5067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.2407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.5357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.4606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.2535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.2226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.5131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.3845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.6177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.4898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.6516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.2511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.2098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.3087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.3567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.2901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.2428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.4468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.2022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.3218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.2629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.2044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.3148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.3317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.2409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.5343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.6314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.3089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.2496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.2841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.2718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.3411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.5178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.3124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.1954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.2064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.1938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.4976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.3128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.4443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.3330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.2017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.2897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.2040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.4174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.1830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.6400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.3293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.1879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.3921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.2697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.1753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.1858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.3640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.4545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.5102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.2125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.2542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.1774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.2859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.1851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.3302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.1920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.3173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.4338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.3313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.2854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.4419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.4362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.1838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.2091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.1960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.6270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.2397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.1497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.2408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.5438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.2123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.4673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.2540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.3868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.2141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.2710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.3532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.5904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.3918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.4361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.2094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.1497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.2045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.3697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.3582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.1838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.3533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.2121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.4649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.5482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.4804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.3254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.1827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.2282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.4627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.6301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.3218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.2405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.2307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.3563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.2295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.3893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.6397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.3270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.3295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.3295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.3114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.3319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.2440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.4863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.3060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.2059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.1955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.4069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.3779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.1537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.1980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.2987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.4227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.3355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.1729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.3287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.3438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.3916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.1978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.5713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.1614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.4341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.1427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.1630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.3547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.4147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.2300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.2979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.3239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.2762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.5446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.4346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.3926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.2783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.2248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.1911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.6632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.2800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.1426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.3382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.1866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.4202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.2307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.3044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.1822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.4829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.4183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.1806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.2284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.1630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.5292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.3193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.4725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.1828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.1427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.2726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.3259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.3213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.4296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.5123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.1725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.2180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.1521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.2793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.3602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.2019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.2714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.2390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.4796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.4835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.3114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.3021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.3420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.2192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.2735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.1822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.2646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.4051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.1617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.3164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.2687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.3244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.4191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.1642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.1525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.3188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.2881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.2490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.2235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.7055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.3530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.3394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.1764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.1806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.3051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.1702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.3502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.1882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.4291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.2306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.2456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.2283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.1533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.3459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.1758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.4692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.2701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.2802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.3994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.4564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.3191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.3091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.2114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.1330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.1943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.6222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.3015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.3985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.2691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.3676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.3466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.2371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.3526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.2239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.3424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.2662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.3024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.4123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.1634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.1509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.3786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.2666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.3520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.1501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.3879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.3689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.1891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.2437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.4197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.2004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.2048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.5498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.2505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.4401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.1848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.1757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.2331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.2919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.3064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.2808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.2076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.2850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.3900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.1786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.1604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.4536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.2667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.2952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.4911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.2935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.4810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.1665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.2099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.2372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.2741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.2312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.2881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.3270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.1960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.3396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.2408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.2812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.1770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.1544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.4560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.5589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.1900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.3231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.1683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.4147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.3722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.2752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.1939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.3030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.2280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.2046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.2216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.3247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.1783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.4483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.3722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.2073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.4017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.2897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.2421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.5180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.3235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.4040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.5056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.2312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.2454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.2675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.5027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.2999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.1918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.1947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.3180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.3682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.2653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.2109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.4254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.2868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.1405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.1901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.2774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.2077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.3363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.1318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.1683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.2133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.3069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.2286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.4434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.1842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.4525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.2079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.4186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.3888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.4305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.2170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.3341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.2458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.2211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.2704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.2172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.3641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.1908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.2285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.2189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.3350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.1995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.1622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.1849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.5300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.3407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.3306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.4257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.2113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.1740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.4297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.4130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.2378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.2199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.4663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.1979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.3153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.2254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.2757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.4138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.2284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.1072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.4586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.2136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.3498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.1813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.4703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.3532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.4115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.1848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.1624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.1938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.5574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.2750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.1623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.3034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.4086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.3157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.2204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.2016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.4215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.4229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.3556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.2340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.2101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.1786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.1972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.2678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.3326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.1827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.1781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.5160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.2034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.4935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.2876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.3714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.1840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.2395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.2160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.5307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.3317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.2001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.1512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.3560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.3330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.3851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.4521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.4246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.3392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.3162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.3203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.2641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.4109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.4030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.2707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.2295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.5688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.3721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.2334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.2830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.3568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.4840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.2220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.1747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.5881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.5227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.1805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.1512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.1643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.1696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.1847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.3665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.4503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.2034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.2326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.1716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.3077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.2406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.4649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.2078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.2714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(1.0374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.4785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.4573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.9204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.3665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.2304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.1892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.2315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.2660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.2567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.1979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.5768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.4091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.2873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.3005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.5771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.5290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.3426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.2892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.5182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.4097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.3045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.3143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.2346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.5258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.2736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.1783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.4741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.3042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.3722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.2741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.3435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.1659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.2004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.5370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.2073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.5440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.1588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.3447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.3201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.3465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.4748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.1966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.3852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.1437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.2935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.1696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.3867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.5539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.2457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.2665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.3992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.1954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.4270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.3248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.1804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.3608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.2114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.1651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.2875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.1640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.3572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.6304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.3758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.4215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.1689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.1725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.4251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.3307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.2276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.2345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.2685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.5609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.2275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.2199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.1863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.5827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.3038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.1545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.1889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.4999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.3145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.2829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.2365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.3307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.2970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.2008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.2076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.2030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.5323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.2431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.2023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.2244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.2670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.2049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.2736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.3259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.3443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.1749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.3911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.3117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.2731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.3628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.2755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.2657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.1665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.2304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.3618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.2747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.2298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.1969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.2389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.2323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.4254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.2823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.4090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.2121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.2001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.3338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.2161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.2008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.3220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.3599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.2829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.3478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.3136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.2281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.2204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.1931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.3667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.1916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.1871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.2035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.1991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.4213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.4170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.1594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.3079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.2376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.2340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.3920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.2950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.1956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.4168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.2384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.2457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.3854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.4577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.2874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.1523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.2328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.1848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.2407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.2076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.3824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.2810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.2394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.2634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.2994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.3967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.2631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.2885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.1651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.3084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.3437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.3723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.2689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.2437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.4325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.3066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.2680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.1622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.1976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.2170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.1801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.1645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.1955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.3704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.3557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.2906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.2253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.3415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.2824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.2866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.1739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.3762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.2178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.3557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.2962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.2723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.2165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.4477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.1847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.4015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.2640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.2154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.5377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.2170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.1860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.3001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.2783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.3453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.2293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.1866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.5893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.2281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.2020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.1570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.1814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.3277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.3027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.2233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.3217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.4962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.2481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.4741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.2888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.2274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.4292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.2323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.1613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.1716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.2019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.2133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.2277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.1784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.4823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.3364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.3163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.1822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.2093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.3201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.1804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.4327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.1611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.1736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.3153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.1742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.1908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.2207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.3491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.2339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.2322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.4734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.1678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.2192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.1851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.6994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.1637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.4190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.2197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.2984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.1525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.5251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.2505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.4899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.2442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.3317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.2089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.1490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.4016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.4414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.1697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.1932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.1127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.2086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.1940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.1813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.2389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.2289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.2299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.5723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.4410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.2762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.3622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.2401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.4230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.2430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.1887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.2104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.3459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.1596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.4375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.2794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.2505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.2208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.2466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.1716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.2060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.6297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.3920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.5850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.2709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.1764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.4089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.3938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.2093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.3745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.2755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.4787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.1580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.3940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.1637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.2235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.3688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.4227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.2133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.3755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.4079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.2632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.3363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.1916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.2228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.3952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.2095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.3828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.2215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.3724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.2828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.3552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.1611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.1843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.2254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.2438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.6843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.7767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.1767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.7302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.3080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.2305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.2449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.5993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.2988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.3628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.5383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.3888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.2737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.3176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.1739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.3610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.1837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.3909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.3502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.2160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.2773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.1560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.3174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.2135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.3667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.2395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.3007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.2217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.2308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.4667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.2636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.2778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.2236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.2186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.2132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.2723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.5365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.3161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.1650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.5584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.1573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.1596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.4113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.1797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.3470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.2073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.4625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.1560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.3756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.3085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.3453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.2358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.2816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.1977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.2432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.2024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.2961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.2988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.2118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.4078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.3861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.1608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.3040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.2403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.3833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.3060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.4841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.2008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.3587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.1850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.2095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.8306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.5028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.3107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.3549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.2735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.2457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.1954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 501 Loss: tensor(0.3570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.2651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.2737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.3614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.2866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.3062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.3920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.1962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 502 Loss: tensor(0.1893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.4696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.3737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.2132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.3956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.1595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.2111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.2149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 503 Loss: tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.1643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.5083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.2241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.2189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.3420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.3296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 504 Loss: tensor(0.3394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.1530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.1726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.3284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.2841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.1480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.1767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.3047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.3336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 505 Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.2022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.1794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.2304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.3352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.1862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.5292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.1488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.3516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 506 Loss: tensor(0.0735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.1605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.1781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.1643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.2954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.1760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.3362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.2127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.2152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 507 Loss: tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.3566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.1765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.1405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.3224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.2419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.2092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.3414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.2266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.3064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 508 Loss: tensor(0.1922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.2533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.2378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.2306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.1979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.2063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.1889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.1823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.1994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 509 Loss: tensor(0.4722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.3026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.1661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.1965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.2713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.4118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.1735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.3075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.1041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 510 Loss: tensor(0.3487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.4431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.2201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.4145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.1688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.2275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.2785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 511 Loss: tensor(0.2198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.2747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.3077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.2823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.1893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.1666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.4058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.3024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 512 Loss: tensor(0.1897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.5465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.1550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.2349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.4872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 513 Loss: tensor(0.2103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.4090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.2123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.1814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.4029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.0931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.2813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.2762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.2081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 514 Loss: tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.1804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.2319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.2199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.3107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.3518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 515 Loss: tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.4203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.1676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.2667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.2537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.2405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.1181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 516 Loss: tensor(0.1521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.4550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.3424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.2141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.3957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.2095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.2701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 517 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.2402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.3179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.3884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.3567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.2306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 518 Loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.3351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.1740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.3294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.1938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.2964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 519 Loss: tensor(0.1958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.2335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.2237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.2962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.1041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.1822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.4488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.1512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.3260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 520 Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.3702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.2739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.2200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.3373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.2434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 521 Loss: tensor(0.1486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.1784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.5810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.2420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.2659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.2362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.1635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 522 Loss: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.3075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.2237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.2278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.2072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.2975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.2030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.3017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.1800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.1909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.3430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 523 Loss: tensor(0.1632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.0765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.1680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.1758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.2190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.3255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.3078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.2059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.3897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 524 Loss: tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.2994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.2916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.2005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.0828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.2792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.2639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.2286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 525 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.2899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.2231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.1082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.2671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.3676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.2254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 526 Loss: tensor(0.1747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.1512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.3338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.3425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.2095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.3276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.1598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.1484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.3578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 527 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.2431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.2352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.2976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.1890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.3206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.2089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.1699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 528 Loss: tensor(0.3046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.2582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.3155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.2671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.2840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.4051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.1774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 529 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.2899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.2822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.1704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.3745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.1661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.1545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.2701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.2917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 530 Loss: tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.1573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.2258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.1794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.4084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.2734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.3920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 531 Loss: tensor(0.2448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.1759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.2346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.3480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.3641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.2144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 532 Loss: tensor(0.2437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.3299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.1564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.2156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.2017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.2019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.3136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 533 Loss: tensor(0.3915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.2409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.4847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.1643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.2990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.2324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.1878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.1793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 534 Loss: tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.2654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.1388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.2275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.5506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.1696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.3844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 535 Loss: tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.1739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.2432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.3652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.2162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.2315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.2326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.3332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.1976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 536 Loss: tensor(0.1613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.1710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.3129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.2378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.4890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.2326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.4315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 537 Loss: tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.4209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.2353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.2297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 538 Loss: tensor(0.2917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.3828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.2757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.1965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.4073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.2752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.2745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 539 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.1728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.1837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.3026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.2506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.1680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.4697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.2908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 540 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.1680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.2356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.2371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.1437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.2256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.4067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.2904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 541 Loss: tensor(0.1768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.1485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.1729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.3457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.1481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.1516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.2773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.1480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.3178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.1717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.0576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 542 Loss: tensor(0.2402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.2208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.2932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.1866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.2659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.1705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.1767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.1699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 543 Loss: tensor(0.2343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.3891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.2026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.4078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.1980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 544 Loss: tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.2386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.1353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.4602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.2419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.2790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.2112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.2241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.1623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.2447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 545 Loss: tensor(0.1828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.1709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.3186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.3765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.2987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.3780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.2207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.1330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 546 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.2859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.2520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.1901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.2072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 547 Loss: tensor(0.3062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.1932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.1899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.2322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.4080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.3832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 548 Loss: tensor(0.2386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.2277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.2722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.2947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.2898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.2126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 549 Loss: tensor(0.1512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.1589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.3396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.2997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.4395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.1637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.2022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.0927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.4350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 550 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.3828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.1851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.2178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.2907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.2990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.2383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.1684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 551 Loss: tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.1824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.3106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.3202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.2635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 552 Loss: tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.2218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.4354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.2542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.2083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.1611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.2262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.1539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.1951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.1711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 553 Loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.3426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.3495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.2515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.2813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.1113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.2030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.1915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 554 Loss: tensor(0.2625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.2702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.2328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.1782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.5730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 555 Loss: tensor(0.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.3594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.2698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.0962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.1798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.4662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.2485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 556 Loss: tensor(0.1550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.1909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.2348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.1789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.2154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.1878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.1681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.2648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.1814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 557 Loss: tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.2119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.3156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.3627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.3987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.2036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 558 Loss: tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.2518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.4056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.3712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.2752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.2020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 559 Loss: tensor(0.1975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.2789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.1441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.2372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.2118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.1522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.2651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.1856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.3636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.3627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 560 Loss: tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.3491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.2827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.2119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.1728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.1754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.2373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 561 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.1459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.2691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.1682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.2490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.3472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.3874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.1713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 562 Loss: tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.2251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.3232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.2293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.2729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.4130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 563 Loss: tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.1625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.2317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.1840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.1891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.2211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.3281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.4569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 564 Loss: tensor(0.3430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.2832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.2394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.2881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.2866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.1585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 565 Loss: tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.3562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.3107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.1608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.2343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.2832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.2029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.2351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.1887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 566 Loss: tensor(0.0724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.3006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.1680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.1540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.3459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.2159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.2394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.2351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.2031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.1586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 567 Loss: tensor(0.2180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.1634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.1926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.1929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 568 Loss: tensor(0.2838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.2410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.2332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.1844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.5167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.1993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.2980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.1481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 569 Loss: tensor(0.1844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.1500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.2795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.2091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.2207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.2329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.1254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.1953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.1818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.1868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 570 Loss: tensor(0.5643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.2156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.3037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.1609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 571 Loss: tensor(0.3638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.6671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.3619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.3014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.3726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 572 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.2354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.3855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.3197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.3399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.2153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.1739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.1676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 573 Loss: tensor(0.1918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.1693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.4353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.2766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.1530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.2653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.2334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 574 Loss: tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.1589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.1971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.2269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.4057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.1480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.2466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 575 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.3032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.0992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.3167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.2298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.2097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 576 Loss: tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.1509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.2461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.2101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.1681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.3076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.3513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.2845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 577 Loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.2378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.3511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.3384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 578 Loss: tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.2368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.3086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 579 Loss: tensor(0.3014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.2749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.3047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.1953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.1827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.3628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.2653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.1983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.1763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.1760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 580 Loss: tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.1917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.3793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.2228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.1626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.2845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.2125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.2321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.2460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 581 Loss: tensor(0.1980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.3076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.1958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.2836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.2190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.3810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.1926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.2921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 582 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.2462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.3335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.1769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.1705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.3244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.2213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 583 Loss: tensor(0.2111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.2173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.3912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.3061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.2164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.2245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.1954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.3245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 584 Loss: tensor(0.1585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.3231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.2143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.1887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.3109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.2103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.4405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.1845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 585 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.2937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.3126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.2042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.2735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 586 Loss: tensor(0.1951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.2877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.2220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.2915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 587 Loss: tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.1867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.2233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.2844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.1613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.4583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 588 Loss: tensor(0.3113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.3842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.4431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.3394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.4169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.1765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 589 Loss: tensor(0.2215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.3299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.4308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.1842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.3037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.2136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.2081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.2676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 590 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.2324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.2080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.0656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.2251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.3352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.2052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 591 Loss: tensor(0.2232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.4321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.3345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.3320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.1585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.2438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 592 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.1860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.3118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.2780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.1797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.3045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.3707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.1759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 593 Loss: tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.1904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.2488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.2137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.1988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.3486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.2087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.3691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 594 Loss: tensor(0.2861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.3055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.1920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.2263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.3078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.1997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.2617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.3848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 595 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.1979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.2352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.3092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.1875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.1659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.3239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.2618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 596 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.1776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.2685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.1871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.4902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.2235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.2335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 597 Loss: tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.2313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.3065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.1488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.2881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.4430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.2698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.2758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 598 Loss: tensor(0.1357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.2873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.3242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.1520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.1948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.3214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.2878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 599 Loss: tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.3173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.3795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.3137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 600 Loss: tensor(0.2424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.1882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.3731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.1954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.2115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.2007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.4514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 601 Loss: tensor(0.1917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.2072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.2048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.2859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.2245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.1895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 602 Loss: tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.2421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.2537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.2822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.1966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.1291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.3309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 603 Loss: tensor(0.1357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.2507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.3712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.0744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.1405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.3321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.2038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.1906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 604 Loss: tensor(0.2059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.3123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.2356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.2976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.2284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.2675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.1920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.2302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.1570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 605 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.3906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.2685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.1707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.2452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.2104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.0848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.1907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.2374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 606 Loss: tensor(0.2087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.2826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.0888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.1645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.1688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.1502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.2352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.1901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.2008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.1577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 607 Loss: tensor(0.3812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.1589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.1787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.4189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.2080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.2135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.1858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.2018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.2205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.2717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 608 Loss: tensor(0.1490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.2136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.3290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.2432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.3603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 609 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.2855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.2008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.1998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 610 Loss: tensor(0.3017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.2802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.1946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.1696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.1982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.3354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.3034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.2343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.1644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 611 Loss: tensor(0.2187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.2822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.3772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.2300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.2048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 612 Loss: tensor(0.1943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.2782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.3097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.1894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.0791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.2518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.1813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 613 Loss: tensor(0.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.2973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.1651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.4026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.2608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.2710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 614 Loss: tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.3866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.3115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 615 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.2406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.2206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 616 Loss: tensor(0.3272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.2362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.2535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.0746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.1742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.2734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.1636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.2200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 617 Loss: tensor(0.2980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.2262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.3338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.2263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.2972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 618 Loss: tensor(0.2261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.2233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.4401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 619 Loss: tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.4261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.2366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.1792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.1512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 620 Loss: tensor(0.2996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.2046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.2757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.1850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.1888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.1742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.2091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.2379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.1623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 621 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.3020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.3500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.2990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 622 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.2707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.2450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.2683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.1774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.2642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 623 Loss: tensor(0.2070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.1634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.3367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.1990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.2349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.0879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.3386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.2520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 624 Loss: tensor(0.2275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.1604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.2417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 625 Loss: tensor(0.1621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.3078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.2076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.2075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.3757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 626 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.1863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.1537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.2845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.3013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.2515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.2252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.3670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 627 Loss: tensor(0.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.2079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.2877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.3678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 628 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.1622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.2520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.1955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.2754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.2007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.2434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.1948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.2988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.1480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 629 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.2167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.2998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.2965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.0845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.4154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.1765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 630 Loss: tensor(0.3295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.2280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.1710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.3109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.2355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 631 Loss: tensor(0.1712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.2700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.1823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.1735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.3718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.2112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 632 Loss: tensor(0.2022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.1897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.1966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.2646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.1907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.2035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.2301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 633 Loss: tensor(0.2227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.2515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.2311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.2966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.1915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.4224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 634 Loss: tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.3624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.4558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 635 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.4025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.2039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.1828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.1967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.1925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.2415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.2040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 636 Loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.1717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.3678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.2535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.2317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.1595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.1850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.3384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.2048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 637 Loss: tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.1595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.1776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.3261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.2013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.2323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 638 Loss: tensor(0.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.4766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 639 Loss: tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.1827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.3447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.2804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 640 Loss: tensor(0.2729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.2961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.1745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.1972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 641 Loss: tensor(0.3126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.1776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.1767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.2283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.1580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.2943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.2811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.3546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 642 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.1683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.3585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.2186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.3623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 643 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.2181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.2350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.1874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 644 Loss: tensor(0.3656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.1847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.1598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.1760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.1713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.2013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.4060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.2490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.2487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.2462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 645 Loss: tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.4080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.4174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.2758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.1666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.1823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 646 Loss: tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.2184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.2218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.3757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 647 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.5074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.2262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.1330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 648 Loss: tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.1392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.2771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.2300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.2790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.2976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 649 Loss: tensor(0.3979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.2323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.2857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 650 Loss: tensor(0.1693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.3723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.1865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.1909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.2728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.1848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 651 Loss: tensor(0.3058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.2857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.3092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.2313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.1932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.1776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.2024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.3408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.0658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 652 Loss: tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.1845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.2809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.3188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 653 Loss: tensor(0.1613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.2090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.2390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.1521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.3373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.2084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.1943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 654 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.1595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.3946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.1907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.2137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.1800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 655 Loss: tensor(0.1544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.3134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.2447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.2083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 656 Loss: tensor(0.2249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.2044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.3382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.1770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.1893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.3121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.1931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 657 Loss: tensor(0.1633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.2072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.1672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.2337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.1956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 658 Loss: tensor(0.2953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.0658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.2230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.1625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.5030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.0870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.2217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.2120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 659 Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.3357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.2594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.3179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.2101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.2863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 660 Loss: tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.3148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.2040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.3026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.1783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.2269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 661 Loss: tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.2551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.1783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.1932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.3239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 662 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.3724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.2405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.0818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.2784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.1872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 663 Loss: tensor(0.2785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.0765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.2120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.3484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.1927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.2033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.2058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 664 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.2072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.2819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.2875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.2020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 665 Loss: tensor(0.1889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.0624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.2485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.2404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.4279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.3885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.1560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 666 Loss: tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.2850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.3490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.1962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.2181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.3092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 667 Loss: tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.3888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.1617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.3107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.2327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.2222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.1984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.0746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 668 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.3445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.3037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.2151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.1976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.1596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 669 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.1545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.2786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.0669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.1716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.2113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.2036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.3123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.2217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.1838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.1909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.1678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 670 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.2174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.2752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.3835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 671 Loss: tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.3607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.2151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.4021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 672 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.1560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.2723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.3670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.2308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.2036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 673 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.1793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.2368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.2511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.1912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 674 Loss: tensor(0.3279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.4045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 675 Loss: tensor(0.1406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.2220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.4158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.2205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 676 Loss: tensor(0.2026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.2120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.2439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.2003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 677 Loss: tensor(0.2768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.1857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.1645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.3332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.2878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.2419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.1700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.2990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 678 Loss: tensor(0.2092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.0816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.2817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.3664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.1662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.2064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.2070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.1697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 679 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.2070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.0927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.1705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.3494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.2635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.2645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.1889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.2083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.0848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 680 Loss: tensor(0.1709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.2228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.2222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.3071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.2732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.1533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.1082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 681 Loss: tensor(0.1609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.2784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.2754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.1550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 682 Loss: tensor(0.3089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.3102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.2120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.3655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.1516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 683 Loss: tensor(0.2746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.2791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.1540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.2725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.2282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.2201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.2181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 684 Loss: tensor(0.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.1854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.2192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.4670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.3426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 685 Loss: tensor(0.2289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.2292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.2647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.2299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.0927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.3051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.2102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.2169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 686 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.0955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.3979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 687 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.2201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.3496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 688 Loss: tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.2506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.2447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.1988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.3367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.1573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.2029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 689 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.2705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.3183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.3174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 690 Loss: tensor(0.2924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.3591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.1849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.2164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.1947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 691 Loss: tensor(0.2131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.0676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.3199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.3340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.2027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 692 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.2337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.2297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.2067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 693 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.2813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.2059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.4501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.2438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.1747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.2538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.2113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 694 Loss: tensor(0.1594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.2256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.3384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.1888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.0795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.2281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.2936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 695 Loss: tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.1707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.2939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.1866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.1634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.2154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.2365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.2987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 696 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.1637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.2679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.3643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.2889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.1644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 697 Loss: tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.4045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.2503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.1948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.2023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.2244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 698 Loss: tensor(0.2353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.3251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.3392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.1405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 699 Loss: tensor(0.2269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.1995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.2539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.2487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.3013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.2407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.1521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 700 Loss: tensor(0.2302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.2830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.2116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.2777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.2110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.3523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 701 Loss: tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.3040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.2754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 702 Loss: tensor(0.2036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.4451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.2374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.1490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.1111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 703 Loss: tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.3002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.2254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.3289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 704 Loss: tensor(0.1046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.3226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.1984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.1569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.2749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 705 Loss: tensor(0.2002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.2047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.3804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.0848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.2645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.2035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 706 Loss: tensor(0.1127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.3143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.3074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.2067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 707 Loss: tensor(0.1426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.2176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.2813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.3144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.3057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 708 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.2167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.3327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.2350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 709 Loss: tensor(0.1976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.2880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.2871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.3092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 710 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.2155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.1897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.3632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.2081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.3028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 711 Loss: tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.2483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.2433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.1866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.1622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 712 Loss: tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.2300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.2135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.1859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.1481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 713 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.3204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.2533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.1497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.2039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 714 Loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.3148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.1693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.3087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.3805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.2084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 715 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.3228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.0888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.2101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.3659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 716 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.1749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.2286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.1643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.2164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.2098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 717 Loss: tensor(0.3539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.2692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.0776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 718 Loss: tensor(0.3349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.1707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.2127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.2839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.1757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.2428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.2067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 719 Loss: tensor(0.2905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.2941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.3006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.2359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.2423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.1569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.1961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 720 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.2896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.3646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.2155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.0852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.2952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 721 Loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.2298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.2867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.3059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.1501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.1844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.3086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 722 Loss: tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.2640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.2461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 723 Loss: tensor(0.1986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.2001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.1683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.2384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.2461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.1789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.2218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 724 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.2010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.2484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.3367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.2326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 725 Loss: tensor(0.1920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.2942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.0702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.3612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 726 Loss: tensor(0.3008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.2256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.3234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 727 Loss: tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.3688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.2442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.2015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.1598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.3130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 728 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.2404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.1539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.2278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.2083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.1832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.2173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.1995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.2530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.1630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.1466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 729 Loss: tensor(0.2724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.2512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.1537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.1683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 730 Loss: tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.2998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.2815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.1951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 731 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.2358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.2766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.2268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 732 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.2344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.2076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.1072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.2092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.2641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.2871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 733 Loss: tensor(0.3059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.2286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.2390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.2022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.1573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.1569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 734 Loss: tensor(0.1862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.3530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.2056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.1995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.2325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.1405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 735 Loss: tensor(0.2147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.4156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 736 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.2642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.1580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.2403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.2094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.2304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.2295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 737 Loss: tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.1694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.1865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.3650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.2567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.2565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.2189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 738 Loss: tensor(0.1801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.3093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.3282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.2061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.3017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 739 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.2396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.1709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.4726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.2222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.1898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.1922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 740 Loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.4035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.2071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 741 Loss: tensor(0.1994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.1650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.2052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.1570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.2222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.1544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 742 Loss: tensor(0.2013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.2447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.1944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.2413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 743 Loss: tensor(0.2211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.3885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.1594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.2087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.2823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.2455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.2651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 744 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.0735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.1111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.2659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.2064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 745 Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.2485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.2488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.2799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 746 Loss: tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.2758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.2958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 747 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.1867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.1551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.2794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.2052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.1584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.1328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.2862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 748 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.1929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.2912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.1705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.2520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.1833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.2078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.2112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.1926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 749 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.3110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.1623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 750 Loss: tensor(0.2299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.3242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.3044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.2047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 751 Loss: tensor(0.2195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.1924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.1046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.1980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 752 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.1797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.1917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.2391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.2730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 753 Loss: tensor(0.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.2909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.3188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.2456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 754 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.2673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.2127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.2104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 755 Loss: tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.1993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.2230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.1893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.4002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.1459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.1388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.1900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.2505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 756 Loss: tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.1925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.2204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.2340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.2637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 757 Loss: tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.0870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.2837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.3290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.2034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.0791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 758 Loss: tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.2440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.1659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.3583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.2176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.1490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 759 Loss: tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.1682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.2056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.0751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.1640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.2173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.2902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.2980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 760 Loss: tensor(0.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.1799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.2357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.3957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 761 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.2721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.1760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.2877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.3759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 762 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.1827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.2119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.3138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.3118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 763 Loss: tensor(0.1948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.2287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.2187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.0805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.2310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.1662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.2328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.1782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.2567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 764 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.2720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.2632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.2078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.1966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.2095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.1576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 765 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.4115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.1997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.2876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.1705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.2097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.0839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 766 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.2304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.2359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.1608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.2988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 767 Loss: tensor(0.1551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.2625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.1977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.2795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.1939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.2233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.1497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 768 Loss: tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.2162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.2467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.1792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.2350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.2966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.1677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 769 Loss: tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.2537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.2293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.3423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 770 Loss: tensor(0.1672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.2085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.3152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.1678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.3014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.1735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.2202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 771 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.4467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.2057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.2288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.2226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 772 Loss: tensor(0.1756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.2125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.2206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.0568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.2242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.4034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 773 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.2126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.3506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.2058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 774 Loss: tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.3482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.3142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.0841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 775 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.2986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.0584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 776 Loss: tensor(0.1930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.1984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.0870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.2397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.2132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.2256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 777 Loss: tensor(0.2806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.2034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.1587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.2340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.2101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 778 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.4058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.1911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.2780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.1788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 779 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.1862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.2406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.3726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.1749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.2057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.2325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.1758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.2375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 780 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.1537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.1800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.1604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.2088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.3514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.2725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 781 Loss: tensor(0.1987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.2393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.2335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.2255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 782 Loss: tensor(0.2373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.2137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.1891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.2863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.2172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.2218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.0767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 783 Loss: tensor(0.2000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.1712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.1800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.2193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.1577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.2832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 784 Loss: tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.2065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.1913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.1693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.2272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.2064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 785 Loss: tensor(0.1837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.1787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.2363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.0625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.2193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 786 Loss: tensor(0.3371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.2149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.4469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 787 Loss: tensor(0.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.1636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.1291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.1988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.3679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.1832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.2231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.1676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 788 Loss: tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.2131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.3228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.2844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 789 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.2154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.2721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.3543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 790 Loss: tensor(0.2661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.2311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.1569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.2042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.1900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.2409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.3281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 791 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.3014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.1754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.1856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.3515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 792 Loss: tensor(0.1863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.1961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.2292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 793 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.3563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.2368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.2155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 794 Loss: tensor(0.1813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.1520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.2273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.1917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.3173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.1865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.2290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.2017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 795 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.2170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.2125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 796 Loss: tensor(0.1931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.0689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.1980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.3398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.2935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.1806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.1520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 797 Loss: tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.2837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.1357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.3460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.2007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 798 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.0781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.2287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.2048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.3152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.2240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 799 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.3402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 800 Loss: tensor(0.2115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.1943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.3024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.2092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.1502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 801 Loss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.1845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.3643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.1955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.2753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.1632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.2199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.2647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 802 Loss: tensor(0.1889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.1757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.2674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.0850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.2368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.0828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.1800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 803 Loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.2390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 804 Loss: tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.2027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.2434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 805 Loss: tensor(0.3721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.1979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.2021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.2102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.3886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.0734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.2043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.1572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.2262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 806 Loss: tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.2221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.1623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 807 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.2174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.2064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 808 Loss: tensor(0.1742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.3403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.2241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.2423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.2860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 809 Loss: tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.2828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.2153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 810 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.1072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.2141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.2033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.2354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 811 Loss: tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.2043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.2199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.1522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.1712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.3143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 812 Loss: tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.2412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.2152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.1889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.2273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 813 Loss: tensor(0.1584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.1597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.1907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.3130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 814 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.1745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.2122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.1848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.1763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.3007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.2181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 815 Loss: tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.3199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.2256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.2278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.1635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.1665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.0992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.2144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 816 Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.4303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.2286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.1111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 817 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.3083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 818 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.2978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.3534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 819 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.2206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.2944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 820 Loss: tensor(0.2765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.2163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.2766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.3369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 821 Loss: tensor(0.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.2079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.2099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.2090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.1648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.1801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.1659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.1975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 822 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.3561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.2362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.1846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.2050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.0480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 823 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.2483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.2410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.2184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 824 Loss: tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.1833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.2886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.1533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.3240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 825 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.0513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.3089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 826 Loss: tensor(0.3950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.2349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.1486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.3220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.3593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.1681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.1484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.1662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.2077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 827 Loss: tensor(0.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.2346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.3235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.1882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 828 Loss: tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.2136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.1957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.2104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.2174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 829 Loss: tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.3566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.1173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.2356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.2701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 830 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.2487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.2636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.1598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.1766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.1818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 831 Loss: tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.2166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.1758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.3407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.2466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.1768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.2414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 832 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.1921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.2292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.2724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.2067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.2424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 833 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.1838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.2336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.1865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.1890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.2230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 834 Loss: tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.1833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.2989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.2149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.2536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 835 Loss: tensor(0.1776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.2442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.2078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.2150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 836 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.2416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.2091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.0781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.2067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.1689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.2611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 837 Loss: tensor(0.2407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.0840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.2472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.2139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.2833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 838 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.1788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.2101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.2244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 839 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.4260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 840 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.3164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.2245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.3606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 841 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.1937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.2038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.0656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.2956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 842 Loss: tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.2206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.2217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.3094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.2320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.1643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 843 Loss: tensor(0.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.2921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 844 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.0748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.1912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.1956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.2391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.1353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 845 Loss: tensor(0.2112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.2048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.2679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.2502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 846 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.2241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.1630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.2518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.1640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 847 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.3706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 848 Loss: tensor(0.1863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.1937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.1974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.1540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.2389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.1597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.1847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 849 Loss: tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.2384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.2147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.3461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 850 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.3158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.0744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 851 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.3047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.2307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.1865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 852 Loss: tensor(0.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.2136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.2260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.1520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.2450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 853 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.2030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.2359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.1857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.0666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.1872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.2252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.2971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 854 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.2379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.2793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 855 Loss: tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.1642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.2237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.0771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.2045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 856 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.1725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.2391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.2835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.1441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.2320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 857 Loss: tensor(0.1618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.2081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.2084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.2709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 858 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.3384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 859 Loss: tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.2361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.2101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.1904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 860 Loss: tensor(0.2863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.1774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.2800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.2804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.1716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.2098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.2689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 861 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.2070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.2253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.2353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 862 Loss: tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.2382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.3403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 863 Loss: tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.2034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.3251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.2010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 864 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.1957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.2348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.2087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 865 Loss: tensor(0.1740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.2221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.3173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.2626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.1911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.2394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.0746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.2273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 866 Loss: tensor(0.0778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.0778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.2319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 867 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.2518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.2384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.2150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.2716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 868 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.1662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.3167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.2153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 869 Loss: tensor(0.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.2961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.2168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 870 Loss: tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.2055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.3033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.2863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 871 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.2931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.0828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.2635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.1764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.2417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.1680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.2105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.2286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.1127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 872 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.2326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.1328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.2163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 873 Loss: tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.1946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.2029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.1764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.1843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.1872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.3058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 874 Loss: tensor(0.0879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.1850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.2112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.2249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.3192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.2631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 875 Loss: tensor(0.1614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.1127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.2227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.2428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.2734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.1898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.1694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 876 Loss: tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.4398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 877 Loss: tensor(0.1111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.2232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.2046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.3072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.2418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.2140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 878 Loss: tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.3074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 879 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.2998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.0994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.2337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 880 Loss: tensor(0.1930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.2279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.2222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.1330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 881 Loss: tensor(0.2401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.2691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.3124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 882 Loss: tensor(0.1586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.2216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.1486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.3034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.2002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.2202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 883 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.3050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.2121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.1683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 884 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.2117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.2972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.2027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.3263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.2060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.0962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 885 Loss: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.2703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.2086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 886 Loss: tensor(0.2415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.2198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.2393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.3229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 887 Loss: tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.2393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.2565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.3142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.1859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.1726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 888 Loss: tensor(0.2047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.1994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.2004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.2140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.1979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.2685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 889 Loss: tensor(0.1918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.2152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.1812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.3661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.1608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.1711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.1459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.2113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 890 Loss: tensor(0.2721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.1611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.1834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.2153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.2410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 891 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.2200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.1586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.2611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.2060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 892 Loss: tensor(0.1874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.0522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.1868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.3182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.1589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 893 Loss: tensor(0.1604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.2950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.3365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 894 Loss: tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.2906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.1726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.1872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.1710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.1747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.2956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 895 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.1707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.2365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.2075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.1570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.2820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.1596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.2207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.2892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 896 Loss: tensor(0.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 897 Loss: tensor(0.1726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.3236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 898 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.2642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.0994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.2310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.2640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 899 Loss: tensor(0.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.2166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.1796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.2467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.0840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.2836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.1551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 900 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.3367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.2403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.1856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.2215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.2002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 901 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.1892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.3300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.2166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.1930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.1840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.0693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.2213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 902 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.2050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.2675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.2211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.2102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 903 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.2265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.3745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 904 Loss: tensor(0.1173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.2168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.2027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.1576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.1765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.2174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 905 Loss: tensor(0.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.2061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.1850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.1745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.1900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.1913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 906 Loss: tensor(0.2120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.3397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.2160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 907 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.3476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.2393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.2044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 908 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.2265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.2991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.2254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.0656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.2179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.2063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 909 Loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.1659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.2237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.2043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.3221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 910 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.2348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.2173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.1924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.3361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 911 Loss: tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.1357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.2127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.2329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.2700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.1987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.2397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 912 Loss: tensor(0.2099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.1500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.1585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.1971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.2113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.3230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 913 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.2399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 914 Loss: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.2357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.1976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.1967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 915 Loss: tensor(0.2793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.2035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.3070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 916 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.1353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.3187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.2335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.1753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 917 Loss: tensor(0.2898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.2031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.2216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.2222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.1486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.3386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.1392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 918 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.3100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.2001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.2220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 919 Loss: tensor(0.1717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.1584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.2169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.2017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.2058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.3202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.2302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.1939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 920 Loss: tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.3003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 921 Loss: tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.0783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.2040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.2038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.1595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 922 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.2864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.1521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.1633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.2840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.2693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 923 Loss: tensor(0.2155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.2089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.2639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.3225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 924 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.2080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.2369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.0841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.1972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.4112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.2424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.1830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 925 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.2325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.0579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.1931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.1989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.2492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.2260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.1726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 926 Loss: tensor(0.2104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 927 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.2404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 928 Loss: tensor(0.1533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.2986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.2325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.0630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.2827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 929 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.2405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.2539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.1711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 930 Loss: tensor(0.2121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.2618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.2538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.1710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.1525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.1618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 931 Loss: tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.2875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.1879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.1516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.2669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.2841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.1162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 932 Loss: tensor(0.2129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.3045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.3662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 933 Loss: tensor(0.2059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.2075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.3031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.1815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.2017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.1835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 934 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.3363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.1562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.2287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.2246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.1318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 935 Loss: tensor(0.1995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.4282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.2110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.2178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 936 Loss: tensor(0.1937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.2778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.2718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.2137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.2431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 937 Loss: tensor(0.1694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.1645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.2492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.2228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.1709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.2215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.1696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.2785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 938 Loss: tensor(0.2017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.3234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.2664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.2133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.0629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.2378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 939 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.1875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.3083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.2819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.2339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.1621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 940 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.3791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.0879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.2172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 941 Loss: tensor(0.2721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.2665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.2109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.2693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 942 Loss: tensor(0.1141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.1976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.2915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.1588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 943 Loss: tensor(0.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.2433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.2050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.1928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.1729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.1676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.2997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 944 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.2354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.2117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.2018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.2022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.2882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.1699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 945 Loss: tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.2965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.3390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.2167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 946 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.2409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.2293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 947 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.2118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.2969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 948 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.2223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.2172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.2540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 949 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.2004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.3403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.1922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 950 Loss: tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.3956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.2299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 951 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.2805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.2899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 952 Loss: tensor(0.3752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 953 Loss: tensor(0.1834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.1994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.1838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.2325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.2276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.2408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.0622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.3242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 954 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.1906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.1705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.1509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.2869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.3223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 955 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.2081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.2418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 956 Loss: tensor(0.1465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.1573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.2127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.3053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.2354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.2826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.2354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.2184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 957 Loss: tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.1783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.1798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.1484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.3179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 958 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.1862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.1605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.3207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.2632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.2145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.1113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 959 Loss: tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.2180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.1676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.2723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.1864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.1908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.2389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 960 Loss: tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.2688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.1975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 961 Loss: tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.3534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 962 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.2269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.2343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.2345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.2759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 963 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.1756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.1969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.0931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.2721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.1862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.1618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.2824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.1485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 964 Loss: tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.1794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.2430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.2254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.3079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.2033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 965 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.2537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.2252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.1868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.2420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.2090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.1427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.2589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.2055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 966 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.1882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.2235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.2231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.2047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.0955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.3222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.2503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 967 Loss: tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.1867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.1530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.1986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.2077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.2983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 968 Loss: tensor(0.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.2551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.1984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.2111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.2419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.2340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 969 Loss: tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.3337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.1854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.0732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 970 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.3228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.2730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 971 Loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.2289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.1975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.1678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.2172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.2119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.3356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 972 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.2691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.2418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.2538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.1906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 973 Loss: tensor(0.2552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.2359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 974 Loss: tensor(0.2708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.2057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.2706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.3490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 975 Loss: tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.2121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.2537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.2608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 976 Loss: tensor(0.0744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.2357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.1813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.2310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.1330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.2396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.2215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 977 Loss: tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.2023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 978 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.0773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.2025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.3205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.1693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.2301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 979 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.1509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.2125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.1840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.3483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 980 Loss: tensor(0.1588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.2467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.2482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 981 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.0640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.2512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 982 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.3981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.0821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.3033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.1904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 983 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.2169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.2679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.2046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 984 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.2759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.1984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.2008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.2873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 985 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.2390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.1580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.1667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.3794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.0776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 986 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.1834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.1921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.1556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.2418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.2067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.1915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 987 Loss: tensor(0.1969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.2866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.1949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.2932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 988 Loss: tensor(0.2867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.2018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.2867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.3191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 989 Loss: tensor(0.1857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.0535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.2179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.2169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.0852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 990 Loss: tensor(0.2003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.2285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.2906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.1426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.2355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.2147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 991 Loss: tensor(0.1490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.2626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.2746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.2440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 992 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.2836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.3213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.2317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 993 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.1901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.2616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.2354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.1793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.2854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 994 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.2990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.2334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.1041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.1648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 995 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.2640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.2664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.1441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.1804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.2239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 996 Loss: tensor(0.1635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.2793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.3279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 997 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.2634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.2277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.0700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.2029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 998 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.4107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.2328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 999 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.1630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.3368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.1569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1000 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "epoch_num = 1000\n",
    "batch_size = 8\n",
    "lr = 0.01\n",
    "gamma = 0.5\n",
    "\n",
    "minimum_loss = float('inf')\n",
    "loss_track = []\n",
    "\n",
    "# Load training data\n",
    "trainset = DataFromH5File5(\"/home/pz281@ad.eng.cam.ac.uk/mnt/PhD/Pro_Down_SR/data/DownBy4_30_120.h5\",N_low,N_high,scale)\n",
    "train_loader = data.DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialise training model\n",
    "G = DownScale()\n",
    "G.apply(weights_init_xavier).to(device)\n",
    "mse = nn.MSELoss(reduction='sum')\n",
    "optG = torch.optim.Adam(G.parameters(), lr = lr, weight_decay=0, betas=(0.5, 0.999))\n",
    "r_scheduleG = torch.optim.lr_scheduler.StepLR(optG, step_size=100, gamma=gamma)\n",
    "\n",
    "# Logger info\n",
    "dir_name = f'models/train_NN/model1/30_120/lr{lr}_gamma{gamma}'\n",
    "makedir(dir_name)\n",
    "logger = setup_logging('job0', dir_name, console=True)\n",
    "logger.info(f'Training for {epoch_num} epoches and learning rate is {lr}')\n",
    "\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    \n",
    "    for i, d in enumerate(train_loader, 0):\n",
    "        \n",
    "        residual, high_res, low_res = d\n",
    "        size = residual.shape[0]\n",
    "        low_res = low_res.to(device).reshape(size,1,N_low,N_low)\n",
    "        high_res = high_res.to(device).reshape(size,1,N_high,N_high)\n",
    "        \n",
    "        optG.zero_grad()\n",
    "        out = G(high_res)\n",
    "        loss = mse(low_res,out)/batch_size\n",
    "        loss.backward()\n",
    "        optG.step()\n",
    "        \n",
    "        if loss < minimum_loss:\n",
    "            save_model(dir_name, epoch, 'best_model', r_scheduleG, G, optG)\n",
    "            minimum_loss = loss\n",
    "            \n",
    "        if epoch%100 == 0:\n",
    "            save_model(dir_name, epoch, 'model_epoch_{}'.format(epoch), r_scheduleG, G, optG)\n",
    "            \n",
    "        loss_track.append(loss.cpu().data.numpy())\n",
    "        np.save(f'{dir_name}/chains/loss_curve.npy', np.array(loss_track))\n",
    "        \n",
    "        print(\"Epoch:\", epoch, \"Loss:\", loss)\n",
    "\n",
    "    r_scheduleG.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_low = 30\n",
    "N_high = 120\n",
    "scale = 4\n",
    "a, b, c = 8,3,5\n",
    "\n",
    "h_low = 1/(N_low-1)\n",
    "x_low = np.arange(0,1.0001,h_low)\n",
    "y_low = np.arange(0,1.0001,h_low)\n",
    "\n",
    "h_high = 1/(N_high-1)\n",
    "x_high = np.arange(0,1.0001,h_high)\n",
    "y_high = np.arange(0,1.0001,h_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_low, r_low, A_low, x_low, y_low = generate_data(N_low,a,b,c)\n",
    "w_high, r_high, A_high, x_high, y_high = generate_data(N_high,a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = DownScale().to(device)\n",
    "G.load_state_dict(torch.load('models/train_NN/model1/30_120/lr0.01_gamma0.5/ckpt/best_model.pth')['netG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_high_tensor = torch.tensor(w_high).to(torch.float32).to(device)\n",
    "w_low_tensor = torch.tensor(w_low).to(torch.float32).to(device)\n",
    "out = G(w_high_tensor.reshape(1,N_high,N_high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(9,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.pcolormesh(x_low, y_low, w_low_tensor.cpu().data.numpy(), cmap='rainbow')\n",
    "cbar = plt.colorbar(pad=0.05, aspect=10)\n",
    "#cbar.mappable.set_clim(-0.03, 0.03)\n",
    "plt.title('LR')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(1,2,2)\n",
    "plt.pcolormesh(x_low, y_low, out.cpu().data.numpy()[0], cmap='rainbow')\n",
    "cbar = plt.colorbar(pad=0.05, aspect=10)\n",
    "#cbar.mappable.set_clim(-0.03, 0.03)\n",
    "plt.title('DownSampled')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upscale by 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_low = 30\n",
    "N_high = 120\n",
    "scale = 4\n",
    "a,b,c = 8,5,5\n",
    "\n",
    "h_low = 1/(N_low-1)\n",
    "x_low = np.arange(0,1.0001,h_low)\n",
    "y_low = np.arange(0,1.0001,h_low)\n",
    "\n",
    "h_high = 1/(N_high-1)\n",
    "x_high = np.arange(0,1.0001,h_high)\n",
    "y_high = np.arange(0,1.0001,h_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_low, r_low, A_low, x_low, y_low = generate_data(N_low,a,b,c)\n",
    "w_high, r_high, A_high, x_high, y_high = generate_data(N_high,a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Parameters for prior variance\n",
    "prior_sigma = 0.002\n",
    "ll_sigma = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.eye(N_high**2) * prior_sigma**2\n",
    "G_inverse = np.eye(N_high**2) * (1/prior_sigma**2)\n",
    "\n",
    "# Turn matrices to tensors\n",
    "G = torch.tensor(G).to(torch.float32).to(device)\n",
    "G_inverse = torch.tensor(G_inverse).to(torch.float32).to(device)\n",
    "A_high = torch.tensor(create_A(N_high)).to(torch.float32).to(device)\n",
    "b_high = torch.tensor(create_forcing_term(N_high,a,b,c)).to(torch.float32).to(device)\n",
    "\n",
    "# Store sparse matrices as sparse tensor\n",
    "A_high = A_high.to_sparse()\n",
    "G = G.to_sparse()\n",
    "G_inverse = G_inverse.to_sparse()\n",
    "operator = torch.spmm(A_high.T,G_inverse).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(w_low).to(torch.float32).to(device)\n",
    "posterior_initial = torch.randn(*[N_high,N_high]).to(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = DownScale().to(device)\n",
    "# G.load_state_dict(torch.load('models/train_NN/model3/31_121/lr0.01_gamma0.1/ckpt/best_model.pth')['netG'])\n",
    "G.load_state_dict(torch.load('models/train_NN/model1/30_120/lr0.01_gamma0.5/ckpt/best_model.pth')['netG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Langevin dynamics\n",
    "K = 1000\n",
    "s = 0.0004\n",
    "\n",
    "z = posterior_initial\n",
    "chains_evolution = []\n",
    "z = z.clone().detach().requires_grad_(True)\n",
    "for i in range(K):\n",
    "    # Grad log-likelihood\n",
    "    x_hat = G(z.reshape(1,N_high,N_high)).reshape(N_low,N_low)\n",
    "    log_likelihood = (-1/(2*math.pow(ll_sigma, 2)) * torch.matmul((x-x_hat).reshape(1,N_low**2),(x-x_hat).reshape(N_low**2,1)))\n",
    "    grad_ll = torch.autograd.grad(log_likelihood, z)[0]\n",
    "    # grad_log_likelihood = torch.matmul(G,grad_ll.reshape(N_high**2,1)).reshape(N_high,N_high)\n",
    "    \n",
    "    # Grad prior\n",
    "    difference = torch.spmm(A_high,z.reshape(N_high*N_high,1)) - b_high.reshape(N_high**2,1)\n",
    "    # log_prior = - 0.5 * difference.T @ G_inverse @ difference\n",
    "    # grad_log_prior = torch.autograd.grad(log_prior, z)[0]\n",
    "    grad_log_prior = (- torch.spmm(operator,difference)).reshape(N_high,N_high)\n",
    "    \n",
    "    # Random noise term\n",
    "    W = torch.randn(*[N_high,N_high]).to(device)\n",
    "    # random = torch.matmul(G_sqrt,W.reshape(N_high**2,1)).reshape(N_high,N_high)\n",
    "    \n",
    "    z = z + 0.5 * s ** 2 * grad_log_prior + 0.5 * s ** 2 * grad_ll + s * W\n",
    "    # chains_evolution.append(z.cpu().data.numpy())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "X, Y = np.meshgrid(x_high, y_high)\n",
    "ax1.plot_wireframe(X, Y, z.cpu().data.numpy(),color='r')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_zlabel('w')\n",
    "ax1.set_title('SR')\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "X, Y = np.meshgrid(x_high,y_high)\n",
    "ax2.plot_wireframe(X, Y, w_high,color='r')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_zlabel('w')\n",
    "ax2.set_title('high-res')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR L2 Error: 0.00023719500703068996\n"
     ]
    }
   ],
   "source": [
    "error1 = abs(w_high - z.cpu().data.numpy())\n",
    "print('SR L2 Error:', (error1**2).sum()/error1.shape[0]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Training $u_l=Hu_h+G(u_h)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Training $u_l = Hu_h + G(Hu_h)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code downscaling matrix\n",
    "N_low = 31\n",
    "N_high = 121\n",
    "scale = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory already exists\n",
      "2024-06-03 12:55:31,777 : Training for 500 epoches and learning rate is 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: tensor(16.6291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(3.3938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(4.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(1.5530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(1.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(1.4716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(1.7028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.6647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.6079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.3417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.3480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(2.7933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(4.4649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(1.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(1.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(1.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.7128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.8857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.4200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(1.2252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(1.0471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(4.2475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(1.0501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(1.4212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.5995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.4970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.6263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.3803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.1945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.3838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.3140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.8878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.4088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.8567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.2812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.7421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.2731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.4558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(1.4367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.3640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.2057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.2828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.4757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.4398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(1.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.2797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.4890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.2119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.4218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.2785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.3084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.2145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.1700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.2327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.2489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.3184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.7281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.2934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.2897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.3197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.2727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.2008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.5193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.2223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.7100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.4516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(1.6445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.9573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(1.3630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.5041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.4311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.3798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.4297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.2824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.9410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.3067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.3101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.3722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.3170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.5265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.4245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.2159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.4259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.0955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.6405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.5817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.3518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.3167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.7488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.3063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.3078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.5690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.4108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.3758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.2781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(9.4686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.8414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(1.9267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(1.3277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(1.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.8520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.5377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.6624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.6352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.5951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.4175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(1.6669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.6450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(3.1162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.4600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(2.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(4.3376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.5917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.5713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.8030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.4778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.7871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.4106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.9722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.7669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.6125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.4177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(3.8303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.5831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(1.2742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(1.4750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.8960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.8170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(1.3868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.8521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.4209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(1.2035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.6520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.5342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.1958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.5157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.3237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(3.7080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.6002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.4825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(1.6770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.5110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.4311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.3819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.6352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.6558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(1.7748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(1.5886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.6935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.8245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.5390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.2707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.6503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(1.4909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.6022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.4397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.4558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.9023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.5133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.3309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(1.0553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(1.4082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.8115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.4118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.6544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(5.2155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.5236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.4557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(1.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(20.4826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(7.8824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.8379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(88.2187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.6614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(2.7444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(4.4507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(7.6771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(2.7922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.7228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(12.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(13.6326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.9327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(4.1985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(1.8862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(5.3933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(7.8318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(3.4337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(2.6800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(1.5626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(1.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.8948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.9596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.5510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.5183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(1.2867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.6210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(2.0246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(3.7825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.5701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(1.5120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(1.9837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.9175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.7247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.7338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.5767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.6921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.5608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.0314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.3948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.5374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(4.4062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.5366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.5590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.8992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(1.7297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.6997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.9842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.6911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(2.3922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.7115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.9417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(1.0606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(1.5106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.2747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.6865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.5941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.5252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(1.8743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(4.3203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.4761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(1.4825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.6921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(1.5791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(1.1757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.5008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.8339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.9253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.7255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(1.7639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(1.0072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(5.2987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(1.9516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.4557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.5137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.4862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.6187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.9175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.4323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.6669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.6206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.6108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.9681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(1.4849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.9318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(5.9755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.7287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(1.6217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(1.6603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.9850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.9380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.6966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.5421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(5.0703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.9393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(1.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.5739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.8577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.8531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(2.2213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.9521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.8832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.6090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.9491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(1.5661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(1.2893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.5888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.8855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(1.0728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(1.6068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.5783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(2.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.9346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(1.3471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(3.7392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.6331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.6026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.9904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.6328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(1.4932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.4081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(2.2949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.6964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.6097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(1.2458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.8232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(1.0529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.6424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.9958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(1.8999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(5.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(1.5146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.5763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(1.1856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(1.0962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.9308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.4622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.8783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.4601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.9811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(1.3842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.5313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(1.8055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.5132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.9875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.3202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.9517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(1.4525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(1.8313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(1.8182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.7229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(3.9757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(1.6625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.7377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.7408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.4077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(1.1617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(1.2601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.5727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.8700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.9769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.7943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.7073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.9356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(3.7730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.9703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.4500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.7436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(1.4943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.7893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(2.4308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(1.9121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(2.4698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(1.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(4.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.4562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.4628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(1.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.6873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.9516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(1.0202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.4276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(1.3941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.9002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(1.6053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(1.4497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(1.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.5455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.9790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.6662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(2.7389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.7231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.6724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.7579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.6160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(1.0488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.9821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(1.8124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(4.2253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.5695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.8655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(1.0142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(1.3338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.8365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(1.2506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.4707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(1.2095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.7767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(1.3147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(1.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.7203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(2.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(2.2200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.5112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.8795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.7568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(1.5692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(3.7352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.3154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.8766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.4398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.7275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(1.6722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(2.4443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(1.8364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.7829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(1.0192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.6051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.7398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(1.5756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(3.7755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.5960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.8651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.9258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.8269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.8233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(1.0280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(4.3599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(1.4838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.7634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(1.0964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(1.1986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(4.2061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(4.0421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(2.9983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(5.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(4.0388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(1.3971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.8064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.7496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.5291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(2.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.9330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(2.4073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(1.0359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(1.1974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(1.3903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.5405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.9330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.7469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.5154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(1.3754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(1.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.6455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(1.5528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(1.4505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(4.4365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.8547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(1.0448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.7976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(4.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.9542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.5960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.5717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(1.5752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(1.3137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(1.4914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(1.6453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(1.6392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(1.1689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.9050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(1.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.8218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.5039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.7647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.5118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(4.3443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.3958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(1.1882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(1.0676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.8229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.4922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.8932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(1.4646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(1.0065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(2.9661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(2.0673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.8090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.6552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.5751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(1.5488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.9638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(1.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(1.5614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(1.4729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(1.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(1.8597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.7570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.3282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.5140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(1.0798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.5743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.8398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(4.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.5740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(1.6019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(1.0561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.3495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(1.5922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(1.1576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.8685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(1.2896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.4040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.5463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.8920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(1.9624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.8610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(1.1725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(1.0632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(1.0039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(4.2833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(1.4126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.9602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.9765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(2.2325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.7390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.8528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.5866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.9876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(4.7794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.7763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(1.7862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(1.0461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(1.0628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.4967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.4005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.8411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(1.3670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.6152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.5722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.8050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.7102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.5992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.5084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.3902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.0555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(3.6485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.1678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.8315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.8575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.4541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.2611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(1.6394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.7613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(3.6056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(1.7032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(1.0327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.8128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.5874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.5054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.9568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.6689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.9882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(1.0489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(1.8576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(1.4582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.4400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(1.9049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.8869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(1.4093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.5484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(1.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(1.0416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.4560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.6199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(1.0411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(1.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(2.0496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(2.5886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.6572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(4.0585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(1.6264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.3738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.9365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.6728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.7855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.4590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(1.1709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.9620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.7764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(1.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(2.0415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(1.9003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.6956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(1.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.8121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(4.6259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.4176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.7058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.5972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(1.4855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.9256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.7283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(1.2845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.8339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(1.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.4508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.9699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.6616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.6318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.9269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(1.2666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(2.4646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(3.6655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(1.2488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(2.0889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(1.0108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.5020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(3.2086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.5581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.0755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.8650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(4.0489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.6462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.3421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.9451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.4598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.4974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.2113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.6597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(1.2946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.7441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.5395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(1.6815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.2993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(1.6722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(1.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.4739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(2.0358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.5326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(1.5859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.6362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(1.3122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.6618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(1.5936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.8629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.4444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(4.2555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.7398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.3780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.2607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.5730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.6103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.4819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.5965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.7988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.6332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.2954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.9064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.6115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.1994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(3.9788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.6002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.5303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.4026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(1.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(2.8288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(1.0558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.7814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.5240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(5.0427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.5160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.4966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(1.2018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(1.0504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.7397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(1.2216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.7637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.8570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(1.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.5514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(1.8470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(1.6671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.5497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.5923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.6685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.9601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.9094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(1.0714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.2864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(1.0570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(1.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(4.0209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.9265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(1.9736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(1.2467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.9558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.6562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.6567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.4825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(1.6705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.7218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(1.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.8001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.8449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(4.0728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(1.6881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.5931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(1.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.9283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(2.4697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(1.2545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.6876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(2.2215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.5961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.6262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.3593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.8156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.3666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.2035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.7118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.0540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.0027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(1.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.5800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(2.2088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.8992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(4.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.9599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.8094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.8927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(2.1697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.0707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.9782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.7892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.3641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(4.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.5484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.5438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.9595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.6463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.4836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.9055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(1.9848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.5957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.8617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.7571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(2.5843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(1.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(2.2785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(1.3096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.8314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.6565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(1.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(3.9491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.9411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.7274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.9195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.4770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.4917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.7588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.8167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.4300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.9639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.5457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.4122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.3008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.0677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.6828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(1.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.7184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.9887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.5145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.8942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(3.9597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.4786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.5836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(1.2817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(4.2101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.7678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.7768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(1.7635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.6886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.6790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(1.0302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(1.3480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(1.8595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.5966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(1.0214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(1.6761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(1.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(1.7836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(3.6072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(1.4882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.5212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.8232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.7980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.4539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.9341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(1.6372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(2.1444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(1.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.6381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(1.2597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(1.3043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.3966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.8416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.6154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.2834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.7868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(5.2039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.9120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.7673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.6535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.5934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.4751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(1.4440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.7553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.8785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.6373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.6746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.9343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.8696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(1.4493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.4720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(2.4971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.7847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.5806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.8888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(2.0105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(1.5866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.8136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(1.1766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.5951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(3.4780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(1.2552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.7261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.6568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.5187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.4010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(1.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.6363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.9022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.4736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.7927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(1.0887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(1.6365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.9050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(4.6822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(1.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.7211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(1.0352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(1.4021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(2.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(2.3090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.5539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.6294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.5687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.7316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.5602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.9223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.2048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.7535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.8753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.9067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.3949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(3.9902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(1.0511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.4503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.9382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(1.6982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.9798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.8696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.7055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(1.5206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.8645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(4.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.9710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(1.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.9554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.6383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(1.4540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.7429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(1.1441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(1.7432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.3508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.5418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.4778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.9558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(1.3773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.5439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(3.8606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(2.2948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.6011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.8239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.5061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.8615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(2.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(1.1931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(1.1757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.8002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(1.7282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.7634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(1.6633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.8548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(1.6622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.7045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.8581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(1.2016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(1.7701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.5824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(2.4528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.4841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(3.9988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.6202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.5653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.7518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.9189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(2.2548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(1.3461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(1.0293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.4736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(1.9153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.9950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.3257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.7596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(1.3266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.5170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.5575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.8284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(2.3991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.4841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(4.0298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.6064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(1.8350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.5565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(3.7733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.6471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.6728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(1.4981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.6380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(1.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.6803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(1.0425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.7437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(1.4133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(1.7276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(2.1961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.6511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.7665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.8375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(1.6593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.8568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(1.0263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(1.1944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(1.4128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(3.6077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.6042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.4066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(2.8837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.8251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(1.5476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.6477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(1.4957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.3844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.4541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(1.7487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.5929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.7436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(1.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.5888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(1.2537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.5050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.6734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(1.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(4.2681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.6298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.9829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.6297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(1.1958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.7369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(3.0505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.9013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.9591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.8284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.0839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.3990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.4860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.6343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.6084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(5.1622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.3061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.7297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.6297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.6744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(1.6138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.5457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.9799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.6641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.8938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(3.7718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(2.5660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(1.2501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(1.0522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.4224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(1.1254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.6432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.5937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.8842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(1.3165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(1.5185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.9878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.9272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.1758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.3263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.3103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.8077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.7337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.7005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(3.6445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.7811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.6453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.0457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.5533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.3866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.7298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.6610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.6328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.3544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(1.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.4068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.4979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(2.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.5022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(2.3093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.9317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.9290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.7937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(1.9659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(1.8673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.8041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(3.7041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(1.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.2613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(3.6168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(1.3219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.8527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(1.4479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(1.6830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.4940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(1.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.9944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(1.6699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(2.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(1.1041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.6479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.8919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.4411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.2272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.2399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.5784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.8146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.5584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.9639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.6121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.8281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.7602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.8550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.8909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.0397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(3.7261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.4905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.6072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.5240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.8452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.6137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.3973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.5845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.2604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.4579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(3.7976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.8040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.9836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.5240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.7563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.7174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.2216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.7456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(3.5358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.7914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(1.4418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(1.0391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(1.3700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.9572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(1.3289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.6072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.4332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(1.0845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.6596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(2.4513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.4978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.9756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.5918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(2.0755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.5953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.5937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.5038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.5361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(1.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(1.0617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(1.2549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.8538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(2.0388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.6620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(2.1406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.8223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(4.4635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(1.1626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.6844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(1.3303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.7991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(1.7703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.6723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(1.3142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(1.2761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.7951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.9270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.5395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.8982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.6231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(4.7296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.7318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(1.9416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.6266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(1.7023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.4936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.7064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(1.3677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(1.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(1.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.7839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.7414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.3833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(4.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(1.8682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(1.7196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.9784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(1.0438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.8512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.5645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(1.8282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.5619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(1.9954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(1.5104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.7074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.7643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.4263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(1.4096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.5282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(4.3449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(1.6593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(1.2536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.7773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.5237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(1.4421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.6876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(1.0244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.7875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.7966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.9174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(1.9891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(1.5415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(1.9247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.5064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.5729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.8325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(1.0499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.8342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.8513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.6121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(4.6839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(1.3494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.7639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.6155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.8261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(1.9273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(1.5240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.8887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.5557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.6097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.6661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.6775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.8226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.9370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(3.8203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(1.6219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.7274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(1.6301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.8135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(1.7927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.6565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(1.5380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.8803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.5779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(1.5015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.5888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.9695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.7060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.6645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(3.8726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.8565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(1.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.7133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(2.2020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(1.9678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(1.0453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(2.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.6444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(1.4655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.9473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(1.7681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.9535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.4896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.5980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(1.6366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.5695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.6774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.7722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(1.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(1.0256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.5546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(4.4846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.6522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.8632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.4071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.6451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(1.9354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.5875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(1.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(1.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(1.4029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(1.1501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(1.3357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(4.9839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(1.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.8695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.7145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(1.0689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(1.6129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.7076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(1.3701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(1.3897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(3.6666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(1.3919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(1.8753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(1.2974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(1.5237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.9246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.5560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.6091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.7044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.6497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.7604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.8144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(1.0209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.5412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.8994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(1.0362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.5353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.5031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(1.6082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(2.7324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.8441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(1.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(1.4172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.8505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(4.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.6210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.9078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(1.0548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(1.8070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.9498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.4500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.8875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(1.7581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(1.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(3.7719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.5964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(2.1956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(1.9833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.7922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.6437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.9136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.4780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(1.0519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.4604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.6294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(3.6482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.9655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(1.7892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.7116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(1.3664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.4917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(1.8917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.6043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(1.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.7185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(1.8387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.6725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(1.2356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.8846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(1.4073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(4.9869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(1.2896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(1.0478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.3113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(1.0243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.4891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.7625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.4684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.6600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(2.2399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(1.8600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.6170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.8273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.9115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(1.3093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(1.0456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.6517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(4.8184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.6474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.1633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.0190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.3719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.3549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.4694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.6075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(2.5438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.6239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.8425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.4071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(1.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.6874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(1.8522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.9163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.7609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.8196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.5728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(1.9659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(2.4926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.4458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.8124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.5083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.7492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(3.9745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(1.1716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.9821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(2.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(1.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(1.7508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(1.0253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.7430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.8981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.4107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(1.0807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(1.6173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.5353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.4745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.4483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(1.8897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.6864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(3.8304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(1.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.6977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(1.2293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(1.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(1.6425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.8566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.4141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.8531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.9536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.9848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(1.6296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(1.2084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(1.9159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.6097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.9984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(4.0101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.7036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(2.0238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.7481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.7105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(1.5529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(3.6606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.8471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.6785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(2.0349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.9255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.2854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(1.5454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.9300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.5472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.5914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(1.5685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(1.1918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.6255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(1.0230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.8132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(1.3519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.8141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.8128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.6846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(1.7807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(4.3845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.5019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.8183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.3774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.6699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.5846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(2.6790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(1.9194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.4772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.9205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.8839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.8295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(1.6186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.8039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(4.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.9155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.4915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(1.4754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.9765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.9129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.7700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(1.0056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(2.2261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(1.3551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.6451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.9847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(1.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.7481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(1.2662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(1.6730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.5621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(1.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.7009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(1.9357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.4378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(4.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.5168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(3.0137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.5288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.4176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.8698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(1.5248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(1.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(1.5681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.7342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.8855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.5876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.6066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(4.5334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(1.6168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(1.3058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.8597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(1.6778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.4625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.7442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.7395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.8247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(1.4384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.9269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(1.7587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.4733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(3.9909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.3813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.9102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(1.6216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.3324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.7018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(1.9784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.6611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(1.3914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.7856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(1.6737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.8047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.7617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(1.3233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.7394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(1.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.7313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(4.0671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(1.6196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.8253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(1.0208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.4391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(1.8445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.8073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(1.3732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(1.6870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.6556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.7617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.6514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.6255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.5807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.7758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(2.1807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.3254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(1.8139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(1.3605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.6157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.7399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.8052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(1.0110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(4.5372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(2.3610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.6977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.5335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.6422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(1.6669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.5479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(1.6886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.6566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(1.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.6753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.4366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.7700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(1.0806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(2.6528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.7977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(1.4260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(1.4455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(3.6859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.8532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(1.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(1.2187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(1.3138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.5791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(1.7448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(1.5841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.5537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(3.4193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(3.6379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.7063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.7173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.2997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(2.2469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.4211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(1.0099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.7709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(1.0813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.5751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(2.4881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.5342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(1.4186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(1.8884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.7981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.8565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.7792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(1.3796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.9589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(1.8306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.4117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.4956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(4.0421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.7250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(2.2319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.8549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.7346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.4847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(1.6988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.4085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(5.4541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.9648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.3326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.7488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.5600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(1.5025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.7942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(1.3942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(1.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.7521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.6276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(1.0399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(1.4745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.5857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(1.0706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(1.5263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(2.6861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.6709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.6783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(4.7421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.9479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.8779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.6749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.4457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(1.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(1.2620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.8354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(3.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(1.0164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.4739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(2.0228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.9531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.7194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.3243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.9026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(1.1525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(1.3489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.4685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.4543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.7540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(4.0037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.8958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(3.8168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.4836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.8926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(1.6149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.6290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.8310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(2.0726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(1.5002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.6636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.7343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(1.6004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(1.7423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(1.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.7052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.5774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.5814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.9771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(1.2179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.7693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.9477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(2.7788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.8465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.5854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(1.0088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(1.9102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.7932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(4.3730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.5061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.7872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(1.5167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.3906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.9802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(1.8490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(1.2018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.8911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(1.9662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.8132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(1.8635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.7253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.4210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(1.1633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(1.4167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.6746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.7214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(3.9166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.8476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.8893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.7095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.8958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(1.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.7284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.3992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(1.4599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(3.6818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(1.8933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.3620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(2.5736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.8631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(1.0677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.6469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.6948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(1.8241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(1.6429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.8250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.9603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.7496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(1.4358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.9364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(1.0352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.4544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(1.9769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(1.6332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(1.0606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(3.9438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(1.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.6533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.6920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.7321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(1.4352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(3.8309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(1.8094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.3578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.5759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.9758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.6502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(1.4543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.6888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.5889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.7425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(1.3736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(1.7893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.8633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(1.5528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(1.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.6909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(2.3941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.5514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.8824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(3.6107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(1.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.6882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.6796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.6843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.9011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.6520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(1.4932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(2.1697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.7858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.7444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(1.7473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(1.6641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.5814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(1.0976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(1.7314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.5315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.6434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(1.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.9699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.8101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(3.7270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(2.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.5904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.5400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(2.0913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.6971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.8764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.5151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.7852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(1.0705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(1.3774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(1.5249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.4250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(1.0663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.5603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(1.2882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(1.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(1.3582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.4200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.4157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(2.0116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(5.1588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.7200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(1.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.6800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(1.3401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.6687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.6071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.5930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.9641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(2.5206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(1.1101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.9567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.7921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(1.8280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.3230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(1.6747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(3.9423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.7519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(1.3790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(1.5518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.7259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(1.2335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.4907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.5916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.7475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(1.1910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(4.0083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.8551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.8298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(1.1712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(1.5643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(1.1781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(1.4733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.7481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.8346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.3309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.4973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(1.5447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.7480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.4582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.7191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(1.6892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(3.9975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(1.2792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(1.2569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.6368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(1.8679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.7466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(1.6654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(1.4272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.8523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.9258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.3739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.5263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(1.1440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.7853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(1.5592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.8168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(2.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(1.8698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(1.3732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(4.0233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.6120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.4516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(1.2232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(1.0296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(1.4701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(1.7914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(1.0249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.5306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.7906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(1.0487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.8463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.6054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(3.7543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(1.2216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.6295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.8457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(1.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(1.3152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(2.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.4967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(2.5514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.5981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.9590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.8049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.7719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.4240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.6357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(1.0229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.8308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(1.5526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.4875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(2.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.5517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(1.6728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(4.0057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.5490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.6851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(2.0582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.6711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(1.5993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.9877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(1.6669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.6350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.5503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.9351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.8109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.7899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.5174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.7036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.6436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(5.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.9673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.8880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.7093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(1.2155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.8003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(1.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(1.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.6292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(1.6090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.8890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(1.6881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.7155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.8796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(1.5890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.8239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.3102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(4.2213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.7586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(1.8673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(1.7218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.6928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.4599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.8381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.6004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(1.6874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.4645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(1.2453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.8104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.9000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.9172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(1.5188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.7684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(3.8361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.6590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.8529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(1.3270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(2.7797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.5817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.3737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.5319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(1.1985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(1.3614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.5443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.6920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(1.9421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.5157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(1.2016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(3.9922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.3290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(2.2101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.6082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.5723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(4.0497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(1.3940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.5273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.5948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.8318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(1.0435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.5814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.5629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.4889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(1.3793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.8566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(2.3966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.5470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.6140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(2.5075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.6690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.7580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.7389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.9624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(1.7876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.5705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(4.0326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(1.5605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.6197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.8926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.5755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(1.3946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.4563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.9198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.6681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(4.1917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.4128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(1.2243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.5740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.8026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(2.0063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(1.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.5017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(2.4502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.5045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.8093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.4040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.4898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(1.0530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.6362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.8564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(1.8509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.8497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.9530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(1.2206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(1.2761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.4248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.3673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(3.8337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(1.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.6450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(1.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(1.3575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.6288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.7066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.7601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(1.4141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.6223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(1.3671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(1.3450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(4.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.8308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.7343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.7863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.8128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.7529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(1.1726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.6199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.5433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.9852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.7396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.3695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(3.7634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.4344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.4907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.4275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(1.1357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.8093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.8141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(1.3817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(1.2845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(1.1696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(2.0504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(1.2361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.7115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.5798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.6828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.4007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.8322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(1.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.3812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(1.0611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(1.2129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.8012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.5580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.7296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(1.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.7826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.8477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(4.5472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.7149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(1.3624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.5383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.7208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.7285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(1.6015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.6673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.6269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(4.3757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.3395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.8094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(1.0496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.5978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.8659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.7226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.2117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.9013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(1.6529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.9756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.4623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.6436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.5655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.4548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(1.0109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(1.0140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(1.3905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(1.0568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(1.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(4.3820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.5933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.8770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.5576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.9353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.6600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.7389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.5299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(1.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.5290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(1.3428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(1.4978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(3.5536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.6879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.9237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.6779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.3804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.7594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.6306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.8308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.9073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(1.3559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.6292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(1.4485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.7161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.8818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.9515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.8125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.5918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.5016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.5661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(4.0494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(1.7170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.7321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.4237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.8936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.3037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(1.0141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.5861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.5982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(1.3735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.8372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.3228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.4144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(1.5859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(1.8757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.6865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.4961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.6701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.4765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.7352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.3982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(4.4161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.7325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.3923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(1.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.4519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(1.2274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.5134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.3888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(4.0467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.9532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.5193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.6380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(1.8651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.6722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.5234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.2868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.5378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.3897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(1.7024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.5613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.6368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.5297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.9927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(1.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.4717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.9968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.4807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.3035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(1.0538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(3.7077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(1.0591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(1.1637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.4725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.6800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(1.4186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.2896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(1.5203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.3237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.8537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(3.7331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.4750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.7748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.5454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.9524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(1.6412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.4218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.3435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(1.5596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.6089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.3693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(1.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(1.4613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.4491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.5564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(1.0473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(1.1756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.3375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.8183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.4492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(4.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(1.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.6979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.3942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.6549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.5737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(1.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.2771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(1.7470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.6435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.6255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.6119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.4071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.3915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(1.8747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.9277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.3209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.5919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.4718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.4716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(4.9573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.7458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.4074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(1.6482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.4610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.6546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(1.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.7634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(1.2919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(3.9036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.5537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.7514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.9675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.7107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.4192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.4881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.3427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(1.2979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.3550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.7435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.3312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.9064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(1.4108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.5671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(1.0463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.9855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(1.3335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.3646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.5843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(1.0539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(3.7413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.6396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.3191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(1.0374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.7170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.5943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.3560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.7710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(1.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.2826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.6086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.7594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.3464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(1.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(3.8300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.6625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.3987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(1.5485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(1.1933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.9603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.8870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.9594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.5418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.5639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(1.2981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.4603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.6354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(4.4143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.8771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.8594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.4098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.7673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.9928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.8350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.4269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.2260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.4466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(1.0627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(3.5221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.5865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.9243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.4841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.5604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(1.4958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.7387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.5192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.3082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(1.5860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.8184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(1.4111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.3890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.1971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.4195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.3208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.6169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.6062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.2036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(1.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.9112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(1.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(1.3690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.8123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.8118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.9011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.7484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(3.8285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.5347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.6656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(1.2340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.6018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.4191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.4077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(4.1478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.8495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.8193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(1.6540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.5710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.6445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.5170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.3339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.3221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.4132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.6573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(1.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.8605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(1.2202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.8693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.6224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.8165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.3409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(1.3716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.5964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.3976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.8664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(3.6535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.4200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.9843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.5658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(1.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.2110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(1.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.9527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.3977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.3900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.9578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.5877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.5552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.4152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(1.0592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(3.6248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(1.1500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.7690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.6200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(1.2473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.5454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.3879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.5958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(3.6343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.8125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.4111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.8408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.6346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.5412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.3696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(1.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.4030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.6131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(1.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(1.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(1.2723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.4100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.9215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.5107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.5689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.7127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(4.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.3390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.6370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.7175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.6043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.9300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.9748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.7589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(1.0130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(1.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.4986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.8081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.4092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.3861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.8962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.8557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.3787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.9849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.3280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.5136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.8904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(1.5058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.9041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.3700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.9698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(3.9329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.6094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.6385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(1.0268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.7453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.7293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.5729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.3866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.3950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(1.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.5360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.6038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.4379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(1.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(4.2760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.5190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.9495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.5790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.4896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(1.0045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.6769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(1.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(1.1838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.8009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.3286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(1.0951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.3492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(4.8420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.3943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.3966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.5474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.5140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.5233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.4303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.4737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(1.4799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(4.0214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.6327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.4776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.2945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.5387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.9695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.7547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.5463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.4987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.6961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(1.7054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.3432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.8002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.4783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.2958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.4834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.4897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(1.1882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.4103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.6789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(1.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.7046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(1.5943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.6172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.4561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.3208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(4.0750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(1.0577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.3541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.4590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.3928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(1.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.3249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.6654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.5500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.6483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.6387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.4265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(4.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(1.6114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.5821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.2333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.5480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(1.7619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.7446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.3327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.8293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(2.0136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.5636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.9486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.3347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.3001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.5995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.5758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.7849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(4.5578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.5611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.4720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.3606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.9048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.6554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.3153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.4725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.3467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.7771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(1.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(3.5972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.6308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.5495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(1.0183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(1.3201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.3666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.8024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(1.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(1.0934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.6969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.3977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.4187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.2221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.4064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.4616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.6628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.4024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.9146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(3.6456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.4640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.9519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(1.9810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.9126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.6303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.4547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.9514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.5619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.5369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.4132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.3448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.4394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.3469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(1.3356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.6927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.4137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.9764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(5.0476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.8709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.4970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(3.6657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.8669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.8976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.5000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.3642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(1.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.5147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(1.7689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.6295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.4140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.4556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.5576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.3962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.8838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.4424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.6917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.3929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.6234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(1.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.4618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.4511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(1.8196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.9890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.3034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.8815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(3.5592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.2507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.5269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.8983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.6423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.4566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.8163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(1.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.5963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.6626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.4954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(1.0089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(1.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.3959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.3253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.3707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.8021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(4.3242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.2886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.2291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.4932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.4687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(1.4416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(1.0278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.5735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.5574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.9518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.3185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.3195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.3640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.4335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.6803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(3.5133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.2803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.7354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.4056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(1.6738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(1.0061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(1.2626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.3535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.4309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.7827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(3.7139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(1.0389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(1.8838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.5525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.4723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(1.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.4702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.5279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.5731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(1.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.3914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.4133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(1.0043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.6794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.3429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(3.5754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.7359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.3462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(1.2087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.9179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.9171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.5458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.2331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.8175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.7072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(1.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.4544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.3898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.4159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.9387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.9214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.4880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.5928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(1.5081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(4.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.8753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.6019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.4050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.5827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.5379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.3265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.6582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.7953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.5425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(1.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.5351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.6995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.4033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.3719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(1.0495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(1.3856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.7033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.5171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.4479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.5164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(3.9016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.7155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.7831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.3784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.5885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.6974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.4567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.4337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(1.1842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.5238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.4150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.5716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.4850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(4.0281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(1.0989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.8497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.7561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.5870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.7540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(1.2312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.3314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.7232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.4247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(1.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.7290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(1.6678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.7498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.9818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.4499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.4418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(4.2237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.4409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.3351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.4840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.8228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.4170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.6351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(3.8131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.4990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(1.5275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.3989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(1.2604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.3356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.9544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.6600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.7686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.3518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.7298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.8971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.3402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.4241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.3777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.3362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(1.3646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.7071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.3845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(3.6253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.3940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.6487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.4520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.9476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.5612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.4161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(1.6220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.8843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.7478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.4058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.9403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.3863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.4738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.3446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.5597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.9709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.6961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(1.7859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.4850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.4300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.9045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(3.4728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.3690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(1.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.3742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.4655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.5982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(4.9033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.1858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(1.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(1.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.5774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.1956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.4527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.3987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.6864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.4454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.6312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.5357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.9795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.5256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.4118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.5002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.4248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.8939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.7917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.3057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.5611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(1.0180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.3404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.4454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.8720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.8137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.7396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.8851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(4.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.4647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.5589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(1.0477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.9053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.5470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(1.9187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.5986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.8893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.7194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.4809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.2645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.5093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.6228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(3.4140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.1974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.3690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.7978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.4037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.8091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.4761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.5200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.3268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(1.5717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.5472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.6806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.3814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(1.0107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.9924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.2493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.3327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(4.2102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.7575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.5760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(1.0927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.5523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.5388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(1.0135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.4187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.3092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.4329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.3524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(1.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.9604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(4.2533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.5250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(1.2743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.4979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.7563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.4222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.3918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.8751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.6341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(1.0461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.5819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.4592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(1.2515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(4.3536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.1537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.8163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(1.2554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.5487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.7677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.4638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.9005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.3645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.7885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.5007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(1.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(1.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(1.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.2684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.3368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(3.9931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.4221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.8726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.3404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.5765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.7084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.9573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.7570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.5442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.4404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(1.1106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.3177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.6291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.7198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.3942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.3131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.5720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(1.2275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.4493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.7557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(4.3975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.8469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(1.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.8475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(1.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.4027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.5851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.6110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.3612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.2883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(3.5555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.5651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.4728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.7196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(1.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.2959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.8433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(1.6678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.5352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.6659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.3111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.6550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.6067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.8981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.2718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.9709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.4902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.5726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(3.7087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.5946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(1.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(1.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.3617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.3873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(1.2617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.3912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.5175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.3424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.8963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(1.0242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.9264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(3.7682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.3732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.7824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.4357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.9304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.8762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.4062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(1.4239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.5833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.2704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.2336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.3492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.4487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.2615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(1.3217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(1.2937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.7794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.6680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(1.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.5516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.4468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.3386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.6128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.8883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.9443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(3.5630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.6245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(3.5623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.7770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.4112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.5006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.8247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(1.9747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.3456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.4335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.4944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(1.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.8214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.4300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.9248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.4505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.5044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.3594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.4724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.5614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(1.0436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.4651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.4735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.5971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(1.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.6535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.9192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(3.5808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.6909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.9011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.6543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.7641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.4804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.7341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.2374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.4210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.6684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.4942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.9944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.6516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.6684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.4421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(3.8825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.7699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.5099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(1.7715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.8641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.8967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(4.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.5958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(1.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.8660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.5433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.5687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.3976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.4064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.5241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.7335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.3363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.9140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.9238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.5568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.2369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(1.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(1.2118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(1.2653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.3827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.3344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.7990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.4233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.7238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.5069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.3570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(3.7356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(1.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.7277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.3193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.5171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.5837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.3275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.6830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(1.4468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.9193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(4.2913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.6859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.3495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.3642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.9655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.4526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.3275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.8043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.6355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.8137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.6027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(1.0215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(3.9108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.3244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(1.2599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.4539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.9674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.4008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.6114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.5393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.5494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(1.0296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.4423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(1.3620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.9040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(3.6588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.5753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.9093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.2545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.6815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.3573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.7388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.8998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.3373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.8691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.7045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.6256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.3402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.6222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.4033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(1.3004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.6206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.3476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.4211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.3518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(4.4889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.5629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.4033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(1.3331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.6405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.5499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.3334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.5572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.2934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(1.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.7655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.5417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(3.5037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.4203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.7488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.7633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(1.5307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.9107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.2258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(1.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.3414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.4542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.4527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.8385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.4370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.6519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.3150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.7843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.3938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.9801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.6712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.6732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(4.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.7874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.3652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.4821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(1.8023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.2991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.4415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.7710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.4478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.3347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.4463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.4165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(1.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(1.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.3196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(1.2170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.3858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.4355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(1.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.7543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.5381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(3.7963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.9757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.4576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.3753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(1.5542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.5677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.5073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.5331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.4126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.6348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.7835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(4.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.6831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.8541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.4847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.7931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.4161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.3441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.5919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.3019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.9648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.6356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.6140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.3055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.7503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.6624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(3.6642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(1.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.3357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.9351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.8114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.3098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(1.0115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.4669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.6830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.8348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.9686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.5447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.3882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.3771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.6265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.6586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.3318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.4682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(1.0767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(1.3492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.3992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.5724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(3.9088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.3808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(1.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.6925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(1.4556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(1.0291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.2255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.5027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(3.4671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.5157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.4843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.6207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.4108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.4665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.5046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(1.0676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.4003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.5915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.3970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(1.0312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.7504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.8822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(1.0083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(1.1556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.5629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(3.5876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.4397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.5470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.5768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.6615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.6902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(1.0792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.7843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(4.4188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.8576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.4238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.6531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.4661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.4317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.2242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.8337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.7147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.3324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.4709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.6364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(1.1971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.4550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.9259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.3480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.2454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.2858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(1.2678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.4808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.3281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(1.1806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(3.6480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.5201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(1.6320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.3330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.6549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.8847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.5287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.4958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.4562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(1.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.3035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.5848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.5752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(3.8942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.9507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.5587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(1.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(1.4540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.2321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.5923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.3214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.8113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(1.2880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.4440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.6235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.3160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(1.4787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.5101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.4685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.7935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.7065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.4673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.8723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(3.5596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.2800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.3742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.3494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.3062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.8532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.3780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.4001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(1.0282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.3010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.6194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(3.5441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.9285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.3270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(1.4948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.4341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.5715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.9651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.8336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.3583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.4443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.5808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.6488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(4.0231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.2040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.2671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.4988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.6034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.4720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(1.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.6578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(1.0680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.7465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.5347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.4797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.9688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.2378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.8375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(3.8062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(1.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.7079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.3428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.8175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.4547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(1.0714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(1.3193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.3867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.3802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.5035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.2825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.4794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.4081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.6237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(1.0254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.7182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.5789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(3.5605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.4370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.3272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(2.2059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(1.4633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.3494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.2493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.4892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.6184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.5348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(1.3419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.4789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.6794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.3356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.6719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.7187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.4620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(1.4111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.6676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.4844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(1.5271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.3222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(4.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.4817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.2698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.6435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.4231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(1.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(3.6395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(1.0497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(1.3089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.5711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.5462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(1.1915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.3186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.3047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.6600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.3926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.6963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.4600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.5495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.3684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.3970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.4810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(1.2340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.5671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(1.1540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(3.7826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.4147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.5724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.7128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.2838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.3131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.4396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.9247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(1.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.5711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.4127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.5577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.6182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.4565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.3897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(3.4934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.9300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.4670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(1.4008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.9095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(1.3686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.8353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.4559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.4172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.3867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.4850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.7380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(4.4576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(1.3745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.2924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.3036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.5431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.5445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.9010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.3020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.4543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.3967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.5763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(1.2449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.6507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.3437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.7905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.5719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.6811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.3498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(1.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.8411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.6683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.3846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.6846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.8858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(3.6146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.4263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.5149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(1.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.8584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(1.2994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.5237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.4522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(4.0246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(1.0186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.4356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.6839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.5778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.3564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.3674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.4388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.4769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.8477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.4867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.4234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.3572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.8851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.5956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(1.0432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.5000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.6502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.8113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.8413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.3957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.6532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.2800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.9148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(3.7195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(1.1672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(1.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.6511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.4970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(1.0099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.4790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(1.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.2002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.2781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.4870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(1.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.5086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.6853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.8459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.5166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(3.4636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.8031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.4327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.4261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.5469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(1.2011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.3728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.7344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.2280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(1.2515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.5293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.6175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(3.8284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.3713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.7592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.7753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.3798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.7499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.4042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.9943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.4265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(1.0088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.5921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(3.4538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.9516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.5474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.2889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.5080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.6624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(1.0443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.8842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.4948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.8894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.6557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(1.4424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.4020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.4595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.8884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.6868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.4152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.8494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.5143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.2914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(3.4766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.4452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.5059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.7252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.5155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.2816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.4473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(1.3508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(3.7018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.5941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.9459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(1.0593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.5084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.3880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.3745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.4504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.2174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.9477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.5448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.9754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.3676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(1.5145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.2848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(3.5087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.3661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(1.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.6128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.5499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.3578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.6592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.5390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.4229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.7289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.5092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.9944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.6965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.3961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.5023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.5477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.3576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(3.4997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.9421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.6342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.5122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.2826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.4845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.6194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(1.6008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.3696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.6066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(1.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.8653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.2637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.6534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.6301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(1.2490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.4077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.5611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.8641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.4488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.4232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.4458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.5195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.6173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.2914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(4.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(1.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.5309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.6718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.7142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(1.0661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(1.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(3.5429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.3878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.4452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.6134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.7068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.6478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.5085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.7141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.4089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.3463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.7982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.3556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.4294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(1.1622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.5973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(3.3816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.3575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.2173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.2968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.3510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.8929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.6398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.4521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(1.1938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(1.5725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.2222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.6992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.5888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.6160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.3821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(1.5171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.6009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.5470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.8832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(3.8066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.3674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(1.2576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.4266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.4772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.4446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.6381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.7001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.6151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(3.3934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(1.2938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.3967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.7331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.9581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.2848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.8809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.5027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.6841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.7671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.4657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.5191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.5666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.3893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.5820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.8568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.8242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.2946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(3.3223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.7868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.8417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.7178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(1.2639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.4003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.6674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.2886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.6567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.4467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.5832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.8897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.7846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(1.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.4931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.6311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.7624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.5079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.7020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(3.9781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.4486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.7471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(1.0623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.3499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(3.4634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.7967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.2996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.3040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.8750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.5657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.4310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(1.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.6902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.4833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.6631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.3094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.5556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.6139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.7362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(1.0395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.7618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(1.0675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.3906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.4173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(1.2640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.4981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.2304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.5459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.6564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.3329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.9134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(3.3367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.5370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(1.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.6328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.6349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.4158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.8685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.5536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.9888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.4426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(1.0527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.2750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.3922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.3382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.3659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.8416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.7693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(3.9311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.6804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.3734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.4858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.3639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.3486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.9611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.3403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.7844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.9438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.3788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.9134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.5842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.9479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.3489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.9862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.5629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.5335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(3.4544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.4622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.3577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.2003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.8272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.5768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.5823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(3.5810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(1.1364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.8247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.5144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.8559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.7276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.5617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.3838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.7587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.5608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(3.5273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.7450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(1.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.3715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.4118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.9190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.4397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.4872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.6971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.9351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.4937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.5733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.8949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.3867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.4609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.3886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(1.0602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.7583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.6782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.4392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.7458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.6576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.3769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.8051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.5640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.4074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.8360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.3315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.8844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(3.5448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.4462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.3774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.5424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.1938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.6279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.2837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(1.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(1.3189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.6351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.4930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.7968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.3813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.6803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.4280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.4774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(4.2169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.5729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.5270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.3064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.4110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.6297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(1.3675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.3637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(1.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.8722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.5878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.4287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.3780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.8793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(3.7907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.4541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.5185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(1.3847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.5041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.5905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(4.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.1928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.4581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.7371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.4026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.8918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.7728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.2373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.9438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.3997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.4171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.5579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.2936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.4670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.4460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.5839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.5830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(1.4966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.3761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(3.2867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.4126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(1.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.4174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.3346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(1.2986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.4812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.3184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.9591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(1.0183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(1.0468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.4677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.6869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.5292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.4575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.7345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(1.3090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.5622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.5894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(3.4409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.2974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.3431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(1.6432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.5363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.4830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.9354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.9437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(3.9011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(1.0736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.4410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.5234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.4438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.2846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.4136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.4793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.4305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(1.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.3557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(1.0117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.4115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.5256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.3643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.4718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(1.1643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.8732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.5044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.2768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(3.4581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.6214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.9679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.3375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.6115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.6068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(1.2660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.5453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.3821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.7824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.3254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(4.4548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.4245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.3718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.7405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.5039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.2653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.5794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.5627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.4329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.4946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.4137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.8413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.7499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(1.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(1.3876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.5189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(3.6096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.5623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.3213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.8132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.3380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.3910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.2796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.4326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.4658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.4236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.7622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.5429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.8073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.3518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.8223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(1.3556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.5503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(3.3141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.4537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.7133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.3243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.3511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(1.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.5009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.4875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.4210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.3042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.2661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(1.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.3318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.3591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(1.1749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(3.7616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.4839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.4881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.7284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.4629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(1.3072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.5070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.6543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.5814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.7747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.5792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.2889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.2754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.7503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.5958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.9187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.6436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(1.0729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(1.0219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.3760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.5052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.8222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.3073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(3.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(3.7847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.3844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.5744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.5731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.5490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.6728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(1.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.5606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.4940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.2724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(1.1753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.4753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(1.2458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.3269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.3945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.4207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.5488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(3.4951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.4188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.6098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.4893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.6349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.6619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(1.4580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.3568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.7730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(1.0177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.5923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.8586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(3.6793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.4365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.8405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.7866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.6064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.6847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.4506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.3041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.4633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.9006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.3280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.2399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.5830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.4856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.7821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(1.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(1.0202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.2722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(3.7797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.4931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.7417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.8606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.6801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.5912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.7257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.5686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.8124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.4374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(1.2095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.4407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.6127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.4547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.8085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(3.4146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.4622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.6280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.8292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(1.0176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.4915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.3603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.2946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.7833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.8414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(1.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.3049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.3496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(3.3096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.3934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.9375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.2725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(1.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.3917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(1.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(1.0942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.5235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.3666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.6253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.6271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.7050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.7838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.3468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.7842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(1.0578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.2872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.4687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.7700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.5185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.4835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(1.0227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.4663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(3.3014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.4410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.3950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.9865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.3399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(1.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.3182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.4384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.4969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.6922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(1.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.3887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(3.7956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.5310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.4763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.5732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.6633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.5137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.6812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.5949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.2971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(1.2948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.4614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.6324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.3292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.5596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.4021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.3855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.8194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.5896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.8935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.3844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(1.3237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.4150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.4733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(3.5850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.5998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.6768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.3943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.5618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.8103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.6110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(3.7338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.5845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.5574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.8636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.9335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.9630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.7692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.3908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.6291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.5197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.8621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.3854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.6399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.5438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(1.0210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(3.6901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.6839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.5648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.4339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.4874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(1.0522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.7235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.3504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.6055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.5729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.4185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(1.1815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.3397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(1.3001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.4944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(3.2832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.5480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.4078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.5608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(1.3710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.4021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.4340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.2709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.5755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.7026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(1.3991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.3589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.6465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.3856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.5990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(3.2584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.3231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(1.0231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.2340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.2987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.4834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.8765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.2804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(1.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.8069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(1.3139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.6704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.4139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.4035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.5794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.3186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.8885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.3533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.7001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.2728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(1.2123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.7050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(3.4976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.4543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.7276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.5082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.3590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(1.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.9608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.7050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.8004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(1.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.4852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.6184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.2404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.4409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(3.4242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.4014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.6438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.4363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.4514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.3586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.4389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.5632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(1.0646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.6225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.4216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.3655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(3.4936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.6280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.3913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.5758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.9807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.9333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.5761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.4060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.9360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(3.3003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.4872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.5245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.3211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.3411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.4258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.3032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.7642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(1.0667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.3114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.4914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.8432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(1.4215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(1.2045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.4128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.5564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.5678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(1.4651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.8833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.3399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.6999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.2673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(3.7895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.5633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.5226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.3982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.3742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.3523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(1.0398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.8162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.3704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.3067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.4286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.4451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.8865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.3519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(3.3536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.3571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.8738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.6489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.5339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.3853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(1.2044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.9179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.5209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.7126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.8333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.3107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.5733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.7162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.8285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.8804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(3.5195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(1.5306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.1986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.2972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.3554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.5163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.4730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.3394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(1.1651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.4770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.5648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.5012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(1.0679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(3.4625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.3529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(1.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.2853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.8717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.7720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.5826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.7318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.7005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.3924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.4838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.6303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.4765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.3417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(3.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.6293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(1.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(1.0794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.7393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.6151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.4490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.5127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(1.0843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.3846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.7305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.6069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.2761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.3583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.5220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(1.1728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.3783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.2731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(3.6839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.4842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.3460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.6554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.4989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.5138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.4033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.3111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.6625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.6637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.9280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.4605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(1.3000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(1.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.2932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.2714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(1.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.4010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.9337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.4751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.7038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.8821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.3877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.3934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(3.5931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.4739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.6141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.9248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.3688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.4824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.4574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.4581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.3401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.8849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.4704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.7820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(3.3613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.7686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.8845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.3174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(1.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.5654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.6892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.7926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(3.5393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.4329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.8885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.4960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(1.0700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(1.5630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.4746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.6821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.3608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.5256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.4128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.4359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.2296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.4274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.9592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.4424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.6381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.6897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(3.5532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.3170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.7908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.4957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.5609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.6145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.9921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.6611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(1.0240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.3410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.6186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.7300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.5331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(1.2018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.4761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.6556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.7083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.2353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.7274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.8154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.5495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(3.3444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(1.0209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.6916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.8710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.3241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.2413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.4494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.3206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(3.4219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.5980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.4452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.8340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(1.4915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.3586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.4324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.4052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.6058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.4951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(1.1830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.7322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.6920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.5674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.2773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.6928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(1.0129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.5248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.7741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(1.2132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(3.4142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.3608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.6948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.9977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.7409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.3753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.4179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.5586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.8100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.2814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.4477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.6984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.7483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(3.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.4652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.6434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(1.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(1.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.5156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(1.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.4744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(1.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.2860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(1.5639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.2277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.2916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.4715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.6454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.6434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(1.0711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.3099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.4920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.8019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(3.5250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.4673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(1.0042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(1.0606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.3416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.7977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.5564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.5765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.2943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.6550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.6383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.3052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(1.2122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.4139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.6045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(3.4192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.3728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.4485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.6496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.3087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(1.4162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.8281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.8164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(3.3370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.7237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.3077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.2960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.3248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.3496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.5083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.4517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(1.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.8265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.4583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.6422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.4066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.4145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.7884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.3392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.6201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.5760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.4528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.5319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.6176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.5569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(1.0263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(3.5682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.3104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(1.3801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.4053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.5222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(3.1819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.7295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.4334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.2362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.6047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.9715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.5427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.6613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.3280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.6222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(1.4358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(1.3681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.3497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.4855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(1.3378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.4249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.5028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.4369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.3460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.2777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.5467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.9130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.8573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.3708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(3.3749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.9154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.7446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.8932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.4210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.4576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.3783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.4452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.5339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.6651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(3.6858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.4053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.6093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(1.0516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.9092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(1.0191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.4935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.4340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.5741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.5799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.4063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.5733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.2824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.2945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(3.3957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.5322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.7445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(1.2204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.5118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.4978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.8169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.8323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.9530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.4518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.8157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.3991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.3578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.5978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.4487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.3474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.4024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.4314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.5814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.7314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.4182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.5617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(4.0572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.5800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.4262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(2.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.4151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.9518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.9271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.5235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.3156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(1.3762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.5379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.6424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.3971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.6793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(3.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.3505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.3549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.5502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(1.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.4707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(3.3226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.3730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.4636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.5710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.4962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.4224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(1.0272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.4416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.2376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.9363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(1.2665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.4108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.5771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.6290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.8417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.6117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.3313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.5571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.7490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.3864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.9251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.9219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.3647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(3.9167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.7837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.3408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.2923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.4314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.6221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.9741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.8135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.3646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.3862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.5732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.5301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.5564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.4414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(1.0070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.4805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.6273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.3132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.7687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.4216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(1.2477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.3617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.6117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(3.9467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.2116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.6776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.2912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(1.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.7212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.4564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.3951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.4515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(1.0080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.6238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.4384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.2758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.6645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(1.3537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.7089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(3.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.6248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.4232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(2.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.3525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(1.0111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.5328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.4476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.2786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.5533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.7505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.3120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.3207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.8306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.6067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(3.2222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.2983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(3.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.3187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.6273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.8201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.4213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.4633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(1.2445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.3879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.5608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.7466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(1.2335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.6420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(1.1806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.2218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.3531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.3696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.8026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(1.1967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.4406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(1.1735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(3.8471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.5901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.4898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.3969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.4573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.4520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.4861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.2742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.4524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.8311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.3998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.3375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(1.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.9561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.5287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.5486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.3636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.7522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.5875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(1.0462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(3.3979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.7126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.5615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.3212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.6837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.2872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(1.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.4592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.5941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.3894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(1.2613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.5029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.5896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.7213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.5561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.4177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.6339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.2132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(4.0795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.5085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.3424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(1.3487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.4233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.2734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.8250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.8237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.6634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.2727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.4160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.4877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.6590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.5652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.5153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.5823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.5212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(3.9674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.2697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.7002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(1.7539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.3883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.8841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.9255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.4942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.3531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.3730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.2816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.3741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.3158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(3.3353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(1.1842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.5089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.4917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.4910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.6802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.6912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.4111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.8890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.8755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.4359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.4256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.3243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(1.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.4437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(3.2980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.5312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(1.0505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.5736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.3410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(1.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.3364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.2757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.5029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(1.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.4182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.2958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(1.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.4356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.6639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.4583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.9562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.7296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.6147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(3.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.8597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.3086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.5337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(1.0047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.3619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.7487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.5887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.5661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.3474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.3138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(1.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(1.0375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.7701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.5782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(3.2368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.3048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(1.2941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(3.6066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(1.5570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.3099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.4846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.4734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.4505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.6866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.8470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.8159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.4794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.3483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.3176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.4255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.9033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(1.4063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(3.8136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.3084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.4510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.4035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.6655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.4717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.3345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.4301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.3060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.4496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(1.4060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.2402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.3774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.6326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.3514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(1.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.3612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(1.0128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.4327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.3452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.7838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.3291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.4090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.6653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.3601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.8511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.9366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(3.6135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.4147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.5815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.8732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.7880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.5040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.3473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(1.0316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(3.4383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.2129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.3913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.4788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(1.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.9944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.5951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.3261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.4384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.6447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.4575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.6553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.4272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.4175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.5021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.3531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.3827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.5551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.7423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.9176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.5508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.8394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.5123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.3405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(3.3203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(1.7982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.2684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(1.1726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.3827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.5783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.5740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(1.3010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.3936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.5218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.6662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.8587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(3.4862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.3275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.6176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.7245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.3983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.3203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.5366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(1.0032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.3556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(1.4620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.7468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.8588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.6146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.3461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.3194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.7044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.6888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.7624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(3.3379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.3807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.3252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(3.1521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.9422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.3307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.4390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(1.0284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.4387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.7710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.7715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(1.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.4638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.4990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.6793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(1.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.9312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.3505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.4646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(1.0409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.3592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.9774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.9270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(3.2343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.3599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.6179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.3300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.5761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(1.0618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.5839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.5182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.4839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.2853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.5656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.8386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(1.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.5265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(1.2092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.5590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(1.0406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.3904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.3093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(3.7278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.4786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.2958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.3082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.4812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.3781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(1.5748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.2935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.8498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.5613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(3.5362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.8164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.4385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.6454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.8852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.6632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.4835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.5355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.3732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.8140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.2866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.4573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.8107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(3.3774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.9746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.6063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.6204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.4795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.4984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.7029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.4915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(1.0195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.4363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.7467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.6638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.5366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.3086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.2316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.6188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(1.0081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.4282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.7853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.3715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.4091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(1.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.6016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.3006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(3.9369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.4069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.7862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.5207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.7325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(1.0722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.9250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.2465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.3614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.5545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.4921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(1.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.7822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(3.5922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.5317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.4869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.7550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.7643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.9207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.4477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.4722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.8339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.2982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.3603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(1.7700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.3294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(3.4735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.4854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.4169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.5291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.6186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.4694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.4214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.3328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.3318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(1.3041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.7357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(3.3933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.2284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.8566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.6138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.9835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.6596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.7568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.6054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.3223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.6219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.3945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.4488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.5288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.6333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(3.4912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.2681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.4627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(1.2329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.3538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.6014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.8340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.5278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(1.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.5980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.4365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.7166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.2958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.4280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(1.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.2840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.4716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(3.2740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(1.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.8284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.7166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.6774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.5299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.7240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.5076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.5676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.4784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.3950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.6190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.6429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(1.2269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.6273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.5481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.5631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.5736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.2170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.4484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(1.5362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.7265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(3.3395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.1945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.8512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.5416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.3529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.5306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.3141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.5638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.4576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(1.0530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(3.2487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.6776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.7407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.8490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.6911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.6081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(1.0642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.5519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.3108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.6270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.7457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.4986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.4353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.7371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(1.1760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.5614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.3070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(3.2511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.5134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.7219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.2992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(1.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.6643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.9550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.2845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.7515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.2842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(1.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.6746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(1.1702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.4614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.5844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.3600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(1.2343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.5414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.2401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(3.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.4415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.7987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.4711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.3330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.6501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.6860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.5181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(1.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.9130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.5865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(3.2984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.3838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.3438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.3677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.9540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.4579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(1.0578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.5932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(3.2512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(1.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(1.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.4272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.8550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.3810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.6247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.5685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.4449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.4530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(1.0405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.3227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.7558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.4244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.5796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.7130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.4142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.9962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(3.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.7858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.4466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.9271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.5690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.7268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.3658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.2637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.5980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.5846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.9923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.5689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.3963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.8485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.7033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.7575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(3.9402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.6454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.7810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.2777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.5162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.4177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(1.0081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.7935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.4622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.6116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.2737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.7932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(1.0297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.4855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.3639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.2688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.8804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.3282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.3536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.8579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.7565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.9616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(3.3756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.9958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.2260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.6495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.9809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.4504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.7092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.2970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.3764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.4615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.5685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.8228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.2811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.7516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.4947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.4112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.7343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(1.0812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.9244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(3.2137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.7321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(3.3171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.8737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.3326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.5696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.4984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.4722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.9098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.3864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.5226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.8819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.5743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.9259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.6312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.8189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.2868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.4766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(1.0566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.4153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.4190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.3553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(3.1770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.4206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.4054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(1.6195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(1.2318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.3643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.6481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.5801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.5754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.5439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.8565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.2559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.5531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.3582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(1.1713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.9519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(1.0474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(3.4073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(1.1767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.4799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.4217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.3036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.4801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.2766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.5457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.5421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.3390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.4284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(1.2915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.7789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.9315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.3026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.8265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(3.1598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.4521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.4024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.3906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.7210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.6084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.3706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(1.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.3805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(3.3654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.3493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.6574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.4857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.3859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(1.3403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(1.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.6366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.6936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.2919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.5288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(1.4122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.2717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.3346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.3838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.7917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.4158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.4389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(3.4955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.7004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.3302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.6179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.6197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.6792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(1.1155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.4616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(1.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.8210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.6235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.8167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.6544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.3124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.9720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(1.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.6835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(3.7420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.4387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.2851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.4828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.3704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.4681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.7341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.4936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.3271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.2687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.5265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.4459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.4095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.7032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(1.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.2452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(1.2554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.3870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(3.2440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.8939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.9924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.4007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.5641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.8117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.7849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.7160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.9506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.6204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.3940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.9312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.9669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(1.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.3540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.2968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.3950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.5870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(3.4012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.5261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.3130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.2440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(1.3112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(3.3018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(1.0394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.3942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.7880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.4102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.4635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.3425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.8865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.5131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(1.4288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.3164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.4738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.3951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.7095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.9277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.6100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.3517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(3.6583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.7207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.5379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.7767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.3925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.3659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.8949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.4938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(1.1733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.5600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(3.3570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.8338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.4332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.6293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.2841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.8883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.4404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.8603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.4419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.4503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.7192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.2374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(1.0931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.9070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.7340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.3480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.5597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.4252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.5007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.9734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(1.0246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.6750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.3967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(3.3069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.9573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.4847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.4471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.8099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.4302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.2888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.9175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.2738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.8878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.3516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.9271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.5160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.4551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(3.3540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.4615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.4953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.5142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.4209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.3660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.8898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.6947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.6989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(1.2376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.4224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.8127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.4425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.5112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.2752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(1.5371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.3601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(1.1072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.7570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.4117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.5706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.2880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.3758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.3906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(3.9750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.3642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.5260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.4397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.5049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.8524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(1.0654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(3.9887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.3032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.6066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.4041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.3811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.5262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.6517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.6869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.4659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.7753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.4016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.4502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.8601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.3303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.4332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.4461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(3.5220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.4675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.9029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(1.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.3261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.3194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(1.1570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(1.2162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(3.4975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.3812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.3552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.9444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(1.2720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.6439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.2994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.7398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.4623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.3636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.3392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.7181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.5424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.6978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(1.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.7210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.9582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.8242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.7723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.3580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.9587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(3.4409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.3524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(1.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.5591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.6739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.7800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.7928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.5686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.7057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.6133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.2845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.4962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(1.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.3281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.6379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(1.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.3547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(1.0107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(3.1623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.4823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.6379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.3139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.7032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.4291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.7288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(1.4909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.4518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.7665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.4312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.4327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.9625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.4956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.4093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(3.1353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.9598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.6132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.2159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.2466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.9575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(1.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.5873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(1.2289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.6925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.2004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.5440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(3.4889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.3958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.9659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.2669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.7028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.4604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.4087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(1.0680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(1.0854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.3577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.8003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.4703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.5507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(3.6176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.9748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.5216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.3388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(1.3256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.3369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.4951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.7100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.5492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(1.5046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(3.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.8502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.4538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.2282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.3340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.7460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.6201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.6274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.5242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.6278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.6790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.6282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.4392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.7633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(1.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.3124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.8330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.3514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.6350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.4246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.6704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(3.7419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.4008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.4847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.5705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.7131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.4407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.3309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.9111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.5274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.9085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.4602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(1.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(3.4010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.8252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.3422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.2677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.5620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.9475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.7596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.5649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.2167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(1.3036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(3.4878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.4818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.3806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.5389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.6300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.2640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(1.1728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.7819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.9437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.4282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.3952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.4964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.7399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.2742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(1.1577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.6251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.9248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(1.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.5696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.5560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.2634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(3.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.9611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.4200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.6277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.7866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.4161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.7884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.7596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.3947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.9286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.5185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.8891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.9649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.5237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(3.1648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.4611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.3785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.4620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.8217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.4044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.7657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.3251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.3698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.4174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.3756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.7621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.6015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.3276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(1.2776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.9075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.6303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.5125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.2626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.8887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.2928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.7940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(3.8201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.6240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.5414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.6224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.4941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.4298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.5014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(1.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.3554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.6750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.4640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(1.2876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(3.1770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.8427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.9618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(1.0287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.6053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.4536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.3800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.7819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.5799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.7892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.2320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(4.1835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.8069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.5164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.4411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.3124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.4748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.7612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.4679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.7809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(3.3780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.7679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.4855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.9441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.3918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.5872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.9389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.5092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.9435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(1.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.3132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.3614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.5796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(1.0647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.4218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.3174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.5924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.4953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(3.3537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.3423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(1.3259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.5146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.4714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.4186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.3449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.5365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.6261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(1.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.7148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.8703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.2716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.3797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.3380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.2304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(3.4081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.7034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.5364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(1.3028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.6496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.5399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.8053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.3848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.8761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.6209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.4413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.5732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.3608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.2778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.6508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.7116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.3514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.7610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.7414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(1.0648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.3943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.3162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(4.3118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.6209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.4971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.7486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.9347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.4916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.2977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.3421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.6318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(3.6179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.7451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.2626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.8222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.3375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.8863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(1.0685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.2462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.5948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.4951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.3869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.5710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(1.0169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.8889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.3682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(3.2762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.5442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.3785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.5463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.3211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.7899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.2402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.6327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(1.6097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.4432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.3094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.3674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.2189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.3990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.6322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(3.6255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.4476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(1.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.5734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.9065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.6032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.8894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.3191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.4240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.8149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.8176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.5968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.5297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(3.2861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.8193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.7180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.3423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.3177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(1.5522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.5710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.3406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.5652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.4321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.7651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.5135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.8778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.3157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.3507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.4278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.9907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.6273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.3782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.5103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(3.3998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.6183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.3983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.4511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.8093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.6012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.9087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.2698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.7045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(1.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.4692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.6318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(4.0188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.4469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.7525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.9810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(1.3394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.4377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.3211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.5142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.3672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.7506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.5688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.3751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.5592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.7405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(1.0313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.2945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.7004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(1.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.3084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(3.3788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(1.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.1796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.3877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.5259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.9779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.5077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.4258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.3622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.3883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.3753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.7911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.4321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.8779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.9817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(1.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.2747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.3234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(4.0118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.4322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.3318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.6736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.4632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.6445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.6097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.6004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.5973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.2821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(3.2283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.3819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.6890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.5735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.4652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.6303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.9196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.3455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.6314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(1.4009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.9077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.8635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(3.4288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.4713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(1.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.2797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.2831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.5862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.2966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.6640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.3734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(1.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.8397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(1.2243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.2811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.2172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.4526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.5240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.8267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.4316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(1.1871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.5777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.4157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.5035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(1.4024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(1.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.3594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(3.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.3569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.3563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.6279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.5274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.3032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(3.6040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.5127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.6658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.6625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.9609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.3700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(1.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.3853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.5359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.8856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.8882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.4420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.3053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.7075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.5258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(1.5170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.2598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.9603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.2013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.5842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.4303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(3.3276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.5888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.3956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.7997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.5810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.7950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.2672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.9587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(3.7360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.6840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.6184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.3320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.5138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.7232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.8367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.4171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.6243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.2951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.3001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.9025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.5364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.7854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.6665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.5254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.4532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.4702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.5953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.6539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.9081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(1.0128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(3.4062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.4427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.7395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.6123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.7013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.7018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.7579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.3013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.5610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(1.6956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.2751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.6053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.4399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.6304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.3883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(3.3460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.2855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(1.2260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.5853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.9518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.3521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.2730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.4845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.4463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.5296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.3012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.5672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.3832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.3163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.6213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(1.3409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.2083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.5259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.5897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.6503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(3.7026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(1.0572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.4334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.9538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.6104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.2977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.3629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.5926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.5031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.5278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.5714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.5768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.8421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(3.2359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.3922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.6047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(1.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.5364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(1.0235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.9018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.3685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.3414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.7778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.4116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.3724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.3328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.3598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(1.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.4090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.7290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.3989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.3661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.5827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.7989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.5316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(3.8667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(1.0616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.3219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.5133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.5820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.4497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.7139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.3481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.9768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(1.4457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.3725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.8359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(3.1492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.5877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.2657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(1.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.4787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.3051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.4099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.4976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.4420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.2778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.6829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.4214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.3189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.5575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.7738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.4704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.6024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.9845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(1.6931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(3.8176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.2348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(1.2841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.4368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.3563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(1.2355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(3.3724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.3039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.4346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.6939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.6349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.3814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.9783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.4692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.3568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.4767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.2938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.7729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.4374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(1.6201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.4848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.8229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.5757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(3.4170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.8317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.6663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(1.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.6646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.6822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.4791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.2742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.6332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(1.0058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.3885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.4197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.3976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(1.1544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.4419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.4405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.4507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.6037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(1.4488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.5063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.2657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(3.5811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(1.5386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.6694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.4152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.4093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(1.2775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(3.2616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.5540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.6610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.7091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.2914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.3560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.8746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.4130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.7493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.2906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.6257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.8633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(1.6327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(3.3187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.6950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.3491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.4624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.7423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.3467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.6391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.3032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.5990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.6595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.8922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.9090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.2467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.3636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.5987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.4454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.7462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(3.3897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.7559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.3851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.4013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.4358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.7390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.3964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(1.4049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.7669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Loss: tensor(0.5997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.8693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.7819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.6607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.2984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.4794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.2957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.8323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.5012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(1.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.4198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.6995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.7712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(3.5955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.4362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Loss: tensor(0.4953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.7819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.4545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.6187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.7434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.4571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.2662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.4654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.8035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.5847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(1.8214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.4022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(3.2810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Loss: tensor(1.0594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(1.0326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.9978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.5944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.3045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.4919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(1.2560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.7503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.3978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.4622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(3.6770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.6739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.4405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.4792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.2163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Loss: tensor(0.4563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.7399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.5584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.6864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.7161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(3.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.9130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.5027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.3378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.3588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.7442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.3713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(0.4335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(1.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Loss: tensor(1.3095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.5276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.7762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.6316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.9810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.3546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.3251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(1.4768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.3397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.2886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.3288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(3.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.3880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.9230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.6245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.7899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Loss: tensor(0.5329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.6448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.2752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.9935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.5316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(3.3658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(1.2245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.5923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.4739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.4434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.8666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.6282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.8135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.3277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.6308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.3414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Loss: tensor(0.3384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.3400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.8650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.2637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.2910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(1.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.8958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.4653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.3098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(3.2869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(1.0225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.7224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.4822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.5321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.5184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(1.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Loss: tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.5429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.5542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.5408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.5382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.7655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(1.3154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.5957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.8167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.3835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.4029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.4268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.4219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(1.0026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(3.0944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.3805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Loss: tensor(0.7058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.4743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.3667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.8915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.1980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.3722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.5897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.5247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.5485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(1.6652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.5406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.7150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.5584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.4512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.3685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(0.2530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Loss: tensor(3.9654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.2166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(1.1749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.5155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.5441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.7640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.5575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.5676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.4520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(3.4717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.3955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.4187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.4092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.3285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(0.5406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(1.0592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Loss: tensor(1.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.5334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.5860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.6241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.5370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(1.2327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.5745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.3384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.9478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.5132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.2665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.3595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(3.8056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(0.4475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Loss: tensor(1.2231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.5616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.9000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.6143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.8999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.3539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.4809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.3730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(1.0684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.6978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.6309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.4841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(3.4798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.3830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Loss: tensor(1.0665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.3591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.3738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(1.0329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.5504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.3214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.9362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.8134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.8114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(3.6443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.7213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.3461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.3065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.5507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.3719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.5925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 414 Loss: tensor(0.7451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(1.2318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.7980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.3184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.4528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.3957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(1.3528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(3.2997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.6194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.3181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.4793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.5826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.4119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(1.0271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 415 Loss: tensor(0.3631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.3057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.8153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.4254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(1.2011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(1.0928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.5016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.2825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.5482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.4386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.6614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.9429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.5164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.4418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(3.3173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.6633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 416 Loss: tensor(0.3132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(1.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.6071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.3634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(3.3543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.9414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.7483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.8394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.4199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.3771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.3734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.6492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.9991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.5083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.5227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 417 Loss: tensor(0.4170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.3599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.2949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(1.2093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.4774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.4951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.4154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.7177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.2109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.3452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.7048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.4719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.3977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(1.4295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.6162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(0.3804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 418 Loss: tensor(3.9485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.3953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.3149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.7395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(3.4762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.8303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.3889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.5978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.5387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.7869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.5073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.3917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.6567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(1.0377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.8224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.5251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 419 Loss: tensor(0.4614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.6477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.6762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(1.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(1.0536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.5173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.7177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.4411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.5509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.8730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.5951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.5687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(3.4699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.5086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 420 Loss: tensor(0.2985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.2984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(1.5202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.7427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.3304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(3.4553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.4220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.6498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(1.0204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.3698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.4062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.4638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.7531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.4517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.4583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.4632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 421 Loss: tensor(0.6821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.2789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.4352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.3430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.8207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.5574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.3215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(1.3196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.7477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.3597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.8476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.5546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.3738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.8236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(3.5250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.7208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 422 Loss: tensor(0.4353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(1.0327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.9121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.4657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(1.0346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.4355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.8868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.4308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.5145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.3996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.4236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.5975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.6888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.6852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.3930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(0.4359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 423 Loss: tensor(3.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.9425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(1.2714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.7699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.5076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.5464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.1813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.3644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(3.1925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.5774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.4235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.4823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.5258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.6595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.4016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(0.4216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 424 Loss: tensor(1.1980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.5266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.5300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.3622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.5115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(1.4319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.4167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.2675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.3731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(1.0239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.3864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.6780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.4213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(1.2824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(3.1596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.4558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 425 Loss: tensor(0.6308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.4030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.4967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.5402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(3.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.4697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(1.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.5463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.3073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.1851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(1.3251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.4031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.8760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.5633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.7188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(0.2732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 426 Loss: tensor(1.0588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.3886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.9732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.4846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.7422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.4768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.4593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(3.3548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.4312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.6281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.6111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.5091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.2439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(1.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.9181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.4309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 427 Loss: tensor(0.6858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.4457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.9240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.3709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.3275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.6054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.2856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(3.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.5778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(1.4235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.5301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.7446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(1.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.4624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.7454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 428 Loss: tensor(0.4549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.8159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.3847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.9431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.4380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.5159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.6132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.8551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.3338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.9972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.9612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.4119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.4228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.3013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(0.9898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 429 Loss: tensor(3.3299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(3.7369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.8607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.5565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.5385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.5185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.3893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.8946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.3863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.3086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.7727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.8318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.9552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.2669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.4461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.7776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 430 Loss: tensor(0.2189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.3998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.3739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.6594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.7198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.9629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(1.2882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(3.3676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.2688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.3631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.2485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.7243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.6506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.5334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(1.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 431 Loss: tensor(0.3801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.4483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.7900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(1.0311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.5447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(4.1173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.5712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.3413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.5982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.8911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.5289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(1.0631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.5229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.2667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 432 Loss: tensor(0.2450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.3736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.5080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.4222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.6479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.8721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(1.0461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.5982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.8230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.9262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.3868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.4944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.7498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.2976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.3506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(3.6094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 433 Loss: tensor(0.3445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.3029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.7203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.2979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.3817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.5165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.4684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.2789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(1.2128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.4431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.7927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(1.0654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(1.2534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.5709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(3.0904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.4627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 434 Loss: tensor(0.5909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.7760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.6147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.3759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.4688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.3083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.7198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.5781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.4879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(3.8058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.9886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.8220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.7196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.5145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.4877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 435 Loss: tensor(0.5356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.4269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.8376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.7119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.3957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.5386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(3.3023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.5078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.5064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.9524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.5303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.6317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.6802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.4868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.5973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.4155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 436 Loss: tensor(0.9206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.5682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.5784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.3732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.4540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.6175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.4066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.4752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.3551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.8568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.6412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(1.4122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(0.4737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(1.3328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 437 Loss: tensor(3.3057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.4208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.2778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.3708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(1.4573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.2994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(1.2221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.4313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.8461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.2971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.4417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.3912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.4671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.4960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(3.8640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 438 Loss: tensor(0.9715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.4913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.3416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.3839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.3743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.3261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.7391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.9212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.3901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(1.2476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.7937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(3.4399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.6419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(1.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 439 Loss: tensor(0.5170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.4772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.5954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.9003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(1.6164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.2778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.3270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.6562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.3150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(4.0422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.9129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.4384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.5181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.3301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.6178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 440 Loss: tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.5733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(1.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.7407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.7004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.5145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.3746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.6772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.6407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.3520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.3840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(1.0172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(3.4076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.4576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 441 Loss: tensor(0.7674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.6622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.7046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(3.3944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.4800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.7161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.8733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.5968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.5518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.6405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.2366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.6615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(1.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.3765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.4073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 442 Loss: tensor(0.8209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.3111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(1.2057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(1.4047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.7112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.2327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.4372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(3.4815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.5621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.3239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.4650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.5502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.9196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.5587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.2287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.6187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 443 Loss: tensor(0.4362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.9363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.7822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.7432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.4929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.5322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(3.3625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.8055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.3814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.2851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.4135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.5876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.3533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.3593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.8809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(1.0504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 444 Loss: tensor(0.4873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(3.3888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.3778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.4364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.3281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(1.0792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.4474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.2648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(1.2474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.3777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.6585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.2678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.5545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.7262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(0.4676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 445 Loss: tensor(1.5557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.6765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(1.0564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.6368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.7044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.6630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.3292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(3.5618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.9465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.9071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.6223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.2222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.5764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.5701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 446 Loss: tensor(0.4259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.4422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(3.5267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.3598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.5781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.3969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.6062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.5665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.3902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.5916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(1.7461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.3288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.6524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.8340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.5636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 447 Loss: tensor(0.5960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.6878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.4835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(1.1978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.6405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.9436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.3580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.5501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.9059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.4962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.5841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.4383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.4180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.3520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(3.2694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.3503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 448 Loss: tensor(0.7687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(1.0569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.5634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.9174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.2353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(4.2325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.3804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.3111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.8953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.3537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.4886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(1.0271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.1907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.4547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 449 Loss: tensor(0.6629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.4488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.5283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.4687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.3345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.4483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(3.5373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(1.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.5475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.5727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.8655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(1.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.6262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.3252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.1804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.5594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 450 Loss: tensor(0.8305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.9386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(1.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.3712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.4074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.3903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.4290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(3.8389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.3260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.3686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.2939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.5141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(1.2416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.2809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(0.4141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 451 Loss: tensor(1.2334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.4531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.9097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(1.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.2289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.3810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(3.2785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.9795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.6006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(1.4571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.6435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.5836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.3306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.5317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.5417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 452 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.2693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.2818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.4029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.6592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.4110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.3143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.8417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.7630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(1.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(3.8341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.8381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.5471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.8078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.7365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 453 Loss: tensor(0.3424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.5602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.6423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(1.3953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(1.1573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.4437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.3241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.3244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(4.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.4869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.4105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.3523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.4872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.8074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.3716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 454 Loss: tensor(0.4019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.3159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.7277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(3.5971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.4959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.8491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.5930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(1.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.8909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.4515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.8767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.3519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.7127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.5236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 455 Loss: tensor(0.3751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.3090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.5127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(3.9349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.3812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.5383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.6956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.7899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.6265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.4228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.3044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.6953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.5215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.4104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.4571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(1.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 456 Loss: tensor(0.7009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.5279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.4334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.5727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.4354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(3.4435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.5010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.6482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.3943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.4813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(1.1822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.2996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(1.8880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.5419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.5022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 457 Loss: tensor(0.2890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.9217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.1905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(1.0399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.4897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.7945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.9866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.2808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.5706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.5711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.8977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.8311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.3514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(3.3999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 458 Loss: tensor(0.5095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.2806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.6977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.1993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(3.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.9818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.3607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(1.2587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(1.3858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.3138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.3976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.9783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.5705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.3448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.3197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.4963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 459 Loss: tensor(0.6154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(1.0728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.4647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.3534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.3793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.5786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.3714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(1.5711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.4845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(3.2985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.9546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.7678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.7802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.4159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 460 Loss: tensor(0.4536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.6479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.8337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.4304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(1.2530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(3.4450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.9158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.2831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.3521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.3765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.3331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(1.0048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.8580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.5629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.3814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 461 Loss: tensor(0.5371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(1.1747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.4503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(1.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.4354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.6426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.4913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.3991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.6291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.5020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(1.0898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.7923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(3.4772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.4556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 462 Loss: tensor(0.3079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.3818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.9851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.3856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.4850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.4587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.7241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(3.1794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.5032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(1.2293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(1.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.4946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.4499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.5060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.9590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 463 Loss: tensor(0.3349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.4260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.3176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(3.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.7911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.4332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(1.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.4689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.8660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.5276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.3832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.7988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.3128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.9523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.5777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 464 Loss: tensor(0.7980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.4075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.8078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.7198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.9802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.7083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.2248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.3180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(1.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.3491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.3746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(3.3332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.3888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.5011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(0.4815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 465 Loss: tensor(1.4304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.2705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.9035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.5565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.6533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.6664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.4528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(3.2266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.9039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(1.0521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.4655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.5031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.6010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.4691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.5663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.2884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 466 Loss: tensor(0.8473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.8998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.5114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(1.2040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.3610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(3.9740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.4075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.8276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.6864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.2340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.4362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.6184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.8349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.3205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.4533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 467 Loss: tensor(0.4068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.3438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.5834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(3.4298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.3541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.3825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(1.1713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.7928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.6379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.3180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.4864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.6753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.9988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(1.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.4024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.4510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 468 Loss: tensor(0.2872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.4233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(1.0578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.2720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.4195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(1.2641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(3.2231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.5390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.2805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.6626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.4272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.6849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.4453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.4872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(1.2525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.4384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 469 Loss: tensor(0.5422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.9852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.2149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.9820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.4479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.5704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(3.3472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.3709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.3527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.3860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.5006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.7931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(1.2462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.6811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.6829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.5561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 470 Loss: tensor(0.3042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.2855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.4904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.4195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.6180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.2746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(1.0276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.3104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.5745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.5628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.7238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.4278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.7472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(1.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.4128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(0.7840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 471 Loss: tensor(3.4937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(1.1716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.4676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(3.2485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.2554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.8996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.5483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.4881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.6304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.8570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.7602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.4104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(1.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.5776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.3964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.3044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 472 Loss: tensor(0.2703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.4526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.3225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.5087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.8538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.2720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(1.0403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.2256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.5231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(1.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.5710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.7954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.4139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(1.3323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.1768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(3.5093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 473 Loss: tensor(0.3662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.3625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.8607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.6739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.4515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.4038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(1.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(3.2561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.6226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.4481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.4788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.5625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(1.3061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.8025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 474 Loss: tensor(0.4888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.5854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(3.7646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(1.1728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.3616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(1.2882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.8430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.4552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.3709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.3783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.6174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.4504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.4605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.8962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 475 Loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.4210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.5670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.4123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.5213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.5199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(1.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(3.8357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.5231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.8540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.4502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.7405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.4631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.3313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(0.4389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 476 Loss: tensor(1.0085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.4326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.2706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.5776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.4809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.6599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.5948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.3687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.5896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.8000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.7938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.3568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(1.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(3.7208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.4835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.5759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 477 Loss: tensor(0.5725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.4080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.4149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.8329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(1.2285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.3920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.1648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.5870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.7833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.5831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.2353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.4647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.5460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(3.3444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(1.4966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.6411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 478 Loss: tensor(0.2915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.5116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.4723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.3944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.4355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(1.2091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.2640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(3.3576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(1.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.9672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.9046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.2762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.6722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(1.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 479 Loss: tensor(0.3315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.3191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.5847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.9174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.8447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.2396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.4482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(1.0644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.3155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.4886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(1.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.5691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(3.3290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.8206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.4887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.2961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 480 Loss: tensor(0.6036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.3314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.6777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.5507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.9838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.3041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(3.4947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.3402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(1.2246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.8909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.8612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.4067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(1.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 481 Loss: tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.4408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.8054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.3253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.2771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.4010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.3848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(1.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.6529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(1.2642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.7164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.4342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.7685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.5644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(3.3693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 482 Loss: tensor(0.6332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(1.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.4480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.2029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.4408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.7764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.4805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.6538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.3079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(1.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(3.5318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(1.1318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.4893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.4801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 483 Loss: tensor(0.3592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.5532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.3536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.6973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.4281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.4001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.4731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.7989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.3214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(3.2990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(1.2036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.4778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(1.2683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 484 Loss: tensor(1.4810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.7859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(3.4354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.3763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.3582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.4595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.4756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.4069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.5855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.3610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.8779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.3718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(1.8046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(1.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 485 Loss: tensor(0.6981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(3.5032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.3362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(1.0635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(1.0614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.5187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.3798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.4436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.2751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.5329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.7171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(1.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.4048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.2237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.9713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.3001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 486 Loss: tensor(0.5196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.9831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.4393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.4795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.2200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.5253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.3155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.4274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.6069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(1.0979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.7098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.4322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.6340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(3.4244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.5213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(1.2790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 487 Loss: tensor(0.3101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.7302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.4240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.2094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.5713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.9488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.6130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.8304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.9104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.6267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.4551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.4018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.5815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.9127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(3.1895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 488 Loss: tensor(0.7487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.8938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.3205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.9771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(3.4070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.3308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.5982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.6433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.7695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.3095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.2887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.2986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.5614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.4386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.6459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(0.6176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 489 Loss: tensor(1.3114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.2693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.3929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.5860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(1.2608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(1.0491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.5705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.5786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.2300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.4706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(3.4083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.7117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.3906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.3054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.7792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.8952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 490 Loss: tensor(0.5092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.3976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.2898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(3.3407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.9101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.6876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.3379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.5268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(1.0950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.3516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.4177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.6013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(1.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.7737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.7230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.4465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 491 Loss: tensor(0.5239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(3.2123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.3995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(1.2266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.3339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.7433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.3854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.5638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.3225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.7820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.2685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.8638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.9003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.6871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.9360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.4415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 492 Loss: tensor(0.3505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.9709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(1.1625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.4975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.4599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.7042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(1.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.6073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.3275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.5843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.3321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.4157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.3367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.4830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.8091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(0.4005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 493 Loss: tensor(3.2311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.2774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(4.1509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(1.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.7150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.4047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.5328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.4369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.5663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.3989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.3092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.5278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.7121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.4105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.4425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 494 Loss: tensor(0.9006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.9784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.6645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.4974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.3665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.6094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.2937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.3045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.4008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.4380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.5339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(1.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.6283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.9779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(0.8075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 495 Loss: tensor(3.5178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.5621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.5132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(3.6461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.9717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.8515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.3447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.1648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(1.0054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.4374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.4251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.5405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.4217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.9308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.8922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.3390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 496 Loss: tensor(0.3510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(1.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.4844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.7524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.3582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.7156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.3812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(3.3202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.4727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.7277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.5269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.7469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.5525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.2698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(0.3789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 497 Loss: tensor(1.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.9784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.2625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.3927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.6161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.4827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.4496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.6668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(1.0288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.6664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(3.4079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.5074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(1.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(0.2251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 498 Loss: tensor(1.1704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.6111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.4550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.6147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.4095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.7585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.5618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(3.1111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.6538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.4156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.7656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(1.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.5433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.7987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.4080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.7415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 499 Loss: tensor(0.4237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.7904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.5093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.5120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.5770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.9098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.3215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(3.3583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.7558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.3401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.3107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.7220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(1.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(0.5779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 500 Loss: tensor(1.1693, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "epoch_num = 500\n",
    "batch_size = 8\n",
    "lr = 0.01\n",
    "gamma = 0.5\n",
    "\n",
    "minimum_loss = float('inf')\n",
    "loss_track = []\n",
    "\n",
    "# Load training data\n",
    "trainset = DataFromH5File5(\"/home/pz281@ad.eng.cam.ac.uk/mnt/PhD/Pro_Down_SR/data/DownBy4_31_121.h5\",N_low,N_high,scale)\n",
    "train_loader = data.DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialise training model\n",
    "G = ResidualLearning()\n",
    "G.apply(weights_init_xavier).to(device)\n",
    "mse = nn.MSELoss(reduction='sum')\n",
    "optG = torch.optim.Adam(G.parameters(), lr = lr, weight_decay=0, betas=(0.5, 0.999))\n",
    "r_scheduleG = torch.optim.lr_scheduler.StepLR(optG, step_size=100, gamma=gamma)\n",
    "\n",
    "# Logger info\n",
    "dir_name = f'models/train_NN/31_121/lr{lr}_gamma{gamma}'\n",
    "makedir(dir_name)\n",
    "logger = setup_logging('job0', dir_name, console=True)\n",
    "logger.info(f'Training for {epoch_num} epoches and learning rate is {lr}')\n",
    "\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    \n",
    "    for i, d in enumerate(train_loader, 0):\n",
    "        \n",
    "        residual, high_res, low_res = d\n",
    "        size = residual.shape[0]\n",
    "        low_res = low_res.to(device).reshape(size,1,N_low,N_low)\n",
    "        high_res = high_res.to(device).reshape(size,1,N_high,N_high)\n",
    "        \n",
    "        downscaled = F.interpolate(high_res.reshape(size,1,N_high,N_high),(N_low,N_low))\n",
    "        \n",
    "        optG.zero_grad()\n",
    "        out = downscaled + G(downscaled)\n",
    "        loss = mse(low_res,out)/batch_size\n",
    "        loss.backward()\n",
    "        optG.step()\n",
    "        \n",
    "        if loss < minimum_loss:\n",
    "            save_model(dir_name, epoch, 'best_model', r_scheduleG, G, optG)\n",
    "            minimum_loss = loss\n",
    "            \n",
    "        if epoch%100 == 0:\n",
    "            save_model(dir_name, epoch, 'model_epoch_{}'.format(epoch), r_scheduleG, G, optG)\n",
    "            \n",
    "        loss_track.append(loss.cpu().data.numpy())\n",
    "        np.save(f'{dir_name}/chains/loss_curve.npy', np.array(loss_track))\n",
    "        \n",
    "        print(\"Epoch:\", epoch, \"Loss:\", loss)\n",
    "\n",
    "    r_scheduleG.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_low = 31\n",
    "N_high = 121\n",
    "scale = 4\n",
    "a, b, c = 8,3,5\n",
    "\n",
    "h_low = 1/(N_low-1)\n",
    "x_low = np.arange(0,1.0001,h_low)\n",
    "y_low = np.arange(0,1.0001,h_low)\n",
    "\n",
    "h_high = 1/(N_high-1)\n",
    "x_high = np.arange(0,1.0001,h_high)\n",
    "y_high = np.arange(0,1.0001,h_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_low, r_low, A_low, x_low, y_low = generate_data(N_low,a,b,c)\n",
    "w_high, r_high, A_high, x_high, y_high = generate_data(N_high,a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = ResidualLearning().to(device)\n",
    "G.load_state_dict(torch.load('models/train_NN/31_121/lr0.01_gamma0.5/ckpt/best_model.pth')['netG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_high_tensor = torch.tensor(w_high).to(torch.float32).to(device)\n",
    "w_low_tensor = torch.tensor(w_low).to(torch.float32).to(device)\n",
    "downscaled = F.interpolate(w_high_tensor.reshape(1,1,N_high,N_high),(N_low,N_low)).reshape(N_low,N_low)\n",
    "out = G(downscaled.reshape(1,N_low,N_low))\n",
    "residual = w_low_tensor-downscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(9,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.pcolormesh(x_low, y_low, residual.cpu().data.numpy(), cmap='rainbow')\n",
    "cbar = plt.colorbar(pad=0.05, aspect=10)\n",
    "#cbar.mappable.set_clim(-0.03, 0.03)\n",
    "plt.title('LR')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(1,2,2)\n",
    "plt.pcolormesh(x_low, y_low, out.cpu().data.numpy()[0], cmap='rainbow')\n",
    "cbar = plt.colorbar(pad=0.05, aspect=10)\n",
    "#cbar.mappable.set_clim(-0.03, 0.03)\n",
    "plt.title('LR')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upscale by 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_low = 31\n",
    "N_high = 121\n",
    "scale = 4\n",
    "a,b,c = 8,5,5\n",
    "\n",
    "h_low = 1/(N_low-1)\n",
    "x_low = np.arange(0,1.0001,h_low)\n",
    "y_low = np.arange(0,1.0001,h_low)\n",
    "\n",
    "h_high = 1/(N_high-1)\n",
    "x_high = np.arange(0,1.0001,h_high)\n",
    "y_high = np.arange(0,1.0001,h_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_low, r_low, A_low, x_low, y_low = generate_data(N_low,a,b,c)\n",
    "w_high, r_high, A_high, x_high, y_high = generate_data(N_high,a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Parameters for prior variance\n",
    "prior_sigma = 0.002\n",
    "ll_sigma = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.eye(N_high**2) * prior_sigma**2\n",
    "G_inverse = np.eye(N_high**2) * (1/prior_sigma**2)\n",
    "\n",
    "# Turn matrices to tensors\n",
    "G = torch.tensor(G).to(torch.float32).to(device)\n",
    "G_inverse = torch.tensor(G_inverse).to(torch.float32).to(device)\n",
    "A_high = torch.tensor(create_A(N_high)).to(torch.float32).to(device)\n",
    "b_high = torch.tensor(create_forcing_term(N_high,a,b,c)).to(torch.float32).to(device)\n",
    "\n",
    "# Store sparse matrices as sparse tensor\n",
    "A_high = A_high.to_sparse()\n",
    "G = G.to_sparse()\n",
    "G_inverse = G_inverse.to_sparse()\n",
    "operator = torch.spmm(A_high.T,G_inverse).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(w_low).to(torch.float32).to(device)\n",
    "posterior_initial = torch.randn(*[N_high,N_high]).to(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = ResidualLearning().to(device)\n",
    "# G.load_state_dict(torch.load('models/train_NN/model3/31_121/lr0.01_gamma0.1/ckpt/best_model.pth')['netG'])\n",
    "G.load_state_dict(torch.load('models/train_NN/model3/31_121/lr0.01_gamma0.5/ckpt/best_model.pth')['netG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Langevin dynamics\n",
    "K = 1000\n",
    "s = 0.0004\n",
    "\n",
    "z = posterior_initial\n",
    "chains_evolution = []\n",
    "z = z.clone().detach().requires_grad_(True)\n",
    "for i in range(K):\n",
    "    # Grad log-likelihood\n",
    "    downscaled = F.interpolate(z.reshape(1,1,N_high,N_high),(N_low,N_low)).reshape(N_low,N_low)\n",
    "    x_hat = downscaled + G(x.reshape(1,N_low,N_low)).reshape(N_low,N_low)\n",
    "    log_likelihood = (-1/(2*math.pow(ll_sigma, 2)) * torch.matmul((x-x_hat).reshape(1,N_low**2),(x-x_hat).reshape(N_low**2,1)))\n",
    "    grad_ll = torch.autograd.grad(log_likelihood, z)[0]\n",
    "    # grad_log_likelihood = torch.matmul(G,grad_ll.reshape(N_high**2,1)).reshape(N_high,N_high)\n",
    "    \n",
    "    # Grad prior\n",
    "    difference = torch.spmm(A_high,z.reshape(N_high*N_high,1)) - b_high.reshape(N_high**2,1)\n",
    "    # log_prior = - 0.5 * difference.T @ G_inverse @ difference\n",
    "    # grad_log_prior = torch.autograd.grad(log_prior, z)[0]\n",
    "    grad_log_prior = (- torch.spmm(operator,difference)).reshape(N_high,N_high)\n",
    "    \n",
    "    # Random noise term\n",
    "    W = torch.randn(*[N_high,N_high]).to(device)\n",
    "    # random = torch.matmul(G_sqrt,W.reshape(N_high**2,1)).reshape(N_high,N_high)\n",
    "    \n",
    "    z = z + 0.5 * s ** 2 * grad_log_prior + 0.5 * s ** 2 * grad_ll + s * W\n",
    "    # chains_evolution.append(z.cpu().data.numpy())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "X, Y = np.meshgrid(x_high, y_high)\n",
    "ax1.plot_wireframe(X, Y, z.cpu().data.numpy(),color='r')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_zlabel('w')\n",
    "ax1.set_title('SR')\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "X, Y = np.meshgrid(x_high,y_high)\n",
    "ax2.plot_wireframe(X, Y, w_high,color='r')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_zlabel('w')\n",
    "ax2.set_title('high-res')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR L2 Error: 0.004840465050151941\n"
     ]
    }
   ],
   "source": [
    "error1 = abs(w_high - z.cpu().data.numpy())\n",
    "print('SR L2 Error:', (error1**2).sum()/error1.shape[0]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Training $u_l = Hu_h + G(u_l)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code downscaling matrix\n",
    "N_low = 31\n",
    "N_high = 121\n",
    "scale = 4\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory already exists\n",
      "2024-06-04 16:10:08,075 : Training for 400 epoches and learning rate is 0.01\n",
      "Epoch: 1 Loss: tensor(53.6763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(4.2408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(1.5791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(105.5328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(4.3576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(6.4123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(7.0294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(2.3801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(2.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(1.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.9896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(2.0046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.5024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.8590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.8154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.5209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.6293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.7786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.8663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(1.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.8801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.6494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.5338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.3467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(1.1640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.3564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.4613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(3.6720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.8403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(1.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Loss: tensor(2.2160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(1.5952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.6397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.7731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.4244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(1.4969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.4304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.4794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.4156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(1.1851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(1.2434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.6394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(3.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.4462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.9690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.4051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.3782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(3.9020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.6433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.4374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.4104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(4.9488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.3941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.4618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.4133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.6050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.2168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.7638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.6424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.2923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.3351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(2.6258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.3671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.3342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.5875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.3492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.6465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.2046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.2039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.4617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.3760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.2022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.8741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.1676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(2.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.2327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.2199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.3080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Loss: tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.2321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.2936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.5859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.2023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.3981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.4670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(1.7011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.4764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.3340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(1.4856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.2937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.3453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.4625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.3959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(1.2317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.3014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.4118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Loss: tensor(0.4874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(1.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.2290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.2123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.2274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.3082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.2853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.2155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.3211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.2075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(1.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.4229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.4098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.7253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.2363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.6116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.2440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.2044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Loss: tensor(0.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.2104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.9244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.5161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.2160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.2794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.2277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.2011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.2363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.1847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.2727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Loss: tensor(1.0105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(2.2766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.1992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(1.0093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.6927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.3438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.2052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.3132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.1951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Loss: tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.2044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(1.4767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.4600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.5895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.7094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.2677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.2984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.1927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.3002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.2256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.1911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.3093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.1677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.1672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(1.0468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.2160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Loss: tensor(0.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.3333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.3403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.2119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.4143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.7685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.2608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.1759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.7949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.1843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.2570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.2218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.2013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.2749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.2781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Loss: tensor(0.7463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.4285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.2086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.1576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.1405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.2332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.3142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.1996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(1.4191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.1745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.7099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.2412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Loss: tensor(0.3144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.1111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.2038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.1972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.2811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.9408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.2999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.4743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Loss: tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.3041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.2677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.1651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.7586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.2391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.3969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.1551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.1597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.1823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.2676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.2098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.6204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.1974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Loss: tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.2114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.4562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.3184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Loss: tensor(0.3868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.1782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.1516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.0702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.0646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.5806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.5151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.4442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Loss: tensor(0.6088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.4023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.2887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.2487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.2176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.1522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.4949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.1906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.2702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.1659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.1623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.4801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Loss: tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.3734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.1440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.2282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.0663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.0841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.0544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.1127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.4084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.6465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Loss: tensor(0.2254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.4642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.3509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.2232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Loss: tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.3130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.4111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.3736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.1848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.1586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.2383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Loss: tensor(0.0754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.0741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.4228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.4677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Loss: tensor(0.5455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.2974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.4330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.4443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.1589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.1992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.5755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.1882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.1930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Loss: tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.1661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.0785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.2153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.0771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.1875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.3380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.2793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.1962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.2862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.1490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.4615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.2838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.3676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.4171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.3119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Loss: tensor(0.1769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.1900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.4168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.2642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.1621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.0511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.3838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Loss: tensor(0.2648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.1966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.4704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.6914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.4593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.2245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.1781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.0664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.0676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.1509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.5025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.4446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.8271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.7631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.1990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.4085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Loss: tensor(0.2189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.8660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.2741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.0818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.5082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Loss: tensor(0.2853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.2952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.3545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.1520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.3083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.3457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.1938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.3480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.7596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.3111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.3270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.2027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.4083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.1485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.4722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.0581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.1540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.0439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.1938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.2923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.5183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.2408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.4433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.2169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Loss: tensor(0.1900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.0552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.0879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.1564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.2206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.3935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.0842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Loss: tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.2986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.1856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.0955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.0816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.2447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.3874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.3422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.2721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.7636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.2661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Loss: tensor(0.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.2302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.2091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.1735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.4336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.2235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.1891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.2093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(1.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Loss: tensor(3.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(1.9942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.7908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(1.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.4523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.7648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.7901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(3.9856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(1.2927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.3521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.8584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.9702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.6641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.5757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.3875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Loss: tensor(0.5181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.2195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.2363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(1.3603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.2833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.3143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.4694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.2872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.1745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.2350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Loss: tensor(0.3313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.1918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.1635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.6690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(1.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(1.6538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.3573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.5580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.6376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.5643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.5065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.2056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Loss: tensor(0.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.2174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.3506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.2002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.2978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.9454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.8003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.2371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.3630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.1940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.1767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.2005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.1560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.1113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.6096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.2042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.2761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.4460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.2099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.1757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.3173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.0601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.3564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.4675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.2739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.0842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.0842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.5824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.4313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.3596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.1624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.1849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.3894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.1812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.1978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.0992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.4961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.4153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.2503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.7905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.4736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.1965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.3409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.4288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.2156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.4550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Loss: tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.1848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(1.0250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.5888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.5064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.1819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.1864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Loss: tensor(0.1710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.5721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.2034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.1540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Loss: tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.2254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.4321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.2193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.2154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.0576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.4956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.1957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.1766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.0491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.0503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.0505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.4041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.5966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.4044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.1865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.0622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.3037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.4680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.1819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Loss: tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.6746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.1634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.6209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.1904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.2376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.0746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.2129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.0722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.1759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Loss: tensor(0.3990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.1588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.2000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.0439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.2842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.2746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.1533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Loss: tensor(0.0773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.3548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.2022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.2109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.1388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Loss: tensor(0.1523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.0693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.1544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Loss: tensor(0.3345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.2908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.4933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.3189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.2484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.2539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.4523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.4180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.3026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(1.3663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Loss: tensor(0.5037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.3729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.3141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(2.1862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.7544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.4299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.2393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.6196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.4239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.1830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Loss: tensor(0.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(1.6466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.4546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.4615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.3412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.1824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.3775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.2708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.0562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(1.0288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.7013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.5659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.3204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Loss: tensor(0.2022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.7018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.3911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.4331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.1540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.9861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.6104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.2804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.1788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Loss: tensor(0.0599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.2403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.2034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.0732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.6278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(1.4543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.4415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.2447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.4922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.1623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(1.3012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.2904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.4731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.2292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.0664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.2283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.0605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.8212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.5248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.1928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.3657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.1342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.0839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.7675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.4603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.6052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.6121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.4524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Loss: tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.3382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.2535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.1586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.6186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.2035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Loss: tensor(0.0773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.0841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.3618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.2262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.3253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.2503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Loss: tensor(0.1328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.1318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.0424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.4618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.5248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.7882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(1.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.5192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.4959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.2733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.0992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.1662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.2989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.4036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Loss: tensor(0.6367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.4214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.3820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.2437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.0482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.1793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.8582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.5738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Loss: tensor(0.8028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.4215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.6444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.2755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.3039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.1879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.1924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.3185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.2415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(1.6717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.7880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.3139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.4345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Loss: tensor(0.3686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.9976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.1991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.8039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(2.9586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.3349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.5488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.4511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.2888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.2724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.3915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.2453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Loss: tensor(0.2827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.7853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.1608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.2414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.3678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.5715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.7881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.4858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.2254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.2094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.1982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.1521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Loss: tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.5097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.2826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.1988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.2537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.1860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.2368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.1533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.2248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.1860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.4472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.6143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.6051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.3712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Loss: tensor(0.2021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.1682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.1678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.2123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.3852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(1.5609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.3715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.7150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Loss: tensor(0.3946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.2702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.3897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.1637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.1141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.1742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.0994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.9566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.7730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.2853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Loss: tensor(0.1758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.3443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.3159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.1988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.6208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.1850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.2485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.0692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Loss: tensor(0.0639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.0442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.5361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.7612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.6513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.9155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.5408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.2258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.1677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Loss: tensor(0.4393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.1651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.1754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.6371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.1594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.2040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.1858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Loss: tensor(0.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.0677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.4592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.3631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.4609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.1807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.5612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.0466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Loss: tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.0829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.2416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.4424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.6174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.3997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.1958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.3161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.2567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Loss: tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.1974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.5284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.2982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.2087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.3505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.2150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Loss: tensor(0.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.3140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.2242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.1929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.0698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Loss: tensor(0.1749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.2137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.1665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.3164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.3200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.2242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Loss: tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.3089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.3291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.1901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.1539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.0598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Loss: tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.1776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.0694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.0518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.1181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.2808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.1640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.0850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.0748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Loss: tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.0495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.0852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.1711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.2351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.1824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.0840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.2036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.0524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.2773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.1736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.0850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.0625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.0597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.1986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.0734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.0456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.0749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.3027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.0603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.1437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Loss: tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.2775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.2324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.0482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Loss: tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.0559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.1497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.0619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.0693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.1046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.0486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Loss: tensor(0.0677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.1831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.0841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.0733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Loss: tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.1437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.0666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.1101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.2373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.2159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.0642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Loss: tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.0554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.1595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.1589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.1846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Loss: tensor(0.1173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.2088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.0754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.2127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.0623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Loss: tensor(0.2305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.0655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.0664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Loss: tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.0555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.0581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.2007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.0606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.0773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Loss: tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.2405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.0679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.0508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Loss: tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.1521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.1805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.0655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.2079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.0545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Loss: tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.1806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.0434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Loss: tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.2031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.0554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.0748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.1713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.0547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.1835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.1572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.2289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Loss: tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.0735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.0578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.0530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Loss: tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.0406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.0717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.0511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.1895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.0603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.0870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.1893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Loss: tensor(0.2248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.0549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.1879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Loss: tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.1580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Loss: tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.0743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.0482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.2680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.1525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.0412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.0781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.0527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.0521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.0598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.0496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.2682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Loss: tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.0693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.0503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.2048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.1046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.0477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.0664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.2260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.1832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Loss: tensor(0.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.0597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.0560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.2246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.0785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.1682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Loss: tensor(0.0931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.0595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.0504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Loss: tensor(0.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.1728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.0879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.1440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.1988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.1640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.0633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.0669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.0533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Loss: tensor(0.0424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.1353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.0559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.0705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.1993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.0661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.1500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Loss: tensor(0.2433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.1967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.0563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.0785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.1846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.0735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Loss: tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.1502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.0663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.1490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Loss: tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.1162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.0638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.0783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.0420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Loss: tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.0829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.1894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Loss: tensor(0.0368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.0778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.0694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.0702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.1859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Loss: tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.1604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.2023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.0640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.0625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.1525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.0510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.0754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.2343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.0614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.0585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.0511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.2244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.0549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.1173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.0870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Loss: tensor(0.2442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.2231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.0693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.0621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.1843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.0484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.2384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.1850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.0621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Loss: tensor(0.0795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.2310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.0581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.1667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.0501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Loss: tensor(0.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.0543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.0697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Loss: tensor(0.0307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.0927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.0343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.0379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.0492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.0463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.1868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.1932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Loss: tensor(0.1486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.1781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.0658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.1645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.0751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Loss: tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.3564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.1046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Loss: tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.2178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.0449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.2184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.0480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.1800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Loss: tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.1824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.0442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.0663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.2178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.1957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.1725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.0828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.0557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.0705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.0646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Loss: tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.0573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.0845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.1427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.0576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Loss: tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.0483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.0498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.0576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.0536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.0663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.1318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.0741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.0525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.1976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.0431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.0795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.0778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.0548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.1466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.1500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.0584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Loss: tensor(0.1551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.0465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.0540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.0571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.1127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.2019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.0523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.1254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.0757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 173 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.2980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.0836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.0785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.0544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.0848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.0615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.1622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Loss: tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.2241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.0616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.0749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.0489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.2086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.0767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.1849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.0816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Loss: tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.1781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.1930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.1777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.1388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.0533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.0470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.0716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.0642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Loss: tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.0692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.0309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.1082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.0589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Loss: tensor(0.1484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.1891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Loss: tensor(0.0541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.0564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.0741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.0507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.1587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.0636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.0495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Loss: tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.0623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.0802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.2354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Loss: tensor(0.0791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.1041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.0484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.1812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.1041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.0666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.2227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Loss: tensor(0.0676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.1642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.0697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.0525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.0508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.0776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.1760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Loss: tensor(0.0689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.0530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Loss: tensor(0.0749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Loss: tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Loss: tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.1082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.1594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.0522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.1800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.1837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.0773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.2031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.0840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.0616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.1916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.0511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.0717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.0840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.0585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Loss: tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.0620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.0754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.2269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.0639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.0527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.1756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.0628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.0616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.0656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.0501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Loss: tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.1509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.0472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.0252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.1588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.0785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Loss: tensor(0.1291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.0842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.0829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.2173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Loss: tensor(0.0717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.0409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.0613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.1955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.1705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Loss: tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.0570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.0516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.1440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Loss: tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.0783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.0556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Loss: tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.1788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.2206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.0622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.0614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.0538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Loss: tensor(0.0692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.1794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.1813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.0498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.0845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.0597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Loss: tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.0551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.0422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.1962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Loss: tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.0994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.1847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.0666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.0458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.0593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.1633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.0931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.0724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Loss: tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.0852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.0614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Loss: tensor(0.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.0783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.0746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.0767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Loss: tensor(0.0621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.0325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Loss: tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.0638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.0620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.1759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.1765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Loss: tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.0491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.0448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.1787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Loss: tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.0640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.0654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.0457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.0503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.0533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.0553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.1977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.0664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.0436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.1824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.0624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.2105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.0449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.0692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.0457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.1632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.0531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.0702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.0755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Loss: tensor(0.0515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.0628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.0400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.0717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.0679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.0481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.0476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.0805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.0392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.1832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.0625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Loss: tensor(0.1598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.0625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.0563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Loss: tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Loss: tensor(0.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.0716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.0870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.0712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.2001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Loss: tensor(0.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.0836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.0746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.0598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Loss: tensor(0.2193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.1141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.0679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.0426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.0556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.2145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.0805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Loss: tensor(0.0472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.0437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.1681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.0512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.1796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.0700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.0568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.0599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.0453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Loss: tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.0845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.0848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.0564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.0541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.1763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.1613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.0620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.0612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Loss: tensor(0.0512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.0698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.0446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.1564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Loss: tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.0465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.0535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.0615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.1465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.0469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Loss: tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.1768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.0399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.1500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Loss: tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.0551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.0597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Loss: tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.0744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.0693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.1768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.0694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.0712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.0423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.0743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.0621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Loss: tensor(0.1759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.0418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.0927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.1589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.0492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.0992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.0594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.0771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Loss: tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.0741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.0698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Loss: tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.0402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.0493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.1520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.2217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.0802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Loss: tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.0407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.2289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.0666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.0629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.0524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.0633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.0461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Loss: tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.1540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.0606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.0712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Loss: tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.0547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.2308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.0679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.0594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Loss: tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.0537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.0410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 255 Loss: tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.0816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.0689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.2164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.1967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.1683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.0510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Loss: tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.1101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.1661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.2049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Loss: tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.0570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Loss: tensor(0.0757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.0534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.0517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Loss: tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.0568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.0642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.0724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.0828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.0848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Loss: tensor(0.0927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.0454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.0795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.0664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Loss: tensor(0.0485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.0555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.0470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.0385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.0840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Loss: tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.0724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.0613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.0654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.1661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Loss: tensor(0.0543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.0622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Loss: tensor(0.0697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Loss: tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.0434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.1632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Loss: tensor(0.1753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.0619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.0512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Loss: tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.1632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.0639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.0484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.0616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.2081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.0628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Loss: tensor(0.0630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.0836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.0593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.1878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Loss: tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.2217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.0461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.0658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.0776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.0511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.0640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.0441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.0755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.0654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Loss: tensor(0.1776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.0299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.2178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.1792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.0619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.0425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.0585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.0538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Loss: tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.2033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.1770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.1500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Loss: tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.0462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.0773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.0640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.0783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.0513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.0724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.0565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Loss: tensor(0.0733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.1516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.0566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.0755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.1342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Loss: tensor(0.0664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.0547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.0614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.0620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.0473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.1623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.1680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.0795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Loss: tensor(0.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.2016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Loss: tensor(0.0733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Loss: tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.0722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.0595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.0470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Loss: tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.0623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.0543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Loss: tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.0658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.0559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.0605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.0821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.1481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.0545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Loss: tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.0593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Loss: tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.0633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Loss: tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.0828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.1725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.0579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.0593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.0482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.0527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Loss: tensor(0.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.0852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.0717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.0579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.0841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.0475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.0805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.2320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Loss: tensor(0.0741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.0755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.0556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.2184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.0553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.0748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Loss: tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.2112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.0439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.0532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Loss: tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.0702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.0566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.0319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.0477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Loss: tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.0638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.0572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Loss: tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.0444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Loss: tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.0629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.0743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Loss: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.0564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.0622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Loss: tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.0646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.0547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.0597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Loss: tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.0485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.0628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.2099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Loss: tensor(0.0778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.0746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.0563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.0514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.0636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.0384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.0476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.1899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Loss: tensor(0.0566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.0507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.0666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Loss: tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.2404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.0581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Loss: tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.0741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.0545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Loss: tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Loss: tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.0616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Loss: tensor(0.0486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.0754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Loss: tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.0511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.0610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Loss: tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.2104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.0724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Loss: tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Loss: tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.2027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Loss: tensor(0.0698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.0504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.2466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.0495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.1625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.0549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.0560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.0712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.0840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.0342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.0568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.0836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Loss: tensor(0.0624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.0677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.0505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Loss: tensor(0.0783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.0783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.0805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Loss: tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.2286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Loss: tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.0677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.0521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.0613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.0515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Loss: tensor(0.0735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.0454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.0555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.0836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Loss: tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.0409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.0625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.0414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.0549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.0414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Loss: tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.0731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.0451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.0536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.0748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Loss: tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.0621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.0605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Loss: tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.0829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.0773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.0576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.0549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.0530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.1590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.1509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Loss: tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.0527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.0534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.0762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.0458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Loss: tensor(0.2035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.0545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.0446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Loss: tensor(0.0655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.0722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.0836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Loss: tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Loss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Loss: tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.0527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Loss: tensor(0.0516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.1141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Loss: tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.0605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.0566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Loss: tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.0466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.0962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Loss: tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.0540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.0778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Loss: tensor(0.2276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.0528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.0603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.0510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Loss: tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.0398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.0447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.2786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.0836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.0623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.0537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Loss: tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.0482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.0633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.0785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.0598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Loss: tensor(0.1992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.1967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Loss: tensor(0.0702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.0449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Loss: tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Loss: tensor(0.0841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.0397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Loss: tensor(0.0694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.2178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.0638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.0528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Loss: tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.0613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.0287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.0785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Loss: tensor(0.0776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.0829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.0585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Loss: tensor(0.0582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.0501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.0522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.0612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Loss: tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.0732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.0697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.0550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Loss: tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.0421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.0749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.0517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Loss: tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.0538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.0521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.0556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.1794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Loss: tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.0848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.0852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.0437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.0888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Loss: tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.0705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.0962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.0485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.0582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.0677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Loss: tensor(0.1735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.0546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.0555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Loss: tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.0544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Loss: tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.0584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Loss: tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.0481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Loss: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.1101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.1954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.1776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Loss: tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.0440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Loss: tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.0702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Loss: tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.0570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.0845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Loss: tensor(0.0716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.0545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.2769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.0458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.0744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.0636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.0550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.0578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.0624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.0630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.0566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.0558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.0393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Loss: tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.0735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Loss: tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.0783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.0550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.0539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Loss: tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.0314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Loss: tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.0802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.0621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Loss: tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.0754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.0514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.2292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.0589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Loss: tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.0612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.0563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.0661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Loss: tensor(0.0310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.0454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Loss: tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.0505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.2071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Loss: tensor(0.0594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.0547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.1889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.1993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.0850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.0575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.0744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Loss: tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.1589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.0554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.1922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.0531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.0717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Loss: tensor(0.0816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.0693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.0994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.0606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.0698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Loss: tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 400\n",
    "batch_size = 8\n",
    "lr = 0.01\n",
    "gamma = 0.1\n",
    "\n",
    "minimum_loss = float('inf')\n",
    "loss_track = []\n",
    "\n",
    "# Load training data\n",
    "trainset = DataFromH5File5(\"/home/pz281@ad.eng.cam.ac.uk/mnt/PhD/Pro_Down_SR/data/DownBy4_31_121.h5\",N_low,N_high,scale)\n",
    "train_loader = data.DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialise training model\n",
    "G = ResidualLearning()\n",
    "G.apply(weights_init_xavier).to(device)\n",
    "mse = nn.MSELoss(reduction='sum')\n",
    "optG = torch.optim.Adam(G.parameters(), lr = lr, weight_decay=0, betas=(0.5, 0.999))\n",
    "r_scheduleG = torch.optim.lr_scheduler.StepLR(optG, step_size=100, gamma=gamma)\n",
    "\n",
    "# Logger info\n",
    "dir_name = f'models/train_NN/model4/31_121/lr{lr}_gamma{gamma}'\n",
    "makedir(dir_name)\n",
    "logger = setup_logging('job0', dir_name, console=True)\n",
    "logger.info(f'Training for {epoch_num} epoches and learning rate is {lr}')\n",
    "\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    \n",
    "    for i, d in enumerate(train_loader, 0):\n",
    "        \n",
    "        residual, high_res, low_res = d\n",
    "        \n",
    "        size = residual.shape[0]\n",
    "        residual = residual.to(device).reshape(size,1,N_low,N_low)\n",
    "        high_res = high_res.to(device).reshape(size,1,N_high,N_high)\n",
    "        low_res = low_res.to(device).reshape(size,1,N_low,N_low)\n",
    "        \n",
    "        downscaled = F.interpolate(high_res.reshape(size,1,N_high,N_high),(N_low,N_low))\n",
    "        \n",
    "        optG.zero_grad()\n",
    "        out = G(low_res) + downscaled\n",
    "        \n",
    "        loss = mse(out,low_res)/batch_size\n",
    "        loss.backward()\n",
    "        optG.step()\n",
    "        \n",
    "        if loss < minimum_loss:\n",
    "            save_model(dir_name, epoch, 'best_model', r_scheduleG, G, optG)\n",
    "            minimum_loss = loss\n",
    "            \n",
    "        if epoch%100 == 0:\n",
    "            save_model(dir_name, epoch, 'model_epoch_{}'.format(epoch), r_scheduleG, G, optG)\n",
    "            \n",
    "        save_model(dir_name, epoch, 'current_epoch', r_scheduleG, G, optG)\n",
    "            \n",
    "        loss_track.append(loss.cpu().data.numpy())\n",
    "        np.save(f'{dir_name}/chains/loss_curve.npy', np.array(loss_track))\n",
    "        \n",
    "        print(\"Epoch:\", epoch, \"Loss:\", loss)\n",
    "\n",
    "    r_scheduleG.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_low = 31\n",
    "N_high = 121\n",
    "scale = 4\n",
    "a, b, c = 8,3,5\n",
    "\n",
    "h_low = 1/(N_low-1)\n",
    "x_low = np.arange(0,1.0001,h_low)\n",
    "y_low = np.arange(0,1.0001,h_low)\n",
    "\n",
    "h_high = 1/(N_high-1)\n",
    "x_high = np.arange(0,1.0001,h_high)\n",
    "y_high = np.arange(0,1.0001,h_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_low, r_low, A_low, x_low, y_low = generate_data(N_low,a,b,c)\n",
    "w_high, r_high, A_high, x_high, y_high = generate_data(N_high,a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = ResidualLearning().to(device)\n",
    "G.load_state_dict(torch.load('models/train_NN/model4/31_121/lr0.01_gamma0.1/ckpt/best_model.pth')['netG'])\n",
    "# G.load_state_dict(torch.load('models/model4/21_121/lr0.01_gamma0.1/ckpt/current_epoch.pth')['netG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_high_tensor = torch.tensor(w_high).to(torch.float32).to(device)\n",
    "w_low_tensor = torch.tensor(w_low).to(torch.float32).to(device)\n",
    "downscaled = F.interpolate(w_high_tensor.reshape(1,1,N_high,N_high),(N_low,N_low)).reshape(N_low,N_low)\n",
    "out = G(w_low_tensor.reshape(1,N_low,N_low))\n",
    "residual = w_low_tensor-downscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(9,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.pcolormesh(x_low, y_low, residual.cpu().data.numpy(), cmap='rainbow')\n",
    "cbar = plt.colorbar(pad=0.05, aspect=10)\n",
    "#cbar.mappable.set_clim(-0.03, 0.03)\n",
    "plt.title('LR')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(1,2,2)\n",
    "plt.pcolormesh(x_low, y_low, out.cpu().data.numpy()[0], cmap='rainbow')\n",
    "cbar = plt.colorbar(pad=0.05, aspect=10)\n",
    "#cbar.mappable.set_clim(-0.03, 0.03)\n",
    "plt.title('LR')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upscale by 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_low = 31\n",
    "N_high = 121\n",
    "scale = 4\n",
    "a,b,c = 8,5,5\n",
    "\n",
    "h_low = 1/(N_low-1)\n",
    "x_low = np.arange(0,1.0001,h_low)\n",
    "y_low = np.arange(0,1.0001,h_low)\n",
    "\n",
    "h_high = 1/(N_high-1)\n",
    "x_high = np.arange(0,1.0001,h_high)\n",
    "y_high = np.arange(0,1.0001,h_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_low, r_low, A_low, x_low, y_low = generate_data(N_low,a,b,c)\n",
    "w_high, r_high, A_high, x_high, y_high = generate_data(N_high,a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Parameters for prior variance\n",
    "prior_sigma = 0.002\n",
    "ll_sigma = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.eye(N_high**2) * prior_sigma**2\n",
    "G_inverse = np.eye(N_high**2) * (1/prior_sigma**2)\n",
    "\n",
    "# Turn matrices to tensors\n",
    "G = torch.tensor(G).to(torch.float32).to(device)\n",
    "G_inverse = torch.tensor(G_inverse).to(torch.float32).to(device)\n",
    "A_high = torch.tensor(create_A(N_high)).to(torch.float32).to(device)\n",
    "b_high = torch.tensor(create_forcing_term(N_high,a,b,c)).to(torch.float32).to(device)\n",
    "\n",
    "# Store sparse matrices as sparse tensor\n",
    "A_high = A_high.to_sparse()\n",
    "G = G.to_sparse()\n",
    "G_inverse = G_inverse.to_sparse()\n",
    "operator = torch.spmm(A_high.T,G_inverse).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(w_low).to(torch.float32).to(device)\n",
    "posterior_initial = torch.randn(*[N_high,N_high]).to(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = ResidualLearning().to(device)\n",
    "# G.load_state_dict(torch.load('models/train_NN/model3/31_121/lr0.01_gamma0.1/ckpt/best_model.pth')['netG'])\n",
    "G.load_state_dict(torch.load('models/train_NN/model4/31_121/lr0.01_gamma0.1/ckpt/best_model.pth')['netG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Langevin dynamics\n",
    "K = 1000\n",
    "s = 0.0004\n",
    "\n",
    "z = posterior_initial\n",
    "chains_evolution = []\n",
    "z = z.clone().detach().requires_grad_(True)\n",
    "for i in range(K):\n",
    "    # Grad log-likelihood\n",
    "    downscaled = F.interpolate(z.reshape(1,1,N_high,N_high),(N_low,N_low)).reshape(N_low,N_low)\n",
    "    x_hat = downscaled + G(downscaled.reshape(1,N_low,N_low)).reshape(N_low,N_low)\n",
    "    log_likelihood = (-1/(2*math.pow(ll_sigma, 2)) * torch.matmul((x-x_hat).reshape(1,N_low**2),(x-x_hat).reshape(N_low**2,1)))\n",
    "    grad_ll = torch.autograd.grad(log_likelihood, z)[0]\n",
    "    # grad_log_likelihood = torch.matmul(G,grad_ll.reshape(N_high**2,1)).reshape(N_high,N_high)\n",
    "    \n",
    "    # Grad prior\n",
    "    difference = torch.spmm(A_high,z.reshape(N_high*N_high,1)) - b_high.reshape(N_high**2,1)\n",
    "    # log_prior = - 0.5 * difference.T @ G_inverse @ difference\n",
    "    # grad_log_prior = torch.autograd.grad(log_prior, z)[0]\n",
    "    grad_log_prior = (- torch.spmm(operator,difference)).reshape(N_high,N_high)\n",
    "    \n",
    "    # Random noise term\n",
    "    W = torch.randn(*[N_high,N_high]).to(device)\n",
    "    # random = torch.matmul(G_sqrt,W.reshape(N_high**2,1)).reshape(N_high,N_high)\n",
    "    \n",
    "    z = z + 0.5 * s ** 2 * grad_log_prior + 0.5 * s ** 2 * grad_ll + s * W\n",
    "    # chains_evolution.append(z.cpu().data.numpy())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "X, Y = np.meshgrid(x_high, y_high)\n",
    "ax1.plot_wireframe(X, Y, z.cpu().data.numpy(),color='r')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_zlabel('w')\n",
    "ax1.set_title('SR')\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "X, Y = np.meshgrid(x_high,y_high)\n",
    "ax2.plot_wireframe(X, Y, w_high,color='r')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_zlabel('w')\n",
    "ax2.set_title('high-res')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR L2 Error: 0.00027030749027159027\n"
     ]
    }
   ],
   "source": [
    "error1 = abs(w_high - z.cpu().data.numpy())\n",
    "print('SR L2 Error:', (error1**2).sum()/error1.shape[0]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR L2 Error: 0.00027030749027159027\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15,4))\n",
    "plt.subplot(1,3,1)\n",
    "plt.pcolormesh(x_low, y_low, w_low, cmap='rainbow')\n",
    "cbar = plt.colorbar(pad=0.05, aspect=10)\n",
    "#cbar.mappable.set_clim(0, 0.15)\n",
    "plt.title('LR')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.pcolormesh(x_high, y_high, z.cpu().data.numpy(), cmap='rainbow')\n",
    "cbar = plt.colorbar(pad=0.05, aspect=10)\n",
    "#cbar.mappable.set_clim(0, 0.15)\n",
    "plt.title('SR')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.pcolormesh(x_high, y_high, w_high, cmap='rainbow')\n",
    "cbar = plt.colorbar(pad=0.05, aspect=10)\n",
    "#cbar.mappable.set_clim(0, 0.15)\n",
    "plt.title('HR')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n",
    "\n",
    "error1 = abs(w_high - z.cpu().data.numpy())\n",
    "print('SR L2 Error:', (error1**2).sum()/error1.shape[0]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upscale by 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_low = 31\n",
    "N_high = 121\n",
    "scale = 4\n",
    "a,b,c = 8,5,5\n",
    "\n",
    "h_low = 1/(N_low-1)\n",
    "x_low = np.arange(0,1.0001,h_low)\n",
    "y_low = np.arange(0,1.0001,h_low)\n",
    "\n",
    "h_high = 1/(N_high-1)\n",
    "x_high = np.arange(0,1.0001,h_high)\n",
    "y_high = np.arange(0,1.0001,h_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_low, r_low, A_low, x_low, y_low = generate_data(N_low,a,b,c)\n",
    "w_high, r_high, A_high, x_high, y_high = generate_data(N_high,a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Parameters for prior variance\n",
    "prior_sigma = 0.002\n",
    "ll_sigma = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.eye(N_high**2) * prior_sigma**2\n",
    "G_inverse = np.eye(N_high**2) * (1/prior_sigma**2)\n",
    "\n",
    "# Turn matrices to tensors\n",
    "G = torch.tensor(G).to(torch.float32).to(device)\n",
    "G_inverse = torch.tensor(G_inverse).to(torch.float32).to(device)\n",
    "A_high = torch.tensor(create_A(N_high)).to(torch.float32).to(device)\n",
    "b_high = torch.tensor(create_forcing_term(N_high,a,b,c)).to(torch.float32).to(device)\n",
    "\n",
    "# Store sparse matrices as sparse tensor\n",
    "A_high = A_high.to_sparse()\n",
    "G = G.to_sparse()\n",
    "G_inverse = G_inverse.to_sparse()\n",
    "operator = torch.spmm(A_high.T,G_inverse).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(w_low).to(torch.float32).to(device)\n",
    "posterior_initial = torch.randn(*[N_high,N_high]).to(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G = ResidualLearning().to(device)\n",
    "G.load_state_dict(torch.load('models/train_NN/31_121/lr0.01_gamma0.5/ckpt/best_model.pth')['netG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Langevin dynamics\n",
    "K = 1000\n",
    "s = 0.0004\n",
    "\n",
    "z = posterior_initial\n",
    "chains_evolution = []\n",
    "z = z.clone().detach().requires_grad_(True)\n",
    "for i in range(K):\n",
    "    # Grad log-likelihood\n",
    "    downscaled = F.interpolate(z.reshape(1,1,N_high,N_high),(N_low,N_low)).reshape(N_low,N_low)\n",
    "    x_hat = downscaled + G(downscaled.reshape(1,N_low,N_low)).reshape(N_low,N_low)\n",
    "    log_likelihood = (-1/(2*math.pow(ll_sigma, 2)) * torch.matmul((x-x_hat).reshape(1,N_low**2),(x-x_hat).reshape(N_low**2,1)))\n",
    "    grad_ll = torch.autograd.grad(log_likelihood, z)[0]\n",
    "    # grad_log_likelihood = torch.matmul(G,grad_ll.reshape(N_high**2,1)).reshape(N_high,N_high)\n",
    "    \n",
    "    # Grad prior\n",
    "    difference = torch.spmm(A_high,z.reshape(N_high*N_high,1)) - b_high.reshape(N_high**2,1)\n",
    "    # log_prior = - 0.5 * difference.T @ G_inverse @ difference\n",
    "    # grad_log_prior = torch.autograd.grad(log_prior, z)[0]\n",
    "    grad_log_prior = (- torch.spmm(operator,difference)).reshape(N_high,N_high)\n",
    "    \n",
    "    # Random noise term\n",
    "    W = torch.randn(*[N_high,N_high]).to(device)\n",
    "    # random = torch.matmul(G_sqrt,W.reshape(N_high**2,1)).reshape(N_high,N_high)\n",
    "    \n",
    "    z = z + 0.5 * s ** 2 * grad_log_prior + 0.5 * s ** 2 * grad_ll + s * W\n",
    "    # chains_evolution.append(z.cpu().data.numpy())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApkAAAFUCAYAAABvMSelAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOx9d3gc1dn9uTO7q271Yrn33rvAEBIISUjyQSBAOoSQkADhF1L5QiB8BNJogUAILSGEJPQaejeW3C032bg32ZZlSbbqtpn7+2Pm3r0zO7M7u1rJtrjnefxYuzs7c3d35p23nPe8hFJKISEhISEhISEhIZFBKMd7ARISEhISEhISEgMP0smUkJCQkJCQkJDIOKSTKSEhISEhISEhkXFIJ1NCQkJCQkJCQiLjkE6mhISEhISEhIRExiGdTAkJCQkJCQkJiYxDOpkSEhISEhISEhIZh3QyJSQkJCQkJCQkMg7pZEpISEhISEhISGQc0smUkJCQkJBwwa9//WsQQnDkyJGE240cORKXXHJJWscYOXIkPv/5z6f1XgmJExnSyZRICxs2bMAFF1yAESNGIDs7G0OGDMFZZ52Fe+65h28zcuRIEEL4v7y8PMyfPx//+Mc/juPKJSQkJCQkJPoDvuO9AImTD7W1tTjjjDMwfPhwXH755aiqqsK+ffuwbNky/OlPf8LVV1/Nt505cyZ+/OMfAwAOHjyIhx56CN/61rcQCoVw+eWXH6+PICEhIZFRfPTRR1AUmbeRkBAhnUyJlHHLLbegsLAQK1euRFFRkeW1w4cPWx4PGTIEX//61/njSy65BKNHj8add94pnUwJCYkBg6ysrOO9BAu6urqQl5d3vJch8TGHDLskUsaOHTswZcqUOAcTACoqKhK+t7y8HBMnTsSOHTv6aHUSEhISmcfRo0dxySWXoKioCIWFhbj00kvR3d3NX3fiZK5fvx6nn346cnJyMHToUPzmN7/B3/72NxBCsHv37rhjfPjhh5g/fz6ys7MxevRoz9QixhttaGjAV7/6VRQXF+PUU0/lr//zn//EnDlzkJOTg5KSElx88cXYt2+fZR/btm3D+eefj6qqKmRnZ2Po0KG4+OKLcezYMe9fkoSEDTKTKZEyRowYgbq6OmzcuBFTp05N6b3RaBT79+9HcXFxH61OQkJCIvO48MILMWrUKPz2t7/FmjVr8NBDD6GiogK///3vHbdvbGzEGWecAUIIrrvuOuTl5eGhhx5yzXhu374dF1xwAS677DJ861vfwiOPPIJLLrkEc+bMwZQpUzyt8ctf/jLGjRuHW2+9FZRSAEbl6Ve/+hUuvPBCfOc730FzczPuuecenHbaaVi7di2KiooQDodx9tlnIxQK4eqrr0ZVVRUaGxvx8ssv4+jRoygsLEzvS5OQoBISKeKNN96gqqpSVVXpokWL6M9+9jP6+uuv03A4bNluxIgR9NOf/jRtbm6mzc3NdMOGDfQb3/gGBUCvvPLK47R6CQkJCe+48cYbKQD67W9/2/L8eeedR0tLS/njESNG0G9961v88dVXX00JIXTt2rX8uZaWFlpSUkIB0F27dlneC4B+8MEH/LnDhw/TrKws+uMf/9jzGr/yla9Ynt+9ezdVVZXecsstluc3bNhAfT4ff37t2rUUAH3qqaeSHktCIhXIcrlEyjjrrLNQV1eHL37xi1i3bh3+8Ic/4Oyzz8aQIUPw4osvWrZ94403UF5ejvLyckybNg2PPfYYLr30Uvzxj388TquXkJCQSB1XXHGF5fHixYvR0tKC9vZ2x+1fe+01LFq0CDNnzuTPlZSU4Gtf+5rj9pMnT8bixYv54/LyckyYMAE7d+5Me43PPvssdF3HhRdeiCNHjvB/VVVVGDduHN59910A4JnK119/3UIBkJDoLaSTKZEW5s2bh2effRZtbW1YsWIFrrvuOnR0dOCCCy5AQ0MD327BggV488038dprr+G2225DUVER2traEAgEjuPqJSQkJFLD8OHDLY8Z5aetrc1x+z179mDs2LFxzzs957R/dgy2f03TcOjQIcu/cDhs2X7UqFGWx9u2bQOlFOPGjePBPvu3efNm3qg5atQoXHvttXjooYdQVlaGs88+G/fee6/kY0r0GpKTKdErBAIBzJs3D/PmzcP48eNx6aWX4qmnnsKNN94IACgrK8OZZ54JADj77LMxceJEfP7zn8ef/vQnXHvttcdz6RISEhKeoaqq4/PU5D729f737dsX50S+++67+MQnPsEf5+TkWF7XdR2EELz66quO+8/Pz+d/33777bjkkkvwwgsv4I033sAPf/hD/Pa3v8WyZcswdOjQdD+WxMcc0smUyBjmzp0LwNDDdMM555yD008/Hbfeeiu+973vSYkNCQmJAYkRI0Zg+/btcc87PecFVVVVePPNNy3PzZgxI+F7xowZA0opRo0ahfHjxyc9xrRp0zBt2jRcf/31qK2txSmnnIL7778fv/nNb9Jas4SELJdLpIx3333XMXp/5ZVXAAATJkxI+P6f//znaGlpwYMPPtgn65OQkJA43jj77LNRV1eH+vp6/lxraysef/zxtPaXnZ2NM8880/IvmUrHl770JaiqiptuuinOZlNK0dLSAgBob29HNBq1vD5t2jQoioJQKJTWeiUkAJnJlEgDV199Nbq7u3Heeedh4sSJCIfDqK2txRNPPIGRI0fi0ksvTfj+z372s5g6dSruuOMOXHnllfD7/f20cgkJCYn+wc9+9jP885//xFlnnYWrr76aSxgNHz4cra2tIIT0+RrGjBmD3/zmN7juuuuwe/dunHvuuSgoKMCuXbvw3HPP4bvf/S5+8pOf4J133sFVV12FL3/5yxg/fjyi0Sgee+wxqKqK888/v8/XKTFwIZ1MiZRx22234amnnsIrr7yCBx54AOFwGMOHD8cPfvADXH/99Y4i7Xb85Cc/wSWXXILHH388TsBYQkJC4mTHsGHD8O677+KHP/whbr31VpSXl+PKK69EXl4efvjDHyI7O7tf1vGLX/wC48ePx5133ombbrqJr+3Tn/40vvjFLwIwyu5nn302XnrpJTQ2NiI3NxczZszAq6++ioULF/bLOiUGJgjNFGtZQkJCQkJCIiH+3//7f/jrX/+Kzs5O12YfCYmBAsnJlJCQkJCQ6AP09PRYHre0tOCxxx7DqaeeKh1MiY8FZLlcQkJCQkKiD7Bo0SJ84hOfwKRJk9DU1ISHH34Y7e3t+NWvfnW8lyYh0S+QTqaEhISEhEQf4HOf+xyefvppPPDAAyCEYPbs2Xj44Ydx2mmnHe+lSUj0CyQnU0JCQkJCQkJCIuOQnEwJCQkJCQkJCYmMQzqZEhISEhISEhISGYd0MiUkJCQkJCQkJDIO6WRKSEhISEhISEhkHNLJlJCQkJCQkJCQyDikkykhISEhISEhIZFxSCdTQkJCQkJCQkIi45BOpoSEhISEhISERMYhnUwJCQkJCQkJCYmMQzqZEhISEhISEhISGYd0MiUkJCQkJCQkJDIO6WRKSEhISEhISEhkHNLJlJCQkJCQkJCQyDikkykhISEhISEhIZFxSCdTQkJCQkJCQkIi45BOpoSEhISEhISERMYhnUwJCQkJCQkJCYmMQzqZEhISEhISEhISGYd0MiUkJCQkJCQkJDIO6WRKSEhISEhISEhkHNLJlJCQkJCQkJCQyDikkykhISEhISEhIZFxSCdTQkJCQkJCQkIi45BOpoSEhISEhISERMbhO94LkOgf6LqOaDQKVVWhKAoIIcd7SRISEhInFXRdh6ZpIIRAVVVpRyUkkkA6mQMclFJEo1FEIhH09PRAURQoigK/3w+fzyedTgkJCYkkoJRC0zREo1F0dXVxO+rz+bgdlU6nhEQ8CKWUHu9FSPQNdF1HJBKBruuglCIcDoMQAkopdF0HAB6Ri8ZSOp0SEhISBiiliEQi0DTN0Y4yWymdTgmJeEgncwCCGb9IJAJKKTeI4XAYiqJYtmP/dF2Hrus4cOAAhg0bhqysLOl0SkhIfKyh6zrC4TB0XYeiKJ7sKAAcPHgQZWVlKCgo4EG8tKMSH0fIcvkAgxh1A0amkjmZdrDXAEBVVUSjUezatQuVlZUAgGAw6FgWksZSQkJiIIOVx1mgzmyeFztKKUVjYyNyc3Ph9/v5NpKmJPFxhHQyBxB0XcfRo0exfft2TJ8+PWUDxqJz5lCy6FzTNGiahlAoZDGWLEIXjayEhITEyQxKKUKhEFavXo1p06YhEAikZN+YPWR2Usx0BoNBvo2kKUl8HCCdzAEAkZQeDofR0tLSK2PFonXRWLLnxWOx1+3GUjqdEhISJyNY9jIajeLIkSOcbiTCi20Ts55OmU5WWpdOp8RAh3QyT3LYy+OMN5QOkhk0N6eTda+LTifLdDJjKSEhIXGigtmxaDQKwHAGk22frgOYyOkMhUKSpiQxoCCdzJMYLOpmpHTmAPa2l8vr+6XTKSEhcbJDVOEAYLFP7DkRXhxMN/6m27bi/iRNSWIgQTqZJyHEqFskpQOpGTc72D568/5ETifgLPMhnU4JCYn+hqjCIQbqDMfLgZM0JYmBBOlknmRgk3vE8rjdMPYmk5lJI+VmLCORCDZs2ICKigqUlpZKp1NCQqJf4UQzcuJeOmUyvaC3dti+L7fgfceOHfD5fBg6dKgjp1NC4nhDOpknCZy0L50cwkwYt76SThWNZSgU4gY8EonwTCchxGIoWVlIQkJCIhNgdlTTtIQ8xxPV7oh2lFWzCCGSpiRxQkI6mScB7KT0RGWREymTmQjMMIoEe9GRZlM1RKdTLAtJSEhIpAKx5OxUHrejt9Sj/phzwuwoaxRiz0maksSJAulknuAQo26xZOIGkVeZrjN2vIZAeXE6FUWJi9Cl0ykhIZEIXsrjdjg5iieDrUlEUwqHwwCk0ynRf5BO5gmKVKNuht46mSeSEfXqdMp5wRISEm5wUuHwgkQTftJ97/GAk9PJ7KikKUn0NaSTeQIinaibobcd4r19b19CdDrZGtlsYVHmQzqdEhISdppRqjqTvXUUTwY7CkiakkTfQjqZJxg0TUNPTw/n2KR6YWdChqi/0JtjiWLGgLvTyRzPQCAgjaWExMcEmqYhGAxyG5COvE8m5OBOBnitGAFAVlaWtKMSKUGSME4QsKi7paUF77//ftrTHQZyJjMRnLTjFEWBpml499130d7ejo6ODrS3t6OrqwuhUIh3ZkpISAwMMJpROBzGW2+9hVAo1Ctb+nGzo4B1xCXjvlNKsWzZMhw4cEDaUYmUIDOZJwDE8jgzbL0ZWcb22Zv3n+yw85AYsZ1SilAo5DpFQ45uk5A4OWGnGfX2Ok7HyVQ2bkTgN7/BgpUrETzjDODBB4GT3J6ImU6WxZQ0JQmvkE7mcYadlM6ixnTxcc1kuoF9FlHiQ5wXTClFMBgEAIvTKecFS0icPHDSvuyNmDqQupOprFmD3HPOAenqgh9A9pNPIlRSgvAf/pD2Grygv2XnJDdeIhVIJ/M4wY2UngnDyPbfm/cPFLDvwWmah8jrdHM6naZoDLTvSELiZEUiFY5MaAZ7fn8ohJxvfhOkq8vydODBBxH+3/8FiorSXkci9GdCwKnClogbHwqFEkomSTv68YDkZB4HsKjPqetRlJlIB2k7mZqG7K99DWdecAEq585F1o9+BNLSktYaTkR40cQTNThZ6VzXdQSDQXR2dnJeZ3d3N8LhMDRNG1BZXwmJkwmsPM6moNkDQEaPSRepOJn+Bx6AsncvqM/I2xz+1KdAARBNQ87FF6e9hhMNXuyofdqQSFPq6urinM7u7m6EQiFpRwc4ZCazHyF27blptmVCTD0dfbfsb3wD/pdfNh50dwMPPwxlyxb0vPwyIHQenmzojbPulOlkEXowGOQleJnplJDoX3jRvuy3cnlzM7JuuMF4j5k4qHj7bf6yr7YW/j//GZGrrkp7LScC0rknea0YSZrSwIXMZPYTxIkLTlE3A8tk9pVxdHQ+GxvhYw4m205R4Fu6FDlnngn0Yi1u6K/I1a1cnirETCdzKgkh0DTNEqE3Nzejs7MT4XAYuq7LCF1CIoMQ7WgycfW+ymTaM2/ZP/whiNlsBADsla7Zs/lzWddfD2XNmrTXciIgE7bMrWLEnE5WMTpy5AiOHTsmK0YDANLJ7AeI5XF2kbkZxkw07jgZR03T0Nrayic8iAjceCMIDMdy/1lnGfswHUvf6tVQ33or7bUcb2TKybTDidxOCEF9fT2amprQ1dWF9vZ2dHZ2oqenh2ddpLGUkEgPrArkVVw905lMSim2bduGDz74AMuWLcPmzZtxaN8++Ez7SM2KDwFwdNYsHPr1r2P70nXkXHQRcBJf/72prrnBzenctm0b9uzZI2lKAwCyXN6HSGc0ZF9kMjs7O1FfX49gMIhoNIqCggKUlJSguLgYhYTA/9xzxvt0HUPffDNuf4H770fPpz+d9nqON/qj7MLKQpRSi7ZcNBpFJBJx1PGU84IlJJJDpBmJHc7JkMnGn1AohHXr1iEUCmHu3LkIh8M4evQoOl98ESQUMrYXsplaXh6igwYZvEzzOaWpCepLL0H74hfTXtPxRl/bUtGOMjspaUonN6ST2UdIdzRkpjOZBw4cwKZNmzBs2DAMHz4c0WgUbW1taGtrw+bNmzHu/vtRZGY3RYMIADQQAAmHoS5ZYkTgJ+FF3BfRd7LjiUoBYiOXm9PJnFLpdEpIWGFX4Uhlck+myuUtLS1Yt24dSktLMWvWLH4tl5WVIfvmm/n2ut8PxbSlJUuXovu++2BfadYtt6D7JHUy+7uTXbSj4vMsecOoSk5VJel0njiQTmYfwAsp3Q1s295mMqPRKDZu3IimpibMmDEDZWVlCIfDyMrKwuDBgzF48GBg1y7kv/ACf98H99yDBb/8JbLb2439mPITJBQCaWgAnTIl7TW5rbOv0d9lFV3XXZsQEjmdgLPMh3Q6JT6uELUvxWvHK3pbLgeApqYmtLS0YOLEiRg6dCgAWChHPrPyo+fkgPT0xI5NKar++9+4/SlbtkAPBqFkZ/dqXccD/Rmwp2pHWcXQrWKUSnAikVlIJzODoJRy7mW6s8eB3kfglFJs3LgRfr8fNTU1yMnJcTS2eeecwyNt6vNhzrRpyDIdTABonTABJR99BADQb7wRwcceQ05OTtrrOh44HplMrxlrJ2PJmhoA6XRKfDzhFHz1tx0NhULo6OgAIQQLFy5EQUEBXxsDOXIE6OwEAGhz5sD/4Ye8GkQB+G2amRSG87nrN79B55e/zClLeXl5J40D1N/C78mQSsVIOp3HB9LJzBBY1F1fX4+CggKMHj064xJEXnDw4EFEIhGUlpZi+vTp/OKzr0VZuRLK/v2xY0ajyPne9yzlnUKfD1pREdSjR5H/zjt4/8MPEcjLQ3FxMTeQgUAgrXX2J45HuTxVOBlLdk6xmy0hxGIoWYe7hMRAAQu0tm3bhq6uLkyfPr1XdjSdTGZLSwvWr18PRVEwcuRI7mDa4bvjDm4viZmZpCUlQDgMYjqfVFVBNA1UUXgz5aS6Omy7/HK0tLRgx44dUFXVYlNTDeRPNMcvU8fKlB2VNKXjC+lk9hJ2UrqbU5cK0jGOmqZhy5YtOHjwIAKBAIYPHx534Yhr8v/lL3H7UM2sJYOyfTvC3/8+1LvughKN4lNbt+LwxRejtbUVe/bswaZNm5CXl8eNY1FREXy+E+uUOlHK5amCGUIG8TwLh8M8ENF1Hfn5+ZYIXULiZART4dB1nTfO9daOpnL9U0qxY8cO7Nq1CxMnTsThw4cTOh/+//zHeJ/PB2XDBuMzjB8P+Hzwffgh+1DGWgR7Hli/HiOGDcOIESOg6zra29vR2tqKgwcP4qOPPkJWVhaKi4u543kiBPJ9pdLhhkzaUS80pUgkgry8PIuAvERmcGJ5BCcZ7M097GTuLQ8o1TJPd3c36uvrQQhBTU0NVq1alfT9/ldeARCLtEVoJSVQW1tBQiFEzzoLWXfdBQDIvusulF5xBUpLSwGAd1i2trZi27ZtCAaDKCgo4MZx0KBBFkfpeKC/o+90I/BkcHI6Ozo6sGbNGpxyyilxUiBydJvEyQLGqRMD9f62o6FQCOvXr0dPTw8WLFiAQYMG4ciRI67vV3bsgHrkCABAr6yE2tgIANAWLDDsqelkEkpBBw0CEWhIJBSCsn499JkzoSgKioqKUGSOnYxGozh27Bja2tqwd+9eNDQ0IE+oHtkD+f7WG+4v9KUddXI66+rqMGfOHOTk5EiaUoYhncw0IZLS7WMhe2scU8lkHjp0CBs3bsSQIUMwYcIEvpaERuHQIWOqDwBaWAjS2mp5OTxhArKXLwfRdfjeeYd3mStNTfC99hqi55wDAAgEAqioqEBFRQUAIBgMorW1FW1tbdi0aROi0SgKCwu5gSwoKOh3p6e/nUygfyWTmFPplOmU84IlTnS4qXD0px1tbW3FunXrUFxcjFmzZnEnLpEd9b36auwzVFQAppOpT5oUp4UpOpj8/a+/jvDMmfHP+3woLS3lgXwkEuFqIPZAvri4uN+cP9/LL+O0X/8aha2tiF54IUJ/+EOfHq+/7Db7jSmlyMrKgs/ni7OjdpqSdDpTg3QyU0Qy7ctMdDR6KfPouo4tW7bgwIEDmDp1Kqqqqjy/P3DzzZycTkxnU0R4zBhkbd8O0twM30svQa+uhrp7NwDAf9993Mm0Izs7G9XV1aiurgalFN3d3Whra0Nrayv27t0LACgqKkJJSUm/Cur2t5PZXwaInX+ANdPJ1sHKj24yH9LplDieSKTCkSknM5GNoZRi586d2LlzJyZMmIBhw4bFXQ+uTuZLL8XWeuBAbPtRo0CzspKuTX3lFeDnP0+6nd/vjwvkmdPZ0NCAcDiM7OxsEEJQUlKC/Pz8jNsf/yOPIPv//T/kmY8D998PfdgwRK6+OqPHEZGpcrkXiHY7EU1JcuPTg3QyU4AX7UtFUbimW7pIVuZh5XEAqKmpQW5uruX1ZMbV/9prxh+m7IZdHzM8ejT0iROhNDdD2boV1IyqAUD98EOgrQ0oLk74GQghyMvLQ15eHoYOHcrLu62trWhubkZ3dze2bNmC5uZmzunM7gNZj/7WdgP6l7fkdENhx5dOp8SJCLv2pZMdzUSwnshRDYfDWL9+Pbq7u3l53On9jvajowPqsmWx7Zqa+N/60KGgwjUpNvxQQkDM/anr1wM9PUCKTT7Z2dlcgo5Sig0bNnDbKgbyLNPZ2851ZeNGZF17bdzzWbfcgshllwG2e0+m0Fflciewc8TNlibjxkuaUmJIJ9MjvGpf9nWZp6mpCRs2bEB1dTUmTpzoemG4OlednSDNzQAAfcwYqBs3ggDQS0uhtLQAACIjRxoE9iVLQAAQ83nA4Bj5//IXRP73f1P+TIMGDcKgQYMwcuRILF++HBUVFdB1HY2NjdiyZQuys7Mt3KNMEN77W9sNOP5Oph2JnM5QKJRQMkkaS4lMgt2gE93Y2fN9lclk5fGioiIsWrQIfr/fdR9O71dffz1OZB0wHEo6eDD8Dz/Mn9MWLYJv6VLj9ZISbkuJpkFdswbaKaek+KliYBm1nJwcjBo1ijubbW1tvHPd5/NxhzOdzvWsH/8YRNdBs7NBgkFEp06Fb+NGkO5uZP30pwjde2/a60+E/sxkJjsXRUinM3VIJzMJxKhbnELght5qXLrtQ9d1fPTRR2hsbIwrj9uRkEv0+OPcQOoTJkDduBEAoC1cCMUUDw6PGAEqyBvZEXj88ZSdTKc15ufno7y8HIBBeGdNRLt27UJXVxfy8/O501lYWJhW5/rx4GQej3J5KhCdTtbFy/6FQiFLppMZSjZT+ONsLCXSh3gz9jKkoi/sqFgeHz9+PIYPH57WGgKPPhrbp8lXBwBaVASoKgJ//jN/XZ84ETCdTCKIuAOAWlfXKyfTDjGQZ53rrIlI7FxnlaNkEnT+u++Gr67O2HcwCEoIfOb9AgD8jz2G6EUXQTvttIx9Bob+zGQysf90bJsbTUly42OQTmYC6LqOaDSa0mjIvshkdnd3Y926ddB1HYsWLUJeXl6CdxtwM9DZf/wj/1tdsoT/rWzaZLwPQGTwYOjV1e7r27cPCAaBXpa3xe/S5/OhrKwMZWVlAIxyFuNzfvTRRwiFQhg0aJClc92LEcp++23MvvdeZI0bh9Af/wiYXZx9gf7OZLKms95CNLB2pzMYDPJtmNMpR7dJpAIvNCM7Mm1HWXm8q6sL8+fPR2Fhoee126GuWRN7PSeHO5mA4Tgqe/YIG6u8TE7a2y3UJN+TTwLBINS6OkTOOw/R73wn5c+YCIqicGcSiAXybW1tXIKOBfJxEnS6jqzf/c6yP0IpaGEh9FGjoNbXgwDIvugidDU0JKVPpYr+rkBlyo4CkqZkh3QyHWDXvkwlysl0mYeVxwcPHoyJEyd6kgRyzQIcOcJL5QCgHD7M/2aNPeYOQF2cTGYkfU89heg3vuHl46SFQCCAyspKVFZWAgB6enq409nY2AhN0zj3iBHe7b+R/847UXnjjcaDNWvge+01dL/7LujYsX2y5v6MvoHMGUc7Ejmdb7/9NmbPno3c3Ny4KRrS6ZSww02FIxkyaUfb2tpQX1+PoqIi1NTUJCyP29cQZ0cPHwY6OmLHEEdJtrXBf+ed1n3s2wd9xgyoJode/PTKli3I2rIFAOBbsgTBcBiRH/zA+wdMEW6BvL1zvaSkBFXr16PAJigPAN333Qffli388yhdXcj5ylfQw3j+GUJ/l8v7yo4Czk7n8uXLMWzYMJSVlQ14p1M6mTbYSempptEzSVjfsmUL9u3bh6lTpxqzxlOAk5OZdeedjlyiyKc+BdLUZHBtAKgHD0K3HY9H4+Zj//PP96mTaUdOTg5ycnJ453pXVxd3Onfv3g1CiEXAeNA//oEs5mCaUI4dQ863v43ut94C+kDguL9HWPaVcbSDXQO6rkPXdQQCAX6OiplO6XRKMCRT4UiGTDmZLGvnpTzuBLsdVZ56ymJDxSwmoRS+11+3br9tG6JnnsmdMsv6bI+zbrwRke98p09skxPcAvm2tjYogrMs6igrHR1x9wa1thZoaQGEBtHeor8bf/rLjgKG06nrOqcgMZqSyI0fSDQlKfYkgKW1ezMzNxPGUdd1bN++HS0tLaipqUnZwXTLZPqefdZx+8i3vw3trLP440HPPx+fybTJcijr16e0pkyC8TmHDRuGGTNmYPHixZgxYwby8/Nx+PBhNP7ud8j52c/ijDgFoNbXw/+3v/XJuvoz+mbH6+/MKQDuQDJyOzOErJGos7MTv/rVr/DLX/6y39YmceKAlcdFcfX+tqPhcBhHjhxBe3s75s+fjxEjRqS8Biduu2pzIgEj08ffAyMg54/37oW2cCF/rJeUxK/1vPOMClEohKw0MpmZsjksiJ8yZQrKhOlv4jfg/9GP0P3BB5bnCYCs3/wmI2sAYgLpJ3smMxE0TYuzo+wxoyl1dXXhsccew5e+9KV+XVumIZ1MxLKXO3bswKFDh/jEiXTQW+N4+PBhtLe3Izs7GwsXLvTEv3RCnJPZ0WHRc9NM3TUKQPv0py0yHIOeew7IybFIccAmy0QOHwZCobTWlmkoioLCwkKMGjUKcwoKMEsg3ocFaRKehb39dsBGws8EBkq53A2MU2enbIgdlSyTeejQIR6sSXx8oGka9u/fj127dvHzIt2GinTtaFtbG2pra0EIweDBgz3zL53WEJfJNMdHiqD5+db3sbKoqoKEw9BHjoxt65Dt87/0Usw2PfkkfM8/73mNfSLRtn8/H9ahjR7NNZUBwNfTgwJTiF78VVVzglwmcLI0UPYGzMkUYe9M9/l8aGtrQ7eDlvXJhI+9kylG3UePHkVHR0fvdMXSdDJZ9/i6deuQn5+PwYMHpz2S0SmTqTzyiMUoaFOmADANRWen0cxjIrB3L8iuXXzuLgAQu5NJKXJPPx1ZP/mJoRnXz2PH3JB1002WtXZ9+cvY9z//wx9TAOqhQwh99rM8W6zZxmqmi4FaLmdgXZjJjkkI4eoAEh8PMDsaDoc5laW/7SilFLu3bMGe++/HlN27UdXLZhRHlQ6B0863c7geKICwWYEix47Fsn4HD8a/PxqFNn688TeA7O9+F0RICPQ3sq67Ljasg9lSocnTf+xY3HuUgwex4q23sGXLFhw+fJiXftPBiaI33JdwcjLtIISgs7Mz7UTTiYKPNSeTlcfZScaaHHqDdKQ3enp6sG7dOkSjUSxatAjbtm3rdck9rszz1FOx17Kz4du+PfbaihVQBCcTiBkaAHFi7fx9DQ1QGxoQeOABhL/7XYRuu61Xa+419u+H78UXLU9RAJrg7LDPUbZiBQ5u2IAtFRUIh8Nx4y/TMTrHo1zen7PhvRhGhq6urpPeOEp4g137knHOegNmR70GbuFwGLsfewwTf/pT+M3MT8nUqWh45JG01xDnZG7ebOEncpi8ZMt7EbM76ocfcrtDzGYaEXp5OYL33Ye8M880tgkGkfOFL6B79eq0194b+N56y/hj0CAopsB7dNgw+Ldt43rKrBmI3RsIgOmbNmHfiBFxEnRxnetJcKLqDWcKrLHYiy0dCMH6x9LJZKR0O2dIUZReZ7VSjcCbm5uxfv16VFZWYtKkSbyzrDfOrmMmUyjz6KNHQ21o4I/V5ctBzNm7DD6hW1CbPh0+k4Pp5nAGHngA0DSEbN2VbuiLMk+2Aw8zu74exWvXOm4/4a23MOLPf7YQ3vfv3w9d1y2d616nZgz0cnkqx+vu7j7pjaNEYripcGSCl87OMy9O5tGjR7H1v//Fop/9DD6htJi7cSOq/vY3wKNNssNuh1VTR5iBO1hCh7kIX2ur8b5Vq2L7dNowGIQ+c6Z1ItC2bVDffhvapz6V1trThVJfD6WrC4AxvYjdJ6ITJsC/bRtgu/5pZSWISbUqfuMNZF9zDQBr5/rWrVstEnTFxcUoLCx0tSUDvVwuBmPJMBDs6MfOyUyk2ZapkZBeDKyu69i2bRv27t2LyZMnY8iQIfy1THSoW5y4gwctXZDURj5XV68GiUQsI9CIeHyh7CQaSbvDGXj4YUS++lXo8+b1au1pgdJYBC4gp77emFiRlQVi45D6XnkFhBDk5uYiNzcXQ4YMAaUUnZ2d3EDu2rXLojfHpmY43fiORyYzHYH6dCEzmRIMdjtql73KRLAOJHYAKKXYvXs3tm/fjtOeeQY+0zmipgSbsn8/Bj/yCKJ/+APgUbZIhN3JJLW11tcBblfstpACyDIl4pSdOxMfp6MD6ptvcgeTIeumm9Ddz06m/6GHYg8EexmeMQM5L78M0t4OQOg4z88HTCdTWbPGoFgpSsLO9QMHDiAajVrGXxYUFPDz53hkMvu7IgR4c6I7OztRmsGu/eOBj5WTmWw0pKqqveKSAN4cxGAwiHXr1iESiWDRokVGpEIplAcegPLKKxhWWYlj3/42MGZM2msQoTz4oHUDW+StmNEqLS216Gg6QTSmTg5n4K9/RfA4OJnqW28ZUymEdVFFAdE0RAMB+IQbgV5VBeXQIWPEm016gxCCgoICFBQUYPjw4dB1He3t7Whra8OhQ4ewdetWZGVlWZzOLLPzfqBnMlN1Mk/2CFzCGcm0LzOZyXTbTyQSwYYNG9De3o6aYBAFQuMJnToVxNSfVEMhkDPOQOSdd1KWBrI7mcq6dXHb6CNGQN261XA4c3J4VjMyeDACJv+S2VRufxQFish3B5D185/H7VtZv95oUEzDQU4LlFroRqJzHJ4/HwDiAnViltMBQzNTaWiAPnVq3K7dJOja2triJOhyzXno/elk+np64Hv2WZCDBxG5+OKMyjHZkYqT2dXVhREjRvTZWvoDHwsn06596dbx2B/lclYeLy8vx5w5c4xMVCgE/2mncSM2GED5Sy9BW7sWSDA+0g12R1f997+ta7TxLxVmBKurnYntPT2gPh9INOpc7gFA8/JAurosZfb+hP+vfwVgZhfMtUJVAV1HsLoa+bt3Az4fEI1CHznScDIBBG67DeHf/tZ1v4qioKioCEVFRRg1ahQ0TeNTM/bu3YuGhgbk5eWhuLi438njJ6qTyW4iBQUF/bAqif6CV+3LvnYyjx49ivr6ehQUFKBm4ULkT5hg1a7ctMngC5q8QWXVKqi33ALtpptSWkMcbUlQ4GDQq6uhbt0KAIjOnw//++8DALqmT+dOJmzdwfrgwVBs9CRFcNYA0yHVdfiefBLRr30tpXWnC2XVKihHj8aOL3z2yKRJCBUWIsvW9BM3KvO99xydTMt7TAk6JkOn6zqfud7c3Iyj5hoaGhq445ndy+lyiZC9ahUmXH01fKbIfuCuu9C1cWOcbF+mwOyoFye6u7v7pK8IDfjuctbck8zBZK9lSkjdaR1bt25FfX09JkyYgOnTp/NSp3rDDXFRsq+tDf7zzgPZti3lNdg/HxHHnMGY9MPMhyisS4RJFpb3Hz4MXSjnO4HxeEh7O0iCueeJ1pk2IhH4hBGZ1BwdyQygzyTmU9NhV5qauLad/7HH4uSZEkFVVZSWlmLs2LGYP38+Fi9ejFGjRoFSikOHDqGjowOrVq3Cjh070NramrHOdSccDyczFU7myW4cJWJIRfsyE+Vye+mUrWH37t1YuXIlRowYgdmzZyNr6VLOCeTv1TToZ5yBoxdfHFvT738P8s47Ka+BO5lHj8YpbACwUIm0c87hdrV72jToZgaSwKyqmK8pDs0/lqqQqsYkjf7xj5TW3Bv4H37YcT16ZSVobi408/NQWLUzRYh22CuYBN3IkSMxa9YszJkzB4qiICsrC42Njairq8OyZcvw0Ucf4fDhwxmVRlPWr8fIK67gDiZg3B+yTG5pXyCV8vxAoB0NWCeTRd3hcNiz9EomuyJFBINBrFy5Ek1NTVi4cCGGDh0ae/HgQaj33QfAaMiJXnutsX4Aytq18J96KtDWltIaLJnM9est/EomFMyMiD5uXGztLtwhcugQiBldsrXZoQ8bxv/2Pf54SuvtLdR337WOdztyxPJ6wHwcXbDAeH3/fujmaEmlvR2+l15K+9h+vx8VFRWYMGECxowZg8LCQgwZMgShUAgNDQ1YsmQJ1q5di927d+PYsWO9Pr8YyOHDKH77baj9qKGWqnGU5fKBAU3TEAqFEI1GPWlfZiJYt+8nEomgvr4eu3fvxty5czFq1ChjytQ99wCw2iQKIHrXXYgIGTUCwP/tb6d0fPEzKjbVCn4soZQd/dSneGmbaBqOzZ0b25fwfShCNtCybnZ/EqtQa9YAfRioivC9/LLj83T4cJDmZmSbjUx00CAL756a5W0AUJYv77WcHZseNmbMGMydOxeLFy/GmDFjQAjBrl27sGTJEqxcubL3EnS6juxrr4UaDEJnlCeTUuH/z39ABAWWTCKVYH0g2NEB6WSKmm2pTJzIZCaTOZpHjhxBbW0tcnJysGjRorgSonrnnTzjpn3rW9zh5LzHY8eg/uEPKa1B/KzMCHMIUZFeVmZxMgEg6DBdiASDFsPoWjI3HZCAnQPax/A//bTlsX19ipmBiJ57rvF6JAJ9woTY+zPkFDMnbPDgwZg8eTJOOeUUzJs3D+Xl5ejo6MC6devw4YcfYv369di3bx86OztT77Lv6kLOZz+LvPHjMfnGGzH6zDOhvvBCRtafDF7L5bquDwjj+HGHaEdTGQ2ZSSeTUopjx46htrYWuq6jpqYGxSx7SCkUszwdt6pt25Blm0pGDh0CefNNz8cXg3XliSec18gcr/x80DFjuEPoa2uDzyFjGb+D2C2Y6LrB6xSbjUIhRy6ofZ29BfnoIyhmU48d+vDhGHT77ZxHSsvKEP3EJ/jr0VNO4X8rra0gSRqdksHeQOnz+VBeXo7x48djwYIFOPXUUzFs2DBEIhF89NFH+OCDD7B69Wrs2rULR48e9XzuBW6+GeqKFQZHNhQyss1mTwbRdWRfdlmvPocbPm7c9gHHyUxGSk+ETHEy2Tp27tyJ3bt3Y9KkSRgyZEj8WlpboZpcQgrAd9ddIA6aa+pf/wrtN78xOIYeYDGOphHmEPZPhwyBLjQXaWPH4ujUqagSJk64SRbFHbOxEdqCBfDV1YEcPgxy+DCoOVWoTxGJwOcybUIvKeE3Ab2qCropQA8YvE0G9e23QZqaQM1OyHRhb/whhCAvLw95eXkYOnQoKKWce3TkyBHs2LEDPp8vrnM9EXIuvhi+pUuN4wHwHT0K9RvfQPDuuxG95JJerT8ZvBpHNqFCcjJPXui6jmg06qjCkQyZsKOAcf00NjZi3759GDNmDM9ecuzezSsYrJkPMLOW3/senM5U3403IiKM0E12fAbFQQaNAlBMPqY+dixw7BjPWBYsWYKcHTuSH8TuEDmUgn1vvIHw7Nme1pwuAvff7/oaLStDnm0Ur3bGGcAf/2i8busbUGtrEU2zaRVILlsVCARQVVWFKvO4PT09aG1ttUjQFRYWoqSkBMXFxcjPz4/fX1sbAnfdBQDcebarkPjWroX69NPQLrgg7c/ihFS47d3d3Se9HR0wmUzW3MPK4+mMM8tEuZwdc9WqVTh48CAvjzutxX/eefyEJgCIrSxOzawj6e6GYjqjqawBQJz+pcgronl5Fq5l5KKLEBYMhl5a6snBBIwLNHL22cbfAAJpatOlCrW2lstqAIBu8jEBIHjPPbwcRfPzLcZQFW4ARNPgs2VD00EyCSNCCAYNGoQRI0Zg1qxZOO200zBlyhTk5OTg4MGDWLZsGerq6rBlyxY0NTXFKR0oa9bAJwQNYpd/9o9+BJiSKX2FVASEAZz0XKKPI9xoRqnYUmZHe6OFyxIFjY2NmDt3LkaPHh2vBiIOfzApSKzcSVpaoLa0QLeP7lu3znP5mQfrXV2AGawCVsoR459r06dbRvMyB5MmKYvav1Un3qdqjnF0Qqb0hp3k3/jxly0DCYehse787m5oc+fy78Fnyw77H30UZMcOZF9wAfLLy5FfVQU1hYbQVLnmOTk5GDJkCKZOnYpTTz0Vc+bMQWlpKdra2rBmzRp8+OGH2LBhAxobG9Hd3Q1KKbL++Mc4YX2qKOh+8UXLmNCcyy4D2b3b81q8QHIyT0KkQkpPhEyUeVhnXCAQQE1NjWsUQtatM/grJkReC4fwnJog0ozbNzOOe/Y4T6gw4autRUAw1No55yAsZPP0yZNj6/NwXEVwkn1PPNEvoyb9jz1mXYP5/eulpdC+8AXozFE/ehTIywM1uTdKQ4OFT+WzdeCng1THSjL9zdGjR2POnDlYvHgxxo0bB1VVsWfPHnz44YdYsWIFtm3bhiNHjiD7W9+KHUswwpQQEE1DToqcs1ThlUvU1dUFv9/PpZ0kTg6Igboorp4qRCH1dMDK4wAwZcqUWHncBkYToTk5vLmRTp9u2aZHCKIpjICSCNPPEoF9drJ0qdUZND8XzcnhmUttwQIQM5PKcEgYZ+sFbt+Wun694ej2FShN2KypmuV6RodSWluBrCxeqVIOHbKsXV2zBrmf+Qz8b7wBEgqBdHcj52tfAxzGUTovJ/3xvKxzfdiwYZgxYwYWL16M6dOnIz8/H01NTVi+fLkx1/6f/zSOJdgzffhw6HPmWChkhFJkX355Wmtxw8etXH7SO5mapqG1tRVLly5NK+oW0ZsyD6UU27dvR319PQBg4sSJCYWy1V/8wvKYmCVGnnmDoa/GZ95u2+a5AYiLy7vwj8Rj+IRJQDQ725LJ1MxGGcBbyVytrwc1y73KkSNQNm1y3TYjEbimwffMM7F9CgZDM4npuil9QVpagK4u0LIy43EkYkgasbWvX9/riLW33d4+nw9lZWUYN24c5s+fj1NPPRUjRowwZJMeeQSKeSPtnjABmhAM0MJC4zMsWRInl5JJeDWObN5ufwrTS/QOuq4jFArhgw8+QDAY7JUdZedIOrPH9+zZgxUrVmDYsGHIyclxP98OHADMhj46Y4ahdwtAu+ACix0IOugd+oQu6kRgwbpiOiT8efP/6MKF/Dl9+vS4Lvfms86yDrUQ4JThtHR0iwMwNM0yNSjTUJYvj8/qIeZUssc+k5pAwmGgtRX66NGxN4ije6NRQ8FD2B+JRJD9wx96Wk8m9YZZ5/qoUaMwe/Zso3pUVASfmYwQfx919274brrJknwAAHXlSqCX+tkivAbrA4XbftI6mSIpHQA6Ojp6fVNLt1weCoWwatUqHDhwAAtMxyyhE9XTA+W994zthDVbhMSZXMTEiQCMiCpOVN0FTHpDccnOsWOEhcwYAJDWVoRMJwwwSkCpQNm0CZoQBdrniGcavn//22IctUmT+N9Rk3fFmqoIpfC98w53MgFYO9IBZN16q7kjLZ4r5QG9icCdwKZmTBw/HjPvvpv/bg233w5qSm7ohPDsLaHUcDT7CF6dzK6uLi6oLHFiQ8xe6rqOnp6ejGlcphKwRyIRrFu3Djt37sScOXMwevRoR6UOBvXJJ2MKGZMnc2dBv+giUKGrXFRf4PSS1as9VVn4BCO3YH3kSP63smYNH2rBUGB7TEW+tapabH8cbNePWleXdL3pwueQ2dVHj7bYVn5fYgmMAwegT5vGX9dMtQ4I2xEYoykZhcH33HNQVq5Mup6+nJymqioq/vnP2Oex6W9m33svort2Ga+ZSQii6xmVkkqV2y6dzOMAu/alz+fjc3R7g3TK5a2traitrYXf70dNTQ2fyZrIyVQefZR3EFpGiZknHlUUKKZzZOERPvywZ+NIKTWMaQIotshbfe89KOKEC5f32+VC+HGPHIE+axZ/3NdOpt+WkaCCNBQtLQUiEaiC/pnvlVfiRmqKUN95B9kXXoj8qirkzZwJuOiGuqGvJv6o777Leaf6sGGYMH06/Kxz1TTG7Hdof+wx7N+/H11dXRmfD5+Kk+lItpc4oeBEM8pE046TxmUitLe3o66uDpFIBDU1NSgxr9FE9lh57rnYAzPRQH0+oKoKdOZM/lLB9u0808/X190NsnGjp89B2ttdK0ii/rD/uefgM2ebM2cyb/Nmy/YWpzIS4deu474FLWPAaE7sK/hs4zKB+ASDxhwd5ngdOABt/HgAhu3RzA5zvmY2f3z//ljHNoCcCy6ImzhnR19PTvObyReqKJZGW726GkTXkWVmyEMC1S3yr3+l1LmeCKly26WT2Y8QSeks2lEUJe3yjB2pGFhKKXbs2IHVq1djzJgxmDFjBi+PJ3NW1Ucese7LvKBY5BgWOvOIwMVR9uwBWbMm6doIIVCPHIHi0KkuwmfrPA889BACAq/IrWvbYhrFbmpYy0BqQ4OFMJ9RaBrnCvHjCzcDpaUFZO9eixOvvvmmZUSbvWRFDh+G/7XXDNmQ3buRe9ZZKfFK+yoCDwgSVtGzz4ZP6P7nnZHm4+Lly9Hc3IyVK1eitrYWDQ0NOHjwIIJJzgUv8EoHGAhk9YEOVh63a19mSkjdiy2llGLv3r1Yvnw5hgwZgrlz51p4vK52tL0dxMyIUUL4CEmUlwOEQDcDcwpA1TQQBy6gIlxDiT5HxbvvWoXSWVDn88G3bBl/Xn3/fT75h1VU8m1Opr1y4lRK5/SoSMRyXHXFCpAtWxC4+WYE/u//DPpPhuCkjywG7ADQU1Nj/MHUBg4csDSt6uboQ7EZkSF0xRWxY7W1WbjlTujLTCaamkCY7JR9mp557rF7RkCwYTmbNmHD+vVYsmQJ1q1bh71796KjoyOtQD6VYH0gcNtPGifTrn0pktLZD9Zb46iqKiilSU+ccDiM1atXY//+/Zg/fz6GDx9ulbtI4mSSjz4yPhN7rOsW/kvPqafGtt2yBbrAv1NtUhKO+ycEhS7TLTRBVoj09EAXysfKoUMof/312LEEMVrXb8T2OQO2Er0qNDc5rTNdKPX11k55VTWEi9m+9+zhHEbAuDkozc3wvfFGbBvb2gms2Qa1oQH+P/3J85r6JAJvbraUyrRx45D1f/8XO6Ytk5nV1ITZgwdj8eLFmDRpEp+aUVtb2+upGalwMk/26HuggpXHQ6GQo/ZlJpxMtp9ENjAajWLdunXYsWMH5syZw8W2RbjZUeWdd/i1Syjl8kLUDM6JbUa5vSQKuIuriyCEoPzddx33RaJRC49eDGb1GTMAAAGbI0i8VKHcnqcUefPnI+uPf0TWbbchd/FiPqmsVw7ZkSMW55dDUOkwD2L8x773xkYowjQ64sJZjHzykwj//vcW1Q/fa68l7ZjvKycz6ze/iTnCtgQIaWy00L1EfruvpwenFRZi9uzZKC4utnSub9y40dK5ngxeOZkDhdt+UjiZYnncqbmHPc6kxqUbWJORqqq8PG6HfXa4BVu38ghQ1JGkAr+l55RTEDQdS9LRAV3k/jz7bFK+ICEEJYIzZVm/TbsyKpSWAKBYkLKwiAK7Hcv+2JYxc8uG9hZiww9gSBSJTqe6bp11RjvrCE2yX0IpaGEhJ95n/e53/dIV6Yasm2+2fMf+p5+GYpZzdEKM9ebnW7YJ3H47VFVFSUlJRqdmpMIlkpzMEw9ieRxw1r7MhIwb27fbftrb21FbWxtXHve6D8V27bMKEGVqGGzELduAiYiLVZdNm5I2yRFCUGBmJ/lzpkNmoQnZ3hc1efSKQyCXSt7LztkUHyn79yNwww0p7M0ZqpCM4A2h2dlxJW2fbTQxaWqCKjSNKjZnnD+/YwcQDFooCwRA1q9+5bqmPiuXU8rvGxTGvYqdE9TnMxxloUSutLZaxi773n8fBQUFGD58uKVzPS8vz9K5vnnzZhw6dAgh8z5vx8eN235CO5mpaF9mIgJP5GRSSrFz506sWrUKo0ePxsyZM+G3daGJ+3HlEv3rX7EHYif3OefE/q6uRqi8nD8Ws4GktTUp15IQEscHYigQydp+Pw4J3xlVFKguFwbfJuGr8fCloI+W0n6ZfAl7wlaeVdessXCmeJOAmblNpF9Hjh3j8k2kuxuBBx7wtKa+KPP4nn3W8lgVfvvwoEEAAE2YXgQYBHs7/H6/ZWrGKaecEjc1Y82aNQmnZshM5skLr6MhM5XJdLKBlFLs27cPy5cvR3V1dVx53Ms+AEARAmG9ujq2f7PEqwj8xXBubizLJmQ0ia6DCOVuJ5CODvhs0kHcjgjSSJpQDQKA9azZ0GmntixrIlCH6WtUVaEPH27s6v77obpM6fEKiz4mu/9NmMCrQkzyzWfT4FV27bKoh/iEhh4Ll3TPHmT9+teWiXGAKWLf3Oy4pr4qlytr1sTmxpu8WS5BZd6L7QoBmjDAw2dzpJ061ydOnAi/3499+/Zh6dKlWL58ObZu3Yrm5mYe3KXCyRwIdvSEdTJT1b7M1NxxIL7sHg6HsWbNGuzbtw8LFizAiBEj0p7dq5rkcAAWCR3985/nf+fU1aFQIKbbj6TefXfCzxFobOR8TLtTSATnVQFQJWT43OQ2UoUuHIM0NRkNNJSm3EjjCkqhmCLz/LsRS+eKAtLRAYVxtQQorISVhOeimlJUAOB/8EFP3eaZjsDJjh0WoXnApFaYf/cwh1mYGw8AyuHDjp9dRFZWFqqqqjBp0iQsWrQICxYsQGVlJbq6urBhwwZH7tHHzTgOBKQ6YjdT03rszmo0GsX69euxbds2zJ49G2PHjk3qSLAGRgsOH7YOrRCcTLS3A52dRpbSRJfwOrFlLpUPPkh4/LwXX4yzvZziJNgbxdYYNG3jRh4AxkG0Uy7H5RnFoqK4bWhREZS9e/kapl5xheOUIK9QRUfb/K612bNjk4xGjTK2M+2QZnIvlc2bjUwgK6MncHYDf/mLoVOMmCwSgdED4IS+ymQGzJHNACySRN0VFdDMAMU+vMQnJHjUZcsSCvmrqorS0lKMHTsW8+bNw+LFizF69Gjev8GqR52dnejp6Ul6nTFuuyyX9wHcSOmJkKmRkPZSd1tbmyHeSohredxpP47cjK4uiwFkXYv64MEWB6/o3nsBuGfblCQl6ME//rH7fHHWtQ6DXK6aIrysdJ9QVgPO0bn9k0Y//WnL9rlz5yK/shL5Q4Ygd86ctOSBRCgrVsTzKcWo2HRw7I6WXlTEKQB2LTTLdrm51oarQ4eSzg8GMh+BB+64w/H7JjC+84j5OZ3Gdwauv97zcQghyM3NtUzNcOIeRaNRNDc3J+UedXd3y8afEwB2FQ4vdrQvMpkdHR2ora1FKBTCKaecglIH7cpk++Dr+/vfrRsJDh7ZuBHKU09ZpHeiZsaKOgRHdv1LOwIJqjDEpKwARrleF6pSef/5D4iL7RbtlqWhyNZACQBwmH2utLSAKgr/PLm7d6M8hUEdFug6d1iBGD1KW7SIZ/Q0UwuUOdXRz3zGeMz4jIyjKuzW8rnswabw2E19pE8ymdEoVKHZi2gadPNe3jlkCO97YLaVbyckRkhXl6f7AAOrHk2YMAELFy7EKaecgqFDh0LTNBw8eBBLlizBmjVrsHv3bhw7dizuXM9ksH7vvfdi5MiRyM7OxoIFC7BixQrXbTdt2oTzzz8fI0eOBCEEd5njN9PFCeVkJiOlJ0KmjSOlFLt27cLKlSsxcuRIzJo1y7U87raPuOfffZcbGVpQwB0jfdEiEFObCwDU1laECwu5RiZglDAYSFcXiItumtbVhRyBK0MQ0/uigQBU5uSaZRvFXAOTo0iGiNMEIxtvhNqiePXgQZBgEASAum1br0dO+h99NO45Qikfw6kzCRSza5LdaMRJDonglNH1wi3NdATuSyBbQgAMYlNOcnLiHH2fqcOaDgghcdyjqab2YEtLS1LuUSa7y4+ncTxZ4TYa0gsyycnUNA379u3DsmXLUF1djXnz5qXUKetkR5WXX7Y8JsJ4WGXJEqg2aouf8TMd7g1k/34ESkrgnzs3TqbowIEDxqQd+3vY/5rG9R8BIHLxxQBiDopTGTsR1cjewAcYwa3T3S/4l79wHWAAKP/rX6HalEK8gOzY4dzhXlgYcyqFqUXR3FxEv/pV44H5fTo2DYmw814FW6Fs2QI4qF70Bbfd98wzcRxZVgHqqqqycE5Z4xZgTI4TkaiRNRmysrIwePBgBAIBTJo0CfPnz0dlZSU6OjqwXuhc37dvH/bs2YOOjo6McDKfeOIJXHvttbjxxhuxZs0azJgxA2effTYOu4wh7u7uxujRo/G73/2Oz4fvDU4YJ1PX9aSk9ETIpJMZDAaxZs0a7NmzB/Pnz+c3rVT24ehkipFxVxePVEkgEKfbtvvCC/lEBQpAv+QSy+vq7bfH7b+7uxvb7rsvvouRcW1GjOBkbZ2VWJn+oikin6wDsvWnP41/0mZIyMGDcZvQ7GyuHxf4wx+g9mJMGusQjyslmQ4wZVGp+Rt0mw4SFadodHa6ZoqJA9UgcM89SctSGTWO0SjIgQPGfh3WSRUF2UyEvbmZd38ykHAYSgKHLBUoisIj6pkzZzpyj5YtW4atW7fi+eefR0tLi+s41VRwvI3jyYhUy+N2ZNKO7tmzJ6XyuNM+7HaUCI044vAKwMw0sU5z8+acd/AgdCGAtmcMSXc3lI0b4T/7bADGfWjz5s3YvGkTsszri7/Xng01nUy9oIDbWAJAz8vj0mKeYZMiA+A4ZYYCiF50kTXpACD7e99L7XgAfEKHNy/Rq6qFKqRPm8aD90hREdcm5txUl5GffG26bnHGxcZQommOwyP6olwe+POf4580Hd5oIACfkKHUamr4+aMtWmR5i+pBQjAZNE2Dz+fj1aNp06ZZqkctLS246KKLcMMNN2Djxo148MEHsdNBZsor7rjjDlx++eW49NJLMXnyZNx///3Izc3FIzYpRYZ58+bhj3/8Iy6++OKMyCcddyfTLepOxyBlwjgSQrDejGBrampQZJdy8LgWJyeTvPRS7G9d5xeq+p//QBVmiANA69SpIIycjJjYLT/G0qWWx83NzaitrcUoW6QPgBswfcQIzh/STJkkrgn2l7/wzRO5mYMKC+N5nvbHy5fHlaMj554b01Lr6cH8a66J4zJ5AWlqguLiZLCoWJzqQxUFYeZQC0ab6Lpr2Z4SAr2kxHoD6+5G1pVXJlxbJss86vPPx3XHiggLhHS1vt4xOPB7kLvyCnY+q6rqyj0KhUK4/vrr8dJLL+HBBx/Eddddh7feeouXa1PF8TaOJxuSqXB4QSbsaEdHB44dO8a7x72Wx53WYrGj4TAgOH5O+pX88YgRoKoKf08PtNmzYy+42HNl/XpEXn0VK1euRGtrK05FfMBtr9DwDuysLGTdcUfs+TRKnIrD9etGlfHffz8U26xxcuAAlBQdINY8aTmWovAJR1RRQMvKuD1Vu7oQ+Mc/LPbffl9yBBPLZ8NGhCqHpfHIRMbL5boORajuMbAqXoXNfuqTJvEkDDl8GLrwuysZGO/pxG0Xq0czZ87Ee++9h3POOQdlZWV47LHHMHHiRHyQhEPsBCa3eOaZZ8Y+g6LgzDPPRF0fTpEScVydTLF73K59mSp6G4FTSrF7926Ew2FUVlZi9uzZCKTQCSjCUcJo3764CTuAmaWcPt1CJAeA/N27LVG7snq1NZJua0OguhrKLbdg57p1qK+vx+TJk1FgRqEWk8X2LTQaBR591Mo9cRi/FrcfmCVch9KOZZuDBxGypfmVDz6AKnAk8/fuxdD586Gm2H2ufvhh3DrZOth4RbGkEa6oQJTNK7dlJhJp0mmf+lTc8/6nnkooe5LJCNwvdJXzzylkB7s/85nYiDeBVyXCl8ERk4nUHfx+PyoqKjBt2jRs3LgRCxYswKc+9SkcOHAA3//+99NyMk8E43iyIBUVjmTojR2llGL//v1YtmwZsrOzMWzYMGQ7aFR6hd2OkjfftHDmLPbQJoNEhw3jYx8twuK27CBFLLuZ9dWvIk/TsHDhQuQ66Tgy2hF7zL6naBS6wIt2svOAu71JFf4bb4RiXgO8EQmGBmQqEOkAfIRiJMIVLGh5OaAo3CkMHDsGSojxPDuuwIV3nQTH/je/L11wMp0mGWU6k6n+97/OTa1mx3vhnj2Wc0mfOJFnv5Xduy3yS+qOHZ4l7dzgRSczOzsbVVVVqKmpwQcffIC2tjYssmVVveDIkSPQNA2VgtY2AFRWVuKQMHilL3HcnExd19Ha2opNJkewN4YR6B2XKBKJYO3atdi9ezdycnJQXl7eO6FwJ8K6jSskGgft6qu5yC9zHAobGkBEHbK33gJEIXUY5GvfzTdj0oIFOPPvf0f19u2WKQzitoBxwcDh+USI62yvreVdiIne47d9f74DBxDNzoYuyohEIshOkh20Q3Qy3daoCKR80cl0M/5O0IU56CwrSzQNqkPkzd+TyUymw4xfTdA0Dc6ciQ42GcqhQQBwpi2kC68Cwmzbs846C48++ii2bduWlqNxIhjHkwGUUnR3d2PNmjW9djCB9J3MaDSKDRs2YOvWrZg1axYGDRqU8TG/ijkogn86YRY4b1xkTwSDoCYHm4qBoe1aIYjRavw9PZh1zTVQKYXiMK+c2KSJ2P/dL76IiDnFJnr66YiKmdNegiI+mFdDIagHDsTRBdQkkkwiyMGD/F4BwDIJjTdHMpkmIUgM33STVbdZKDN7PetUoRKlbN0aNxUu05zMgL1ZDIgT0I+YDU2AMfCC2X/S3ByXNbbLyqWCdFU68vLyPPeEnGjodydTjLqDwSCampoyErWkaxyPHTuG2tpaUEpRU1MDv9+fEeNo774VZ+1SQiwcOuWFF3iEzU78ooYGg8/CHJzVqy2NQAxsL9nPPIPAF77guiYKWDKJelERNNOI0EAAoWuusZCc3dxIcuSIJ2Oi2rKGAHDs/PMRtGnKKc3NoI8/7mGP5n5dmmGiplGw86bClZWxTGaC8nwcv1PkXwp/+xOsNWMReDAYp9cGWEtT4SFDcNScL0wAy6QK3cwik0jEohXaG3jVyATkWMn+AtO+ZN2qmbg5pxOsd3R0YNVrryHr/fdxyrBhKCsry5iknGhHFbs+sIOTxB3AhgZQk7eouMjBsT1HBGdV2bAB6v/+L4gTB85FpoeOHMm7zbVFiyzOr/1YXuBGR7I/r9vK8qSzE42vv+5pxrZflPMBYlQjoXqnV1UBmsaHWkRzchD+4Q8tDqnb6OI46SchG2jnxfpsiYNMl8udaARx6xMcZ+Tm8iZRQmkcbcLvoEPsFcxH8ao33FtuO7sWm2z3k6ampn7jrferk2nXvvT7/RnhUQKpO5msPL5ixQoMGzaMl8czZRwt+9A0i9GiVVWWE1d54424dH6OeVJQU+eNHDoE3SVC5lnRBELq9ouqe/VqhP/3f43lnXYawjffDF3IlLmWkoVjpmoGil95BTlC1Mp5VLfeihUrVmD79u1obW11/R3J4cNQzWysq9G2XbyBQ4e4k+nUycj3bXssznUniDmvqo0LKyJTEbj64YcxYr1p0KmiQDMF4imMDO1Rs1kLMH5DdoMQOamqy+SnVOHVyWSZtYFgHE9U2Jt7WIajL/Qtk6Fx1y6E/+d/cPoFF2D6T3+KgpkzQZYsSTpa1wvs+xAVOAAjiOIOi13s+8gRXs5WhfGHQMzJYdeYLxy2SBCpd9/t2I3OJwepKrruuYf/jcJC7mTS8nKLSDl/q4Owuhvc5IDsto04NN0U/fvfXOd2/fr12L9/v6PkmO+pp6z7YtlLITikVVXwP/II7yDXs7ONBqcE54ebXQ5/4xv8b23uXMtr9qpNRsvlnZ18zjunWQDQxo61bCYO3CCtraAuU6gAZ6fVK0RuezL09PT0OlgPBAKYM2cO3haSM7qu4+23306r/J4O+s3JdNK+9Pl8aTcF2JEKYT0SiaC+vh67du3C3LlzMXr0aO4c9IlxfPNNqxMpRKC0sJBPpKCqyp0ZH3uOTZ4BQG2RtFhyd3reDZQQ0JISXj7m3dguExgyBaWtjXM/2UhEACjYtw+jiooQiUSwefNmLFmyBPX19di7dy86Ozu5gRSzmHFlfHMePAmHQX0+fiPJa2iwvIfadE7dvis7UVxnYr3t7a68zExF4JaJPSbpnFZXx2gKhEAnBD2sXA5DtomyTLSQafClIW3iBK8lHiAzmcwTwTieiLBrXzJbqqpqRmypVzuqaRo2bNiAwNVXo7q2lj9PNA3+886DouuZD9adKhGmo+VEDSFmk4aoaQkgXmNX0ywBulvmkD2vnXUWp67QkhKAkJiTWVoax/023mT9TiOf/CT/O5k2Md/O5nhRc5+acD+pWLuWdyoXFhaiubkZy5cvR11dHbZs2YLDhw8jEgxCEb4vsUnTUu3RNAvP03fsmJEwSSZb5IDo5z7Hg2BCqeWYis3JzGQm0/fss3H3Cn30aFCzCRUA2keN4lQIACAtLaBCg1jceM/29rixm17Bmpu9fD42u7y3uPbaa/Hggw/i0UcfxebNm/H9738fXV1duPTSSwEA3/zmN3Hdddfx7cPhMOrr61FfX49wOIzGxkbU19dj+/btaR2/X5xMN+1LVVU5R6G38JqBZOVxTdNwyimnoLi42DBepmHIlKi7uBbVXmIVnBR91qzY8xUV0E29NQYqvB6ylYoJ4Cgq7uQ40bw8RJi2WlERoKq8JMuFaG2ZAsv7CbE0nvTWBNgzokNeeAGTJk1CTU0N5s2bh9LSUrS1tWH16tVYunQpGhoaQG0TIvjcWUWx3Diin/scFwlWNA3FggivZqccuMkY2bhbuunQEQCqi2ZmpiJwiz6m6ThoU6dygXjCpicJHdS+d97h3a/iDTMV8eBESIWTmSkR4eNtHE80MBUOdhO229L+ymR2dnairq4Oypo1GPrWW9zeaJ/7HADj2hn85z9n1o7u2eMsr8YUOMLhuO5v7rzY9REdbvCJqDQMXGd39GgoZkWGZby4I3vwoKNttCtiqA7ZzmTJAWL7HNxRFL4Xsns3SHs7CgoKMGLECMyaNQunnXYaJkyYAFVVsWvXLuy47TbLdykKpluqNu+/b/leFF0HaWwEMbPGTut1vS+oKnRTEYPs2cOVRgAzkyl8tow2UIqKLub/0S99KRYUEIL1P/uZ5ZwgR45Y5O6Qm2uhYRGkb1dT4U13dXVlRAruoosuwm233YYbbrgBM2fORH19PV577TXOd9+7dy8OCkHHgQMHMGvWLMyaNQsHDx7EbbfdhlmzZuE73/lOWsfvFyeTZaLsX67P7GjrD+NIKcWePXuwYsUKDB06FHPmzDG6xw8cQGDKFASGD4d6/fUoqq9H6R/+YEgKpen82rsiFVs2iekfAgAVslF05Eho3/++ZVvdlBoCgFzBCeQXuIN2o6P0RVcX/IzM3tEBsmsXdzJpZSUQDvPpBrysIF4IgwZZ5vXqtoYMLxDLFdzImU6yzzQGhBDk5eVh2LBhXAh8ypQpyMrKQpb9wjbPH3FdABD55jctj4veeitWSratmzrwp4wXbCZUuNj9fTmpoqfHcn4wg64tXgxFaHghra2oEErhvtWreTZXzPgoe/camqy9hNdyuaZp6OnpyYiTebyN44kINxWOTDqZiYL1xsZG1NXVoaKiAjMZr4+tRbhGyv/+dxT0YiAAYHUyXaecCc6ILnCW9UmTjKkuqho/xSVJ46ITtC9/GdTcPy0r484XczKZHI5b842dCyo2IXpdj30f7H2i5jChNE5VgkmOjRs3DgsWLMB0mwxP2Dxv+CrYdy40inIli927ecUrmaUTP5W6dCm0mhrjfa2tUEQbF4lYNH2prkNJQP1KBXE8XhhJCMKaeQhBz+jR1o75lhaeIQdg0KzMjCL7TH4hcZEKjhe3/aqrrsKePXsQCoWwfPlyLBCoVu+99x7+LjRHjRw5EpTSuH/vpXk994uTqSiKo/fOvuy+djIjkQjWrVuHnTt3Ys6cORgzZoxhqDdsQGDuXJDWVpBwGL7bbsPkK69E6cMPw3f99fBdcUVaa7FE4JQCtjI0oZRLRog8QZqfDzpnjkWXa29FBcJsTCKlSTUqxedobi60c84BAOgLFyJq/k2iUeR+4QtQ2MSYqiqQAwdi72OGW5R1KCuzyn8wp004btJI3GnNTHx/40ZHzqSiKCguLsa4Y8eg2sWJzSxfs6AZSfPyoH3ykzGh3exsY/oGO/dsnYwkAXGd+nzQzbIJEd6nCuVBEZmIwNWlS2N8zLy8WIlu/nwQQaoo7/33McrkhQHGb8ZlSLq6YjOFKYWagWymV+PYZd7wMjUO7XgaxxMNibQv+zqTycrjW7ZswcyZMzGxro5nc9i0LfWJJywUnrE//znI5s1pr0UM1tlIwDgbI1AEdIHrR01KBb8ObG9zrPbYqkJEeL/2ve8BQkncksmMRHiJ3M02iLBPHqPmcVIJTxNtm0gBAwD8Niczi1VI2L5N55UgJjfES92bN8fNgPcC3zPPILp4sbGPaDRuH4G//hVk507kfPazWLR4MSbNmYOsq69O+TgWHD0aR5WghEAfPZrbc6LryD52zJJUUHbtsmTFiaZZqngAoKZpU1LltmfKjh5PHFedTGY0+5JL1N7ejrq6Oi4MXMIIveEw/OecY3Ee4vb5j38ALDuU4lo40XrHDmtpwnaDsKTdIxGDb8c6pQnB9uZmQCjxOjpqLoi8804sE3bVVdBN7Uealwdl714opk4arayEInAXeYeh+H2qKndKAcQiwTTgNKeXRKOxJhUnYXEHAW5WIu+58EJ+02gdMQIfrV7NifsRxlM0nVnVxrUUCf5xR1VV/lso+/bxspJy+LDzVKMMNP74//GP2NqEDAUdOdLy/VfYukOJriNiZuyIsRj+mlM0nyqOl5Mp4Q19yclk5fGuri6ccsopKC8vh+/GG61vNH/36N13x64TTYPv3HMTNookWwsP1s3ychxfUszSi1WhoiJQQqCm8p3Yyu0UgM4ExKurLc09vJmktJTfQyghPKMJACwfLNo7Sgj0efPiDk1t1Zi411N43v+vfyFw553GvcWelW5tNTiFAuxNTmJpWDG/34ipWOEkau66FsEWqlu2QFu82F1b+d13kfvZz8K3dCm/X/offRSqS9XIC9S6uvjzpagIvv/+13JPzt+92/K7qUuW8PsmA7XJsClpqnakym0fCHb0uE/88fl8fRKBU0qxd+9eLF++HEOGDMHcuXMtU0CUZ54BMXkyfG6scFFQv9+QV/j5z1Nei2gcVdMZ4Kc0k9pgxH1RXsO8+MNsDBqlqBk/HuqoUSmvAYAh4WFePLS8nGfxop//PLQJE7hx8d99Ny9Xs+MC1jIOOXzYiOjYY0rjom8v7hVFPPGeIefyy5Fz0UXImzAB6quvghw4gMBNN4Hs3x/X1S3O+i0/7TT+fGDyZOQJRlRjn4GNbUsgpBu3/lAI2pw5xmtNTdCHD+cvOUWymSiXOzU3Ub8ftKLC4tj7jx2DZp9rK5DRxVWoGZpS4SVL29XVhaysrJNW0+1ERqJzq6/s6IEDB1BXV4fy8nLMnz8f2dnZIBs2gJjUDeaQEAD6qFHQL7/cQgFS9uyBevPNaa2FB+uUxiUDGB+d8wOLiwHheiA7diBs6+h2Cm4tEJUvzG24k1pdzTOZKCuLOZYlJbFsmVB5AITMqOigUMrHBYtr0ZPMqHZaLzWpAID13kWCQWTdeCPyFi9G3rhxyL7sMvj+9S+QQ4fg/+c/E9ppbexYa+DNMsFmkN5pC1idRNdjLwr3D00zqDvMaYf198CxY1AOHozjPmb/5CeWbHUq8Jm6qsYDk1o1cqQxVEPAIJOzzSpBysaNfDwph3CeAzCCm3RoF8eB23680S9OZiLj2Bdcomg0inXr1mHHjh2YPXs2L49bthcyQYRSg8MjnjRmNk95800gBRFvwMYlEk90wBJZMiPBZSMOH0ZzczMOspnmAHJ/+1sozzzj+djsE+iqCuTkxDrGKyp49K0PG4ZuoYPZ/8or8P/73/yxffoQEJumI0anuimvlCmQnh74Xn0VyqFDyL3oIuRPnIis229H/uTJUHbssGzLJSaysuB76SV+8WcRghGC1lvOkSM4OnmyJQPs1TQQAD7Gvenpscic+ByczF6Xy48d47xYy37NUo0oCqz7fIgI4vwAXMXXMzVv12smMy8vL7Nj4SSSItPlck3TsHHjRmzevBkzZszAhAkT+LmtCDdpSxZM1w1ut63RSr377rT47cyOku3bnQNTsVS+cCEgNNdoH3yAgMD7A8DF2QFYpHoY3LiRtKQEyM52zF5CcDLtMkHciRIdQFirV1xOKR0OojDBza6aEZ0yBdTvh9LcDP9TTyHniiuQP348sm69NeEuNVspnzlXAfOeVGjPgibYl/01/+9/Hxs6UlRk6eBm1ASiadACAejM4Tt0CIGbbkq4ZjdYEgHmb6ONH88HelAz6ZTPZPHMqpfS0hKnx2zvqCcAlDSoIMeD2368cdwzmZkq8zDj2N7ejtra2oRzc8n69bzzkHcoCw4TJSTWyatpUP/5z5TWInKJiClkK5aF7YLh1Iy4SWMjNixbhnIh46o+9JBr5s/RJLKIS9OAtrZYxF1eHjOGJSVQTKNB8/KgTZtmOYbi4WZFYeuM97I2JM926sXFcQbT8X1Ms66wEL6nn+ZPK3v3cmeLEgI1HEaBx0lHukP2TTUdOwLAJ8yOVd97Ly6SDTQ1IfuFF6wi0SnA98ADjvIpJBoFaWmxGLqjp54Kvy34ETOd4ug2Zc+eOG5SqvBqHDs7O5GbJCsjkXlk0o5SSlFXV4fOzk7U1NSgwhbMKOb1FscP37MHyn33WWkeAEh3N5S//jXltXAn06XJwkJDOuUUXpkCgEBbWzwP05SDAwDtjDPi9ueWldMHDzZ4l6zZx9b4w64tO7+br8/moIjzuhm1wK5m4aU8bnFMbdemNnOmobIBQy5JGz2a/xaJjsOmpdHsbNDi4riEg2o62l5g37f/zTdjjjEhvAmTb8camcJhKMJxA3/6U8IyvSO6uqAI2tQ8GMrK4p+JJSpyzGCECkmEgE0Rxk4xAADfyy+ntiZ8PGlHJ4STmYkIXFEU3hxQXV0dVx63HPO22/jfRNeNjKJQOufCtCxyf/jhlFLjPJPZ3h43KxcA18kkmgY6aBDvcCaUYpHfjzyhbCOSz+2IM6JmJMheI2Y3OVUUI+IWI3HTEdOHDUP3889bOr8TwUIKF2Qo0oVucyjDl1/OO0ZpIABt2jTHNSmmkSeHD1tK6Wp9fYwvY2Y0VY9EdcWhU1+vrIxRBJhxgiEfQrZvByiFsno1si69FGd+97souuIK5Fx4YVqlFIthE0ts3d1xk3siBQVQe3qsHZyi+oD5vbLXe8vLTMU45ufny0xmH6A/yuXNZuWjtLQU8+fPR45dfSES4VJndNgw/jT1+Yzy8h//CADQ7Y0StrG6XsDsqPLf/zq+ToVgRluwAB2s7Gmep3H2SdSvdJIxclsIIQCznYQYttSpXG77/pk9idPlFK5bVqVw1NZ0Worb8zYakP+FF3gVi06ahMh3v+tYxbHvj1Fr9BEjEP3EJ/jzYVY5SmBL7U2g9n2Trq7Y2OPOTj6e0qnPoPWaa2KSbAByvvjFhMM07FBXrXKkEogVMeZUBtj3JDb72GlVwmP2OVWH0aPJIJ3MPkJfG8doNIpdu3YhEolg9uzZGDt2rPsxOzos5R4AoEOHgpgjF0OijiKTXtq5E6S+3vN6uHF88knn7m/hhA2dcw7CQkYqf926uJFm9jKOq/siyDAAgMLGdZWXG44bM4ylpVwmhw4eDHXbtpQaimKLj8/Yid2lbhAvel3ILgBml6HpQHZu3gx9zJikJRkx+0dCIah1dcZrrMPcYTKG47qcnjx2jJfW7J/N9847yK2pQd4ZZyDwzDNQzJuJ7913QWzlfS8QyeQWjlU0Ct+//mVZQ4CdM+ZNivp8lkwny6rwtfZi3i6QGidTjpTsf/Q2WNc0DZs2bcJHZqPj6NGjHX9v8sQT3B7pQjaQ/c26rsNmlYPblS1bUhawVhQFuqbxCSv265N1k1MAm0IhhMzrhwXadOpU6/7efTf2t8vkLicboG7ciMD8+caDvDxDAk50Mk0HNM6p8hJomsGkvfkmLoHg8nYxALbYjM5ObgcD996LwC23OO7XDi6L9NFHlkk8h7/61aTv93Lv4HYpEnGVwTs6cSLar7mG8+EBo4SdnYLai9ukM1XgWjKOvc+kKCVSBrB8NpZ8EpplveLjyG0/ITKZvSnzdHR0oK6uDuFwmOuBJTzeXXcZTSvCc8qePcaIssJCdDMttMJC6+jHFHiR3MkUOoXdsH7cOGQJPDzl9dcdHZSEBGsGm+AvMbNX1Cx3iVMpmOYira6Om7ggHs8pi8q1wp58Mu41T05qAuOrMCJ/URFQXg5l69bEu3I4tmrqkuqMV5uG5AbfZzCIHhdB3Kxf/9oiqiyuJfD736d2nJ07LTcaOwcowLrrzcyS3yYGbR+DZm+U8KURdYtIlZMp0TdwC55742R2dXVh2bJlaG9vR42pZei2L1WQjGKKDdTvh24K5DOEhSwY03RMtWROCEHO3r18Iloc2LQfAMXPP48ye8bQ5gSI35zS2upZTJwCvNJFOjuRPWxYLCA8dCgtKgo7DpsL7iiplGRdcdsLNoDA6uQqDlxv+3HiSucC/WbwAw+4VtQSfY+J3OxWQZJNRM6BA1AdRjv6XnzRURfaCX6hlM0rkzDoAoyLqZujJVXT1vLghDWVmvcPXRjTa7zBsINKR0fKU/JSsaO5ubkDoiJ0QjiZ6RhHSin279+PZcuWoaqqCjNmzPA08UcxM0KWLkD2RziM8LRpzu977TXPa2NdkYqZ/YyLwE3+JwUw5IILoIgZqNpaxwjYsl6B8O22DSBEWhUVAKUxJ7OsLFYur6riEa/TvhKtRXHgqSSDvYziRp7Whw41StEO01qSjWFjxkIJh6H7fJ6Ffd3KSdlMK9P+BpvIufh+/1NPgdi4oIngt0sSAdZOS0aDMM8Vn1leYwEEbDxI+2chR44kLHUlg3QyT2ykO6L34MGDqKurQ2lpKRYsWIDc3Fx3QfZgEMry5QAMzh67dumYMdDPOMPirOjTp8feZ2Zu1P/8J6W1KYqCKiHjaD+no6aDBgAjX3kFqlkBYs0lRHjdCTRBKZLarqfItdcaz+fkGGMozesx95JLLLJjrvsTmhFFMAfa0bn1kPGycEfN8jN/P3s+SYOmU1Nk6Cc/Qc+f/sS3UcNhT5lZryMyAaDEVrFjyGpvR+kvfxkr97P1RaPwewlUdN0yvc6+akZR0M2qJftcEUGDFwBXghG5mgAstAglReWOVLjtA8WOnpTl8mg0ig0bNmDr1q2YNWsWxo0bB5/Pl3xEZWNj3OhEmpUVu8h6elBmdrLZR2cpGzcCtm5FNyiKAv+hQxYDIp7oPUzGCEA5i2QDAYsDFrXpclngMaJkDgmtqAA6O3mpgpaVxS7gigqowrQFL/tN9nwixDnCR486R/FDhhiySWyGu/iaOGsXgG7SBBy5myneeO03F8BKlmcOPvutNMHh/+j883HsRz8y3qPryL7mGs/H9TlMNLGX0MTjB0xKAQ9YmDi+aMAETjIB4HvhBc/rscOrvttAkd042ZBqsM7K45s2bcK0adMwceJEXsZz2xdZsoRL2dDRo3kQpc+dCxQX85sxAeDbsiXWOc2aIDdtSkmORlEUVNkn6JjXfrSwEDrrCvb7DfqPmW3Uzj/f2DbJsezNNiKoUBEjiDmD+llnISgE5TQ/3zHTas8OujmZ4jZx60vS8BmXvLDRpdh9h7jctxztrsmz1UePhmZOm6P5+dj4z3/iyJe+5LxO8YH9c7okRAAg4BIEUEKQ+/rrAFPFEOyYU/XMDvW11xyl9fhz5veqjxxpcYqDDz5obMecaZbZtAfw4shohypgIqRqR2UmMwNI1Tiy8nhPTw9qampQZqayvUwPUp56Kp7rYhPG9TnosfH3e+wmUxQFZbZRkgya349sIcXOS+qKYjmWLwHJ2T7D1mmtImhlZUwvMzfX0HNjJZ5AgHcUuh4P1gYdL7xLcbtkcCytRCLwCw1alu3ts4gFp12vquKOWORTn0JQkMnwBAcDIHatstIJN1xCMHDg1FOxbMEC/jl8776LqEcurzhmzaLXatsu8rWvGdub57nOmi+caA2mcebZVdOIpgOv+m6dnZ3SyexDZKJc3t3djeXLl/PyeKWNG+c22EIRZF3otGm8GYKak1zEsZJ5N90U3/ASiYA4VE3coCgKCtyykT09yGaUEXP9zDnQrruONyIlQkJ+oX1KGxvVWFbGKSt00CB07tkD3UnBxP6/ac91oQQcl2FLYX1OrysOzUOMs+5oi23nEi0o4M0vtLw8RqmqqkL3uHHoMQdT8O2dmqfsVaNETpLL+coSLD6mgCI48cqmTdCTlMxFqpI9G0wB3mTle+mlWCk9Px8YMcJaPWL3YMHJtX+PqWoQfxwrQv3mZCYyjl7LPI2NjVi2bBkqKysxb948ZAs3eHYDTGRo1b/9DYD1RNG+9rW4E6fDLDvYyymqSZ5OBkIIhtgcUs4XjEQs3c5sXBoJBj05ZelkD1FRYeFjAoIR9cgnEvUbEzb1pLM+h/363nkHWUJpxBKZ2so23BhmZaHn8cd5F3jw8cfRYE4m8ezwOjn34nO2C18RsiG5TU1YePbZ0IVGo2M334wVK1Zg+/btaGlpcb55r19vvSGLn4/d0MzrJ2pObWLQmfA1e7+4f1sWQTUnPKUDr8axu7tbShgdB3i1o4cOHUJtbS2Ki4t5edxpX47nqdBMQYTJLDobhiA4AyQSsWT5eUXIpCt5gbJ3L3z2LKHpYPjC4RhtR+AOUgAYNQpwkEFLBXY7wKajoakpptJRUgL4/c7atrb7HbNJisOEOa9Nl8mCe8VlOl34e99z3o/NjoYvvzz22SoqQMzmQqYPnGtvdHEon8eN5kzgELp9Dn9Pj2XYhiKKukci2PTAA1i3bh327duHrq6uOH1SVRhwYs+sEoArygTuvTe27pISgBBH+Ty7zqnlWGvWOH4PbvAarEsnM4PwUi63z80dP3583A/FZvq6lst1HcRsIhFLIfonPxm3KXcCbeUUpakJxC6u7gBF05DnMnYxrqRhRn5Okg/OO0/9JyPLl8P3q18Zx2eZONO59AkZ17jIWry4dN1y4Xs6rn1/Dtv0xinlxzF/8/Dll3OBX1pQAOTmItvMELoR+uNgz5La3puI6D3mxRcNnUGhK3LEe+9h1ODBiEQi2LJlC5YsWYK1a9di79696OzsBKUU/sces34ep/WwG7pNLJl1aHJpEMuObDe6cDhOCskrUpUwkuhfJLOjuq6joaEBGzduxLRp0zBp0iTXm52jk3nokKWbljl2FABM/jSxaSg2CdcBdwhdun6dkCUMiLDvR58xgz9nGfmXk2NUI1LsZE8G3nX93/9CvfNO47jFxVyA3m17IEE5PMHx0qIiCZlMsaQevvRSx/KxfbvIFVfEaFSVlbGpTpWVoJQi1z6S12Gd0S9+MY2Vx+9HYzxI02kVK2kzGhpQXFyMI0eOYOXKlaitrcXmzZvR1NRkVI5EG+52Tfh8IJqGiGmruDi/U5OnpsVpWzOQ9vY4NZhEkJnM44BkZR6nubnp7Iu88ELswh86FAAMhyQatZRrqaoil3USsucFYxw3s9cBOc895166FhqLNCaLAfCMlWVb2/8A0nIy1RdegGI6k7SgANA0fkMQJR3spWLdNpZN1Mi0R6x8m5RXlxoSGV997lwoTO/UbIjJFsvQ9n0Jn4+V2JOtP1GzU2lDA5T16xEVb66RCAa/8w4mTZqEmpoazJs3D+Xl5Th69ChWr16NpUuXQjOz3uL6WFmNjx9l6xw71mLwWLMDOjvjswgOTQV2h9YLGNdZOpnHH+mUy7u7u7Fs2TIcPXrUsTzutC97sK4IgwgoIbFzze83/rW1xXEcs5hguahT2NjIqTvJoAii5XEQ7gM6G8MLAMEg1BtuiBMdzyRUdr2WlBif2+P7KIDgjTdCmzAhreMmPY6Y8ROeDiQY68ntyogRRlaW8RDLy6GYmUxaVQVKKQJCN7iYVbWPY45bVqIlO6wXEHiPjBYkBNfZtbUYPnw4Zs2ahcWLF2PSpEnw+/3Ys2cPOq6/3upQRyLO3e+hEGh2NkLsWmBce0YxEkeUdnXFjQIVoaYgb/hxtKMndLncaW5uIiQytKpZeqUA7wqm48dbpqQQABFBew0wHEyxlEnWrUs60SVHmEBjBxGntAizsO2SNWw9cc85fFepNOb4VqwA2bIl5jCKHdJ2knaC75s68JCSRd+On8fjexOBZ1grKzl/UjedzBwzGgcQ56BHTzst1oHp0pnpFPW7gQDI+tGP4LM1UgVMIWpCCPLy8jB06FBMnz4dixcvxpTJk5FtdvqLxwoL5wYXly4uBrKyLDQONjKSHDsWz39yKOP5Et24XUApBaXUc7l8oBjHkwlutk8sjy9cuNATlcFpX5Yyd0EB79CFrhsC7abOsIhCpq5gp7cIDmsiOO2TQ7Db6vr1lhKw7w9/8LT/dEAF7jwtKbEMgnAD376iApEf/xj6lCmx/SV5Typws69+FzF7EdFPfzo2kKS42HA4TdvJyuWKkLEVG5lESUBy9Ch31Pi2Nikii+qFy3oUMxDhTWPCfVPZsYNrPquqipKSEowdOxbz58/HUDPb6pSYoT6f5fnw1VfHd/Cz2epCIEba20EZLcnhM6ivvuryKeLxcawInZCZzERzc1PdFwAgGoXChFYLCmLyPXPmxM3ZZQKt3DDYnA9CKRTbyCkRlFIoYnbQBrJtW2y9CZxRy3s8beUOy0UdDCLnG98wnrdPRLILAieasJBEZilVpPteqihcvkcXeETMSOSJMkK2NWvFxfy4mpBhdqMueFmjb+VKqILoM2BKSTnQOBRFQelHHzl2kYaZRBEhXEyez/oVnH92kyOaZulyFVUT2H4AUyXBo9YcA7umvDb+DJQyz8kEe7Cu6zo2b96MjRs3YurUqQnL4077inMyhS5aWlHBByYQTYPy6qt8wAUf05ufD184bHRf2/aveBjT27pvn+MoP8C8PgU7CsDiBCRrqOkNLAmH7dvhN3VDPfHpWfe9kMntj95hL8fQx4+PC9CJUBXK2bzZUZDcfgxl504+wY5/Jy46wwnXbLOJqtAARgD42KAREV1dsfNSOD53VIWqJWD0Q/jZOcZsJ8ucVlTEqklHj0IfMsR6LLG6abP3iZAKJ3OgcNtPOCeTlcfd5uYmAh/naANZsiQmhVNSwrN3+plnQmGjF800v2J/v8O0GLcRaZFIBOvfeguqfQ4ti46ysmLr8BDNeIZ9Frr5v0goF6NJlTnWTI6EbWfLkoqC3nGdj7a52ekgXQkky/vEOfNHj8YMo1lOyzEDCgBxIvx+0VCJjlEC2Q0R1OVve/aTaBoC118P33//axlPBgD+Rx+N36/fj3zTWHbPno2IubYuAJs2bUKUlXYUBUpTk6NuKrUZdlb+IeGwp+yLCHZ9eo3AC9K4qZyIePnll1FUVMQ/f319PQgh+MUvfsG3+c53voOvf/3rx2uJHKKEG+seb2trQ01NDarsOn9JENdd3t3NxyoCBn/NIvT91FNcR5hTUJgWoUM2JhEvk1KKXbt24eD998dd67yEGQjET8gRgsm+dNzEDJ5v7Vr4zK5zca1uTq696ZImqcyltb40t6NVVRanEkCMk1lVheF/+Ytle8UlAaFs28bl/3iixqH5prdQHSTf/P/4R0JOevj883kQpBMC37ZtyGJJic5Ow3dgVcpBg6Ax3m9nZxzfWEwakObmOM1kN8hMZh/CrVwuEtZZebysrMx5bm4SuGUyVYFAbhndN2kSCBtZZkbC6vbtVo1Kh9I4Wb8+LhvEpJUqXnkl/iJiPA/BkSGaFq9zZuNAeoYH6RLq4Ky76bABMESHBUMSOffc2GuEpGwoHHkxKe7D/j7mwDHkfv7z8Jl8KbJvH9DSAp+Nm2WJZIVyHIuAATjyY5MhYhuPaT9e1p//jJyvfAV5c+bwMXkA4HMoHepTp3JDrVxxBbJM0ntWfj6ys7MRNX+3UCJ5Jjs3SnBEfS++mOTTWMGiby+abQOJsL548WJ0dHRgrVmZeP/991FWVob33nuPb/P+++/jE5/4RL+tKRHtCIiVxwsLCz2Xx532JQbryosvWpwoxdYAorzwAhQ2z3zhQuNJliFiMjTiZ9A0EIdzMBqNYt26ddi9ezcmmVPPLAEbs8sOmpNOmrJ9ATp4sNVpcro/2B7r5nhLFugzJzNqTpfLJLza1LimzMrKmPNrBuiihNEgD8oUVFFAKI0XbU/zt6Fwd5oD//oXchcuRNb//i/Ut98GenriR+famq/o0KGxrGZODqLTp8e+h5YWfPDBB9BMuxsJBPhYSxIOW875uGZQAD7bqGo3SE7mcQAr82zatImXx0Vh4FT3FedkRqNQnniCP7SctMeO8akQ+umnAzBKm6KTSRob445DdN1S8jlw4ACWLVuG6upqDHOaZ8pOdlvGKY7sLPIHndbrgrj9OG0jZPSSvR+wRtk0NxeRH/84tn0Kkg2JjtFbaAsWoOehhwCYWeKeHu44+l97DXmnnppYC0/I3Co7d8YyDnYagdv7hb91ux6bXYPO/O2Vw4eR+5nPIOcLX0DumWc6nl/o7o6J8n/uczxT7VMUjBkzBlnmvrPMTLMTT9eeaRYbIXwvv+xYvneDV8NIKR1QnMzCwkLMnDmTO5XvvfcefvSjH2Ht2rXo7OxEY2Mjtm/fjtNN23E8wZzPTZs2YerUqZg8eXJaNhSIt6MsS8krI3b9S4GmoZ9yCqiq8uoCr+rYHEPfL39pecxGW4bDYdTU1CDLyalh15TDuZgoK+jUBe0VcRWc/fuhi/cH23Gc3qOZ049oaanRaMrmu//kJxkt5acDzkmvqLA6maEQD7z1rCzL1DTdLXBhFTvb0+mM3QQAWlhoabjRhQoJBaA2NCDw5z8j97zzkD9sGBdGd2xKys+PjeaFYQ/Dwj3NFwxi7qRJXJuzpb0dG0zNUABQhVHP1EEz2i+OW3X7PCk0UHZ3dw+YYP24O5nhcBjRaJQLA6dSHrfDyckkr74akwkixDo94CtfiYmxLloEWlwMEolwIXQKI8Ol20i/AKA++STnPW3evBkzZ87E2LFjncckspGADmK5onH06rylZZiSjICMMwxCZi/4q19xw+g0EacvDWWifUfPOouLB+uTJqHnkUe4MLJeUmJ0snpco7JtWyz7lwaVIWALLuxSQ5zrM3QoSDAI3/vvQ12xwvE3V029OxoIGGVHdlPv6oKycSPv+iSA6+g5JyFsBuXQoaRTnqxL98YjMpY4cDKZAHD66afjvffeA6UUS5YswZe+9CVMmjQJH374Id5//31UV1djnP237md0d3djhfl7zpw5M+XyuB32cjkRMu+A7SZrpxONGgVqzoTuEW25vWS6bRuXGWpqauIVrLlz5yIrKwvEYa41D6ZE7jGAyP33g5oz13WX7H5vqyb8saZZmyVd3sOdt7IyzqGmpaUgra0GbcfUZOwPTmYicMdYaJqkFRWxvwMB+J980rpON4fe/H3iJuR4HD8cV8KvrIRm/q6A0Zwkrjt03XXc3pNwOJalFPfBJqHl5IB0dFgbdkwhdfZc8T//ySfEVZSWotImx8R/U6HSxY6l2rL7TkiV2z5QgvXjWi4/ePAgL0XNmzcv5fK4HU6TKpimGQCj6UdwOBWBx0NLS0FnzgQQm7YjysbEYdUqrFy5Eq2trVi0aFFMWslJnsO8wVsi/okTEWpo4FlOmkRWpNdgx/G4ufhraeedx6Ncbc4crs3otG2mkWjf+rRpMZH58nJEL7iAO4rBhx92nfFuL8PQrCzjBsacS4dgIBniuLw27Tw+H/fb30bopz/l60gEVrZi54+yaxfyamp4aVAvLuYTgADjhs+4xU7Op3i8VErmXnlEwMDiZALAJz7xCXz44YdYt24d/H4/Jk6ciE984hN477338P777/d7FtNuRw8fPoy6ujoMGjQIfr8fgQTjC73CHqzHzQAXzi3tW9+yvESHDAE1u6c10Z470FaUv/4VW7duxfr16zF16tRYBevAAcfsPC9NC0ocdPp06JdcwjmjuuCIWNbl+Gx6UDyUf9mvFL7sMssgDO68lZbC76ADejxA/X4gL493dNOKCotGpt8+jtZFDYYrltjK1GmX8EtKLMMn4hpRu7t5dTD8hS847pNlYNn9S8xu8pGQpm0L3H137H2dnSgePdpiR1mFK+zU9+GisCDi48ptPy6ZTE3T0NDQgE2bNmGKaZDsqv3pwFHfTRz7JEZgdgmekhLos2bxhxa9L5sEAwCQjg4U9PRYeU8rVzpmpiwXHeNnnnYaUFnJnd6Ii+yG1y5nz/JBaWTpaEmJZdZ5dMEC921T2a+H5xNqrFVWxgxjebmh/8k6JMeOtRhDe1nLUupmGRfz3FGSSFR5geJCT9BHjIhF5El+C6WxEbmLF0Mxb/J2Hq/S1gbNlNwCjOwtKy8RXY93sgUHRX/qKezdswcdHR1Jrz2vTmY0GkUoFBowETgQ42Xeeeed3KFkTuZ7773Xr3xMEbquY8uWLVi3bh0mT56MKVOmeBps4QUWJ7OnJ07YXKxyUHO4A3+cn8+dTFWsCDkpKPzlLzh06BAWLVpkyb6qv/sdf58FQvCvmxxoWl1tPMdKsi76vfQ4ZNcpgA8WL0bQlFvSioosdtRnTns77tB1KKtXx2xneblFb9g+SciemYz7nYTzpVeKI8eO8fnpAOATxpoCgP+pp/iaVZtKTNy+xAemvWNTnHSzGqYI5zX/jELQxoL+LJdAruuWW3Do0CGEHcT5AcOOEkI8ZTJlubwXYJ2PTBh4sNns4nW0ZCLElcvff9+SPRRJ2tTGH6HFxaDCFAndpeTEIhsCYMratZabr+/22637tL1XP+006Ew+qLiYa31Rvx/0wgs9cwF7AzeCvJseZDQnB3uamhA1Rc1pebljs4odvQkZnHhOTvulVVUWHhE5coRPJlKXLHEXxLeLljPxfRfjkAhOn5MGApZJTpbXhg2DwgTUHX4L3XYOqOvWOY705OeYrTwoavDZtT/FYCe7qQn6W29hzZo1WLp0KTZt2oSDBw8i5OBge3UyO00+00ByMouLizF9+nQ8/vjj3KE87bTTsGbNGmzduvW48DF7enqwfPlytLS0WGxoKiN6E0EM1skHHziWHxns9CD1uedAzUYXv01JwV5Gzd27FzULFsSdL8ozzxh/2CdWmf9r554LnWXwWbme8ZNd5OMSyrFlAI72jhCMnTQJPtN5WX/wIPaaSY9oUREPHvt1TQ4gmoa8M86AYoqKK2vXxqbjZWfHq46Ix8jPjxvFaHndxen3smayb59VMso2epkcOGBQD/x+KDYn09EumzaMyy2Z2XXHARvmczwpFAiAmkNcHLPsAIqXLsXevXvx4Ycf8lHCra2t/FpKhdsuG3/SACHEURiYEJJ06o9X2Pfjs5NxBaMn8toAAKWlFiczMmlSbNvnn4/T3AKMEWMclHI5JAa74xa9446YQHZJSSwjwOamJpgqkAxeI0a7E5NsX3pxMY4ePYoWM5o9HI06ckvt7+2rErroZFGBrK6Xl8dKPOXlicvBTLqJaUc6OFb2m2my9YhINNFDHzaM0zQcs9RJGnLsDUW+2loe+CiNjdCF89YugmzH5EcfxeLFizF16lTk5OSgsbERS5cuxfLly7Ft2zY+az2VjkhgYDmZgMHL1DSNO5klJSWYPHkyqqqqMCHN6S3poqOjA7W1tRg0aBAWLlxoyXb0RSZTETrpAViUF6iixPSH2Xvvuw/UnMCj2mlHtsCdUIrASy9Zn1u/HgqTi7E3z5nnufaDH3BbTouLjUY5M3tmUQ8R9+vxe0k3OHa6lqPZ2SgrK0OWGXyNW7QIRWYg25HCpKB015bK/mlODrc92b//PbLNyXaOPQYCtFNPtXBU49aYQJEiafWts9MiTQXA0jzLz6uSkrgZ6XHJCZ8PoZ/8BIAxhCN4880xHUyHc0PZv9+QemNZR0UBZVqZtoCFOa/+I0ewYNgwnHrqqRg+fDjC4TAaGhrwwQcfoL6+HgdYosZD1XYgcdv7zck8ePCgqzBwXzmZiqlhxiDyMSyjsAAgEgEdN44bMv/y5bH39fQ4XrDKxo2xbd57L6bX6LS4sjIjwmci20VFsUwmE9vuRdOTVyQqBYunPtO3UysrMWPGDFSbEWlWc7Mn4+VFB7TXjqiixDKZZWUWXTfV1qxgPy4lJKEB1EeMSHtZuiDsHncESi1c4Li1OcxOB4wsUPjSSxG+8krLfv0PPxwjvAeD1kYMF/1UBqW+HuqBAygqKsLo0aMxd+5cLF68GKNGjYKmaXzW+t69exEMBpOW1ru6upCTk+OZv3my4K677gKlFBMnTuTP1dfX42ACxYa+Qn5+PqZPn44pU6bEfc99YUfjBkuIwVdhIciuXTGbCoA0NoJs2gTq98c1poUcyoTKww9bjy3oMYoBlz5yJMAyZiUlsUC3qIjzManPZ9ErTMe+eH2PF4cvWFwMUMqbJrOHDkWx+b0W25qH+qPLPNExwj/8If9bE5ItiqCV7AS9qMiS2Yv7/hJUh5y6/uOkgezJAqfMqIfyc/B3v4tx2SdMQOSaa7hkYPf//i/CV15poReRzk7kfvazMXH3YJAnaOKqVOY1QQD4/vUvBAIBVFVVYfLkyTjllFMwd+5clJSU4NixY4hGo1i6dCkaGhoSltYlJzMNVFZWugoDZ6rMYxFjj0QAJ3kYNnWBUj6ZgADwffe7xslqnsTqsWMWR7Tl85+P39fRo9xp9N16q+OaGBeIC/EK2Uv+t+kYOMrZuCATRinRBa6Zendc2800NiW2SRuuSFM+xSsIDCeJk+rLymKzdsvLLVM1HN9PaWKdUFsJKBVQYSSkHb5nnzUmADm9z/Z/dNYsBM2brj5yJEJ/+hM3aDor/diuG58grUVsNwgnqaus666zPOf3+1FRUYGJEyeipqYG8+fPR25uLqLRaNLSOptS4UVPMxnuvfdejBw5EtnZ2ViwYAHvnnbDU089hYkTJyI7OxvTpk3DKw5izQMBiqLEmgxtyKQdZU4msZ+r4m/LSonDhhkvsff/+988a6kJQY/uEOCKmrFoa7OOr2TvCwQQqauLZS/NmeEAgOLi2HnuMF3ICfZqQDrwsof2kSNBjx6NzQMXuO2KTWLMTSXCggRDInp7P2CjPml+PrqXLEH0zDM97ddt2o0oI9Sb9YlOptiwadlfkkZNqiiIfuc7UFgm0eTxMvUR7fOfR+jWWy0BVHTBAuglJZbfOYudm7YMvcj9tzdzEUKQn5+P4cOHY+TIkcjLy8PkyZMRCAQcS+uapnFueyYymSeCHe03J1NRFFdh4L6IwMnrrztLAgnRvy40sKivvALl3//mvE09JwetX/kKf72QiQwLIACUZ58FWbUqLmsKAFpFBaI33WQ8YFlK0zhaMpnMkfMwRYd/ohQMpdsFnmgPvnfeMbbZvdvg6JjOnL184bpvISOXySjd0iH96qsWIj13LMPhuN/e6xq8bOfWtc5fz8tz3Y/vxRcNuSQnmL8p+11Cv/99bJ9sfrBpKPedey567rsPmsDBBABffX1MNNvkVVnWxka+mcfyvfSSZZqLdTkEubm5yMvLQ1lZWcLS+pYtW9Dc3JwRw/jEE0/g2muvxY033og1a9ZgxowZOPvss3HY5M7aUVtbi6985Su47LLLsHbtWpx77rk499xzsVGoNAwUJHLgM1ku58G6/dwQu8TZNrYhEsrrr/Mmy7DAGc4VJqHx6+PYMcC0e+pjj/EskbhNePRogJBYUCgE6FTIZDqNunX5gN626yW6Kyp4JpDm5wPZ2TEbZXO4e1sd8vJ+N949APhM54M1tzDHPREnHoh3lmMHS8+Rj9u/MKOeAJbzgz9va0yL22d1tVH1Mm2nPniwIQfHqopDh4I0N4N0d8cCEL8fQTYyVJiwBiDu3iLe69StW0EY594GTdPg8/kss9btpfU77rgDnzYbQ/ft29erhugTxY4e94k/QN84mepzz1le45GiTf5ChO+qq/hF1T5qFPYIU1xEx0K82JXnnoMqOANALHvZwbKjEC5eMQK3ZTKTjaayyEE4nHxenEkvp6yOWKlK3bEDuZ/+NO+WJjYpEi8Zy0zyM8V9+V56yVouN523dEZe2iNv2EaDWrZNwtdUGhtdP7O6fn38d8h3bP119AkT+PfOu2jN6LtrwgREv/51aGagxJoqtClTYrxYJwPFbtTModV15P7P/xjPtbUh+xvfAGxGiHEyFUVxLa3feuutuPjii3HkyBHcdtttqK+vdxzx6gV33HEHLr/8clx66aWYPHky7r//fuTm5uIRQUxZxJ/+9Cd85jOfwU9/+lNMmjQJN998M2bPno0///nPaR3/ZEXG7WgkEt+cJl4X5nksjjCllZXGjGjzBp4lcCRJWxtvBBG52+ojjxgdzn/6U2w/imJwLwFEKypiJfG8PMOBZdmrkpJYJtPjaL90J9CkimHvvouAWeFiiQRFkNIRkYyLDQC0D9fNs622kZJx24nrSXBPj3PE0l2XfT8OWpjJ9q2bNBciZDLZ35GcHJCiIt6MSQcPBlVV+D780BgDjJjmcfTLX4ZuVrgSNTRl/fKXjjqvuq7HdZbbS+v/8z//g/nz5wMAzjrrLAwZMgR33XVXkk/ojBPFjh53MXagjwjrNrkDfnNlJRdV5WUewHAcxJt/Vlsbxn/72zHnY+dOLvwtTktRamuhvvRSLI2fn8+70CITJvDOZZSXG04Ei8CLi61/RyJJDY39wkpU7vayDzfsuvhiPkZSGz3aiB7Nm4vdYRXX3Bcl/ERQtmzh5eKs669HwCxnKA6RZFxE7iIozLOAphFygt1JjIu+BT4vYC2F2btcLc0J9vUVFcWib5bJNJ3MsKlVyrKimskDjZ51FsJf+pLlPZa1M904sYFt/XrkDxuGghEj4H/hBeRPmGAht7uJsYul9b///e+44YYbUFZWhiVLlmDx4sX4u4cpGHaEw2GsXr0aZ5rlOsCogpx55pmoq6tzfE9dXZ1lewA4++yzXbc/2ZFotGQm7Sh57rk4O0MQu3YIczjFzD5rDDIrH2o0anFG7JxjwBxL+dvfWuhC+ve+B5jySJHy8viA3KEixMXAk3y+VCeWpWvXso8dQ9bTTxvH3L8f2V/5Cog5fjOd/asZoEIwON0/AIBs24b80lJudxLuQ/ge9cGD0+KxO1F4Mg3dbNgRA3aWIQ2y5I95z9DHjUP0s58FAPjMUrFmOn3Kli28qU03E1Q666cQjuf/73+RP3UqfI8+allHMpUOQgjGjx+Pyy67DDk5OWhpacHjjz/Onc5UcCLZ0RPCycw4lygaBWyRGIHhzDGnhC5aZE2z246ffegQ/NnZvKNMWbEilv0RLi57sw8tLAQx5RTCQ4ZYR3V1dsY62YqLQViZp7TUmT/qADenJJPY97nPcUc68oMfQJs61ZNeZ1+txw3MUaIA/M8+GwsIkpxLNDsboRtusO6L/cG4jh6nVADxZSx13TrbQhNE/G77HDLEKBGKmUxKufG3O5mMQ+V7801EL77Y2LeQkYycfXa8bJe4DkF5QZ8xw6Ip60XCSFEUlJSUYPTo0XjxxRfR0tKCrwh0E684cuQINE1DpU3wv7KyEodcsiuHDh1KafuBikzbUcV0kOIgOJX6mDHWa8X8zpmN1AMBaNdey192ygCR9evhv/lmw0abDYf6GWfwbFqktDRGLWLcdpbJFOyomB3NJNLd39bzzkPErDQQXYf/v/+F4jBiMaUu8F50a3uB0tpqCIt73L9uJlT0adPQY5vfnQnuayIk+7y8Ia26Gujo4FJw+uDBPKAJmoGMYjr/+qhRiJgDBojpiDKnU9myhTvSfOiF6aQyvVgLncumvJCKFFxubi6ys7NxxhlnoEaYeuQVJ5IdHXDlcl3XQV54wfnCFSOvM8+MRcOqaugrstdU1WgM2bIFdM4cY/1btlhuxG5QGhu5I1nxjW+ALF1qHKOiIna8QMCI+FkJqLQUyrJl3j5kEj5gKnDUEiMEwfJybrhpWZml8zDZ+xM972XbZGbJMfr2+F6Gnvvui30++03PpqXmZY12CYy4jHQK5zY/B1lwwzKZ1dUgLS08ExqtrATa26GwG/GFF4IqCtRNm6CPGMGzzGw6k7phAzTTEY2edZZxLLMEbxeqDl92mW353oyjKLsRCAR6PcFLIjVksiJEKYViTkSJO99FbuW8eXzKmZ6ba8nUUwBKOMzF2QFAd9AVZdeLXlLCS/D6hAncYY2UlcVK4mbHtpNKhxMyxQdPtB/7a+zxwZoaRM45B4ARBIZ+8YuU9x2HDGope3UkY2+wvoMCiJx3HgBAr6yEPnGixZ7SFLujPfPmPTqvTEOYVlfHlEcKCoCCAl4RCplOIlP8oKNGQfvUp6CXlRnNwYEAtDPPBM3PBwmFYtVM23XGnmdBElUURE87zbJNKk7mQJEvAk6QTGamy+XqE084vi7qO+pnnBFzNFhGjJ0ozNHYvNlwRoE4bSwR7KTXTz8d0ZtvNp4D4G9shGKOmlLefDOWuSwuNrJU7HFJCcjLL/P3JUQGeTmORoaVwgQHmOuD2bd1mRPc2zVkGha5KkKgnX8+J6xHzzjDup40BNlds5FJXneEee4p69Yh50tf4tM2aF4ej6wjpaUgWVlcgFivqABGjYJuTv/xvf4658pGvvhF0KwsKAcOxPQ7zWwX510JGf3wVVch+vWvW5aUipPZW43MsrIyqKqKJhuvtqmpyXUmd1VVVUrbn+zoj3K5Eom48vJE6PPn86bAdvv3zTJJ4jnhsnZKiJFFM21xYNEi3vGs+XzWTGZHRyywKyqK2VFxf+z/DIzZBNKzU6FBg/ja9HHjEPnmN3u/7wyIylOXv9ladPsUJ/6HdevoBRfE5HxYBkxwMpPNeLfD8/dg4/W6gmXFhwyJBetmkxrLZIZMDqqYyYTPB41N/8vLAwIBPmGKfQecMmWjfyidnaA+H4J/+xuiwshfwLsYO7OjvVHpOJHsaL86mYmMYyYn/vDsoe115kBRAHTKFERMI6qwi8c8KRlviDQ0QDdT5XYOi2XfbC713/8OaqbTO6ZNw6Hf/Y5386ovvQT16quNzZlzJnSXKybvIZnDYr/QU4mwPYEQUEHbTZTdiIPLBZPqpZFK53dal5041tMUvmelZO2cc7gmqBvSJq2n8x7GKT52DL633uLGLPfcc5FtNkJEqqqgKAqUHTsAmCM0AUTMBp7AAw/wm7XS3g7NzMYz4+yrr4c2eTIfPcm21ebNQ+jXv45zBJwI607IxCi0QCCAOXPm4G2BU63rOt5++20sWrTI8T2LFi2ybA8Ab775puv2AxWZtKOFO3bwknecHRUyVOEpUzhfsoAF6+wcYDfkpqZY4+OePY5yPfr06Yh+//vG2/x+kO5unhQY/n//F2uuDIdjFSBWEUogV6akETT2FuzqCRcWxuxoaamrHU1lKk4im+LV3liqNE7apbaSvlulKPyzn8VmsVdUGA6XOFLSnu1z+ztDgYD9WKw8TocMiTX9mE6mYnMymWoKn5LGzvGjR0FaWqCZU6zYMBV2brJjcHkkvx89//43omaGV4Qbt92O7u5uVyUerziR7OgJkcnMZATuO3KET4ywXxT67Nn8+chFF4GuXg1AyFya5XDmdJKGBmDYMJ4Jc+toI4AhMTN4MIjZTRkaMgTHzj2Xa2/RrCyobI666WTyElBZmeeO6FQcl0TbupUcSHc3lGDQksl0M45OGQS+f8+r9A63z6N7iA4ZNHYOsBJfVRUiZqNMMmT6M9n3F50zh2dWw5deip5bbuHbEU2DakpJRPPyjGyTUOIBgKjpZBJB9kN9+21oppFQGhtBCwpA2tqgmcR1xl/VR4xA95tvWsW2TfR3mefaa6/Fgw8+iEcffRSbN2/G97//fXR1deHSSy8FAHzzm9/EdYK+5zXXXIPXXnsNt99+O7Zs2YJf//rXWLVqFa666qper+VkQqbsKCEEpYI+ZlzTnOBk7jIn9lBFgcrkzQRxagAgW7caPF8AZMcOxwZHZfNmHrRq3/kOwkuXWjjErPKgvvQSAkx6LjsbaG3lqhKWz2D+r/eBA+MFNDsbWnY2vxcltKMucm99YUPjD55eCE1zc6FPnMjvW7SyEuTwYaPE7HYo8YHgbGlmM41XeKk20cGDuSOoV1dzWhG1ZTLDFRVAZyef1a6btpRViQil8D37LHTTyWT74aOIma8RDILm5aHnueegnX2245pSsaOZmJp2otjRE8LJzFS5XFEUlJqOoxMYl4gCyH/7bWSbJ4h2+eXGBrb0vtLQAN+VV1q5nOJEFQGUde0yJ7O6GgiFuOMaefJJLoNE1q2D+utfx/Tdjh1L2qyS8bKyS4clAVC5ZIlVQNhFVytTa+rtfpJxdCyR+5gxxnOCcdQ9EqtT5jClsD8KIPTnP/PIWDvzTOhMEH/IEHStWgXdbHooWL0aFU8/zTtVWfRNhw83mtsAaJMngxYUQDlyhJPS1WXLEP3Up4y/zTnFgFHODP7hD65yVP1ZLgeAiy66CLfddhtuuOEGzJw5E/X19Xjttdc4KX3v3r2WaTs1NTX417/+hQceeAAzZszA008/jeeffx5TWfZhgMGtIpQpO0oIQVUC0WZRXWEcGwspnjs2cWzlo49AzXIj0TRnXnU4zKs5dPp00JEjuQ1a99JLsWshO5s3GpH2dgSGDXOUi+HlchcVCXEbL68l2tbRLjBNRTGT6dD0k3Bffdw4A8SyjeLn83IGsfKxIjqZ7Jr0YgNEVRKXe2pvwKYW0bw8YNCgmEoHE2JnEkaVlXwUKS0uNqZKdXdD2bSJ78v/xBMxJ3PnTqOHIxIxqkAs219QgO7nn4dm42Fa1pQGt703OFHs6AlTLs9UJrPcNgaNG5vSUsD8QjvN8iKPdr/zHSPysa93zx6oDz9sfd6M4uO4LEePAprGDV5k8ODYNBpVBT3rLOjnn29sGwzCJ4y58n3veyl9zr7uMB9mzmCnubmGgHAKk4gY+rPTXEmlsaayEtB1i4g7EtyIHPeR4e0AAFlZ0KdMsRhDUXJDHz8e2imnADBuDMN//3v43nrL2JaVeILBWKBEKaJmRK3U1xtzpnfv5nIcqskVDt56Kzr374dm0kKckCqXKBO46qqrsGfPHoRCISxfvhwLhMEJ7733Xpw80pe//GV89NFHCIVC2LhxIz73uc9lZB0nEzJlR0EpikwqRtxLJSWgLFhXFK6DSaJR0OxsIyi1axuuXw9VGB/pZhvYdCE6fTrng0aLiozmDJMvH73zTkTMudps3nYi6TclAS8wE6Vn1/ezqTCCk8kaqUQktBF9PDUNcC6Fe6kLMe1IloDQKyp4lk8fOza5jJT4d4KyutNjL4iatlKvrjboUcLIYXR28ixntKqKV4SYHVXXrwfRNOgVFaAA1BUrOKVKOXCAN0xyznFREbpfecUy3MUJH1c7ekJkMjPGJSIEFbaZ1exkDo0ezTOH2eecYy1LlJbypolkcJtPTiiF8tBDwL59AIBIdTUvlaC8HFAUrp+pffrTlmYaxcWg626RbB9P+xlkrocJCKvr1yfdn70spZvv7Q+kMt1HKy8H2tp4iYqWl3tqcLAcz+XvRNslgz5lihGksMxAdTV37ln0zYKW5s99znAamVFnxnHpUpBw2DCMmzcjYhoI//PP80gcBw7EAq/CQkPuKMnNLBUuUaaMo0TqyJiTuXMnVAc9SwDoKC+HwigWtilo2ve/z9U4AEBnShiHDrk2gVgC5p4eIyCfMoUnBLSKCkPUn+lklpfzCUP66acjtHFjYsWJDDVKpup0El1HVmtrbOJPSQl8bHSjZcP4PfPXhbX3S+k8BbQEAmjbvz9WHayo4HZUHzaMi7p7gZfxt6mAAvC/8ILxN+seF4XY2bmVn2/Qh8SmHwCKWQ3V5s7lmUn/G29AN8cFU6F3Qx88GN1vvsnpIImQih2V3eUZRqaMo2/bNmS5TGo5kpsLhU0L6OmxnrilpbGSoy3SsBOjRR6i/cJXH3gAxHQyo9XVnEDNypWc57hoESJPPmn8PWhQ6gYkFTHhNKJhn0ne5uMuHcTN4zK5dp6M21SbfkAio7S+uRlbzRGgelERkJVlcTKPlzGPnHeewWnSNONGW1Fh1chEjKze9MUvoo1N6QF4s5lqfi62ve/DD6HNmmVIb5i/ZeDf/zY4yRdeiM59+/i56QZKab+XeSQSI1G5PCM6mc88w/+2U1FyhKqGJnRLU0Kg/fCHsS5cgKt1EMRu4A6LtjykEyYY1RPzmtTKyw0nkzlrxcUxlZCiIpANG/pdn9crRr72mjWTaWbMCITv1T7ly6S7sO04HK6//pBnckOopAS7THqDlp2N/ceOQTPvfbSyEhGbQkWiYyj79mXU7hIAPrP/wVdbi9xTTuEqL3pZGbejkcpKo4HS5mSqppOpz56N6AUXGPt5+ukYRYBlPquq0P3aa4bclgf0NyfzRMEJUS7PGCfzjTf43/aTttTMIgLg3B+Ow4ehvPuu8bd9HS4dlgDi9AXJ5s08sotUVUEVM5lAzFCWlcW03fLzXY2kkoA36RkeR/tR4X+2f1pSYpSWPTiMcdFnBqQ2MgkWLIxdvBilZpamKz8fdXV16DQNEOD9u3XigfbGUOqTJ/PMJa2sBFTVopEJXeel9GB5OY4JzUo+M2DxmU5mxBRj9//tb7yRiDAprZYW0EAAoZtu8rYuNl7Uo5NZkKI2nkTmwPQt0x3nyaC89pq4U8trfiGI9//856BMt7GoCBg8mFdoKABVyFBRc7RfHOy6j6xpiDmZZiaTZ7tKSmJZzeJiKLbxwSK4GLfrFpmF/ThDPvwwNgaxtdUqd8OaS23vYU6NHXZZIaf39gXcStcVM2ZgrjkxTystxeHmZhzZsAEA0OzzoekrX/H8vZOurox+lsgXvgBt5kz+WN2wgXPdc7/0JQSuvx4AEC0sNJxM1kDJKkIm5U6bNcuQgPP5oG7cGJP36+mBNm4cut99lzddesHHNVgfUJlMVZw4YPsxA8JjYhv4rjz/PO/c5TxNh+k+DLyBx5Y14BNoystBcnPhY5lMk2jLid/ivF3z5HdC724V5pp6sT0tKYH6yiuO5WG7pFNvj9vXYL9N9qhRqDTPtewxYzBu3Dj4zd9FTyHrSx1EkTUHAju1/e8GfeTIGAeTdUCKJZ7mZoNsrigIlpRANRvNACDr//4PSm0tFNM4Ri69FJGvfMXojHzpJUPZQMjWhr/zHVft07h1pehkDiTjeLKB/Ua9taVi04M9SNVMWhElxGhqZOdhKGTQPRhHE7ZzXmgetARodhu6davxBytpVlZCj0Ri4uslJTyTSYuKoDDFDif0Q+OMCLsUUR7jARYWInDbba40G24jCEH0k5903ncaIxu9Ih3FElpVxTuy1SFDMHv2bJhMRYTLynDEHEnqFZkMBMLXX88pRsGbb0bP7bfzY5DubvhM+lf+mjWY/uUvQzW5snpVFXD0aEwabvZsoKQEmvmb+F59FQCgTZyIntde82xDGbxyMgca7eiEcTIzUeYhgnGkdudQmNZDKOX8CgBQ//EPy6YUQA8j98IooVsuGGZ4hRu95f3DhkFRFJ7JpEzMVBQUZtG4rbwvrjrRj5Pp6NyxQ7K4GIHf/S7Bm+IzBY4Z394sLIOgPp9RtmIO1+DBKCsrQx6bZ5+CuLzikKmN2kZyAYJRTiKlQocOde2ApNXVXJaIVlVBVxRkMb5mRQVIOIycb30LJBqFPnw46IgRCN16K/TCQijbtnHBZH3ECIR++lOEPWYxgZjDkoxLRCnNKGFdwh2JGigB9M6WdndbbaU9K8p+36Ii6MK4WdLdDd/ll0O9997YewFo5nmj7NrlWCImdhva3Q2sXBnj91VWQunoiAX7xcWWTCajJzmCZRHNh32hx2iBbcIVo2fRwkL4nn026du1yZNjXHH7dJ0kuonp2thUGnRE6JWVnD/OpoqxTvPKWbMwzWwe9YwMNTlRRYE+aRIP2PXx46GbzY60ogJdH3zAdYMpIcjeu5cHLTlf/Spyv/AF433V1ZxipE2fbjiooRC0uXPR/frrnOuZCvpbpeNEwcApl69dazFYiiiRAGspHQDopEmxbYXGFsC4sI6IAqR2XqbNeNnBnEyWIQPLZAqzylkm064r5jX6y2SM7mpo/H7e9OO4jVDy0cyOfTZbONPIxBxcWlkJKArnOrLpD9zpTDKyM5kzrSe4ESTqgNUrKoCcHNc55fqQIZxHRKuroes6Aubj6Oc+B334cG7gtWnTzAVSkFCInyfRU05BV10dwr/6VUqj6RhZ3cv0CZnJPL4ghPS6KqSYI3ndznUuvl1cHJOsMaH+619xdinCbpZHj3JHkcDKfbfbP/9PfhI79ysr4WNBYH4+EAjEMpnZ2XETV+z7E5Gs+7e3cJ1wEw4nvP7Zdxb+0Y9i1S42npBtk2SkcbrWMd330dJSqxA7YOng9q1b16vjuAq3J3tfYaFxPMFeihUhfeZMfo/a++MfY++vfsX3SyIRqOa6lQMHkDdpErLPOw+Be+4BARBdvBjdL7xgBDppwGvjz0CzoydMJrPXXKL77wfgfBISGDwK8XUiiA07vc/X3h7b1qXT0u14aG+HoijWcrlIXi8pQUgw0MkuwL7OBLpyQhsaEpbHeYYgKwsa07ETuK/J9u8E18+aSrOT2y7MuccWOYuOjtjUBpYhcYG93JXSihJkl6iZVbdkLltbOa+VDh4c6zQfOhS6rsNvZjb18ePR/cILnC+kfvghfPfeC//dd4MEg9CHDUPXW2+h57//9aZfZ4PX6BuQnMwTAb1xMnVdR+d//gPAds2aZWCqqjE5M1UFaWmxzqoG+IQzhogZeNmdLEYJAeIrCGTFipiTMHgwVNbowxQr2LSVurqk6g5iKVp34TtmCm6d7K4T02zQFy3iTqZmznvn9lcYsAB4p+H0FXzvvx837UdhsnCRiDGZKRX0kkfMQAsLgXCYl/LpkCExIXazosiczp4hQxBhDb+jRqFr1So+2Yf6fFAOHID/7bdBQiFEzzwTPU8/HZsElCJ0XQel9GPJbT9hnEwg/TJPW1sbNJOsbuG6mJkpXTBozPAotjKL3VgNeeONGD8zUVThkL1SGhpACIGflcsrKw3BddMI7Q8G0ca4Ry6wRG9Dh/brJAi2f8WmOeo2RjJ4yy3ciWcjDtOF/XegLs+nA3XjRuR85jMx8d3Bg2MOZ25uwmBCXAtD1Oye5Uggtpxo/Yy6IWZYuVNZXg6Ys8eBWCaTOZl05EiDr8XKkseOIee665B1110AgNAvf2mUi9IsR3l1MsPhMCKRyIAq85yMSJd6FA6HsWrVKmTZqjrmTgEAtKyMZ9TYKEmWSRQbBkX4XChFEK8de6WIUoA5mVVVsUwmq5KYx9Zs1Sn+fqe/i4qgf/3rx8UpszufukvFhJaX82qXNm+elTplc1R7Yw8z8R3kfOMb8Js9EOTYsVhQ4PPB//TTveoFsD/2KhkHGA49t+mBgJFxtdOQTNsZLC+P0Y5GjoQ+fjw/v8M/+AFvFo188Yvo+c9/4ugQqSBVbntvx0qeSDghyuXpEtYppdizZw/WfvABcpym0jCRbRt/wuKI2iWLbP8DzhEq384p4mhqgtrZCT8zxJWVMeORm4uPdu9GRbLpD8K69PPPB4QydF/T2dn+FXtTkouMRvTyy3n5X+zqY69nYi1ekLSUAsBXVwfFnHajV1XFmm1SGE3JYNcSDBw6lF4wwDIzYiaTGW2TXC6WzjVNg49lMocPh7J5M0h3N6jfD230aMuu3UaceUUqAsIApJPZD0hEXUiHenT06FHU1tYi4Pcjx8kusSyTkHFkGbc4uR1hdjUA5LS1OV8H4oxr23uAmM0VnUyeyTTtaiDBWFs7aHExkJeXElWkN4gmmkcujMtkoH6/Id3Eql/V1Rben9svns69wLOCRpLXmJJK4L77kMeoCPn58P33v2msKgb7mOBU7iGkq4s3rlEmxM5sfFUV0NXF6RbBsrKYkzl6NEhzM08+Be6+G0TXEbngAgT//nfHcbupIFVuu8xkZhjpcIk0TcOGDRuwc+dOLGxvd+wCZyXKhIRvVXXkRFouxGDQoidIfb7Y6w7GhAAovece+MzxZ7SsDBEzugoPGoRFixbBb2bTXCFySk8/HbogcnzcGmmcfp+8POiUcuOoT54MXchS0H50Olw5suyP/HxoM2fy0l3g1lvhM0V74xoQPOxfsd0cfeFwWkbfV1sLBIMxsvrgwVb5Itgc0K4uLg+jjxgB1RxAQCIRqIKmaeTCC3vNkfXKI+o0bzgDiUt0MiJVO7pv3z6sXLkSI0aMwIySEudsPtufg4NGhakngMs1yJwqn49vbxmx6CJ3RgsKDJUOZkdLSnC4qYk7mU4d2nH7MLNPvCSfAp+uN3ZWdZlHDlg5/TxZYeqBci3lsjJEzj23FyvIPCyfgxA+cEMvLuaBAjl6FKqpO5k2bJneqFCJTAYCwP/448a6WOZS4LpzO5qfj0hODue26yNHchF2th9aUIDgX/6SlKvvBZqmgRAiOZnHE6kYx+7ubixbtgw9PT2oqanBIHM0ksi/AcBLOXbDqc+cCd2UhCCCY+BmVAicuYYAXLknhf/8JzcmHYEAttbWAgAC1dXIVZS4rvK4YwpOMy0pgX7eeZb1JIObvlmv4PD7aMOHIxqNct6RVloaaz4BMnKBJkPSz8bOh64udAtC0/733kPgwQeNTczfMdOiwInAqQDBIPz33x+bnuGQyVSEx1nMaBYVAYWFUMxzi0EvKUFHSwuCDz3U68/gtVzOplR4MaISfQevdlTTNGzcuBHbtm3D7NmzMWrUKKiiPqZ1Y+N/obGF+v2I3Hort1Ph7dvjBlcw8EpQNGrMhgaAjg4+s9pi62zHVRSFO5nHfD5sXLbMcYys27Wm1dQAMBwhAFwgvi/g1sAZtzaBzsBe04YMMWgOLFgvKYG+eHEfrNI77OvWmEoKjN+Mcdm733sPoWuvBZBeUiHO5tr4mUQ4rpf9qO+9ZzxmVSAWvFdVcTuqV1dDpxQBJiA/fDgC99xj2V/wj3/MWOY7FW57d3e3zGSmi0RlHq9coubmZtTW1qKkpATz5s1Dlt8PZdkythPrxqYxIkLWUJ80CZG33uKGLXrllVzzMKFTIETboj4m6ehw7HxmhlDPz8fyNWtQziL40lIof/1rzLH14oSVlsbmpXpE3IoycPN3+n70WbOgKgqPwKNFRYiKwsvHcfKPHYRSqMuXAzCMYfjKK3s1/jKTVAD/n/5k7LOwEMjLs3STWzrNBw9GDpN3GTEC2ZdfjsC//21ZT/D++x0z7OkglSkVubm5nrrQJXqHZOXyZHa0p6cHy5cvR0dHB2pqalBqZruVp58GEB+s8+qOKVoNANrPfmbQeACj6Sw/H7o5L9oOkVfNSpUEVoeEOaiWT9bTA0XT4DfL5W2EYL45M9sLKIwqECBkWj1ULBhSLSsnraSw7ZyqbpWV8Pl8fBRxpKgI0RTW2h+wU8O43FJVFU8m6ClqRwIOfExbUkhxosIl2p8ZlDhWgYRgXdd1+E0n0/fUU3yYBWDY1uhFF6V03ETwSjsKh8MIh8MDinZ0wqQdkkXglFJs374d9fX1mDx5MiZNmmRIq7z8cixSZhxM+zQF1p0IQL/oIqPLlnXx/eAHiCbQguSGdu9e5w16eoxRaOJ7xAfd3ZheUYEq1qFZXAzfLbeIHyz2pxshXJCLcF1nwleTUAZ6g1GjEAgGuWFQKiqgjx/PX44bN5kGkmlvJr0ZCN+x3+ye1aurEfrtb6HZboypuEjpuFNOnF8KcE3V7vJyHDx4EDDPN33oUJCWFv496lVV3MlUGhrgf+IJy3qin/xkr3mYIlLhZA6kEs/JimR29MiRI6itrUVhYSEWLFiAbGYzEZvZzDP/NmeWaBqXiKFTp8aaf8wsofa1ryVdn+ioWJovHTJGhFL4HngAATNjNmT6dBQkac6zICcn1pDIMqjJuPBpIGkziod9KAcPItDQwGkEalWVZWKSiExWW1LZl5M2MB00yPieTZtkv0+ls9Y4p9Mj99ZOddseDKJhzRo+P14fPNhSESKdnfCZr/lfftmyr9BNN7k2uqaDVDQygYHFbT9hnMxEhPVIJII1a9bgwIEDWLhwIaqFrJ4o/stK106daqw0Q0tLge7u2KjEsrLEJV3zx3YbrUgArhPmBEXXMfSLXwRMMjJZtYpHWoCtqcgh+0QVxZjRa+og8ucd1pEITjptyYjdlsduTVurVvGbE83Nhb+wEH7h+/TCm0oGpyOnQhkQt2UTQpichWKTBkm0n0x0+Dtxfi2fJSsL+/fvR8icOrFfUdC5eTMAQC8tBQ4dQo55LtgjfgogdMstcc5Bb5AKJzMvL09mMvsJiZoonewopRQ7d+7E2rVrMWHCBEyZMsX6u+7aFVd1sNuM6DXX8IoKHTQoJsnGsoSCw2rZj/C3qFUp8oWdmn8AQP3LXxAw7aVaWQny4ovWz+X4LvO16dO5I6wXFwPBoKOWZSp2sK+grl6NnJoafk0H1qyBX5jSlQj9tUZ7hzsA3pzEZILi9Dx7UUHjnyvNEcWVc+agwAxQNL8fK3fsQAebYT5kCLKExJH4HepFRYhmmA/7cea2nzBOpptx7OjoQJ05a3zRokVWrsLhw1A++IA/TKhnycjDJSUA0/Py+4FBg2J6X07d0wJRnEXxdthnocc5uYcOQX3sMWNboTEj7nhOWmElJcaFaosQU76VO2QUk2nMAQ48VxvU119HtjklgcmS2B3i4wWnCTxMtJwLCCdrwIJLM1gv4XZjyNu0CYu2bUOeeQPvLC7GfvP8Iq2tKJg5E9WMHmJD9LzzoJv6eplCqpxMieMLJzsajUZRX1+PvXv3Yv78+RjqwC9X77gjdp47jdIdOhTa738fC5ALC3npm3WdkwROEQ/4tm+PPSfYU+py7uQePIgCdo3u2wff739v3Z/rEU1lBZbFKiriWUy7LTueYRH7HPrkyZZRtVnf+AZ8JoXGjkRyP6kiJX6/UyaTjVhmga/9HpYBfeN0P1/OsGEYySp4Q4Zg6LBhUM3S+db2dkywcTAZIpddlrEJRAyp2NHc3NwBxW0/oTmZBw4cwLJly1BdXY3Zs2fDb8v0qf/+NzeIcZk30znUZ8xAaPdu7sDRkpJY+r28HCCEO5ls/JQFIm9I0MmiwjGJQych77o0/zk2F9kjf8ER5PsxOYPE7NhLV4Q3GV8oUdMTYJ2gJG6vzZ0bI/w3NUH929+SZl37C2GhAYn/VoI0CkIhXkpJFYkMn6fPm0CmI/uqq0DCYVBCMPb00zGFOe+Ugmgacp0yCgCCd9zh5cgpIRVOpnQyjz/sdrSzsxO1tbWIRqOoqalBoVOgHAxC/de/HPfHVDXYwAAITibr8uaBOGtIc9qRabvJvn0xDrzA8RSrSXYqTLZ5TN8NN1j48MmgX3hhLJNZWMhl1lJxIDIh9yNCs93DmJh9+Oc/R8hUuqAFBdBHjkw4JcgrMmF7WTLEqSrFpaxs058Y7AFLSnJEidbk9rzgqCtr11r4mIMHD8YgM9M64f33UfLRR3HHogBCV16Zwiq9IVU7OpAqQv3uLnsZLanrOjZv3ozNmzdj5syZGDt2bPz7KIVidpUDsMx2pYRAu+IK4+/qaqCqKmZgSktjES2TJWJO5nnnxfMiBa1IIkyEIRBOTPHmaq6TcYDE7WD7O47zIVyQTECelZRYBiBTWTXuXHpsEHG7qJdecw0ar77aWBOlyLrqKihml2qqJX2vx/VqqEJTp8aMuu131SsruQHKNDx9Tlu2STRy7EZKy8qM0Z4uJX3xe+gePRqNwSCCaZaW3Jf58Zy3e6LDix09dOgQ6urqUFVVhblz5yLgwstWnn2Wl5HF6krn0KGI/uIXxvNFRYCm8Y5iOmhQfCaTOZmmcocFpo0kmsZ1iy1OVEdHLCtmPiUG6uLz7O9EATIFgLFjOR9fEzKZjlJsvYVH/h6xbaebv0n9gQPYu3EjAGNEb3DjRuiiSkcfwKsdtTiX9mawo0cBQV0kFeh90EEt+gGBZ56JnZNshLBpSwO2iX8MwbIyfLBpEzZs2IADBw5kzJ5+nLntJ0xOlpV5gsEgVq5cidbWVixatAjlLoPolddfh7J5c2w6jcAn6pg6NabOX15uOG9Mf6y0NHZBmE4mz7xVVyP6859bjkMEcrq9M5E5l7SnJ2YImaNoM+jUia9k25+FuzR7tvE+lsl0aDxKN6spHos4RKmJtrc/HjF/PjfaR8eMge7z8ZK023v7C/6mJmguUxpoZSXXouTPiX/3IpK0BypOv4/b3i030tZWKO++C/Wtt5Ies/WSS7hTsXz5cmzfvh2tra29G9UK78axu7tbOpknAFgmc8uWLdi4cSOmT5+O8ePHJ64imTJegJUjvuuCC2KNe4WFloDbKZPJyuXaN78Zf84L9tBRRkjX0WHrTOZjANljmw1NeIWybVm5fNAgnmjoE3vksSxMbE6LamZVRy1YgByTj9eiKFi1ejWiScbc9huEc4La1DiIpkFZtw6EUk/3Ics9zikY8Qj7b8iPLXB7lTVroJjcdlpdDTQ2cs6o21qV88/HrFmzUFBQgIMHD1rsaVtbW9r2NNW55QMpk9n3IoYeoaoqurq6UFdXh9LSUkyZMiXhzU295hoAzgaj6cwzMYrxLisqLCMdUVoaE7xlxHNhW3ruuaCC/huLmJ2OE500Cf5Vq+JKyQC45iGHU0SUSKLCNLB6SYmhq+ZAWP//7H13eBzV+fWZ2aZeVl2yqovkqi433GgxbrIJBBJCJ6GEQEgIIZQEAvmRQEIJhBaSL0AgodjYdDDFBmMb2youki1LbrItq/eybeZ+f+zcuzOzs01a2QJ0nofHaHfKnd2dd956DjuX56MA8Lx+AArONq/baR3XbEbChAmguVDD0qU4smgRsi+9FLwojppz6e9xI15/HYQaf1X2giQlKct16uN6eGgQwNli4eWhQmJilGTTwwQnCAgvL1ecWysrTgDEXHstiiMjYbfb0dXVhY6ODtTW1kIQBMTGxsJsNiMuLg6hAUqjBWocx3FmQQhBd3c3LBYL5s6d6/M74WprwW/bxn5bxGAA0tLAHT2KoZgYpSNJH9BGo1OdRjVdDtrvPH++037JezRlAyFE3hYUEgLOYgEHQBcbC8h6pOVtNwROB43IJsbl+7pBpwP/wQcuJbLoaMWxgw1/Stvq+5dwHMsMR06cCP2WLQCA6EmTkJSUBF0wbMgw3/O0HUlNBensVNg/PZWXDHBt4qRJgJS9HSlYW5ecapAQ6KR+djEyEuELF7p2MBo15xQcF1+MqKgoREVFISsrS2FPa2pqmD2Ni4uD2Wz2254GUhH6ttnR0+5kchznevBLIISgv78fHR0dyMvLQ0ZGhndP/vhxpj9NIZxzDvitW8ENDaGjsBA5VNoqPt6VxQwLc0a41KmkZRs6VJOYCOj1Tk1reZZLp2NOitxQDHZ3Q3sUCIppdKLTaUpTeuyTNJlYJpbExgLr17v1w6jL8MOGBjGw+jxqiGFh4AcHnZrsAMsMG1JTkXLBBeB4XnuIKQB4usZAHGFOEBTDDMRkcmWje3uh//RTz/t6fINzDjjJH5qq7TlVBsLb9yzPjhMAJDoavHpC09dxkpIAqfRkMBiQmJiIxMREJlHW0dGB1tZW1NfXIzQ0lBnImJgYn4YvkF6i8Uzm6YOWfezu7kaD1FYzZ84c6P3g4NX96lfO40l/2z/5BAaJH3AwOtplB2NimEPECNVpuVyVyURyMhx33gnDL37hWq/sdy7nPbTHxMDQ3AwOQKic7B1Ox40YjUrBjLQ01jpEoqLcMoPsfAMDMKxZwzJWxk8+UWZiRxF0zT63y84Gd/iws6ddNiugS0xEutkMnXRtgQb/owqed7N/+o8+8mtXFshI/8rVl/y5RuIjuNeCTiqLm554QsksoMW2otcrlPUAd3va39+Pzs5OtLS04ODBg8yexsXFITo62qOt/C73tp/xTKYgCKipqUFXVxdiY2OR6UcKnZdk9ChIRAQcTzwB04wZAIBBs9mlARsf7+rHpKVnOvgTHw9Yra4UemKis+9I7STIHET5jRDhYZqSGAyKYSC1g6l1QymGg+bOBS/rJTL85z/KjTnO7/KMes3BeI/k5wPbtrkmtOlnnZAAdHUpmvOHayD9KSf7A1tEBIw0qywzLPy+fdDL6FC8rVP+HkcIRJNJua3q+9AKKDTB8xBlTiUHwFFWBn7jRp/rkMMhEU6rwXEcIiIiEBERgczMTDgcDhaVHzhwAHa7XZHlDJP1M1EEEoEneqHyGsfogRCC48ePo66uDikpKejs7PTtYFqt0P/yl9B9/rnrOMnJIKWlLAi3RkeDyPsuqZ2kg2jSeyQmBhgactnR5GSQ668Hue02TaeA6+11ORx9fSDh4eAGBhTDI/R3LixdqrhP5dUHzsvQnjhrFrj2duYkx8i5iUcZJDxc08lU37uOZctgfOop53OI55XPLJkjLnfMzrTDSYaGICYlQSdzMtUJH4/70u+Z/i0PEAwGptDnCYE6mIp9VZVArQEyMS/Pa28tx3GIjIxEZGSkmz3dv38/s6c0iJfbU0EQYPJDPejb2Nt+Rp3MwcFBVFVVQa/XY+LEiejypwdlaIhF2hSkuJhF2UJ8POx6vavJOyFBoQcLQDn4Q+mL9HpntH74MLihIUXU5Mkp1PX3a0at3qiUoHEsAIqbTFy4EJzEPdlvNCJ+xw7lOoJAC6EFfw0YyclxOpmqTCZJSHDRQUnHInq9XxOho2U85f2R8u/FsHat8nuTZavVa3LrR1U/3LyVzjX2Z8cZGoJQWKiQheRlE4+K4+j1zvNoOLD2G2/0eH459Ho9EhISkJCQAEIIBgcH0dHRgfb2djQ0NCAkJIQZyNjYWOh0uoB6Mr9tEfg3AYIgoLa2Fm1tbSguLgbHcWj3o8zK//vf0P3znyBw2hvdF19AzM8HOjpYkGSNimLZShId7cpk0p5KuQMqBdwkJMSV6TQaFS1B8ooOvSdMAwMQc3OBujpNqV1e9kwgPK9UW/NiV8RLLoGwZg1M06ZB1OsxNG0awvbsGVlrkZ/gBgZ8Zt0IXGwmWsG6J/GNgNqZAtzen2Nwvb0gM2cCBw+6XvRh3+kxxOnTwUvPMgDQyUrlJCpKk3Q9mM8FX466Y/nygI6ntqcDAwPo7OxEW1sb6uvrFfbU37ajb6MdPWNOZltbG3bv3o20tDTk5ubi1KlTvmUlrVYYpIEYABAnTwZfX++Ui5IGdMQJEyCKojIqlAhYQSe1qRGWDwElJjqjSSm9bklJQagUBXv9kUdFeVSRIBwHkpLiPmASG+uWLZVn2cT586H7+GMAQHNXFxJUDetnsteRwJXJoE6mvP2g9+BBhMqO5W/06e3cIzE0eg/lNF7G1+c8iWudvtoR1A+3QNcmfwCJKi5P3oOyFDGbwbe2Oh+0st8KCQlxK/H4A47jEB4ejvDwcGRkZEAQBBaVHzx4EDabDTExMbBarbDZbCCEeG1hGRgY+Fbp7Y51cByHwcFBVFdXg+M4zJs3DyEhIejr6/NLnlc891zncQDoJK5hrqUF/Pr1AJx2k+j1rCdTnslkfLi0X1MuFpGY6MzsNzWBs1qV967BoBkkseFGaNzrkoiFc9EiqxKp7wPNY9J+zPh4bPvrXzHv0ksR5kM9Jhi2lbPZnCVwb7YvJIQFubRtC7LnkqWxEfIxJ0/roq1LmusIbNnaUFdpOjthmzABegTQtiW1T9lXr4Ze5mTyEi0fAGebmsZ3GoznAnMuExLAtbVpJoYIAPs11/hxNG3Iq0YZGRlwOBzo7u5m9tRisaC/vx86nY5lObXs6bcxk3lGpsu15CG9Kf4wmEwgMu1avr7e+e+XX4J/7jnnizodBIdDka10y2TSsk5MjCILBwCcpK7SN22ai/9RAyzlL6dOUm1DOA62iy5SvCYuXMjoPBT7yHo+7UVFzEDmyfoKtTA6OU3PECdPdpXJEhMBQpjTfsrhwAkqTUcRBLqQkVy/lhSa1jHlxk3R/+pHiSPgdcmNtmwaUgwJ8XytNCOrMsJCYeGw1qeGTqdDfHw8cnNzMXfuXJSVlSEuLg6CIODAgQPYtm0b6urq0NbWpunEjFbDemdnJy677DJERUUhJiYG1157LVPF8ITnn38eixcvRlRUFDiOQ7dMVvbbgvb2dmzbtg0xMTEKeUhfspIM8fGwP/MMhJUr2dQ2X10Ng0RHBpsN6Zs3s6w9iY5mHJmMRJ06nbGxzMlkVDF79jj/lmfBZfeivMLAy22GqszPzg/pvqR62enpXi+PxMWBSHafj493OuEazlig9tPv7X0E10JpqavqQ589kh3tNhrR9s47/p1nmPYJ8PNaVNfB22weRUk8QnqOiueeq2DtkA/HckNDzkx6oOvzAxycfbI048pp8FEjPNwl2BIE6PV6hT2NiopCREQEOjo6sHPnTo/2dLR628+kHT3tTmZtba22PKSfxlG45x6317gTJ6CThjj0FRUo+uMfXY3m8fFuvJgKfjfaB0RLv1LWcygnBxapx1MN+Y9fPiCkdhB4UXTrlxNuuslNvUexr9EI0WhkJOF8VZXmGjyd0x+M6OYNDXU9UJKSgO5uVoau6+rCRJWjEWh5J1D4Or7CYQyAFoKuRdRQR9HaTv23VtZZ/R7glJNjr8t7WXleEeRQpRWa7aGwX3211/UNBxzHISwsDOnp6eA4DiUlJcjNzQXHcWhoaMCXX36JqqoqNDY2or+/H6IojloEftlll6GmpgYbN27Eu+++iy+++AI//elPve4zODiIpUuX4q677gr6esYKeJ5HXl4epk2bpijD6XQ6EEJ8U61ER0O8+mo43ngDtlOnYF+3DsI117haYHp7UfTYY4wChn//fSYIgagop/MhK6VDbhMAcLt3AwBssvtHcffJy97yrJL8HggLY/uI1HbT9zw4mfTeEGJiQGhbCx1M0lKsCVCf2m8L4svJLC93JThU5fJ9LS3IlFpofAbRHlrMguU8a12vSVIc83sAU/pOxdRUV/ULMucPAAYGYP31r32eWwEpIPH0HcqvyXHeeSzzrij/S/8Kw6gG+QuasUxISEBBQQEWLFigaU+ffvppNDY2avbGjxRn0o6e9nJ5dnY2Jk6c6K7eo6H4owVSVgbHn/8MtLVB9/zz7OErTpoEvqEBHIDUr79m2+tvuMGVOaRfniyTyZ886fx/yRhyUk+cJTsbp2JikCNF5HIofqS++lGGhlgZgAAQCwsVRtUto2azIXzOHJbJ1Gmc/0yCP3QIhJKFJyWBSL1Y9vBwlMyfj3BJtWI4GPWG9gB6WUl0NLieHohZWeBPnHDjSKVw+/68HTQkRJnNMRrBt7U5nV9ClE5merqioZ7r72dldvagNRjg+MEP/L6mQEGdFYPBgMjISMRJ7SaDg4Po7OxER0cHvv76a/zmN7+BxWJBdXU1zj//fG1VmWFg//79+PDDD7Fz506UlJQAAJ588kksW7YMf/nLXxRBqhy/kKaaN23aFJR1jEXExcUhSoNvkvbPOhwOj+TrbggNhbhsGcRlywBRBFdRAf7ddzH02muIlAZt9H/7G9ucq6kB9+mnrgG32FjXZDl1MiW7NVBUhBCNwRBF8BURAfT3u5deZXayf9UqRP/rX673PPAn0/KuGBsLvVRqJ7Gxziys1hBSECotWmVbn7asvV2RySSDg2w4ZWpeHgxS8kMdpLrNBniaZPdjOFTL2fIHOg+ytgDcmFRYqTo8HIiMhJCfz3TOAakXs70dnCBAzMkJqDWKGI1Om6nXA4KgHJ6VUV0BgIGyzdD3VT2z9ssv9/Osw4O8t12n07GJdMBpT9vb2/Huu+9i69at2L59O1pbW3HBBRdg1apVfrFEeMOZtqOnPZMZHh7u5mAC8K9cLkG49VYIDz4I+7vvwvHAA7B2dcG+bx+sQ0MYeu891Fx5JexXXw1iMED3xhvQScpA+kceAf/yyyxNz3/9NThJS5ykpQF2O+vJbE9Kwv7SUp8Roa/3dbt2sZudA6D75z+9HoPwPPj9+13l21Eg5B2JM8cNDICTVBPsZjMapIibT0lBeHg4eCmDEQhGq+SvPq6n69ZqixCyspz/JiXBPneu5jEDXjfHMSUoABCnTJEOJOsHpf2uGllBoopwHUuWBF1jVw6aDVMP/oSFhWHChAnIz8/HihUr8Oijj0IURbzyyiuIj4/H5UEy2LQcTA0jAJx77rngeR5fywLJcbhAvyt/bakbeB6ktBTC/fdj23PPoWXbNjj++leIS5awjBFfVQXjihUAJHv18cfMJqgzmYenT/ddQRgcVMj3UsiDLktZmVJZzUOpjzkOcXGuilVsLHSvvaZ5/2tVGgLFcOyp4fXXWSZTTEhAg8TnSAwGJLzzjvYxNT5Hj1RJI3RM/IXbZ6aWH5bsnZiUBJvdDlFd6ZK1MOg2bgzs+6Cfh+pzISYT+isrWUsGAZS/HQDqHnzH97/v62wjgrfBn7CwMGRkZOD999/H4sWL8eMf/xiRkZH461//GhRS9jNtR8ec4o+aQ9MbSFkZhF//2qXuw3Hgzj4bDWvWYPCxx2B/+223h7VeVm43XHMN+Ndfdx4rLc0ZoVsscEREoDs+HmmTJvnseVHcFFrO8+bNioiJV9MRqWB76CHYfvtbzeOPGUjZ46qmJpioIZdKPrzU0wp4NxIjUdRxO5aH1/0+g9bNL6mPcDwPXq7LK/uOA74CiwXi1KnsTyKTHqVwzJnj/B8tChRZZA4A1lGmZaGOirepyNDQUJSXl0Ov12PdunWor6/3WYbxF83NzW60SHq9HmazGc0e6MO+6+A4zv++TB/Q6XSwT5gA4Wc/g/2DD2BraoL9pZcg/OAHrt+uKMJw6aUuu9bQANTXg6NKK2VlsHhoOWFtIqLIhjLlr8thj46GKAlUELgypR7v/bg4xWCS7t13fV6vP5PnwQJ3+DA4qYp2qK8PVuqkx8VBL1NgUpxX7hjxvKvUrAWtASsP/+8J/mzj9pmpObBzcpz/pqaC53k3GwaZk6n34ztSnJtWl2w2RRZTzM6G8X//cwUpOh0bsFRLlwJSH/EoO+X+UsFZLBYUFxfj0UcfxVdffeXXPr5wpu3omHIyCSEBOZla4DgOPM87HdYlS2D/6ivYX3gB1oYGkMxMhYoEANZPyFdWQi/1Tw5lZSE5NRWm1laPZVJNaJQJ9apyt3rSXA0yZQoEiUrBTUddvp2H17z1GPn7yXraTt5TSACEZ2Uhm0prJiaC37BBWQ6m72kcS+54ByObMBKoWx4Iz0MvlYSMr74KvZxWSIOeyt81c4QoHFr9V18pj6PTuXSgNbSA5cNJQloaSG6un2ceHvxxMgEwOqTIyEhkZWVhwYIFXre/8847wXGc1/8OUEaIcWjCq0xkEJ1MxXGioyH+4AdwvPQSbCdOwPbBB3D8/OcgWVnst6n/3/9gmjnTyScbHo5kQtDtqd9Ndg1quUL2Ot20u1shC6m24/JtSUwMoNe7nMzYWPABZmzUdnQ0qHQgtSLYYmIwXd6rKAXxrhecZ1bYybg4WDZtYtKM6mqM1uT9cMvjnvrOtd5zaxugAXpUFEwmE3Qqu6boT1fNH/hcIx3kkdTlRMl2QqeD8eGHXccRBOikiqVWC4H9wgt9nWnECIRv2N/e9m+KHT0jij9aGFYvkQfIjSPJzWUPY8eDD8IgK+XZ//lP6G++GdzQEPj/9/+YwxlusUCv0yF27VrnMeC7NwaAm/SjoNNBF6CxJwkJrjIP7X30k9qBAyAUFECnnvD257wejqmAijB3Wk8PeMlocC0tMP34x0pD5oFaw/rAA0B4OEy//KX7m8NQCwp2tpcTRdYTy4kihNmzoZMeUupziRER4H1M6cnhRp0kR0QEKzvy3d0elaIAwHbvvX6fc7igfUS+SjZWqxUOh8Nv4/irX/0KV111lddtcnJykJycjFbVkJzD4UBnZyeSpazWONyh1+v96m/3Ba/OqsEAsmQJhCVLIDz8sJOV4+23YX3jDUTU1IADwA8MIKO8HHYPvwt5oCnPymk5Q4YDBxS0b5qDdfHx4NrbXXLBdPvISBfHp79QOSPBtDFs7dLzYsrChUxSUiu41HKMSHY2SH4+SHY2cOyY09GnjlTQFqrd1xmIs0r7L/Xvvw++oEBBuE9Bnz28HypJntZhu+Ya6HbsALq7nT30Q0NMdlSxjyC4cWDbbr89oPMOB/7wDdNg3V+Wjm+KHT3jij8UI+4lkoFmMtUQL74Yjv37of+//4OYkwPxRz+CUFEB/dNPK4i6+YYGpD72GOJeew2AM2rUIopVgxsaUpCPCyYTdB4cLcDlPCpu1KQkNsXJmpg5zm8j56+DqW589sdwcHY7BJ6HTlpzyKWXQpg923leqadI6/g088nKGZdeylSb3JxbLwT4pwu2m2+G4X//A9feDuuLLwJ2O3My1WuzpqUh1AOBuhbkJMuE42BftQpGOiw1MKAY9hFzcqCTaLoU3Jo6HRwqQYLRQCDRNwC/nUxKYOwLc+fORXd3NyoqKlAsZcM+++wziKKI2dLvbhzuCFYm05MddQPHYSArC1ULFsBw9tkoTEmBaeNG50T6J5/A4EcQxvko24Vv3eqyh2quWDjvR3HyZPAyJ5NNE3/9tV+2RIyLAy/ZeX+0yOXnDvQ9yN7jkpKYXfBXfpjS7dCJdPvll8N0//1+n9sb2L4871TAG+ZxxMREkORk6PbscfbuSrZMjeEcX/E8SUiA9bHHEFZa6jxeT49LvEILBoOrHSk8XNGqMRoQRRGEEL9lJf3lG/6m2NExUy4Pdi+RJwoP4Xe/g23bNtg3b4ZDEFArqS4AgDh7NhzSuH7CSy+Bl0rlvMrB9Go4ZBkEvbS/x/KCVoQaH8/oQNgxR6gDzo7j49x+HUPek9jZCd0HH2huR7xIDJK4OBeNk5oXT+aYngkQjsPxm29mWWmxuJhF31p9pEY/swdavUAgBLrqanZszuFQUGIRqS8UgELurL+szKv8WbDgr0pFf38/oz0KJqZOnYqlS5fiJz/5CXbs2IGvvvoKN998My699FI2EXny5Enk5eVhh4zkubm5GdXV1UzHe+/evaiurkanFxnCbxNGrVzuAZ2dndi2bRtiY2NRUlICQ3o6xGuugePNN9G0Zw92P/AAG2jzBF/ShCFydRgVnyFzNqhQByV3pzRwH36oeUy1BRTnz1e87q1MrD63FjSdQ42/TeefD8Nf/6q5jcfWJUp7RIeHzjlHUTInI3Cc2LpH2DffO28eRCnwtP3977A++6xf+wXcC2o0OucxZPe37bbbWKubm92WJZQcixf7taaRwN+2I2B0+IbPtB097U7mGeklUoEUFmIoIgJff/01urOyIEjDGOLZZ0P4zW/guPtuDJaW4tSll0IcgaevllAjERHKjKG6STo2FjAaFXrCWtux7aV/6Y3MjKPMEQx2jyMvl4mD69oEVX8gUUVY8s8AJpOLviPI6fqRXq9l0iScOHiQNagfGRyEXVLhIdINqegj8iEhSqFFdcUB0EkPV0K5/AhxXYNs6Ey+f9sIlCkCgb+ZTFriCcYkpBqvvPIK8vLycM4552DZsmU466yz8Pzzz7P37XY76urqMCirGDz77LMoLCzET37yEwDAwoULUVhYiLdlGtjfdJwuO+qLb7OxsREVFRWYMmWKG2cnAHBhYWibMwfCtdf6fV71sCYBoJMNjBCNTA8BnJzIgFu5XKfucaRrk+/P84zGTiwocHvf+ULwhxU5OBlI3Ejn6XYenHOSmOhsK6IqQcnJEKdNcy3Vj8qbT4yw5eLQ974Hq1SVO24yoXvSJABOWyfnpQzEZms6+h0dEDs7XSp/ej0clP0gJsbt+Sn/23oa2o7ovehvuXw0+IbPpB0dM5lMwH+uTH+O483IyiPv0rIyCH/7G4SLL4Zw442AyQTh3ntx4j//wdFbboH900/h+MtfnM3kAULdxynIKAS0QJKTAULAf/JJQMcnEhWO4/LLYbv/fmefjmybQCNwf6E4hp8GmKlbSE4mzR4EDSN8EOiXLEFZRgYAQAgPR7fdjh6J1qrLAzl/MCBK5wSk7ywsjJUQ5ZG4YDBgyMfvKGhr8lO3vL+/f9ScTLPZjFdffRV9fX3o6enBv/71L4URzsrKAiEEi2UZifvuu48NEcr/89W/9E2Dp8/7dPRkiqKImpoaNDQ0oKSkBOkeyNF5nocoihCuv96vzCAAhRIMAIgqhg+OKg3JYTK5lMjMZoAQd+leLxDz89lxhfJyCJKjqVzwyEN2rV5SQOl0KrZX9ZKyFSQmOoUw6OxBfDyINASkdZyRrHU4IDyPqZdfjnDpMx2IjsYxaZhyKDYW7V6GbfzJDstFMjiLBWGrV7s+W4cDkJxbOY2RGoJeDyJj+xgtiKLonKz3s7d9NOR5z6QdHVNOZiBcmd7gzTgeP34cFRUVmDRpEou8yYIFcLz8MqPhAWT9SHo9hJtvhv3ppxXH8TWB7QaOA79zp9d1k+RktD32mCJb6A+o40amTYPj9tsVfX/DgVfqIQ9/61RTbJ4iaaa6RJ3MggLvVByBYoQPAmH5cja5yqWkoKCgAEnSb6lvGM6d1mqoeon8fUEWGACAY948zSGhzgULwAfz8/ICf8vloyUpOY7hYbR7Mm02G3bu3Imenh7MnTsXsVIW3utasrLcuDC99TIq1qGyh5qT5RMmuOSD4+LQ1NDgKpd6XJ0L9p//3JVNTEiA9eOP3bbx5XT5zd6hCtxEo5Ede0jVZuRWxZIcFRIf71IMio52Si57+R5ON8TMTKC3lw1/Tl64EPnSBL2QmIjdeXkeHWt/oGZ9McjajgAwiisasGido3/mzKBmpz1htHrbvyn4VpbLafQshyiKqK2txcGDB1FcXIwMWebI01rkxyBr1ihl/gJcE0cIeNX0OTu29G+nwYC0hx5SvkfJuVXbUogREWxoicTHA4ODroheKpsHvFYPr2s1k3scEpJNESrWrHIySWoqK08FA/48uLw9DMQ5c5SymXANJXSnpMAucbL6nZXReI2nJS7Z+7yaaD0ujk2fyh80J7//fb8cv2AgEOM4WpnMcQSO0Ww76u3txdatW2EymTB79myEUo5iD5DbYjGAIE2U9SO72RxRdOuzE2fNYk5miyjimIwOR10WV4MAEC+80DWNbjazrGYgIau/v341XZOcUN3oobTPtpVsgeHnP4dBmh9gxwti8DnSnK3j6qtdvezR0YCsMmOLjXXS22nwSov+8lWqpvCZUEVICABAL/G0chYLiCwTLnfwe84+279zjRCBBOuj0dt+pjGmMpmjVS632WzYtWsXurq6MHfuXJg9cLLJ4eaochxE2ZAQhS+eML9uVumHb2xshF41ja7uP3Kj0Jk3z9WLEh/vurHDwiDOnOn1tIEaEo8OnMowqKfh5SV7dbmcJCYqCMqHC4UT6cPZ8XgdRqOTRoiWqaX2BWYc4+PB5eU5N1YZjcEpUzxnt1XbEp3Ojbjf8Morir9DJWYDxX4hIeieOhUcx/nWpg4CAnUyx3F64Y0OLlh2VP47a25uxtdff4309HTk5+f79dtQOJl+kvRzkJw+b9uo+9kJYcOE7RyHsuPHle97O5heDxgMrkxmbKyr11H1wNc6jr+vsbVrcEWyipCGvrriuNJ3znd2Qi8NNHFHj8K0Zo1TXc4P+GX3NZw9vzO1AISbb3Y9i+iglmRH+yIiUFpaqulkWtPTMSSr9Mghyr4L9S9fkDiuaVubTvb9C7NmyTZ0+QX9hYVj0o5+24L1M+JkeuslCnYE3tfXh23btsFgMGD27Nl+Rwla2VDhz392287Xz0Hdl6m5jbTWKKqSIY9ItaaSZbDfcgsziCQhQXFj22XKQcHuy5Q7SeqhFq1BJRpBNjkcOHr0KHsgkMREd8kv+X5+rkdxLRpRo1/XSjO/NJOZmAhbWxvjWpt29tkgUsO6euI/VK/3eI7u889X/G355BPWRws4PxtRNSilRcRvnTYN/QMDMBqNcDgcsNvtEARh1Aylv8aR9mSOY2wg2HaUEIL6+nrs27cP+fn5mDhxot8PQmpHCSEQV6/WzCRqQfBBzq6GYf168BJ92/QdOxBx333K7el6Ne4VNnRHnUyz2RW4q9WKNBwj1hvvYW2etvf1mltwCpdt3fOHP6BfygxzhED38cfgVcIf8v18ncttWxmVnGtHz3u6XbvD4XoWJSdDEAT0SC1VSQUFCOF5TR5lY3o6sGGD5mc5JOs5BQBx4kSWhOGlY1NGDkUlTRo4AlzX7jAaIc6cCYfDAZvNBofDMWp2dCz0tp9JjLlMZjCNY0tLC7Zv3460tDQUFBQEJDSvtRZSVqYpHekvfDqkdFJZ/mP3EtkSAGThQldknJDApMpISgrEpUvdy7oeykXeoM4MEgDCued6fd8NkiEPychAd2sreKkcVd/dDYeMZ9JtvcPoT5FzzQWUrR0YAFpamIGyJSRgnzSERaKjwYeHuz90JPDScJAW+mVDEQRAS1ISBGlSHQCEZctgkWUhxOxsV2QuM06HCgsxZcoUxMfHK3hl1YYyWMbSX+MYiErFOEYfQZWVtNtRVVWFU6dOYfbs2W7ydP4cA3D+lsDzIPKskgbo/cpXVASsUEatkPGDD1xBILVNXqjRSE6O831aLo+LczmZycmKHmpvE9fq6o3H9XqQKnazfWpHm7bqhIUh/Ec/QpfUZnRqwQIc/9nP3AakPK3Fr89VrUEOzywnWufT/7//x+yokJKCqqoqGKTPlE9NdQXy6ucRz8Pw5z/7Rf/Us2ABBMmBZM89qbedBQx6PWMKke8/mJ+PjKws6HQ651wGIcyOBjt4/65XhMackxmMMg/Hcejs7MSePXswa9YsTJo0KeDoQCuTCY4bEaWRv1BkBr316JhMQF+foieTk6TKSFaWM6NHZQrZwd0/B5/Or4ZxEb7/fcX7xJemt2QwoydPRqHkdBGehy0iApxKTkxxbg99rH7DhwMs/5sDoH/rLWYcDw0OIpFOb9L+TA3FCl9InDXL1S5gMqHh5EmclK3LNmECSEQE28Zx7rmuoR9ZRiH05z/HhAkToNPpYDQaERISApPJBL1erzCUwcpy+ttLFIhKxThGH8FyMh0OB7q7uyEIAubMmTOsqVf6+6G/Q0FL5Uu5g/Of3bv9qgIBgEPlXDlkVQF/eHeFefOAnh7XpHZsrGuIKD4eoqwSwWll+GTwdrexfaxW/4YrVT2WokQTRxITkZKSgmTJcQkvKEDHdddB9PMZ58/0ttopD6RiBwD6v/+d2cpTcP4OoiRbTpKTGR8wmTABgoy1g6uogN4DRU7Y4KCifaw5NRUnaPuV1NcqTJ/ufFMaDBIXLgSvIZZhuvBC6PV6GI1GmEwmGI1G6PV6r8H7cBFIT2ZYWNh4JjMY8NZLNFLj6HA40N7ejv7+fsyZMwdJMk3YQKDpZAIQr7jC7bVgcVESAKKKCoSX8cO5bZ+U5JowjIoCQkLAS9QNohTRyRvoASh6UoYLDk51DcV1y5wMN91fnmdlf5KQ4CJij4/HtNRUhMjIXd2a/EdKG6LeXzWooD6f7p//hChFxRFTpiBDMvSUz5OTen1st98O21//6mxqh48erIEBlwqJTod58+YhUdYv20AIqtatc9FzZGczA00zMo7kZCRPnux2bJ7nYTAYmKE0Go1BM5SBlMvHM5mnH6NJYdTR0YGGhgbo9XoUFxcPW+qXPlypXRcvusjNPihAew5VCkDenB3bWWexIJcA4FXZVp+Vmtxcl855WBgQEuLKZMbFQTjnHB9HcELkebceTsV5aFnew9rcrk01QS3OnevcR0XEHpKRgSmpqdD76OfUXNMI3/cErrERhD6LkpNRUFDgyl7KnczUVNhee82VwdaQ/2SZ6s5OiLQnHkDWj36EJEnlh6JaCjhYWfyyy5jNln++ouo7pXaU2lBqR2n/u9yOBhq8j4Zu+TcJYyqTOdJeosHBQXz99dcQRRHx8fEj4pvyKE15wQXBGfbR2JZMnw6rTJ1C9DGg5EhJgeHBB5370ohOnskE/KYN8bpGjQcMf+SIkjtUMg4EcJNGI7GxLqOdkKD4f92nn46Y081b473bd+OjJ1dXW8s+w5TiYvCy3lEA4CWDJc6dC+Hss9kUqrffANfezpxRWm7Ty8rlk84/H9NkkmuNlZWKiVMAwKpVXtcNOH+zNMtJI3R1ljOQctB33Th+UzGSYJ0QgmPHjqGyshITJkyA0WgcEZsB5QdkvzWe986NK23HeRE5UN/v+gsvhHDBBc79APA1NQpHVpT6nz32xD/zDHT/7/85t6E2l1KwxcdDOOccv/oaOVFUOJlu55PZc9bHOXkyRFXwyBxqiSWEHotMnOj8f+pkym0qtVMa6/L2ukd2EB/v+3rGcQAEibIvubgY/NAQ4/xUO5kkM1Oz19VtjQMDTBADcD5XeJn6EwGQWVzM2rcIgF1JSYCKd5WYTCAy4no15HZUq1pEg/dg29Fva2/7mHIyR2Ic5QTrmZmZzmnDEa5F88eTkAD4UKkJxGmSD73wNTXgP/3U+ToAu0yLlr6m+LumBvo33wQA2GNjQQgBL8mvsd4UmaEaLtwcHgB8dbXCgWWOpYax4Ds6WPaSO3UK3IkTzjXGx0N4992Rr8/H+4rPTePh5fbQkq6XpKQoJ80h6/2ZMAGmH/zAv/W1trqmNW02gBAFpx03aRKiv/qK/Z0lSVXKaavqV69Gd3e3379rnufdspwGgyGgLKe/PZmjpVIxjuFhuHaUEqwfOnQIJSUlSEpKGhVKOYcXeUHNoUH1OlWKZsKFF0KQSKTdBn0AQBow8WQnjLt3w0hlHdvboXvoIfB0CDMuzk3b2pvDJudvdDufIGgO9AkafarqYJ2kpLj6DGnrDq1iJSTAppqm11qbJwTqmDoP6PspF0K149PSXHY0LAyIjHQ5mSkp4DZt8hhUKIJ1UVRkd7mODkBWqeQAxD/5JFNKE81mJB865HbttilTIASQiQy0WqRFn/hdtqP+T8IEEcGm3mhsbERdXR3y8vKQnp6OEydOjNg40qiFEKJYLyEEjkWLYJAoZgjAKCjUfGyeNMfl29KeQ/qajlLXhIaC99H/Z5JFaJbOTux86y2cK93YwqlTTqMXBHkxrWvhKys1pwMRFgbIFDkInM4k5YYMufBClmUQmpsR+sUXI14fPY+nxntiNDJHWXPNGscgALgDB5Scmf39zNCHLF2qUBTxdn6urQ28tB8HOHtQqSPLcSAZGeArK9n2OllWE3Aa5v64OByVCIfj4uIQHx+P+Ph4GPwcRKNOJwDXtK9kEGmWE3DemzT7FGgv0ThOL4JpR61WK6qqqiCKIubOnYvQ0FD09PSMDm9xTg5IZCS4vj5N7l011PZV3rPOAc4WIKlSwLaVbaOjQa2GHbO88AK4xkZgwwaYdu8Gb7HAJFWHAIB7/33wSUlKu6Dx/wwa5V6Gjg5n37ysFYBraADmzHHfVq9XDBk5LrzQJbKhKpcPhIXh2CefoEhrPQHAmw1ze9+fYFf6rElKivMzhhSsc5yrt91qRcgll2ju7rjwQug++QTo7WXn5mUa9lxTE3O46fr077zDHFMhMREJUvAgX/vxmTOxf9MmmM1mxMfHIyEhASESv6YvUHsoH2ij2cxg2NHxTOYoI9ByuVzarLi4mEmbeeqnDATqXiJ6PkEQYP/Rj9hrHssKtDyqAa0bmf6r270bgNMx4w4e9HgMdiNJTdPRhw/jHLnc0y9/iaZ77gFo9OshkvJ30lBU9bbyVVUKZ5IdT9WEL5aVwbp+vfM9g8F5XdJnaqyrG3bPpbqE77WZXR4le9AQp//Ky+wh55wDTpoaJ4mJ4GUT4GrJOm/TkFxjIyttAYDu7bddzj/Pg//qKzYBCbj6kliP5uLFmDFjBhYtWoSCggKEhobi2LFj2Lx5M3bu3IkjR46gr68voCynTqdTROdaTe8Oh8MvTs7xcvnYQqB2tKenB9u2bUNoaKiCYN1Ty1CgUGdWCSFwLF8OwP8qhPx+51W/c37fPsX9hdhYRS865VckKptM9HqIl14K4Te/gbB1KwYbGmB98klYzzsPonQ+w2efIeTyy9k+ivUGOETJ9/UpJDNJaKhTpKOmxn1jlX0TbrpJwS0MQWAl/coTJ5DsD8OHB9AWIrnzrAV/p+dFyY6w4yUluVeEJCdT/+9/aw53EgC2J55wDmXJjsWfOOHq39y5k7UOAIB41lnKbY8eRZTk3Mpp7VLuuQezZ89GTEwMmpubsWXLFmzbtg319fXo6uoKyHfwp1pkt9v9sqPf1t72MeVkBlLmodJm3d3dbgTrwRggkkcqNOtDOePIkiUgPpQutMoi3iab6d/UCJH0dPD79yvel9/YwpIlsHzxBaxffgnb73/vjNJl1xze0oJJjz3GIvdT0s2qPrcvw8K2kUsh6vXg+vrcei8BuFEuOW6+2aVANGkSBo8cQb/UrC2qsnBiILJofpQfKOSOrK8eI1rGppQdlHuOxMWB//xz7X1lUTABXJROkmFjpSFpG/0bb7CyOycI0L/+OttfkEnMUdiliVyO4xATE4NJkyZhzpw5OOuss5CSkoKenh7s3LkTX375JWpra9Ha2hrQ71+r6b2lpQVDQ0MIDQ312fQ+7mSOLcj5LX3h1KlT2LFjBzIyMjBr1ixFWY+2DI209UhByE4DdRk7hRqKs9Gg1UuPJr93LziZrC3X1eWaLk5KAqdyoth5Jk5UOoopKRCuuQbC+vWwnDwJ6+uvw3rZZXD4Id7hLxROptRPSIc1FZC1KBGdDiQrS1lV6ehwsnpwHDKLipCgut/9sevs/WDLUcp69QnPA0aju5MpTXyrOZbZfsnJgNkMx09+4v6m5IDzVVUKJ9OxciUbsAQAvcXiun6aVQ0LA5eZiYiICGRnZ6O0tBSLFi1CdnY2rFYrdu/ejc2bN2Pv3r04deoUbBqtYp7A8zybWKf/9fX1ob29HZGRkT574r+tdnTMOZn+lHn6+vq8SpsFw8mUZzKpYQScD3pOp4PgQ5JKVDUba4GDa/qbqJwLccoUZykF0FSwEX74Q4jFxYDRCMcdd0BYs4a9pxjIgdOQJO7YofjbbYrb11ppRAgo+NuI6l9eRrlEAAjnnecyjgkJOFhfD1qw5lUPDs5LqUnNAccNDSmHpkYqtUgzB/T3Rx1EKuP24IPQ//e/il1Yg7nMWRZzclz67NSI0Iyv5IzyR48qsqI6KdMLAIJsehIAxMREEGmqVI2QkBBMmDABBQUFWLx4MaZPnw6e53Hw4EFs2rQJlZWVaGxsxKCXFgE1eJ5Hc3MzDh8+jMLCQsTExPhsev+29hKNdXgrl9NWH08ghODgwYOoqalBfn4+cnJy3I7nz3H8Ac2IKgL1s87yqMwlf3VQ4kFUZy8Vx9+zBzopAKS8urTSIBYUuPgvVUwdjqVLPS86LAzC8uUQnn8etmPHMPTpp7CqmDo8VWG8fVry90Ta26+ymYDS+RKlYRd5JrNVKhuLsbGYkJUFSIGsGm6OtcpOcoC7Az9SCh1ZooETRXAHD7qczKQk6NaudT0TZMkYxWezZInz3/PPdyellyqW3IEDTs12aqsbG8F1dLieSTLlOVYV0uh/NRgMSE5OZtWiwsJCVi364osvsGPHDhw+fDjgalFvby/27duH3NxcJCcn+6RI+rba0W8chVFzczO2b9/OpM20CNaD4WRyHAeO49jDFHBNSgKA/be/9WpM9BrUQ5olVelH5ea0hoUpmsgV+wAQVq9WvEazXUSnw1BtLYaqqhTZSr23hnTZcT1B4QDK+1ckB1+TlsNkAqKimHHsMpnQ1taGWA+0THLDKjcshOdhffll9x3kmVCNzKY/5sBtalQKDjhRVLynq64GT4d+VL85+Wfj+NWv2BQoe59G0TLnX14ioxPqYkwMeNW+9j/+0Y+rcP424+LikJeXh/nz52POnDmIi4tDW1sbtm7diq1bt+LgwYPo7Oz0WrZpampCXV0dCgsLERsb67Pp3W6348SJE7B6+K2O4/SD2kRPAbvD4UBlZSWam5sxZ84cjwTr8u95JOB5nrVfAJJtjYpiSize7tMuL0OWLLDdvh28xAjByvCUMmnaNPb/nKrKIsjbi7yAcBz2x8Rg9403uq1Xa+3q3nw5KNclAFfGT+PzVThcEt0OdcwabTY0SxUWTmpj0m3f7usynNur7Brgsj/s75EGFaryt/7ZZ5mTydXVwXjlla7PSN1fS1++9FLpYDwEWc8q4TiIktIRf/iwkyea2rN33lEcR+s6HLLWBy1oVYtSU1PR29vrVi3ylhDr6upCVVUVcnNzkZaW5pEiSc78sX//fnQHYVB3rGFMZTK99RJRabO9e/di1qxZXqXNgtFLRAiBTqfD8ePHMTg46HYuUlioKAt4PZaX92hviuOqq5TbyW9U9c0SGangpQQAUlAAyzvvwPrJJ0B0NIYyMmCRPTzsN98Mu1bpQbY+f+NXxfCMhsoEK9VQ0nXJwAxGRaG0tBR66YEAyLKBaidR5kA6fvhDEC3qKHkE7qWc5g2sf4gOBsk+a6LmGGULcii2lZemhB/+EGJRkfZ+8r5WrT6kqVMVfbgETjWgQMFxHMLDw5GZmYni4mIsXrwYEydOhN1ux969e7F582bs3r0bTU1NCuewqakJBw4cQEFBAWI1Smhqag+j0Yj7778fdrt92Hy04wg+tPrJKQYGBrB9+3Y24OMtc+LtOP6CEAKe53Hq1Cn09PSw4B0ABMkh9IZ41T2oUFyTKOpoxQcAxDVrFI4c8eBAE5MJRIN3Vg1BELB79250dnZi4g03OOnY5Bv4UJFzG5hsa1OSsut0Xnv0Aef0PPr7md09ZrEgTyoLk4QEgBBwdBpefo2e1qR631syIxgwPPccdJIDqP/sM7f2Jbe2MZ6HuHAh+1v83vdc2xMCUVJd4ywW8DLKP2NjI6t4adHuEY6D8OMfB7R2rWqRTqfzWi3q7u5GVVUVpkyZgjSNZ4jcjtLg/bXXXsP+/fuRLbHCfJtwRqbLPUHeSyR36hwOB/bu3Yve3l6/lCc80g/5CVoWnDp1Kpqbm7Fjxw6YTCYkJCQgISEBMTExzui8vByGF1/0eTxPQyEcXFkwUljodBwl50MnUz1QT1cqomEZRCkb2t/fj6qqKhSVlSFUogiy/+lPwMAA9K+/Dq6nRzmt6fMKVJA32XshABYWLoTNZsPQ/v1IAZA4YwbEjg4lb5lO53TajEZlOUtm+EhenrN8zXHuDrfsGrxOmEP7Or1GWaprY98ZADEuzknNJH8/ORkwmSAsXQrD00+7HU6cOBH87t0QU1PBNzW5mAn0enAOB0hcHHTbtrm2LyryO5DxBr1ej6SkJCQlJYEQgr6+PrS1teH48eOoqalBVFQUTCYTOjo6kJ+fr+hv9gRRFHHffffhzTffxM6dO5Hr4Tc5jtGDpyCb4zjNak57ezt2796NtLQ0TJkyxefEq3w6djigdnTixIloamrCHin7lpCQgMTERMRdeSUMjz/u1f7o5W06HKco5ZLISKdGttQ6w8FZjnV873sw1tU5X/PAriEUF/ssC9tsNlRVVYHneZSWlsJgMMD2m9/AdOedrjXExbEMoz/gOjud10GIc4glLs5VBg8PdxuCIXAOtBDpc3CEhKBo4UKEUV7PhATwH37IqkBeB3IiIpz0QRLziM+1+n1V7nCzxbJqD/uuOE6bsiojQzH4pFbZ46XhWADQv/ee4j1x2TLwb73l5OKU/XYA6bkZgLS0GrRaFBcXh9zcXAwMDKC9vR1tbW04ePAgQkNDERkZiba2NkyePBkTPEgQy0EIwWuvvYY77rgD7777Ls6VyTV/WzDmKIzUtEGDg4NO3VODAXPnzvVLecKTs+oL9NyU2iUpKQnJyckQBAGdnZ1obW1lhjI+Ph7JP/850l980a+bUX3TicnJ0DU3s+ZtdHY6lWGk7XjV9DIMBpatc3gh5u7s7MTu3buRkZGBsH/+E/Y//QmOiy5yGtSICFj//W+Y1qwZkQFRGA+puVrLybPOmoWdO3eilBKWJyfDdO21ynNTKTe93rODmJwM9Pb6LuP4cEI14eEBKvA8dKoHlGJ9VHZO9rooGQjxrLPcKa0iIlxkyvHxQFOTK6MQEQGuuxu6jz9W/kYWL/a06mGD4zhERUUhKioKEydOhM1mQ0NDA5qamsBxHGpqahg9UlxcnGY7CiEE//d//4f//Oc/+Oyzz8YdzDEIeVWIEqzX19dj2rRpmtkVTxhuwE4dTFEUERsbC7PZDFEU0dPTg9bWVtTV1cFqteKC8HDovUjH8nI6r/BwRYDK9fa6glGeB0TROcksc7j0lBJOBYGWYz1gYGAAVVVViIqKwowZM1xZ3ZtvhvDvf0MnDRpx3mR/4aH/nVZADh1SKJCRmBj3SWudDg6dDoe3bEEBnDY0NDTUxZEZHw/DQw/5PCcA2P/xDwjz5iEsM9N5fj/XOxx4OwZJSXFW8EwmwGJx21ZYtEjxt1hU5Mz4Sr9n3ebNrvdkQTmJjnb2XL71lrM1SeVkOn7xi2FciWeEh4ezipHD4cDx48dx6NAh6HQ6NDQ0oKuri9lSkwdd+bVr1+LWW2/F66+//q10MIExmMkEnJlLo9GIjo4OVFdXIyUlBXl5eX4rT8gnw/0hQQWgcC4BZf+lTqdjWUxCCDOUB1pbYSwpQbJsiMNf8BaLi7ctNtbJBwYwfjS3m13eCO5h6OjUqVOora1FXl4ee5DYZZxvgLORWrj4YujfeCPgNXuCp4xo7cAA4uLiEEkzlFYrdBIvJssKUoOrkRFlzmtyMpvGdttGHg0Po5fIY7YzIQFQZSi0sr/y/e0/+5nzf0wmJ4WVPGM8OMj6s6jcGgsopD4cNem92tiOBjo7O9Hc3IyCggKYzWZ0d3ejvb0dhw4dwt69exETE8O45CgX5l/+8hc8//zz+PTTTzGdagWPY0yBDlFSmrf29naUlpYiJsDMeKD97TRQ1+pj53kesbGxiI2NxZQpU9Df34+BuXMR/cknHp0bTp7xFwRF5UE+qc36nhMTGecsgUuhS358rZ52Obq7u1FdXY20tDRMmjRJmajgONjeeAMhxcXgbDYF9ZgWvFVTOIdDyaspOayK7YxG7Nq1Cyk06UCnsyUnE/390FVUKE8qOdxuQz9JSQplIM3P28Na/YWnhAN7n+Ngs9kQAihanOTbO66+WrlTeDjEoiLoJAUheZuUQeJABZxSx7wkZKHuMyVGI4TLLhvGFfmHgYEBHD16FFOmTEF6ejqbKj958iRqa2sRGRmJhIQExMfHIyoqChzH4e2338aNN96IV199FcuG0Rb1TcGYdDIFQXAjWB/ucfxxMqlRpJNj3pxZ2hgcERGBvr4+HLj9diRefrnbpLTbfvLzmUzgurshJieDa24GiYhw0djQJnX3RTr/0etBZLrXdP1Hjx7F0aNHUVBQgDiVQoUatueegzh9OkhYGIx33OHVsHgjlfcF8/TpyHjvPTYww2/axN7joCwPcXa7u4GSMpNyJ9MtQxgTwyZJ3dau8ZrWe1plG51GCYxubw0Lg0k1sU3CwkBkk4tidjZ01dUuZ1QUYXjiCQCAXnqwiEVF0FVWsrU4VqyAXmpvIFFRir6k0UBLSwubLo6XJuLNZjPMZjOmTJmCoaEhVg6qqanB7bffjri4ONTX1+Ojjz5Cfn7+qK5vHN7hrUqj0+lgsViwY8cOEEIwd+5cvwmn1cfx18lUB+ry/kuttUdGRoL84Q8gn3zi8d7lCHH1Dmo4dMRgYE4HiYpy6o5L1G8kJwccdTrkO4WEuKn4UNB7YvLkyR6fOyQnB9Y33oCpvDwwR8xLpQXwoNttsSCaEORQrk/a+yw5mbotW9wP5EkEJDkZHKVLCg1VtCfJP0dgBM5mSIjXFirb6tUwSWwaWhR4RK8HUemRA84qEXUyPbV6cZ2dgNTTri6VCxddpODKDCZ6e3tRWVmJnJwcZGRkAACrFuXk5MBms6G9vR3t7e1obGzEXXfdBZPJhN27d+P5559HeXn5qKxrrGBMTZdTlvy6ujo0NDSgpKQkYAcTcDmJ/pR55GUden5fGBoaws6dO8FxHAqXLoX9sce8n0P1/8L559OFOv91OMDv3essGfso94oFBYq+ElEUsX//fhw/fhwlJSU+HUwAgMkEx69/DeFnP2PN8/JzKBc/vPZvAiDz9ddh/N3vGGmw/oMPFNuIMt1ZLdDPgqSkuDKZakUELxxvaionBcLCXMTx0jHV1y9K5M1ExefJS9ONcvTm5aG5uRl2yVBTLWW2Fo5j2Vr6iTquvZadl4SFKYadhJUr3QiZg4nW1lbs27cPs2bNYg6mGqGhoUhPT0dRURGWLFmC+fPnY9++fQgPD8d5552HK664YtTWN46RgRCCAwcOICwsDGVlZcNyMAH/hyjldpTu56tVyeFwoEoQYNfosddqndHMjMkGe0hiIrijR8FTtoaCAtd7sn3ErCzN9Rw7dgw1NTWYOXOmz+eOeO65sN92m9dt1PB3alt+nTwhyL/7bugktS/GMyllJPljx9i2vgY4SWKiq8yek+P2XlDgwZbS9elPnFAOV6qI2wczMjTZKqhsKN1WkNlGdt3Hj4On/JuEKOy2/Y47hnM1PtHX14fKykpkZ2cjU2pDUMNoNCI1NRWzZs3CwoULsXLlSlRVVSEhIQHXXXcdlixZggEvLSPfdIyp6XKbzQZCCHp7ezF37lzNCVd/QJ1FX8ZRnsH0xygCTnWMHTt2ICYmBgUFBTAYDBCuvtqj4XJbGwAH5T2kvYrSv1TdgBK9a5kkyh8GOI307t270dPTg7KyMp8DUVoQZMfTXK8Pw+htgtHw6qvs/wG4TTFyHhx6ddYXMTGM0FycNs3reuQQvETUsNudgwMAa0+QQ5wwgTngYlkZU8UAAE5D+qv1lltw5MgRbN68GRUVFTiyapWCvoQjBHXXXceuj3Cc4rMXJ02C7uOP2d+OCy/08yoDR2trK/bu3YuZM2ciISHB5/aEELz66qt477338Nlnn+HUqVPYvn071si4WcdxZqBls5qamtDf3w+z2YyZM2f63TKkBX96MkcSqAOAePPNw1ob0evBnzzJgkUSEQFe1q8nB62QAEobStdfV1eHo0ePori42K97AgAcv/sdE29wW5ufcq/+QP/119BTCrdt26B7/31wcoYO6V+vfZDR0UBoKHNOxZycoE2PK86jEqawy7J0HMCykQyq32b/0qVoamrCl19+ia+//hqHDh1Cb28vhNJSJXWc6nOnmViuu9t1XVLALyYk+MUkECj6+vpQUVGBzMxMZPn5/P/yyy/x+OOP44UXXsDx48dRX1+Pq6666lspJ0kxZpzM3t5ebN26FTzPIy8vz41gPVB4K/PIFXyoYfTHwWxubkZFRQWys7PdekRtXrKZ8tIDANSdOgXC8y4+Man0KpaVOf+mUZoGvQjlDLNardi1axdEUURJScmwMxW2++5TZloDJOINtG9HYdioupHGsRi1UUoK5Fq3YnGx8oB0Ol/j+Aa54oPqPc5ud2WEVc3nhONgXbeOTY0KixZBlCJ/wvOMk49CTE5G2sUXY+7cuZg/fz4SEhLQ5nCgU0WsPiErixlKkpUFZGQojDLTsQ8NdXsQBgttbW3MwfTEjygHIQQvv/wy7r77bmzYsAFnnXUWOI7DzJkzx53MMQbqLNXW1iImJgaxsbEBDT5qwVe5XO5gDjdQF++6i/EFB4J26f6iEpDQ6RgpOwBmVylYz98Pf8heEwQBe/bsYT2r0V7kgN1gNMKyaROEkhI3u6mWsBwu6OdCbZdhzx6YLr7YpWMOpd0UZcGw4jhSmZ31ZE6YACLrp2Zk6ar9Av31cJKMMT2HKFN2EidMgKiumqj6MiN//WuUlZVh4cKFSE9Px8DAAHbt2oUvv/4afTJHjpcFPhwAREUp/vba4xkE9Pf3MwfTX9qhLVu24JJLLsFjjz2GK664AhzHISsrC1deeWXQ1zeWMCbK5c3Nzfj666+Rnp4+YueSwpNxVEtE+mMYCSE4fPgwamtrMXPmTGRkZLjtI557rk+pSUgGYCKAQVlfJe07stF0O72B6HSoLNoTy8rQ39+PHTt2ICIiAoWFhTCMJGrOzVVGk8Moj2vtQfR6CAUFcNDWAAms7M9xrIyuRSVCy0L0X16WyZRnCVgDvOr4Wn+7vScZXLfXCXFOs9NIWD5oRQjr+aJw3HQT+//Q0FBkZGSgqKgIYRdfrNjO9vLLcEgRqzBhgvO6aXlJ5rg6rrhCk390pGhra8OePXswY8YMvx3M//73v7j99tvx1ltvYbGsZDWOsQW73Y7Kykq0tLRgzpw5CAsLGxXdcQp1oO6vg6kZqPM8bM8849d65LYmQgrKaXA21NkJfPYZe1/u8Mj3p73TNpsNFRUVsNlsKC0tZYNtgYBMmgTr5s0QVIwf8iE+TfvoZ3+gmJ3tzNJJfwuTJ8OenOzR+VNXi1jwTZ1MWi5PTIQgaX0Dzv5IuULOcCHvmyVTpsBw//2uN81m8HL6O6gqZZGRgGSX5CXmRYsWISYmBsdl6yXq71Y16EMFQwgAx623Dv+CNNDf349du3YhIyPDbwdz+/btuPjii/GnP/0J11133YiDv28SzmgmU06wnp+fj4kTJ0Kv1/slLekLWsZxOH1DdDrz5MmTKC0t9VxK4XnYf/9774uSbqiQw4dhVBERW1JTcai21vmHFIGzG5Zm9cLD0Qlg586dSElJYTKCI4W8d0k9Del2CRqfl+aUosMB27PPupXjqXHlCWEGUaskL86Y4dxe6ttk+t9paRDlEbiXNfiCt4Em/f/+51pzVpZLsYIQd8qNH/3IbX9BEHBAZoAIgNi6OrZvm8OBnTt3QpQcWSrHSTgO9nvvDfxifKC9vZ05mP4Sp38X6DW+6eA4jhGs0wGfiIgIvyV6fcGTHQ12oC5ceCEcfkz/ys+iN5mcnLPSfRzS1QU95aEEIMj6FRkiIwGDAQMDA9ixYwdCQkJQVFTkFzWeN9geflhpL2XURpo21c9hSr61Ffb77nMdy+GAIHFkAoCoKrO6DdNI1+WWyUxIcKdI8zPB4G0rRaKluxv8oUOsekOHsNTHof8K8+e7H48QHDp0CN3d3Ui8+26XyhNNwADonTLFTQOd9r+L2dlB4RqmoBnM9PR05Kj6Wj2hoqICF154Ie6//37cdNNN3ykHEziDTqYgCKiurkZTU5NC2iwYkpCA04GU9xLJJx/97Ruike7AwIBfPY+Om292Kz+z83Mccxr5ujo3ehpjSgqmSH0mnCBAkGcnpRvImpGBqqoqTJ482Z1aYwRwqNL11EhrNm/LOPbURkJ93botW6B/803ne3FxIAkJzLETvETjBIAoafOyRnfqZCYnK2TGtM47XAiyfk+dlBEhHAcSGemR1FmcOpU5wuw4kkpIT0YGROl3Ta9VJxm/uMREpMTEuE2U2goL2cBRsNDR0YE9e/Zg+vTpfjuYGzZs+E7Qa3zT0dbWhm3btiExMRHFxcWsquFNPS0QqHvbRxKonzhxwmugbnvsMQgq5gyva6uvh0OSegQAPZXkkyozBllJma0lMxPd3d3YuXMnEhMTR9yzyiDr4QaUPaByaAXF3uwX19ICx+WXu5yrI0eg/93vnPuFhDip0ryBZlR7eoDuboB+JomJbAZAvTZf8LR2YjbD+sor7G9Kmk6kiWs55RQAl2KT9Kf97rsVb9P2j5aWFpSUlCA8NZWpyDGEh6P76aeVz0sZAlX48YaBgQFUVFQgLS3Nbwdz9+7dKC8vx1133YVbb731O+dgAmfIyRQEAdu3b4fdbsfcuXMVzluwjKPcWaWGURAEv8s6NNI1Go0oKSnxSKaqAMc5p7a1eCxljcrc4cNuPUhcTw/0MgJ2opGtO5Gbi6ysLKT4mMoOFKJqWpp4KRsRVe+L+l+50eE3bAAvcbgJixY5SeHpOX/wA+VxZf/PATBKPZiNdjsO19W5yjypqYCqRCGq+pYCBeF52B54QDHNzag+4uPB79vHsq2CSlvcoSJ1FgQBVVVVEAQBRcXFjKCdQcre6i0WZLS2KictAey8+mps3rwZe/bsQVNTE2wq7sxA0dHRgd27d2Pq1KlI9qIDLcd7772H6667Di+++OK3nl7jm44TJ05g2rRpyM3NVdi1YAXrWnZ0uIH67NmzvQfq4eGwbt2qHPCQoHBm6ERyXR0c11zjVl3hZLKv6rL0yeRk7Ny5E3FxccjOzg7qQ98tWPfA2uAv6EATX1mpsK2Myic6mimHeQK9Ov3GjQjNzARPg3dBcCuti5KjFpAdlX2+1uefd7aN0SSFIDhL8h4ypPLvhuj1IDI5XkII9u/fj/b2dpSUlLBWBru69G2zIb6sDPYXXnBdB+UjBlAxdy4aGxsx5IPP1Bdob2hqaqpXSWs5ampqsHLlStx222349a9//Z10MIEz5GTqdDrk5uaipKTErUwRbOM4nL6hjo4O7NixA0lJSZg1a1bAka5Dg9qCDngQkwmcKILfvl3xPnf4MMvWAQCmTHE7hmXVKpw6dQqbNm1i2tMjdUIAp0Mr13r1RjDMSeTGbF/1+7LXdFu3unowZ82CKONV1HqQUIgyJzLnX//CJIkOSOR5HGxsdKN7cFPJCBCcKMJxzTWs7xNwlfDFjAzwW7e6XldTa8hInR0OByolIuiioiJnwCRzMklEhMshP3QIRikLw8pFK1ei8OqrUVxcjPDwcBw/fhxffPEFduzYgSNHjqC/v59xufoDqv40depUvwOTjRs34uqrr8YLL7yAi2RBwTjGJgoLC5Gamur2ejDtqCiKwxrwGVagzvOwycrDDPKMHXW+jh93thJp9XTTzBYlaZdeby0qQlJSEgYGBhgTRDCcEEDiYpTDy/Wqg2rNbSQ6Okour6YH4qXBRDZYqrKpBIBl3TpYf/EL2CZNAudwMPsV8sMfQn/eeYptGddzAD3+ipaj0FBnFpk6eXo9bH/7GxvapOdh+8oGs8SpU13bEILa2lp0dnaipKREMach3HADRNnvnbPbwdXXw/Dvf7PXaPuEkJeHmKwstLW14auvvsK2bdtQX1+P7u7ugOzo4OAgKioqkJqa6ncF8cCBA1ixYgVuuOEG3HPPPd9ZBxM4g2TsiYmJmtQYweol4nkeDodDU3nCG06cOIG6ujpMnTpV03j7A/Gss9wIvpnjZjQ6lW9kKkGE48CJoqJnRVQNZhAAOT/4AbLh7Atpa2tDY2MjmySlesDDGpzS6yHOnMmUI7z1KnIahMFuiI0FurpczeQqQnUACo1uQGlo7X/8Iwx33gm+sRGcKCJEMqa8KCL7t7+FSTZ4I/I8MyrqqUI1tIjlqW44d/iwYmKTvT9hAniqUsTz4OUKEwkJIJMmOddst6Oqqgp6vR75+fkuQYBly0CMRqc6iFyhpKFBkQEW09Nhe+YZN9lHi8XCiHwPHz4Mo9HIlCPMZrPHbFJnZyeqq6uRl5fnt4O5adMmXHbZZXj66adxqQ/ZvXGMDXiT6A1WT6bFYhlWoL5nzx5MmDAh4NYe4bbbQB56SBk8yoJpbnDQ2XrT1gZ+61ZwougScqD3uMkE2O1uVZa0669HtJTRHxoaQltbG9OejoiIYHY0IiIiYMdALChg9zrgGjwKmNBcApkwAWhqAk/J5ZOSFM8I+bnY+3JltKgoiN/7HvC97wF//COEQ4fAv/ce8PbbMO7YAYOsZ1WxPi/2X30tCkGNU6fAb9vGBlaFc891fk8yKjnFIKZsstxxyy3SqZ2tFX19fdqsKRwH67vvIqS0lPWfGq+/XvE8pRDuuw+ZmZnIzMyE3W5HR0cH2tvbUS1xjlIlM0/yuYDTwdy1axeSk5P9/h3X19djxYoVuPLKK/GHP/zhO+1gAmNM8QcITrmcEAKdTofW1laEhobCbDb71ZheX1+PpqYmFBYWwmw2D38BRiNIerpCdYCq0oDekDJHiTqj1IEhPA9RLTEWGemk8gEQGRmJyMhI5OTkwGKxoK2tDa2traivr0d4eDgSExORkJCAyMhIv3/g4tlnu8uTaUBhyKFtPMVJk8Dv3OlS9envB0lOho5yvQHgvUhxCvPnQ/zsM/AVFRAnTQJ36hS41laYrrkG0bKsIqCksgAAEhvr+qzV68rMBH/kiHLNYWFAby/4vXud+6sNd1oa9BLfJ6KjAdmxhcsvB+B0MCsqKmAymdwz35GREM45x42IXmGojUbYXnxRk1g+JCQEEyZMwIQJEyAIArq6utDW1ob9+/fDbrcjLi7OTR+3q6sL1dXVyM3N9TtQovQajz/+OC6//PLvvGH8piNYdpTjOHR3d6O1tRVxcXGnLVC3/+QnMD7+uHMdcK+uUGJx3Y4dzhckOV4WRKoqDoCzkhAtaxmhTBAZGRmw2+1ob29Ha2srjh07BoPBwOxoTEyMfwOWBgPEkhLoJBvltSIEQIyJYZKyinVK75PcXGDHDqfGOaBQ6AHgnKCWV7JUFTd1zyWZOBHCLbcAt9yCoc5O6D76CJbXX0fUxx8rnT9/FZ5CQiBOm8bK97qPP4ZOpt5EcnNdSm0y7XEAiiQMgbMiJIoi9u3bh4GBARQXF3vMfJPcXNjuvx/Ge+5xcm/u2uX6zEwmcFYrxJkznYIWEgwGA5KTk5GcnMykodva2ph8bmxsLAveaWl+aGgIFRUVSEpKEVA57QAAbvlJREFUwuTJk/367R85cgQrVqxgk+TBGMz9pmPMOZk6nW5EJWA64JOZmYkTJ06gpqYGhBAWoZrNZrfytyAI2Lt3LwYGBlBaWhoUYlTHsmUwPvus4jUxIQG81FvIS4aDZtIAMBoGx6RJGKiuhjyGE3NzNc8TEhKC9PR0pKenM0PZ1tbGDCXVXI+NjfX6gxfmz4fhkUcUr3mMwH3cbHx9vSuDQLkf4+OZE0v0ekUUK4eYmwvExzsNz4oVzu0lPjyrxQJ+yxa0RkaiPTIS+X/5i9v+3XFxMHtwMnW0zxJwyahJvwVFtkDeEhAeDk56EJDISObAEgD2229nPWehoaGYNWuW5mdsv/NONyeTrYPnYfn0U0U/kifodDrmUBJCWEb75MmT2L9/P6KiohAREYFTp05hypQpTL/eF+T0Gtdee+24g/ktwEjL5bQ8npKSApvNhvr6euzbtw/x8fFITExEfHy8G3VaMAN1x913w/D4405pSfk5oGzJ4aTgEOrpYg37QjRakCgMBgNSUlKQkpICQRDQ2dnJOGUJISzrFR8f77V9Sli2jDmZDJID7Aaz2TmM4+lYJSXQv/wyc9TkZWcA4Hp7lc6bqm3Icc01Ho8NsxlH5s9HQ1ISzhkaQuiXXwLwnXVVvBcZyZ5jAKBbt04x5c2dOOFau1TVgskEzmJR9qKnpEAMCcGePXtgsVhQXFzsc9pfuO02iB98AN1XX7F1ETjbmUhsLCzvvOP5GiRp6JiYGEyePBmDg4OsWnTw4EGEhYUhJiYGbW1tSExMxJQpU/yyiY2NjVi2bBlWrFiBxx57bNzBlHDGnMzRKPPI+4YiIyMxbdo0EEJYJF5XVwebzYa4uDhmKOmUu16vR1lZ2cg4J2UQf/ADQOVkksmTmeYsJREXysqg37rVeYNIUfjJSZOQWlUFwHVTO2S9f54gN5SiKKKzs5PJB4qiyB4QWuUBcc4cn3reFJ4iUvZ+dzeL0ul73IkTLlqJqVOhow8HKA2bsGCBx+uzX345aoqK0Nvbi6KCApDHHwcnqfXQ/c0NDf6Vp4xGJxGwVMJm2QJ12UTeHiB/aEdEwBoSgopduxAREYEZM2Z4NCqkpATCnDnQSX24JDSUZTkc113nl4OpBtV+phltq9WK48eP4+jRo+A4jvVw0rK6pwfjd51e45uO0bKjlInDZDIhNzcXU6ZMQX9/P8v01dTUIDY2FomJiUhMTIRerw9uoB4W5qQOUwkfsOCVBuv19ex1WkKnEPR66GSfgejFtsih0+lYcC7PejU0NGDfvn0wm80sy6l2hoSlS4F77lGuWfU9MPskJy6XJRs4OO0qXS8ncUtyABwrV0L3zjuuXveJE6Gjet3y43EcRA+sEIQQHDlyBMeOHUNxcTG43/4WkJxMZocLCkBOnIBexWupQHs743jmpOsUs7KYWAV/6BB4WfleLC5m/aVyrXTH+edj9+7dsNlsCoYEX7C++ipCs7MVVTWi08H2t78Bfqo2AUBYWBjLaDscDpw6dQr19fUghKC5uRkOh4OV1T2trampCcuWLcN5552Hv//97+MOpgxjMpM5nAicGkV13xDHcYiNjUVsbKzCUB49ehQ1NTUAnGL206dPD5qDCThvKPmNBMAlYwgZbcMDD0C3cqWiCdqwYgUMMlJhABClrJ6/4HlekfXq7e1Fa2srKw/IDaXJZAIiI0EmTABHew55XulUeYIWx+WECbC+8w5CSkqYQ2p49FHX2mRtBACcDp+UvRY1uNIAlzKHxWJhQwQkJwfcwYNuMpTq4Rw5eqdNQ1RtrYuLVPp+6HVzqsyCfBiLkxlce1kZdu3ahejoaEybNs2nUbG+8Qb0zz8PsagI4ty50L/yCtDZqaBgGQksFguOHz+O3NxcpKWlsbL6gQMHYLPZYDabWSaG9jmN02t8ezHccrmnAR95UDNx4kQMDQ2htbUVzc3NOHDgAHieh8lkwsyZM4MmkWd/8EGYZBQ0tE2H8Dx4KqQgc2Icl10Gg1RiBwAhLg46qZ8bAOxXXRXwGtRZr4GBAbS2trLqQXR0NHNIw8PDQfLynBUPqkTmLViXE4hLDibL1MbGgkyapLBnxGCA/a9/he7TT11qRgkJwMGDbuchmZnaA1FStvnUqVMoKSlBZGQkxEWLICYmss8UcGZkHbffDp3Z7BawM6eSJhBk7zlWrIDxqaecrx865HqewMkwwnonZb/NQ9nZsNvtKCoqCuwZHB8P+1/+AsMvf+lcV3o6bI8/DnHpUv+PoYLD4cCxY8eQkpKC3Nxc9PX1oa2tDUeOHMG+ffsQExPDstr0d97c3Ixly5bhrLPOwnPPPTfuYKow5pzMQI0jIYQZRsD7gI/cUEZGRjJny26346uvvkJ0dDSLzEesPKTXQ8zLU2TsuI4OZS9KSAjInDkQli6Fft0652sAYhcsUDRLE72eDZgMBxzHITo6GtHR0cxQtrW1oampCQcOHEBUVBQSEhKQM3cuQt94w2lEZGS3fpdPJFj/9z+QKVNAZswAJ3Glsd4pqIwroHBURZmqA4XD4UB1dTWT0KSGyH799TD96lfK9Wj1YsnWKeTmArW14AhRDg1JGRCuq0uxPS9lCdTHPpifj5iYGEybNs0/58xshuPOO13XdMMNvvfxEz09PaisrMTEiRORLvHIxcXFIS4uDrm5uez7PnXqFA4cOIDnn38eYWFh+Pjjj7/z9BrfVgwnWPcUqGshNDQUmZmZiI2NRVVVFUJDQ6HX67Fz507WFz7cARoKYflypfNEJ8UzM8EdOaLgHiYhIbD/5jfQPfMMeEoTJqtKkNBQTcaOQBEeHo7s7GxkZ2fDarWyfviGhgaEhYUhISEBuUVFCNm82WlHKEuFwcCmt1k2Vj4YSv/HYHBWWHge0Omc2dy6OgCA46KLnBRu8u+V2qTwcFaVAQC7hlQhpQXq6OhwUziyP/EETDK5Tb621iM3sG3JEphk8p1DiYkIlRxUWr4mHAeur08xeyDK9MPlA5jdM2cyNo5A4bj+ejjWrHH2y49QJc1isWDXrl0wm83Iy8tTPDcnTZqEoaEhVlY/dOgQ3nrrLfT29mLHjh2YO3cu/vWvfwWHc/VbhjPmcnsr8/hrHOX8l/SY/gz4HD16FPv27cPMmTNRWFiIsrIyLFiwAMnJyejo6GB0B4cOHUJfX19AdAdy0MZjRqRbWQkimxonEyY4I0uZvisHZwO1HOLMmT77IANBeHg4srKy2HWnpqaiu7sbO+bOZWvwBU+yaITjQAoLAbj6SImKf42ojQGVbzSbnUZUBtrzyHGcWylFuO46RvPhcZ2q64mUOe8OObG8rNQkSg8jwnHMwKuPaVu1yn8HcxTR29vLHMwMifRYDo7jEBERgezsbJSWlmLhwoWYPn06NmzYAIvFgueeew4//elP0eHhgTKOsQ1fdtQf2zUcBR8AaG1txa5du5CZmYnS0lIUFRVh0aJFyMrKwsDAAHbu3IktW7agrq4OXV1dgdtRo1FBbcNaeaiCi5zaZvlyHO/pgUNOxSZrdRGH0ZLiCyaTCRMmTEBRUREWL17M2CBqZ89225ZTT0lrgMCZwQTgZKIQRUXPpuP664H+fkWwyzc0OPeVOYwEgCCTugWcAcTevXvR3d2tKaEprFrllLOVoPvoI5iWL9cW5JAGHimsF17o+kOqDorSdfB79jj/Tkx0zSHInh226GjMOO+8YTmYDImJQXEwKyoqEBsbi6lTp2r+/kNDQ5Geno7CwkIsXrwYs2fPxsaNG9Ha2ooPP/wQl112GfarJIfHcYZlJbXgby+RloKPP8oTtbW1OHbsGEpKShT6zSaTCenp6QpDSTXCv/rqKxw8eDBgfi3H9dcrnBxOFBm3GeCcvN69ezdOJiZClJGcG/7v/xTH0ZItDBaooSwsLMSMK66AQ5XB9fSJulEB0dcJAaSyMnOoaVZUcuo4q1VBoMz6i0pLFce0Wq3YtWsXQkJCUFhY6B4l6vWwfPYZrK+9hsF9+yAsXuxaD3VG1UTNsvINX1ICUXLMeJnhPiZT/uEIcSN7FsPCkFtaOiYczIqKCuTk5Gg6mFo4duwYXnrpJdx6663o6enBK6+8gtjYWJ9qVuP4ZkGv17MqjzeMNFCfMWMGsrKy2D60L5xqTufl5cHhcGD37t344osvUFtbi/b2dk36Oi0IsgCcglV5ZC1GB3/0IxxqaIBBFkTKpR0dV1/t1/mGC71ej6SkJMycOROTfvMbiDyvbOORrVUOxbcTFcU0tzmLBYZf/lL5vMjIYPK2FKy9R17BiYwEZGIfVIFscHBQmxZIgu3hhyFS+cmhIfAHD2qrFqmqRSEyvk2d1PbULxHRE6ndyD5/vibNEDd37hnP/lmtVlRUVARUmert7cVzzz2HRYsWobu7G5999hmmTp3q8bP9LmNMOpm+MpnDUfCx2+2orKxEX18fZs+ejSiZU6cGNZT5+flYvHgxpkyZApvNhurqanzxxRes5ODTUMbHO7nO5GuX9SvZWlpgt9tRWlKijE5lWSUCwDGMXqJAYbFYUF1djV6Zjrk3yI2PkJwMImu0ppPaVEGHE0WnSoc8WtWg6xFkfadDQ0PYuXMnoqKiMHPmTM9DNZMmOffLzob1nXdg+fhjDG3f7lIXUj1kaeQPOPXR6WfLHN0JE2A+5xzna7TnSP2g9pPOYjTR19eHyspKZGdnIzMz0699Dh8+jBUrVuCSSy7Bn/70J5hMJixZsgQPP/zwiLWbxzG2QB/c3gL2YAfqWmtISEjA9OnTsXDhQnYf79+/H5s3b8bevXvR0tLidY2CxvAKd/gwxKQk1z3L8zgRHo6yzExFDzzLfPI8hOXLvV5XsCAIAvbu349+lTIY7+GZRmSVGceyZYpBQ8M//uHajuOAhATFhLlcXpeXtSAJUkUKcAlEOBwO31PbkZGw7NjBSN2JwaCY5GcVudpa9hyjA0pE1YcbJiUMaIvA7rw82KXWMXmCwtNw0ukCdTBpb72/DuaaNWuQmJiI119/HSEhISguLsZ9992HbJUa3TjGoJPpqydzOAo+g4OD2LFjB/R6vddITgs6nQ6JiYmYMWMGFi5ciBkzZoDjONTU1CgMpac1C2vWKP523Hgju1lDWltRPGMGjA0NzMkUVdqsJCXFyeU4iqClraioKJgeftjtfaLRjK1o9v7DH1gEDjiNEABFqUecP1/R48MUkGTHoQ+U/v5+7Ny5E/Hx8Zg+fbr/jdQ8D3H+fJCZM+GQ5McU2QS9XsFdR7KzIch0gQHAfsstCPPAXUfROXVqwFntYKKvrw8VFRXIzMxEVlaWX/scO3YMy5cvx8qVK/Hoo4+ON6d/S+DJ/tHv15NdGu1AXWs9tNftrLPOQlFREUJDQ3Ho0CFs3rwZVVVVOHnypBt9HZk5082B4axWZYZPr0fZ7NmIkE+Wz5jB/l9cvNiZJRxl0NYeQRCg+/WvnWuTva+lcsbLnGJh5kzwKvo1u/z5wXEKejXbb3+ruQ6qPGSz2bBr1y7odDr/h2ri42GXFOs4VQ8pW8beva4h1rAwIDzc+ZySgcoPUyd1yo03wqTRktNeUuJ3VjvYoN9XZGQkpk+f7tc90N/fjwsvvBCRkZF46623xjOXfmDM9mSqH+DD7Rvq6urCjh07kJCQgPz8/BH1fvA8j7i4OOTl5WHBggUoKipCSEgIGhoasGnTJlRXV6OpqQl2meGw/+pXSkPzwQeK8rl+927oPvqIvW9Tl8pXrRr2ev1BT08Pdu7cieTkZGckV1QEUWUw5A3bWji5dSuIzIBwBw44/5UZRJKWplC8oX2YTILMZAKSk9Hb28s0YtV6zIGAzJjhVuamDxoWmcfFOTOw0nYETtky5iTLII/o2xYvRlVVFb744gvU1NSgtbU1KBJ+/qC/v585mP5GzSdPnsTy5ctx/vnn46mnnhpVB/OLL77AypUrkZqaCo7jsH79ep/7bNq0CUVFRTCZTJg0aRL+LZOIG8fwwHGcx6rQSAJ1nU4XcKCutTY6TDFv3jzMmTMHMTExOHHiBL744gvs2rULjY2NsFgsAMdBKCsDoOzlI7ISq85mg7G7G5ycB1emG+5QBfqjgaGhIezatQsmkwmFhYXgLrsMJCpKGeSqqlpqGO+917Ut/VfKVnKEgGtsZHLEJCQEvAd6IXHBAjbEEhoaioKCgoBK0o577oEoc9KJqoWKb2hQaJYDcOul13/4oeuP8HDw+/e7VYSE0FDs7ekJukyyPxiOgzkwMICLLroIBoMBGzZsGPlwsBd8m+zomJsu1+l0zKGkNwaNuqnj6U/fEODkrtq/fz9yc3MxwccNHijUk2eU2oJKPVIOuYSEBISkpTGqDb3kgFHw773nmsjjeYV+NgAI558f1HXL0d7ejj179mDSpEmKnj7rq68i5OyzXUbBA3E6RdKhQ9ANDrL+U+v27eju7ESqXNWINn1L27CmfDoxOnEiU6rJzs72O0PnERznlLKU6+bq9UpyZ4cD+n/+U0HFEZqQoGhdUPTUwvkdZV12GTIAdHd3M0k6q9XKaIIYLVSQQR3MjIwMvx3M5uZmLF++HAsWLMCzzz476hnMgYEB5Ofn45prrsGF8oEADzhy5AiWL1+OG264Aa+88go+/fRTXHfddUhJScH3vve9UV3rtx16vV5Rig6EiUOOrq4u7N69GykpKX4TUwcC+cS2xWJBa2srWltbcfDgQURGRmLS+ecj/fPPFXKHR1etQsbHH0MnEZDrdu1ycTByHHhJfpEAo14q7+/vR2VlJeLj4xVDI7YHHoBJqqgAgJiSwjgkKRRMFrLrY/zI778PWuDm9+0DTwUtcnLA0+eGjGOTGI0YiItD5a5diI2NHd5wol4Py+bN4PfsgZieDn7fPoSsXu2yg83NrBUKFgsgigoHmuj14I8cYdcmpKWh/89/hlsuecYMLFiwgNEE0WenmhYq2KAOZnh4uN+VsqGhIVx66aUQBAEffPABImQ9r6OBb5MdHXNOJs00CoLAHE4addO+IV8ghODQoUM4fvw4CgoKEOdjAnmkoBO8ERERyMnJYZq4LS0tqKurQ8G8ech44w0Art4cqv6jX7uWZfxITg74zZtd16HTQZT11wQTp06dQm1tLaZPn45kmdQaAJCyMjh+8xsY/vQn55olwmM1SEgIOIsFobTP0WQCrFaENjTgyz17kCpzmOmUIQdnBpGWzqnh6j3/fFRVVWHKlClBCwjEefPAr13L/uZUihj8/v0K/k6mGCFblxokORngefAAzGYzzGYzpkyZ4kYTFBkZyQzlSGhcKAYGBlBRUYEJEyYgJyfHr31aW1uxYsUKFBcX45///OdpabC/4IILcMEFF/i9/bPPPovs7Gz89a9/BQBMnToVW7ZswWOPPXbGjeM3Ad5+V/JM5lgM1LUQEhLCiLFtNhva29txAsAEFQ9kQlMTeJkDzW/a5NTNhkRxRG3qxImANMwyGuju7kZVVRUyMjKQk5Oj+EyFa6+FsGEDdBLnsW7fPjfbQiskHMA4MUlYGONNNsikfvu3bkWsFKyLhYXgJcEOeVbRkZuLnZLW9ogCgpAQiFIGWYyLU1BJcQ4H4/XkBAFcXR0b6gScNHT85s1se6G5GSkSFZyCTu6CC8BxHKKiohAVFcWm86mevJwWKiEhAdHR0SO2o7TlIywszKuAhhxWqxWXXXYZ+vr68PHHHwfUJjJcfJvs6Jgrl8t7idTEwP78IChpd3NzM0pLS0fdwdQC1cQtKSnBggULcOKKKxQlc9FoRD8dODl2jDVCi2Vl0H3xhWu7OXOc/F9BxrFjx7B//34UFBS4OZgU9ttvh4MOwMC9+ZvwPARpqpByTIpSs7tucBCLm5pYZO6QnFEKhyQTKcfOmTMxbdq0oD7IHBdfrPibGxhQlNn0L74IrrMTRIpKSXY2hg4c0CTNpxBlzfZsGw2aoPT0dPT19WHHjh3YsmULDhw44N+wmAYGBgawa9cupKWl+e1gdnR0YNWqVZg6dSpeeumlkVGEjCK2bduGc889V/Ha9773PWyTHIZxDB/y1iN1oO7PBHlDQ4MzSC4oOC0OphpGoxGpqanInz0bomQzWD/77t0sIAQA3fr1jNNWyMtjPL/2IPLRqtHW1obKykpMmjQJEydOdP9MOQ7Wf/yD2ROur0+bEog6aJR0XWpXIiEhMMhbjL76Crz0d2tuLjjK4SurNJ3IycGECROCm3E2GkG8VE747dsVmUxh/nwXzRQAU2+v67plrUkODS5PKpMsp4WyWq2orq7G5s2bWXvScNSs7HY7kwD2Nkwqh81mwxVXXMFoimJk1zWWMJbt6Jjr/qe9RA6HI+C+IUp5Y7PZUFZWNuopbV8QBAEHDhzAgMkER0kJe91mNuOr0lJndCjbnoSHK/oWHTJy3GCAEIKDBw/iyJEjKC4u9u6Ah4bC9vbbECTOS3nJmEJYuND5mnTDi7IfuVGKqIjRCE6KiCnaZETvACDq9ZhyzjkeHd7hQly6VOFUAlBIYvL19c5sMW0VcDjQ6XCAl0tJqmCXccl5Ans4SuwEeXl5EEUR+/btw+bNm7Fnzx6cOnVK0bvrCdTBTE1N1X6QaaCrqwvl5eXIysrCf//736AqWQUbzc3NSFJlmpKSktDb24sh2ZDWODzDl7RkoHZ0LATqchBC0KSS1dVLQWu/NCjJnTzJyMipAAYBIFx//ais6eTJk9izZw+mT5/OBBA0kZwMy/btzA659YkD7gwXEk+vmtvTLNMJ7yEEvFSZkWd4+VWr/LYTgUDtrMuTJrrNmyHKMplcTw/4ri6I1KGUPYfZWsPDAR/2ntJCzZgxA4sWLUJ+fj4MBgPq6+vZsNiJEyecvbu+1i85mCEhIX47mHa7HVdffTWOHTuGjz/+GGaz2ec+Zwpj2Y6OOSeTEAKdToehoaGABnxo1ig8PNw3VcNpAO37sNlsKC0thX39eta4bmppwYKzzoIg0X/QG7Zf1sNI4CJzDwZEUURNTQ1aWlpQWlqKaD8zpLYXX2TcaXJwogiiyqo5LrvMlVmQek9JdjZEmYMNAPEqTsb+jAx0d3ejp6cnuBPbBoOTyN4DSGgobM8/75L07O5Gg0zOUz3VSvR6kLPPDmgJlMZl2rRpWLhwIYqKihAWFoajR49i8+bNqKioQGNjIwY1ePQGBwdRUVGB1NRUTJo0ya/7oKenB2vWrEFSUhJef/31M34fjOPMQafTwWKxfKMDdRqc7V+wAESnc8sEGu+5B2JYGOu1JgDTyxbT0oAgt4hQ3e+DBw+isLDQ7cGuuU9WFuzSUI+WxKSiBzw2FkQioCdZWQpnTq5NnqMxdEIAdOblDbti4g3Cj3+sHGBNS2MDQfzmzSByR1saZBXpb0fDtgkqTmRfoPLQU6ZMwfz58zFnzhzExsbi1KlT2LJlC7Zv3+5RPIWWyE0mE2bNmuWXg+lwOPDTn/4UdXV12LhxI+Jlg2TjCAxnrIamZfDowI/ZbEZVVRUbnklMTPQ6SNHW1oa9e/ciKysL2dnZZ5zDcHBwEJWVlUwTXafTAUYjHDfdBMNTT4EjBOGTJ7MeQQ5OByZS6lsEAGtKCpodDsQ7HCMudcp1v8vKygIaSiETJ8JSUwOuvh4h8+Y5ycmlNXOnTrFeHTE21jnRnZKiGLYRJ02CKFPAIEYjdFR3WHrNdvnlsFgsqKysBM/zbGDKbDaPeFDFcdVV0P3iF8prktZMoqIgfP/7MErZDr6vD7my6UahqAj6L790XcvChSN6aGnJlNH+o4MHDyI8PJzp4hoMBlRUVCA5OdlvB7Ovrw/f//73ERUVhXXr1n0j6DWSk5PRIqOjAYCWlhZERUWN6vTmtxl0wCcmJgb19fVobm5mdtTbIEVfXx+qq6vZwMiZprmy2+3YvXs3BEFA6Zw5EMrLmfwu4OxZF8rLwe/eDf7ppwEoexwbZ83CycpKZk9GOoxHK0HNzc1M99tfOH7xC+j/+1/wGgpiChaO8HAQaeiRa211cX0ajeBktkmrT16MjYVoMqGmpgaCIDBbEh8fP/J2mehokLw8F3NIe7uz9/XgQafmueweNtTXQzSZoJOcZ7VwBzBycvzw8HCmXEd7d9va2nDs2DEYDAbWxxkZGYnq6moYjUbk5+f73XL3s5/9DFVVVdi8ebNfgcSZxli2o2OmUUvemD59+nRMmjQJra2taG5uRl1dnaauOCEEx48fR0NDA6ZNmxb0cutw0N3djerqaqSmpmKyirTb/uCD0D/7LDiHgzmYRKdzlnA5DvreXmYgu1evxpEjR7Bv3z7ExcUhISEBiYmJAWemKIk8z/MK3e+AEBoKMmsWyMSJ4GRk5rotW5zDPhYL6x0l6enAqVOuZvbsbAgLF7K/xawsiEePQu6qhV9+OWampEAURXR1daGtrQ21tbVwOBwKQzmctQuXXw7yy1+6+l4TE0GmTYNu0yZwLS3g9u8H53AwxzNOmkoFnETvkDmZgtSjGizQ3t2MjAzY7XZ0dHSwPi9BEBAeHo6YmBgF04InDAwM4OKLL4bBYMD69evPuGHxF3PnzsX777+veG3jxo2YO0oDb99GcBzHsjdygvWsrCykpaWhvb0dra2tOHToENMVT0pKQnh4OLNPYy1QHxoaYproVO3L9sQT0L39NmvPgV7vVLaR8QiLycngJVWc6HvvxVB0NJqamnDgwAE2tZyYmOgmq+gLtBLU09OjKcvoEwYDLJs2QffyyzD8+c8KwQ1+927XYE1PD0Sp/5GTHEkCKBxMEh8PfudO93PMnImpU6ciLy8Pvb29aGtrw+HDh7Fv3z6YzeYRO9vCwoXgqZNptUKUlY/1qntYuPxyGF54QXOIkuh0EINIK0Xbk1JTUyEIAnuG1NTUwGq1wmg0Ii0tjXHCeoMoirj11luxdetWfP7550hR0fmNVYxlO3pGnUxqHNUDPhzHITQ0FJmZmcjMzITVamW0FvX19Wxyd2BgAJ2dnSgqKhoTDbmtra3Yt2+fGyUQg8HgjMbXrgXR6TBUWwvTqlXQ1dUpiG+JXo+o++/H3PBwNrUsN5RqZ9sTqKEODw/HjBkzRjxd7Lj8chh//3sX5UZVlYtWxG4HurvdtL5JTo6Tn5LnAVGEhRCEyeTeiNnMGt0pD2lcXBxyc3PR19eH1tZWHD16FDU1NUpaKH+zdNKUpE7ilwMAxw9+AN2mTeAADH7wAULhLO3o+vpctCAGg4JrDwAbdBoNGAwGJCcnIzo6Gl1dXTCbzQgNDfWLHmloaAiXXHIJBEHAhx9+eEZLnP39/WiQBSJHjhxBdXU1zGYzMjIy8Nvf/hYnT57ESy+9BAC44YYb8NRTT+GOO+7ANddcg88++wyvv/463nvvvTN1Cd9YaA34mEwmpKWlIS0tDXa7nTmcR48eRUhICBITE1mwrsU0cSbQ29uLqqoqJCYmIi8vz+Xwms2w338/jHffDUAiZX/tNehlyjjUwRRTUhCSn48sAFlZWbBarWhra0NraysaGhqYs52YmOiT/YHKYtrtdpSVlQ2/BSUqCsLPfgZuaAjG3/+evczV1bEyOt/Xx3S4Ke0dkVHgAU6ic7662n2ddBBTg15PznwRFRWloAjyN6AQ58wBnn/etW4Z+T0+/9y1ndkMYeVKGF54wanspiKYF4uLg97GQKHT6RAfH4+YmBj09fUhJCQEZrMZx48fx/79+xETE8OuXR0oiKKI22+/HZ999hk+//xzv6V6RwPfJjvKkTMlWwJnli1QYmCbzYbm5mYcPnwYdrsdYWFhSE5OdovMTzcaGxvR0NCAGTNmeJVaw6lTCJ00CRycQyT6N9909QTCObVtef99kAUL3Hal9A6tra3o6upCRESEogwmv3ZP3G0jQmcnQtPTXSUcOT9baCgc118Pw+OPK6JXy/r1EAsLEZqZ6cxk8ryCD85x0UWwvfiiz1MPDg6y0nJ3dzcLNLSuXQ3dv/8N089+5lwnx2HoyBGEZmWBA9BcXIzkigqI06eDr6kBCQ0FNzQEx4IF4HgeOolSSjjrLFhlpPmjAUronJCQwIjoCSHsIdHW1obe3l72kOjt7cXkyZNx2WWXobu7Gx9//LHfvbajhU2bNmHJkiVur1955ZX497//jauuugpHjx7Fpk2bFPvcdtttqK2txYQJE3DvvffiqtMgpfptgd1uZ+o9/tpRQRAYTczQ0BCMRiOzo8GgihkuaEY1JycHmZmZ7usQRZhWroRO+v2w1hcVxZH1X/+CcMklmueQO9vt7e0wmUzMjqqv3WazoaqqCnq9fsRiHgx9fQhNTvZIk2Z9+mkYb72VJR4cS5ZAL3PitEAADB0+7JOuyWazsWdIZ2cnQkJCmB319b1z0rNLfk5O4/8dl18OYd48mG68UZFZprC8/z7ERYu8rnMkcDgcqKqqAs/zCiJ6OT1SZ2cno0fq7+/H9OnTce+992L9+vX4/PPPMUl2nWcC3yY7esacTEEQYLVaWXnH38Z0mp0LCQnBtGnT0NXVxYxFSEgIkpKSkJiYiMjIyNNiKGmfzqlTp1BYWOjXQ9509tnQff216xhw3qCOxYthf/hhkOnTfR7DbrezG4ZeO83yEUJQXV2tyd02UoRMmcIa69WgDhqJjQUnRa9De/eCW78eIffeq1k6Gdq8GUQ1GOQLtAentbUVHR0dMJlMzFDGxMS4X29XF0Kzs5nRtqxdC/0NN0Df1gYhNha6ri44fvQj6F99le1iffZZGH/7W3Yd1ldfhVBeHtA6AwFV6KCKUp6+M/qQOHToEFZLE7dRUVF4/vnnsXz58jE9ST6O0cHQ0BArkQciEbl3715YrVbMmjULg4ODrFpEpXTp/XS6ejNPnDiBuro63xnVzk6EzJsHXuplFLKyoDt61Km1bbdDWLQIVlXp0BMEQUBHRwd7hnAcx2xJaGgoqqurERkZ6Tenor/wZkcdl18Ofts2p7IOACE/HzpZSV0dqAPOXs4hqdfdX3i6dtoPr1X5Cpk6FXxjo9fjOq66CsRshuHRRxn3J1tndDSGTp5kVEbBhiAIqKqqAsdxXpWOHA4Hu/aLLroIbW1t4HkeDz/8MK666qozPvD2bcIZczI/+eQTXHfddVi1ahXKy8tRVlbms5xL+x0p0az8phcEAe3t7WhpaUF7ezsMBgNzOEcrMhcEAfv27UN/fz8KCwv97tPhDhxASGmpoiHafu21sD/xxLBuPrmxoBKHMTExyMnJQWxsbFCNo/6RR2C87z72N+E4gBAX/UZBAcSUFOg/+AAEQN/OncCPf4youjqIYWHg5Vlbk8lpGEeQHaDXTh1uAMxQxsXFsd+U8cc/hv6ttwAAvcuWob+nB6lffeVSKXrmGZhuvJEdd6iqCiGFhc7sa0ICLA0NI1qnN1AH02w2+511ttvt+PGPf4w9e/Zg8eLF2LhxIwwGA44cOXLGBzbGcfrQ0tKCWbNmYenSpVi9ejWWLFnis5wrD9RnzZqlyM7RvuiWlha0tbWBEMIczmAM4mlBLZ4RGxvre6e+PoROmODqz6THMplgqaoCycwMeB2iKKK7uxutra1oaWmBzWZDWFgYJk6ciISEhKCKGej+8Q+YZAOJJDyc9emL6enOvnGpckKHfuzR0TD09EAwm6GTTZoDzmltqyyrFSjotdMsp91uZ7MAdBARAAy33ALDP//p9VjCWWeBxMZC/847zvXLHE37ddc5n3OjAOpgAmB9vL5ACMEf/vAHPPfcc1izZg2++uorNDY24siRI9+YfsyxjjPmZFosFnzwwQdYu3Yt3nvvPYSHh2PlypVYvXo15s6d61aWoAo1kydP9tkrIQgCOjs7maGUR+axsbFBcTjpQA0AFBQUBNynw33yCUy//jW4U6fguOQS2B97zE0PNlCcPHkS+/fvR1ZWFux2O1pbWyGKIovM5U7XcMHV1yO0oEDzPQLA+vbb4D/7DMbHHwcAdBQXw1xZ6SxpyTKcgLOR3PrBByNaj+L8hCgMpdVqRVxcHBITE5FcUYGISy8FAFijojDwyCMwS1PlRK+HWFzMsstEr4f9uutgfPZZdk1ikId+KCwWCyoqKhATE+O3BJzD4cB1112Hffv2YdOmTUhMTIQoijh69KjfZO3j+HZAEAR8+eWXeOONN7B+/XoMDAxg+fLlKC8vx7nnnuvWu+wtUFeD3k8tLS0seA2mLQFcAzXd3d0oLCwMKIOk/+MfYfy//3OtV6+H7aWXRlxx6OzsRHV1NVJSUqDX69Ha2gqLxcJsidzpGsFJECaj/aEKcDRbqa6s9E+eDL6/H2EyRg85rH/5CwRZkDwSEELQ39+P1tZWtLW1ob+/HzExMUhMTETq3r2I+sEPlNvzvJPSDtJMQWIiSFwceImST4yOBt/TAwLAsn8/yCj0OgqCgOrqaoiiiKKiIr8dzEceeQRPPfUUPv30U+Tn5wMAGhoazni5/NuEM9qTSWGxWPDJJ59g3bp12LBhA/R6PVauXIk1a9Zg3rx5eOSRR5Cfn4+5c+cGzFc1GpH54OAgqqqqEBEREZSBmpGCEIKjR4/i6NGjyM/PZ6SxhBD09PQwiUur1cqmtYdtKAlxlnokyUgSHg5Yrc4J7bAwDLW2Qv+738H46KPak4Wy1+y/+Q3sv/vdcC/bxzIJ05Nva2tDX08Pzr/6aoR0dwMAhj75BKESeTwzjpKxFFNSwHV1gbNYQCIjMaTqKQoWKCdhIA6mIAi48cYbsXPnTmzatGk82h4HgyAI2Lp1K9auXYu33noLXV1dWLp0KcrLy3H++eczYv4lS5YEPNRACEFvb68iyxcfH4/ExMRhU+RQiiKHw4HCwsLAp54Jgf6vf4Xu7bchFhY6y7SSeMRw0dLSgpqaGuTm5iJNRjBOna7W1lb09/cjNjaWOdzDpQoLmTED/JEjykuS+twdK1eyTCAA1N5zD/Kef95JFyTbDpD6MdvbgVFilJBTrfU0N2PZpZeycj1jR6Hrh2RLpdYFQGZXk5JgkbF3BAuCIDCqq8LCQr9+i4QQ/O1vf8MjjzyCjRs3ori4OOjrGocTY8LJlMNut+Pzzz9nhrKnpwc8z+OBBx7AtddeOyKuM0II6+EcbmTe09ODqqoqpKSkBFe6a5gghKCurg4tLS0oKiryyN0md7rkhjLgaW0Axp/+FPpXXnEel+Pg+NnPYHjqKQDA0JYt4B59FCESnx01MAAUmrwAYHnrLYjnnz+s6w4U9fX1MDz2GKZJQ0b9GRkIP3HCtTadDmTCBPDHjoFERoKTVH+sd94JQSJSDiasVisqKioYl6o/vyNRFPHzn/8cX375JT7//HPvSiPj+E5DFEXs3LkTb775JtatW4fjx49DFEXceOONuOeeewLieFSDZrpohnNoaCjgLJ+comjmzJljQvb0+PHjqK+v9zm8SZ2u1tZWNoToDw+pGoZf/hKG557TfE/IzYVOYuroz8mBuGULItPSWAZT7tyJkybBsnu33+cdCZqampBw3nmIPnrUeW69XqEhL7f3ABS21Pa738Hxm98EdT3UwXQ4HCgqKvLbwXzmmWfw4IMP4qOPPsJsGY/zOIKPMedkUrS1taG8vBzd3d0oKyvDxo0bFaWgc845Z0RcgDQyp4bSn8jcJ0XRaQZVw+jt7WVKMv5iaGiIOZw9PT2IiopiDwlfhlL3v//BdO217G/bHXfA+PDDAID+X/4S5M03ESlrDmeDTeedB/3Gjc7XQkIwdOLEqEXf7NyE4PDhwzh+/DiKZ85EYna2IvL2uq9Oh6G2NkYpEizYbDbs2rWLDRT462D+6le/wkcffYRNmzYhSyJsHm38/e9/xyOPPILm5mbk5+fjySefRJlKJlSOxx9/HM888wwaGxsRHx+Piy66CA899NA3ghj+2wiLxYJrr70Wn332GZYtW4atW7fi6NGjOOecc1BeXo7ly5ePuGd9YGCA2dH+/n7GyeiJ17evrw+VlZVISEhAXl7eGe8hpjaisbHR/55QCfJp7Y6ODoSFhbFr9zV8qlu/HqbLLnOtQ579g6viM/j22+AyMhBaUKBdKv/jHyGoBCdGA83NzaitrcW8r76C+U9/cqtU9aemIkKqcFHQfkwCOPvvA3DCfUEURUYtFYiD+c9//hP33nsv3nvvPZx11llBW483fJft6JkPHz3g6NGjmDx5Mp599lmEhoZCEARs27YNb775Ju644w50dnYqSkGBRJCAkkts8uTJLDI/fPgwampq3CJzGuVOnz59TCgAjJS7Tc5DarPZmMNJOeRohlfLUAoqaUWup8f13rp1iFZPHxoMgN0OvrLStd25554WB7OhoQFNTU0oKSlBREQEhHPOgf7jjxXbiSEh6Fi2DPHr1imMpuXBB0fFwayoqEBERERAGczf/va3eP/99/H555+fNgfztddewy9/+Us8++yzmD17Nh5//HF873vfQ11dnWam59VXX8Wdd96Jf/3rX5g3bx4OHjyIq666ChzH4dFHHz0tax6HEp2dnSxrmJycDEIIampq8Oabb+LJJ5/EzTffjMWLF2P16tVYsWIFzGZzwA5neHg4cnJykJOTw6bUKa8v7eWjZeX29nbs2bMH2dnZyMrKGhOVoAMHDqCtrQ2lpaUBTxVTou+0tDQ4HA7GerFr1y6mPONpFkBYvFjhNFIHUwwJAS/T4+bMZnBUt1zlYBKOgzBC9Rx/cOrUKezfvx+zZs1CyOzZIH/+s8LZJWFhGPzXvxC2bJmrlA6XZCbJzh4VB9NmswXkYL788su4++678c4775w2B/O7bkfHbCbTG+SloLfeegunTp3C+eefj/LyclxwwQUjKgUB7v03JpMJdrsdM2fOREJCQpCuYvgYFe42CXJDSaf05XQm1FDKqSyExYvBbd8O3mJxKfvExYHv6HD16Kh57P7xDwg/+lHQ1q0GpZZqaWlBcXExC0J0L74I0003ubaLiQHX3Q379dfD8NxzbL1tJSXYdu+9ChL0kUaR1MGk5Pj+ZHBEUcTvf/97/Pe//8Xnn3+O3NzcEa0hEMyePRulpaV4SmqFEEUR6enp+PnPf44777zTbfubb74Z+/fvx6effspe+9WvfoWvv/4aW7ZsOW3rHod/oPfI2rVrsXbtWuzZswcLFizA6tWrsXLlSiQmJo7ICbRYLMyOdnd3IyQkBBaLBZMnT0bmMKa/gw05O0hRUVFQVbJEUURnZye7fgDM4ZTTA4UUFoI/eBAANHvYASfzBdfXB+MddziPnZQEXpIQFObPh1UVNAcbJ0+eRF1dHfLz8xEXFwcAMC1YAJ0saSCmpMDS0AD9n/4E4wMPsNeZxOcPfoD+3//er0qZL4iiyGSSi4uL/WrPIITgv//9L37xi19g/fr1OFfqxz8d+K7b0W8k1wnP85g9ezYeeeQRHDx4EF9++SWmTp2KP//5z8jKysIPfvADvPLKK+ju7sZwfOiIiAjk5OSgtLQUZrMZDocDoaGh2L17N3bt2oXjx4/DIos0TyeGhoawY8cOJrcW7F4mvV6P5ORkzJo1C4sWLUJeXh7Lmn7xxReora1Fe3s7U5cAAO7rr9E1caLz/10HUv4tK+UTjoOwdGlQ1y0H7VNtbW1FSUmJwqgJq1eDyLK+VNWH9kZxcE69h3/6KebOnQuz2Yzm5mZs2bIFO3bswJEjR9Df3x/w78put6OyshJhYWF+O5iEEPzf//0f/vOf/2Djxo2n1cGkDrHcGPM8j3PPPRfbtm3T3GfevHmoqKjAjh07AACHDx/G+++/j2XLlp2WNY8jMHAch9zcXNx1113YtWsXDhw4gKVLl+LVV1/F5MmTccEFF+CZZ57ByZMnh2VHQ0JCkJGRgeLiYqSnp8NqtSIyMhL19fXYvn07jhw5ggGJtud0w263o6qqClarFaWlpUGXYeV5HvHx8Zg2bRoWLVrEkgEHDhzA5s2bsWfPHjQ3N8Mu9aTLHUyrapiP37cPnFzuVibn6JC1LY0GKHdpQUEBczABwCaJblBwPT2AIECcN4+9LmRnMy15269+ha6uLmzbtg1bt25FfX39sJ7Poihi7969ATmYALB27VrceuuteP3110+rgzluR7+hmUxPkJeC1q1bhwMHDmDJkiVYvXo1li9fjri4OL8jc7vdjurqahBCGEURjcxbWlpYHyPl4jwdWtG0lykpKYkpwpwuyDnk2traEL5vH866/XbX2i68EJHSsA+FQhFC1m8kzJwJq0zmMZgghGD//v3o7OxEcXGx5vfCf/wx9C++CN369W6ZA8ell8L2+OOAKhs+EqUMu92OiooKNuTgr4NJ6TU+++wzzJo1y5/LDxqampqQlpaGrVu3KvRv77jjDmzevBlfy8QE5Pjb3/6G22+/HYQQOBwO3HDDDXjmmWdO17LHEQQQQtDY2Ih169Zh3bp12LZtG0pLS1FeXo7y8nJkZGT4L0UoiqitrUVXVxejKKJCEi0tLejs7ERoaCizo74kHoMBq9WKyspKmEwm5Ofnn1Z2EEIIk8tta2sDv28flqj6KcXsbMXUuXDWWYDJBJ2U2WJVIp3OOVU+XJlLH2hsbMShQ4dQWFioKdtsuOEGGF5+mf1tefttGG+6CfyJE8rrmToVll27ALhI0Om0Os/zigyvN9tIHczBwUEUFxf73SK2YcMGXHfddXj11VdRPoqCGloYt6PfMidTjpGUgoaGhlBZWYnw8HDMnDlT0whRLdyWlhYm8UgN5UjLAVro7OzE7t27kZWVdcZ7mQgh6OvtRVxeHgySDnnLsmVIUqlsiDNmgN+3z7UfnE6n7aGH4LjlllFZV21tLbq7u1FcXOyzvM1v2gTjXXcBra0Qy8rg+PGPIfoRLQailEEdTEp87a+D+cQTT+Avf/nLGaPXGI5x3LRpEy699FI8+OCDmD17NhoaGnDrrbfiJz/5Ce4dhQn9cYw+CCFoamrCW2+9hXXr1uHLL79Efn4+czgnTpzo0RbZ7Xbs2bMHdrsdBQUFmvejvD2nra0NJpOJ2dGoqKig27nBwUFUVlYy2rAzPXQ00N8Pc1YWdEND7DW3Ce3QUCAsDFxHB0h0NNDbC46QEROwe8PRo0dx5MgRFBUVeVaxGxpylvsl5SVKGg/I5D4BWD76CESj/5HSC1KH0263M4q9+Ph4RZaSDrkODAwE5GC+9957uOqqq/Diiy/ioosuCuxDCALG7ei32MmUg04Prl27FuvWrcOuXbswb948lJeXY9WqVUhNTWXGrLu7G7t37w4oWyiPzDs6OhAeHs76GIMRmXvibjtToLycYb/9LbIlLreBggKE7dnDjKMjOhr9772H6AULlA3iHOecMgxgEt4fUFLnvr4+FBcXB0Z1RciwZc68KWXExMRg7969MBqNyM/P99vBfPrpp/HHP/7xjNJrULWTN998k8lXAk7t3O7ubmzYsMFtnwULFmDOnDl45JFH2Gv/+c9/8NOf/hT9/f1n/IE+jpGBEILW1lasX78e69atw+eff46pU6eivLwcq1evVtjLoaEhVFdXw2QyuakKeYI8eGtra4Ner9fsBx8uent7UVlZidTUVEyePPmMDx0BTtseesklSN65060n0xYVBaMUxFMIM2ZAJwXuQx98ALJwYdDXRCfti4qKEBUV5XVb7vBhhBQVuabiJZo6MSICfH8/HJdcAtu//uXznDTDS+3owMAA4yKNj4/HoUOH0N/fH5CDuXHjRlx22WX4xz/+gR/+8Id+7RNsjNvRb2hPZqDgOA4TJ07EHXfcgW3btuHw4cNYs2YNNmzYgKlTp+Lcc8/FE088gaeeeoqVgwIpRxsMBqSmpqKwsBCLFy9GdnY2+vv7sWPHDtZ/0tPTM6y+puPHj6OmpgYzZswYMw5mQ0MDGhsbEfbww05ZSQBh1dWK6Ls/OxtbJHUKOcRFi0bFwaQN/AE7mMCIdHR5nofZbEZubi7OOussNqF67NgxfPXVVxgaGkJsbCysMv1eTyCE4IUXXsCDDz6I995774zytxmNRhQXFyuaz0VRxKdSr6oWBgcH3Qwgzep+B2LZbz04jkNSUhKuv/56fPjhh2hubsYvfvELVFZWYt68eSgtLcUDDzyAV199FYsWLQLP8ygoKPC7b5wqs82YMQOLFi3C1KlTFf3g+/fvR0dHB0SVbrc/6OjowK5du5CVlTUm+I0BZ5arpqYGkLUdydH9i19AfdfwtbUAnGTswXYwqbxnY2MjiouLfTqYAEBycmCVlcy5wUEQAHx/P8TMTNikYRdf4DgOUVFRmDhxIubOnYv58+cjISEBra2t+Oqrr9Da2or4+HhYrVa/bMmmTZtw2WWX4emnn8alktLbmcC4Hf2OZDI9QV4KevLJJ3Hw4EFkZGTguuuu81kK8gc0Mqd66oFE5nLuNk89MacbtN+xo6MDRUVFCA8Ph+n886H76ivn+5D1YPI8LPfei9D772f7CwYDDrz7LswzZwatFCafNCwqKgqYymk04HA4UFlZycroHR0d6OrqYhnuhIQEN2ooQgheeukl3HHHHXjnnXewePHiM3cBEl577TVceeWVeO6551BWVobHH38cr7/+Og4cOICkpCRcccUVSEtLw0MPPQQAuO+++/Doo4/i+eefZ2WeG2+8EcXFxXjttdfO8NWMYzTR09ODd955B8888wy2bt2KmJgYXHPNNbjwwgv9zuJ7Aq0WUC5OQohCRMPXsZubm1FTU4OpU6ciNTV12OsIJhobG9HQ0ICCggKYzWaEpqYqqOBIWBiGWlpgWrECus2b3fbvnzYNXR9+iNjY2KBktuR0b8XFxQFTOYWUljIHGADE1FRY33oLZMaMEa2ppqYGPT09SE9PR1dXF9rb22EymVh7UkxMjNv1b9myBd///vfx2GOP4dprrz3jAcV33Y6OWZ7M0wGO45CWlob29na0t7fj7bffRlNTE9atW4cHHngAeXl5WL16NcrLy5GXlxfwj1WumS6KIisF7d69GxzHKfTU5TfKSLnbRgO0HN3b24vS0lLWXyVceCFzMpmDKUmeyR1MEhWFpvXr0R8WhqOVlYrPRstQ+ANBELBnzx7YbLaAJg1HEw6HA1VVVdDpdCgoKIBOp2Na8rT37NixY4xDTxAETJo0CW+++SZ+/etfY8OGDWPCwQSASy65BG1tbfjd736H5uZmFBQU4MMPP2Q8sY2NjYrv7Z577gHHcbjnnntw8uRJJCQkYOXKlfjjH/94pi5hHKcJ0dHRMBqNqK6uxvPPP4+oqCisXbsWS5cuRXx8PFatWoXVq1ejtLQ04HudVgvMZjPy8vLQ09ODlpYWHDhwAA6HQyGioe6fp85cfn5+wJLEowFCCI4cOYJjx46huLiY9Tvab7lFSf0THQ3wPGz33YfQJUucr4WEABYLOAAdK1agdt8+iKI4Yj15Od2bmo3DX1g++ACm664D2tshXHABHNdcA4xA8pb21/f09KCkpAQmkwkZGRkQBIFRQ+3ZswcAEB8fD57nkZ6ejpqaGlx88cX405/+NCYcTGDcjn6nM5kUH3/8MTIzMxlFDJWf3LBhA9auXYtPPvkEOTk5KC8vx5o1a0bcME4bnimHmjwyj4mJQW1t7ahwtw0X1JmzWq3u2cLOToRmZ7t0dM1mcJ2dECdNAt/Q4HwtNBSWTZtYVKulJ08fFP4aSkEQUF1dzfRqx4KDKQgCKisrWZnQ03VQQ9nW1oaf/exnbDjizjvvxJ133jkmgopxjCNQ1NTUoKWlBWfLxBoGBwfx4YcfYu3atXjvvfcQGRmJVatWoby8HHPnzh3RZLdcT721tRUWi0XhcB47dgwnTpxAYWGh5+GV0wjqzDU3N7tnCwlByOTJ4E+dcv7J8xg6dQqGu+6C4Z//BACI8fHg29vZVDkxGNDT08PmAaxWKxuc8Vfek9K9tbW1obi4OCDVuNGCvwOchBD09PSgtbUVDz/8MN58800QQnDRRRfhiSee8CoNOo7Th3En0w/QUtDatWvx0UcfIS0tjWU4CwoKRuRwEkIYNRA1FAaDAVOmTEFSUtJppdfQgsPhQHV1NURR9OjM6Z9+GvpHHgHf2gpxwgQFhQXheVi2bAHJz9c8vtxQtLa2MkNJHxRa56NrIoSMClfocCAIAqqqqgAAhYWFfn9v69atw3XXXYfly5ejtrYWR44cwXvvvYdzzjlnNJc7jnGcdlgsFmzcuBHr1q3Dhg0bYDKZsGLFCqxZswbz588fUaBI9dSpHR0YGADP88jJycGECRPOeBBKHSdKrablzPGVlTAtWuQanly6FPoPP3TbzvG978GmposjBAMDAwoRkdjYWNaeo+Wo+UP3drohX1NJSYnfAhhVVVVYtmwZ5syZg+7ublRUVODxxx/HzTffPMorHocvjDuZAaKvrw/vv/8+1q5diw8++GDEpSAKq9WKiooK6PV6REdHo62tjTlcSUlJHvXURxNUWchgMPjkk+MaGxFSWAhORlJPANj+8hcIN97o1/nkDwo6YUh1kBMSEmAymVg52le28HSCZlWp0+vvmii9xksvvYTvf//7AIC6ujqkpqaOWLVqHOMYy7DZbPj888+xdu1arF+/HoQQLF++HGvWrMGiRYuG3VstCAL27t2LgYEBJCYmorOzE319fYiNjUVSUhKzI6cT8sHEoqIir46T/oknnLRqKjANcKMRQ/X1gI/S/9DQELOjlNOZ2tHw8HBFv6M/dG+nA7RNrKOjIyAHc9++fVi2bBluvfVWVmpukjTUx0oP7ncZ407mCEBLQevWrcO7776LyMhIrFy5EqtXrw6oFDQwMICqqioFd5s6Mh8aGoLZbGaGcrQjc4vFouAK9cd55r/+GvrHHgN3/DjI1Kmw33YbyPTpw14D1UFua2tDT08PIiMjYbPZEBISgqKiojHlYNJMr7+BwMaNG/GjH/0IL7zwwhmj1xjHOMYCHA4HvvzyS7zxxhtYv349hoaGsHz5cqxevRpnn322384GFdAAgIKCAmYj1Q5XdHQ04+IcbedKEASFxrY/zrPhJz+B4dVXQQCQxETwra2MO9P6739DuPjigNZgs9mYHe3o6GBZVEEQFP31ZxLysn1JSYnfWdX9+/dj2bJl+OlPf4o//OEPY6IHcxxKjDuZQcJwS0H+crfRUkhLSwv6+/tZhi8xMTHoE9VDQ0OoqKhAbGwspk6dOiZ4ufr7+1FZWQlRFOFwOILORToc0AcI7Qv118H8/PPPcckll+Dpp5/G5ZdfPm4YxzEOCYIgYOvWrXjzzTfx1ltvoaenB0uXLsXq1atx3nnneewZpEFxWFiYRwENwFkxog5nV1cXy/AlJiYGvR+RVl0ApdPrE6KI0JQUcP39yuMtXw7ba6+NiHKNVqcGBwdBCIHBYAgqF+lwMFwHs76+HkuXLsXll1+OP/3pT2PiOTUOd4w7maMAf0tBJ0+eRF1dHXJycpCVleX38Wlk3tLSgt7eXsTExDBDMdKolDpziYmJp1260hOo/it9gAiCwCa1Ozo6YDQa2fX7kngMFkRRRHV1NRwOB4qKivx2ML/88ktcdNFFp51e4+9//zseeeQRNDc3Iz8/H08++STKyso8bt/d3Y27774b69atQ2dnJzIzM/H4449/Y/Vzx/HNgyiK2LFjB3M4W1pacP7556O8vBxLly5lLSUdHR2ora2F2WwOKCimUrFU3jIiIkIRuI4ENpsNlZWVTIgh0KoL/9lnMK1eDU4QQDgOwpVXwvbYYyOSkFTTvel0Ojap3dbWBgCspO4PNVQwQIehWltbA3IwDx8+jAsuuADf//738eijj542B3PcjgaOcSdzlOGpFBQWFoZ33nkHn376aUAOphoWi4UZyu7u7hFF5j09PaiqqkJ6ejpycnLGhINJe1UjIiIwY8YMN2NCuUipNBnlpvRHC3e4EEVRUQLzN0Oxbds2rFmzBg899BBuuumm0/b5vvbaa7jiiivw7LPPYvbs2Xj88cfxxhtvoK6uTnMC02azYf78+UhMTMRdd92FtLQ0HDt2DDExMcj3MMA1jnGMJkRRRFVVFd58802sW7cOjY2NOPfcczFlyhT8+9//xssvv4xFixYN+56iFGNUtS00NJTZUTWnrS/QrKonm+UvuBMnAIsFJDsbGGFrEK262O12TZulpVwmH8AcjXkAQgjq6+vR3NyMkpISv59Xx44dw9KlS7F8+XI89dRTp83BHLejw8O4k3kaQUtB99xzD7788kuEhIRg5cqVKC8vx/nnnz/icg3tvWltbQ04Mu/q6kJ1dTVycnKQmZk5onUECxaLBRUVFYiOjsb06dN9GnpqKOlnIAiCghopGIZyuA7mrl27sGrVKtx///245ZZbTqsDP3v2bJSWluIpSX1DFEWkp6fj5z//Oe6880637Z999lk88sgjOHDgwBmfyh3HONQghGDfvn146KGHGDk1zXAuX74cZrN5RPeXw+FQiGgEUikZHBxERUUFzGYzpk2bNiYC9UDp3qjEI7WjdB6AZjmD0Z5Fyd9PnToVkIPZ1NSE888/H+eccw6ee+6501oiH7ejw8O4k3ma8dhjj+GPf/wj3nnnHXAchzfffBPr169Hc3MzzjvvPKxevVpRChouqJ46LSnTyDwpKcmth7GtrQ179+4dM9rogLIvdDjGWs6h19bWhqGhIcTFxbHIfDiGUl5uCoT8vbq6GsuXL8ddd92F22+//bQ+eIajnbts2TKYzWaEhYVhw4YNSEhIwI9+9CP85je/GRPDVuMYx0cffYQLL7wQL7zwAgoLC1mGc9++fViwYAFWr16NlStXIiEhISiqbdSOyEUkYmNjFcfu7+9HRUUFkpOTx4x0ZTDo3uTUSH19faw9KyEhYVi0R1S+8uTJkwGRvzc3N2Pp0qWYO3cu/vWvf51WWzRuR4ePcSfzNOPw4cOw2WzIy8tjr9FS0Nq1a7Fu3TocO3YM5557LsrLy7Fs2bIR9xk6HA7WwyiPzJOSkjA4OIja2lpMnz4dycnJwbjEEWNoaAi7du1CfHz8sJSWtNDf38+cbrmh9LePVRRF7N27F0NDQwE5mPv27cMFF1yA2267DXffffdpf/A0NTUhLS0NW7duVWjl3nHHHdi8eTO+/vprt33y8vJw9OhRXHbZZbjpppvQ0NCAm266Cbfccgt+//vfn87lj2Mcmujr68Pu3btx1llnsdeo80LtaGVlJebOnYvVq1dj1apVSElJGdH9J4oi62FsbW1lrTlJSUngeR67d+8eU61Go0H3Rtuz6OCUvFoWHh7u13U3NDQE7GC2trZi2bJlyM/Px8svv3za6fzG7ejwMe5kjjHQUhCNzA8ePIglS5Zg9erVQSkFySPzlpYWJkuWmZl5xqYL5RgYGEBFRQWSkpJGLRtgsVjYg6K7uxuRkZEKQ6kG5bkbGBhAcXGx31nQ/fv344ILLsANN9yA+++//4x8tsMxjlOmTIHFYsGRI0fYg+nRRx/FI488glOSIsk4xjGWQQhBY2Mjczi3b9+OsrIylJeXo7y8HOnp6SO6H6kqXGtrK5qbm2G32xEVFYWcnByYzeYznqmy2+2orKz0i+N4uLDZbIoBzJCQEGZHo6KiND/fQ4cO4cSJEwHpo3d0dGD58uWYPHky/ve//52R0vO4HR0+zrxUyjgU4DgOM2fOxMyZM3Hfffehrq4Oa9euxfPPP49bbrllxKUgWu6hHJSTJ0/G4OAg01OnkblaT/10gJabUlNTMWnSpFFzykJCQpCRkYGMjAw2Ydra2orDhw+ztoKEhARERUUxpz9QB/PgwYNYsWIFrr76atx3331nzHmnes4tLS2K11taWjxmrlNSUmAwGBQPpqlTp6K5uRk2my3olFnjGEewwXEcMjMz8ctf/hK33XYbmpqasG7dOqxbtw733HMPCgoKmMM5nMwjx3Ewm80QBAEnT55EVlYWo+Kx2WwKEY3T7XDSyXaTyYT8/PxRs+NGoxGpqalITU1VMH5UVlay50xCQgJ7lhw+fBjHjx9HSUmJ3w5mV1cXysvLkZWVhf/+979nrLdx3I4OH+OZzG8IglUKosc5ceIEioqKEBUVBUB7aIZGpacjMqcOZlpaGiZOnHhGnDLa8E/bCnQ6HXQ6HURRRFlZmd9KIYcPH8bSpUtx8cUX469//esZ52+bPXs2ysrK8OSTTwJwftcZGRm4+eabNRvW77rrLrz66qs4fPgwW/sTTzyBP//5z0xJYxzj+CaCEIKWlhasX78e69atw6ZNmzBt2jSUl5dj9erVAVVPTp06hdraWsyYMQNJSUns+OqhGV8yucGEmu7tTNgeURRZlre1tRWEEISEhGBwcBDFxcV+68j39PSgvLwccXFxeOutt844afy4HR0eRs3JDJRP6o033sC9996Lo0ePYvLkyfjzn//8neKSCgTyUtBbb72Fbdu2oaysjMlbeioF0Ui7tbUVRUVFHqNJuZ54S0sLo7MYrci8r68PFRUVyMjIQE5OTlCPPVxQLfK+vj72WcqpkTx9BpReY8WKFXjyySfPuIMJOKk3rrzySjz33HMoKyvD448/jtdffx0HDhxAUlISrrjiCqSlpeGhhx4CABw/fhzTp0/HlVdeiZ///Oeor6/HNddcg1tuuQV33333Gb6a7x7GbenogBCCzs5ObNiwAWvXrsUnn3yCyZMnY9WqVVizZo1Xzs0TJ078//buPC7Kcu0D+A+QARVZTBREBVxAj2IIBG7hLpUKY1q45F5mSiXWcXldKM0tOyePG33EzDKNo4KkgCgikIrhAi4JCoigIAyosSsDw/X+0TvzOgE6Mw6zwPX9fPjDx+eZuYbq1/3MfT/XjYyMDPTv3x8dnrPF49/3U5c+fKiup7Sf9aJ2b9og3SrywYMHMDY2rtcaqbFBd3l5OSZOnChr9acL+6pzjqqmSQaZyvaTSkpKgre3NzZu3Ijx48fj4MGD2Lx5M1JSUtCvXz91l9esEJHcVNC5c+canAoSi8VIS0tDRUUF3N3dFf6P9tk7c5FIhKdPn6r1zry0tBQpKSlwdHR8qX6h6iTd17esrEw2Rf7st7zSoLS2toa1tbVsEXp+fj58fHy00l7jRXbs2CEbqLi6umLbtm3w8vICAAwfPhwODg7Yt2+f7PwLFy4gMDAQV69ehZ2dHebNm9finorUBZylmiG9sT5+/DjCwsJw6tQpdOnSBX5+fpg4cSL69+8v++85IyMD+fn5cHV1hZWVlcLvIV2iJBKJZPupS2eLXnY/dWXbvWlKTk4OcnJyZGswpYPuoqIiVFZWyrVGkv4OKisrMWnSJBgYGCAqKuqlG+OrE+eo8ppkkKlsPyl/f39UVlYiMjJSdmzgwIFwdXXFd999p+7ymi0iQlFRESIiIhAWFiabCnrrrbdw+vRpODk5Yfv27SoHGhGhsrISIpFIFhIvc2deUlKC1NRUnerNSURIS0tDSUkJPDw86v2unt1TXvo7OHToEOzs7HD48GG8/vrrGm+vwZovzlLtKC8vR1RUFMLCwhATE4MOHTrA19cXOTk5KCoqwtGjR2VLjVQhffhQJBLJ9lOXDjiV/dbuZdu9NZXc3FxkZ2fD3d29wd9VVVWVbD18aWkp4uLiYGhoiAsXLsDIyAgxMTEv3cqPaZ/aB5mq9JPq1q0blixZgsWLF8uOBQUFISIiAteuXVNneS2GdCro0KFDWLNmDR49eoSePXti8uTJL5wKUlRVVZVswKnsnfmff/6J1NRU9OrVC127dn2pOtSFiJCeno7Hjx/Dw8NDoTVAVVVV+PLLLxESEgKxWIzBgwdj0qRJmDlzJl555RUNVM2aK85S3VBZWYno6GisXLkSWVlZsLa2xjvvvAM/Pz8MHDjwpW8o/76f+ou6XTxL2vxdne3e1OHevXu4c+cO3NzcFFqDWV1dje+//x7r169HaWkp+vTpg3feeQczZ87UmSVUTDVqn897+PAhJBKJbCG0VKdOnVBYWNjgNYWFhUqdz17MwMAAFhYWOHDgAFxcXJCbm4vVq1cjLS0Nw4YNg5ubG4KCgpCamoq6ujqV3qNNmzZwdHSEl5cXhgwZgg4dOqCwsBBnz57FpUuXkJubiydPntS77vHjx0hNTYWzs7NeDzCBv0I+ISEB48ePR05ODt577z2cOHECpaWlTVwxa+44S3VD27ZtERcXJ8uIkJAQVFRUwN/fH87OzggMDERiYiJqa2tVen0TExN07doV7u7u8Pb2RpcuXVBSUoILFy7gwoULuHPnDioqKvD374MqKytx+fJldOzYUacGmPfv31dqgAn89f+rxMREODo6Ijs7GytXrsTNmzdx69atJq6WNTVuYdSMtWrVCsuWLcOYMWNgamqKGTNmYMaMGXJTQW+88YZsKmjixInw8PBQ6RvO1q1bw97eHvb29nJ35pmZmbI7c2nz9+vXr6N3797o3LlzE3xq5UkXpys7wJS21+jevTsOHjwIgUCABQsWYMGCBU1cMWNMk6ZNm4YvvvgCNjY2cHZ2hq+vL8RiMc6cOYOwsDDMnDkTBgYGGDduHCZOnAhvb2+VHuwRCASws7ODnZ0damtrZdPJOTk5sj6UnTp1goGBAVJSUpq83Zuy7t+/j6ysLAwYMEDhAWZNTQ3mzJmD3NxcnDlzBh06dICDgwOmTZvWxNUyTVD7IFOVflI2NjZKnc8UN2HChHrH2rVrhylTpmDKlCmorKxETEwMwsPDIRQKYW5ujgkTJkAoFKo8FSS9M+/atatcH8o7d+6AiGTNeolI6+EofeL+4cOHSg0wS0tLIRQKYWNjg0OHDrWYnmdMczhLdYe3t3e9YwKBAG+88QbeeOMNBAcH47fffsPhw4fx4Ycforq6GuPGjYNQKMSIESNUar/TqlUr2NrawtbWVq4P5eXLlyGRSGBubv7cJ9s1LS8vD5mZmXBzc4OlpaVC19TW1mL+/Pm4ffs24uPjderzMPVQ+3S5QCCAu7s74uLiZMfq6uoQFxcn1yn/WYMGDZI7HwBiY2MbPZ+pT9u2bTFp0iQcOHAABQUF2LFjByorK+Hv7w8nJycsXrz4paaCnr0zByCbHk9OTkZSUhIyMzNRVlZWbypIE4gIGRkZKC4uhoeHh8IL7svLy/H222/DwsIC4eHhL/1kqKJ27twJBwcHmJqawsvLCxcvXlToutDQUBgYGMit62O6j7NUf7Rq1QojR45EcHAw8vLyEBERASsrKwQGBsLR0RFz587FsWPHUFVVpdLrGxkZoVOnTrC3t4eBgQFsbGxgZmaGa9eu4ezZs7KZGFWXPr2s/Px8ZGRkYMCAAQoPMCUSCRYuXIjU1FTExcXVW+bRlDhLNafJWhgp008qKSkJw4YNw6ZNmzBu3DiEhoZiw4YN3HZDi8RiMeLj43HkyBHZAwaqTgUVFhYiLS0NLi4usLa2BgC5O/Pi4mIYGxvLpoJedq92RUgHmEVFRXB3d0ebNm0Uuk7aXsPQ0BBRUVEK7737spRtZSOVk5ODoUOHyra7i4iI0Ei9TD04S/VbXV0dkpOTceTIEURERKCoqAhjx46FUCiEj4+PUu15Gmr31lDjc+mube3bt9dIG7UHDx7g1q1bGDBggMItnerq6vDxxx/j7NmziI+P1+jafM5SDaMmsn37durWrRsJBALy9PSk33//XfZ3w4YNo1mzZsmdf+jQIXJyciKBQEB9+/alqKgohd9rx44dZG9vTyYmJuTp6UnJycmNnrt7924aOnQoWVpakqWlJY0aNeq55zOimpoaiouLowULFpCtrS1ZWVnRe++9R0eOHKFHjx5RZWVloz9ZWVl0/Phxys3NbfScsrIyysnJoYsXL1JkZCSdOHGCrly5Qvfv36fy8vLnvr4qPxUVFZSamkonTpyg4uJiha97+PAhjRgxgoYMGUJlZWUa/Wfg6elJixYtkv1ZIpFQ586daePGjY1eU1tbS4MHD6Y9e/bQrFmzyM/PTwOVMnXTVJZyjjYtiURCly5douXLl1OvXr2odevWNGHCBNqzZw89ePCAKioqGs2e/Px8ioyMpPT09OfmWl5eHqWkpFBMTAxFRkZScnIy3b17l8rKytSeo5WVlZSZmUnHjx+n+/fvK3xNeXk5zZ8/n+zt7enu3bsa/+fAWapZer+tpLJ3JdOnT8eQIUMwePBgmJqaYvPmzTh69Chu3rwpm9JljZNIJDh//rzszry0tBRvvvkm/Pz8MGbMGLlvBPPz83H79m28+uqrCrfzkd6Zi0QiFBcXy9ZwSnfaedk7cyJCVlYWCgoK4O7urvA3kU+fPsXUqVNRWlqKkydPKryoXR1UaWUD/NW65vr16zh69Chmz56NkpISvvtmDeIc1ay6ujr88ccfOHLkCMLDw5GZmYlRo0bB19cX48ePh5WVlWw2R5V2b0SEsrIyWS9O6X7q0k00pBtIvIyCggKkp6crne8rVqxAREQE4uPj0bNnz5euQxmcpZqn94NMZZsV/51EIoGVlRV27NiBmTNnNnW5zcrfp4JEIhF8fHzg5+eH27dvIz09Hdu2bUP79u1Ven0iQklJiawXp0QikW3t+Morryj9UBL9377t+fn58PDwUHiAKRaL8d5776GgoACnT59WapcPdXjw4AHs7OyQlJQkt7Zu6dKlSExMRHJycr1rzp07hylTpuDq1avo0KEDByN7Ls5R7aH/624hHXDevHkT3t7eEAqFEAgE2Lt3L3788UeVp5TpmQ0kRCIRnjx5IreJhiq7tqk6wAwKCsIvv/yC+Ph4ODs7K/2+L4uzVPN0Z987FYjFYly5cgWjR4+WHTM0NMTo0aNx4cIFhV6jqqoKNTU1Kg+EWjJDQ0MMGjQI//rXv5CZmYmEhAQ4OTnh888/x4YNG1BQUICTJ0+itLRUpQd7DAwMYGVlhd69e+P111+Hm5sbTExMkJGRgcTERFy/fh2FhYUKP5SUnZ2t9ACzpqYGs2fPxv3793Hy5EmNDzBVUV5ejhkzZiAkJISf1mQvxDmqXQYGBujTpw9Wr16NlJQUpKWlYfTo0di+fTs+/PBDPHz4ENHR0SgoKFA5R9u1a4cePXpg8ODBGDhwICwsLHDv3j0kJiYiJSUFeXl5EIvFCr1eYWEh0tPT0b9/f4UHmESEDRs24Oeff0ZsbKxWBpiq4Cx9eXrdJ/N5zYoVbeK6bNkydO7cWS5gmfIMDQ3h4eGB+Ph41NTU4MCBA7h16xa+/fZbLFy4ECNHjoSfn1+9qSBFSZvLW1hYoGfPnqioqIBIJEJ2djZu3rz5wjvzO3fuIC8vT6kp8traWnzwwQfIzMzUansNZVvZ3LlzBzk5OXLtq6RPnbZq1Qq3b99Gjx49mrZopjc4R3WHgYEBevbsib59+yIvLw/bt29HdXU1wsLCsHTpUnh6esLPzw9+fn7o0qWLSg9Itm3bFo6OjnB0dMSTJ08gEolkD+9YWlrKlic11HZJJBLh5s2bePXVVxXOQyLCli1bsHv3bpw5cwZ9+/ZVumZ14SzVPL0eZL6sTZs2ITQ0FAkJCSr1MWP1CQQCxMXFwc3NDQDw5ZdfyqaCdu/ejU8++UQ2FTR+/HhYW1urNOBs164d2rVrh549e8r2U7937x7S0tLQvn17WVAKBAJkZ2fj/v378PDwUPhpTml7jWvXriEhIeG5Tx02tWdb2UjXEUlb2QQEBNQ7v3fv3rhx44bcsVWrVqG8vBz/+c9/dGaXJdY8cI6qHxFh//79ePvttwEAS5YsQX5+PsLDwxEeHo6VK1diwIABEAqF8PPzg4ODg0oDztatW8PBwQEODg6y/dSLioqQkZEBc3NzWceP1q1bo6ioCH/88Qf69++v1ABz27Zt2LZtG2JjY9G/f3+la1QnzlLN0+s1maou4gWAb775Bl999RVOnz4NDw8PDVTLpGsijxw5gqNHjyIlJQWDBw+GUCiEr68vbGxsXrp1UVVVlSwoy8rKYGpqiurqari6uio8tSORSPDxxx/j3LlzGm+v0RhlW9n8nTrWEf30008IDAzEgwcP5HqDCoVCtGvXDvv371f5tZn2cI7qFyKCSCRCREQEwsLCkJCQgH79+sHPzw9CoRC9evV66RwVi8WyHH38+DFMTU3x9OlTODk5oVu3bgrXGRwcjK+++gonT56El5fXS9WkLtrO0paWo3q9JlOVZsUA8PXXX2PdunWIiYnhYNQg6VTQ8uXL8fvvvyMzMxO+vr4ICwuDs7Mzxo4dix07duD+/fsqN2dv06YNHBwc4OnpKdvism3btkhNTcXFixeRk5PT4H7qUnV1dfjss8+QmJiI06dP68QAEwD8/f3xzTffYM2aNXB1dcXVq1cRExMjm+K8d+8eCgoKmrSGd955BxKJBMeOHZMdKyoqQlRUFObOnduk782aDueofpE2Y1+wYAFOnTqFgoICBAQE4OLFi/Dy8sLAgQOxfv16pKWlqZyjAoEAXbp0gZubG/r27YunT5+iXbt2yMzMRFJSErKyslBeXt7o6xMRvv/+e6xbtw6RkZE6M8AEtJ+lLS1H9fqbTED5u5LNmzdjzZo1OHjwIIYMGSJ7HTMzM6Ua4zL1ISK5qaDz589jwIABsrVHjo6OSt+Z5+bmIjs7G+7u7jA3N693Z25mZoZOnTqhY8eOsjWadXV1WL58OX799VckJCTwWpsGLFy4EDk5OYiOjgYA/Pvf/8bOnTuRlZWl9S1Cmeo4R/UfEaG0tBTHjh1DWFgYTp06BXt7e/j6+mLixIlwcXFRugVccXExrl+/jn79+qFTp06ora2VbaLx8OFDCAQCWY6am5vDwMAARISffvoJS5cuxfHjxzF8+PCm+cB6rEXlqAZ6cTY5ZZoV29vbE4B6P0FBQQq9lzINi5/1yy+/EABu4voCdXV1VFBQQMHBwTR69GgyNjYmV1dXCgoKopSUlOc2LJb+pKWlUWRkJBUUFDT49yUlJZSZmUnnzp2jY8eO0bp162j+/Pk0ZcoUsrGxodu3b2v716CzUlJSyMjIiPLy8oiIyMXFhdauXavlqpg6cI42L6WlpXTw4EGaNGkStW3blrp3706LFy+mxMREhTa5yM3NpWPHjlF2dnajm2jcvXuXkpOTKTIykr777juaMmUKffLJJ9SmTRuKjY3V9q9AZ7WkHNX7bzI1ibej0iwiwuPHj2Vrj+Li4tCrVy/4+flh4sSJ6NOnT727vnv37uHOnTtwc3NTqGF6bW0toqOjsWLFCuTk5KBbt26YMmUKpk6dCldX1yb6ZPrN3d0dkydPxtixY+Hp6YmcnBydWVbAdB/nqOZVVlbixIkTCA8PR1RUFCwtLeHr6ws/Pz94eXnV6zn86NEjXLt2Df/4xz8afOr67+rq6nDp0iUsXboUly9fhqWlJfz9/fHuu+9i5MiRTfWx9FpLyVEeZCpBlYbFEokE3t7emDt3Ls6ePctNXFVEz0wFhYeH4+TJk+jWrZtswOni4oLdu3fDxsYGI0aMUHhHHiLC119/jZ07dyIqKgoPHjxAWFgYunfvjrVr1zbxp9JPwcHB2Lp1K8aMGYPMzEycPHlS2yUxPcI5ql1PnjxBbGwswsLCcPz4cZiamsLX1xdCoRCDBw9GdHQ0Hj9+DB8fH9ja2ir8ur/++ivef/99/Pzzz7CwsEBYWBj+/PNPHDx4sAk/jf5qMTmqxW9R9Up1dTUZGRnR0aNH5Y7PnDmTfH19G71uzZo1JBQKiYh4z1M1kk4FTZ48mdq2bUuvvPIKtWrVir799luF9zuvqKig9evXk5WVFV2+fFnbH0lvlJSUUJs2bUggEFBoaKi2y2F6hHNUt1RXV1N0dDTNmzePOnToQBYWFmRkZEQLFiygkpIShfcjP3ToELVp04aOHDmi7Y+kN1pKjur10+Wa9LyGxYWFhQ1ec+7cOXz//fcICQnRRIktirm5OaZOnYrDhw9j06ZNqKqqgre3N4KCgtC3b18sW7YMSUlJkEgkDV5PRNi1axe2bNmCmJgYuLu7a/gT6C8LCwtMmjQJZmZmci1vGHsRzlHdIhAI8Oabb2LPnj345ZdfIBaLMXToUERERKB79+746KOPEBMTg+rq6kZfIzY2FnPmzMGePXswadIkDVav31pKjvIgs4nwdlSa8ejRI2zatAmnTp1CXFwcCgsLsX37dpSVleHdd9+Fs7MzAgMD8dtvv8m2nyQi7NmzB1999RUiIyPh6emp0Zp37twJBwcHmJqawsvLCxcvXmz03JCQELz++uuwsrKClZUVRo8e/dzzNSU/Px/Tp0+X6/PGmLpxjmpGXV0dPv/8c+zcuRMJCQnIy8tDeHg4zM3N8emnn8LR0RHz5s3D8ePH5VrAJSQkYPr06di1axemTJmi0Zo5R/WEtr9K1RfKTvOkpqYSADIyMpL9GBgYkIGBARkZGVFWVpaGKm/+njx50uDxv08FWVtb05w5cyggIIDMzMwoPj5es4USUWhoKAkEAtq7dy/dvHmTPvjgA7K0tCSRSNTg+dOmTaOdO3dSamoqpaen0+zZs8nCwkL2VKKmPX78mMLDw8nQ0JBu3bqllRqY/uIc1V2N5ahEIqHz589TYGAgOTo6kpmZGU2aNIlWrVpFbdu2pZCQEKqrq9NorZyj+oMHmUrw9PSkgIAA2Z8lEgnZ2dnRxo0b65375MkTunHjhtyPn58fjRw5km7cuEHV1dWaLL3Fq6mpodOnT9PcuXPJyMiIfv75Z63U4enpSYsWLZL9WSKRUOfOnRv8d6ghtbW11K5dO/rxxx+bqsTnsre3J3Nzc9qyZYtW3p/pP85R/SWRSOjixYu0dOlSat26NS1YsEDjA0wizlF90qL3LlfWkiVLMGvWLHh4eMgaFldWVmLOnDkAINew2NTUFP369ZO73tLSEgDqHWdNr1WrVhg1ahRGjRqFXbt2aWV6QiwW48qVK1ixYoXsmKGhIUaPHo0LFy4o9BpVVVWoqalB+/btm6rM58rJydHK+7Lmg3NUfxkaGuK1117Da6+9hrVr18LY2FjjzcM5R/ULr8lUgja2o1Jm3QkAlJSUYNGiRbC1tYWJiQmcnJxkuwqwv2hr/YsqDz383bJly9C5c2eMHj26KUpkrMlxjjYPJiYmSu8gpA6co/qFv8lUUkBAAAICAhr8u4SEhOdeu2/fPqXe67///S+WLFki17TYx8en0abFYrEYY8aMQceOHXHkyBHY2dkhNzdXdufP9NumTZsQGhqKhIQEmJqaarscxlTGOcq0hXNUw7Q9X88ap+y6k+DgYOrevTuJxWJNlciUoGqPQCKiLVu2kIWFBV26dKkJK2Ss+eEcbV44R/ULT5frKOm6k2e/zn/RupNjx45h0KBBWLRoETp16oR+/fphw4YNjfaKZJolEAjg7u6OuLg42bG6ujrExcVh0KBBjV739ddfY926dYiJiYGHh4cmSmWsWeAcbX44R/ULT5frqOetO7l161aD12RnZ+PMmTOYPn06oqOjkZWVhYULF6KmpgZBQUGaKJu9gDIPPQDA5s2bsWbNGhw8eBAODg6yNUdmZmYwMzPT2udgTB9wjjZPnKP6gweZzUhdXR06duyI3bt3w8jICO7u7sjPz8eWLVs4HHWEv78/iouLsWbNGhQWFsLV1bXeQw/PLqYPDg6GWCzG5MmT5V4nKCgIX3zxhSZLZ6xF4BzVfZyj+oMHmTqqQ4cOMDIygkgkkjsuEolgY2PT4DW2trYwNjaGkZGR7FifPn1QWFgIsVgMgUDQpDUzxSjz0ENLanXBmLpxjjZfnKP6gddk6ihV1p0MGTIEWVlZqKurkx3LyMiAra0tByNjrMXhHGVMu3iQqcOWLFmCkJAQ/Pjjj0hPT8dHH31Ub93Jsw1pP/roIzx+/BiffvopMjIyEBUVhQ0bNmDRokXa+giMMaZVnKOMaZG2H29nz7d9+3bq1q0bCQQC8vT0pN9//132d8OGDaNZs2bJnZ+UlEReXl5kYmJC3bt3p/Xr11Ntba3C77djxw6yt7cnExMT8vT0pOTk5Oee/+2335KTkxOZmppSly5daPHixY3ugcsYY9rAOcqYdvAgk8mEhoaSQCCgvXv30s2bN+mDDz4gS0tLEolEDZ5/4MABMjExoQMHDtDdu3fp5MmTZGtrS4GBgRqunDHGdAPnKGP/z4CISNvfpjLd4OXlhddeew07duwA8Nfapa5du+Ljjz/G8uXL650fEBCA9PR0ufVOn332GZKTk3Hu3DmN1c0YY7qCc5Sx/8drMhkA1ZoWDx48GFeuXJHtA5ydnY3o6Gi89dZbGqlZW5TdB/nw4cPo3bs3TE1N4eLiwnsgM9ZMcY4qjnO0ZeBBJgPw/KbF0sa1fzdt2jSsXbsWQ4cOhbGxMXr06IHhw4fjf/7nfzRRslZI90EOCgpCSkoKXn31Vfj4+KCoqKjB85OSkjB16lTMmzcPqampEAqFEAqF+OOPPzRcOWOsqXGOKoZztAXR9nw90w35+fkEgJKSkuSO//Of/yRPT88Gr4mPj6dOnTpRSEgIXb9+ncLDw6lr1660du1aTZSsFcrug/zuu+/SuHHj5I55eXnRhx9+2KR1MsY0j3NUMZyjLQd/k8kAqNa0ePXq1ZgxYwbef/99uLi4YOLEidiwYQM2btwo12OuuVBlKuzChQty5wOAj49Po+czxvQX5+iLcY62LDzIZABUa1pcVVUlt3UXANkuGdQMnydTZSqssLBQqfMZY/qLc/TFOEdbFh5kqklxcTFsbGywYcMG2bGkpCQIBAK5wNFlyjYtnjBhAoKDgxEaGoq7d+8iNjYWq1evxoQJE+S2ZGOMMUVwjnKOsuaF9y5XE2tra+zduxdCoRBjx46Fs7MzZsyYgYCAAIwaNUrb5SnE398fxcXFWLNmDQoLC+Hq6oqYmBjZHeS9e/fk7rhXrVoFAwMDrFq1Cvn5+bC2tsaECROwfv16bX2EJqXKVJiNjY1S5zPWknGOco42hHNUj2l7UWhzs3DhQnJycqJp06aRi4sLPX36VNsl6azExEQaP3482draEgA6evToC6+Jj4+nAQMGkEAgoB49etAPP/zQ5HU+y9PTkwICAmR/lkgkZGdn99wF6+PHj5c7NmjQIF6wzthzcI4qjnOU6TIeZKpZVVUVde/enYyNjen69evaLkenRUdH08qVKyk8PFyhcMzOzqY2bdrQkiVLKC0tjbZv305GRkYUExOjmYLpr908TExMaN++fZSWlkbz588nS0tLKiwsJCKiGTNm0PLly2Xnnz9/nlq1akXffPMNpaenU1BQEBkbG9ONGzc0VjNj+oZzVHGco0yX8SBTzW7cuEGmpqZkZGREx44d03Y5ekORcFy6dCn17dtX7pi/vz/5+Pg0YWX1KbsP8qFDh8jJyYkEAgH17duXoqKiNFovY/qGc1Q1nKNM1/C2kmokFovh6ekJV1dXODs7Y+vWrbhx4wY6duyo7dJ0noGBAY4ePQqhUNjoOd7e3nBzc8PWrVtlx3744QcsXrwYpaWlTV8kY6zJcY6qjnOU6Rp+ulyNVq5cidLSUmzbtg3Lli2Dk5MT5s6dq+2ymo3G2liUlZXhyZMnWqqKMaZOnKNNi3OUaRIPMtUkISEBW7duxf79+2Fubg5DQ0Ps378fZ8+eRXBwsLbLY4wxncc5yljzwi2M1GT48OGoqamRO+bg4MDTD2rUWBsLc3NztG7dWktVMcbUhXO06XGOMk3ibzKZ3hg0aFC9hsyxsbGN7qTBGGNMHuco0yQeZDKtqaiowNWrV3H16lUAwN27d3H16lXcu3cPALBixQrMnDlTdv6CBQuQnZ2NpUuX4tatW9i1axcOHTqEwMBAbZTPGGNaxznKdBk/Xc60JiEhASNGjKh3fNasWdi3bx9mz56NnJwcJCQkyF0TGBiItLQ0dOnSBatXr8bs2bM1VzRjjOkQzlGmy3iQyRhjjDHG1I6nyxljjDHGmNrxIJMxxhhjjKkdDzIZY4wxxpja8SCTMcYYY4ypHQ8yGWOMMcaY2vEgkzHGGGOMqR0PMhljjDHGmNrxIJMxxhhjjKkdDzIZY4wxxpja8SCTMcYYY4ypHQ8yGWOMMcaY2vEgkzHGGGOMqd3/Ahsv3h02EKHjAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "X, Y = np.meshgrid(x_high, y_high)\n",
    "ax1.plot_wireframe(X, Y, z.cpu().data.numpy(),color='r')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_zlabel('w')\n",
    "ax1.set_title('SR')\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "X, Y = np.meshgrid(x_high,y_high)\n",
    "ax2.plot_wireframe(X, Y, w_high,color='r')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_zlabel('w')\n",
    "ax2.set_title('high-res')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR L2 Error: 0.0001569370913305863\n"
     ]
    }
   ],
   "source": [
    "error1 = abs(w_high - z.cpu().data.numpy())\n",
    "print('SR L2 Error:', (error1**2).sum()/error1.shape[0]**2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
